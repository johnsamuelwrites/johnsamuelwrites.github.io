<html>

<head>
    <meta charset="utf-8" />
    <title>Apprentissage machine (2022-2023): Cours: John Samuel</title>
    <style type="text/css">
        body {
            height: 100%;
            width: 100%;
            background-color: white;
            margin: 0;
            overflow: hidden;
            font-family: Arial;
        }
        
        .slide {
            height: 100%;
            width: 100%;
        }
        
        .content {
            height: 79%;
            width: 95vw;
            display: flex;
            flex-direction: column;
            color: #000000;
            text-align: left;
            padding-left: 1.5vmax;
            padding-top: 1.5vmax;
            overflow-x: auto;
            font-size: 3vmin;
            flex-wrap: wrap;
        }
        
        .content h1,
        h2,
        h3,
        h4 {
            color: #1B80CF;
        }
        
        .content .topichighlight {
            background-color: #78002E;
            color: #FFFFFF;
        }
        
        .content .topicheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 2vmax 2vmax 0%;
            height: 4vmax;
            line-height: 4vmax;
            padding-left: 1vmax;
            margin: 0.1vmax;
            width: 50%;
        }
        
        .content .flexcontent {
            display: flex;
            overflow-y: auto;
            font-size: 3vmin;
            flex-wrap: wrap;
        }
        
        .content .gridcontent {
            display: grid;
            grid-template-columns: auto auto auto auto;
            grid-column-gap: 0px;
            grid-row-gap: 0px;
            grid-gap: 0px;
        }
        
        .content .topicsubheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 1.5vmax 1.5vmax 0%;
            height: 3vmax;
            margin: 0.1vmax;
            font-size: 90%;
            line-height: 3vmax;
            padding-left: 1vmax;
            width: 40%;
        }
        
        .content table {
            color: #000000;
            font-size: 100%;
            width: 100%;
        }
        
        .content a:link,
        .content a:visited {
            color: #1B80CF;
            text-decoration: none;
        }
        
        .content th {
            color: #FFFFFF;
            background-color: #1B80CF;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
            font-size: 120%;
            padding: 15px;
        }
        
        .content figure {
            max-width: 100%;
            max-height: 100%;
        }
        
        .content figure img {
            display: block;
            margin-left: auto;
            margin-right: auto;
        }
        
        .content figure figcaption {
            max-width: 90%;
            max-height: 90%;
            margin: 0.1vmax;
            font-size: 90%;
            text-align: center;
            padding: 0.5vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }
        
        .content td {
            color: #000000;
            width: 8%;
            padding-left: 3vmax;
            padding-top: 1vmax;
            padding-bottom: 1vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }
        
        .content li {
            line-height: 4vh;
        }
        
        .header {
            color: #ffffff;
            background-color: #00549d;
            height: 5vmax;
        }
        
        .header h1 {
            text-align: center;
            vertical-align: middle;
            font-size: 3vmax;
            line-height: 4vmax;
            margin: 0;
        }
        
        .footer {
            height: 3vmax;
            line-height: 3vmax;
            vertical-align: middle;
            color: #ffffff;
            background-color: #00549d;
            margin: 0;
            padding: .3vmax;
            overflow: hidden;
        }
        
        .footer .contact {
            float: left;
            color: #ffffff;
            text-align: left;
            font-size: 3.2vmin;
        }
        
        .footer .navigation {
            float: right;
            text-align: right;
            width: 8vw;
            font-size: 3vmin;
        }
        
        .footer .navigation .next,
        .prev {
            font-size: 3vmin;
            color: #ffffff;
            text-decoration: none;
        }
        
        .footer .navigation .next::after {
            content: "| >";
        }
        
        .footer .navigation .prev::after {
            content: "< ";
        }
        /* Using same Jupyter CSS
     */
        
        .highlight {
            background: #f8f8f8;
        }
        
        .highlight .c {
            color: #408080;
            font-style: italic
        }
        /* Comment */
        
        .highlight .err {
            border: 1px solid #FF0000
        }
        /* Error */
        
        .highlight .k {
            color: #008000;
            font-weight: bold
        }
        /* Keyword */
        
        .highlight .o {
            color: #666666
        }
        /* Operator */
        
        .highlight .ch {
            color: #408080;
            font-style: italic
        }
        /* Comment.Hashbang */
        
        .highlight .c1 {
            color: #408080;
            font-style: italic
        }
        /* Comment.Single */
        
        .highlight .cs {
            color: #408080;
            font-style: italic
        }
        /* Comment.Special */
        
        .highlight .cm {
            color: #408080;
            font-style: italic
        }
        /* Comment.Multiline */
        
        .highlight .nn {
            color: #0000FF;
            font-weight: bold
        }
        /* Name.Namespace */
        
        .highlight .k {
            color: #008000;
            font-weight: bold
        }
        /* Keyword */
        
        .highlight .s2 {
            color: #BA2121
        }
        /* Literal.String.Double */
        
        .highlight .s1 {
            color: #BA2121
        }
        /* Literal.String.Single */
        
        .highlight .kn {
            color: #008000;
            font-weight: bold
        }
        /* Keyword.Namespace */
        
        .highlight .nb {
            color: #008000
        }
        /* Name.Builtin */
        
        .highlight .mb {
            color: #666666
        }
        /* Literal.Number.Bin */
        
        .highlight .mf {
            color: #666666
        }
        /* Literal.Number.Float */
        
        .highlight .mh {
            color: #666666
        }
        /* Literal.Number.Hex */
        
        .highlight .mi {
            color: #666666
        }
        /* Literal.Number.Integer */
        
        .highlight .mo {
            color: #666666
        }
        /* Literal.Number.Oct */
        
        @media (max-width: 640px),
        screen and (orientation: portrait) {
            body {
                max-width: 100%;
                max-height: 100%;
            }
            .slide {
                height: 100%;
                width: 100%;
            }
            .content {
                width: 100%;
                height: 92%;
                display: flex;
                flex-direction: row;
                text-align: left;
                padding: 1vw;
                line-height: 3.8vmax;
                font-size: 1.8vmax;
                flex-wrap: wrap;
            }
            .content .topicheading {
                width: 90%;
            }
            .content h1,
            h2,
            h3,
            h4 {
                width: 100%;
            }
            .content figure img {
                max-width: 80vmin;
                max-height: 50vmin;
            }
            .content figure figcaption {
                max-width: 90%;
                max-height: 90%;
            }
        }
        
        @media print {
            body {
                max-width: 100%;
                max-height: 100%;
            }
            .content {
                height: 76%;
                width: 90vw;
                display: flex;
                color: #000000;
                text-align: left;
                padding: 5vw;
                font-size: 3vmin;
                flex-wrap: wrap;
            }
            .content figure img {
                max-width: 80%;
                max-height: 80%;
            }
            .content figcaption {
                max-width: 80%;
                max-height: 80%;
            }
        }
    </style>
    <script src="tex-mml-chtml.js" id="MathJax-script"></script>
</head>

<body>
    <section class="slide" id="slide1">
        <div class="header">
        </div>
        <div class="content">
            <h1 style="font-size:2.5vw">Apprentissage machine</h1>
            <p><b>John Samuel</b><br/> CPE Lyon<br/><br/>
                <b>Year</b>: 2022-2023<br/>
                <b>Email</b>: john(dot)samuel(at)cpe(dot)fr<br/><br/>
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="../../../../../en/teaching/courses/2017/C/88x31.png" /></a>
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">1

                <a class="next" href="#slide2"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide2">
        <div class="header">
            <h1>1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1>Intelligence Artificielle [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>La méthode d'apprentissage profond</li>
                <li>les fusions et acquisitions d'entreprises
                    <ul>
                        <li>DNNresearch par Google</li>
                        <li>LinkedIn par Microsoft</li>
                    </ul>
                </li>
                <li>Les chatbots
                    <ul>
                        <li>Xiaobing par Microsoft</li>
                    </ul>
                </li>
                <li>Les programmes de jeux
                    <ul>
                        <li>AlphaGo par Google</li>
                    </ul>
                </li>
                <li>L'utilisation dans les hôpitaux
                    <ul>
                        <li>Watson par IBM</li>
                    </ul>
                </li>
                <li>La compréhension du langage naturel
                    <ul>
                        <li>Baidu</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">2
                <a class="prev" href="#slide1"></a>
                <a class="next" href="#slide3"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide3">
        <div class="header">
            <h1>1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1>Intelligence Artificielle [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>1956: la definition d'IA
                    <ul>
                        <li>Proposée par J. McCarthy, M. L. Minsky, H. Simon, A. Newell, C. E. Shannon, N. Rochester,...</li>
                        <li>La capacité des machines à comprendre, à penser et à apprendre d'une manière similaire à celle des êtres humains, </li>
                    </ul>
                </li>
                <li>1970-2000
                    <ul>
                        <li>1983: le rapport par James Lighthill</li>
                        <li>1982-1992: l'échec du développement d'un ordinateur intelligent par le Japon</li>
                        <li>1984: la construction manuelle d'une encyclopédie de la connaissance (Cyc) par Stanford</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">3
                <a class="prev" href="#slide2"></a>
                <a class="next" href="#slide4"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide4">
        <div class="header">
            <h1>1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1>Intelligence Artificielle 2.0 [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>1990s-présent
                    <ul>
                        <li>Popularité de l'Internet</li>
                        <li>l'utilisation des capteurs
                            <li>Big Data</li>
                            <li>l'e-commerce</li>
                    </ul>
                    </li>
                    <li>Des demandes sociales pour IA
                        <ul>
                            <li>des villes intelligentes</li>
                            <li>médecine</li>
                            <li>transport</li>
                            <li>les automobiles sans conducteur</li>
                            <li>les smartphones</li>
                        </ul>
                    </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">4
                <a class="prev" href="#slide3"></a>
                <a class="next" href="#slide5"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide5">
        <div class="header">
            <h1>1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1>Intelligence Artificielle 2.0 [Pan 2016]</h1>
            <ul>
                <li>les technologies à l'origine de l'IA
                    <ul>
                        <li>L'IA basée sur des données massives (Big Data)</li>
                        <li>L'intelligence de la foule sur Internet</li>
                        <li>Le savoir médiatique croisé</li>
                        <li>L'intelligence hybride homme-machine</li>
                        <li>Systèmes autonomes et intelligents</li>
                    </ul>
                </li>
                <li>L'avenir
                    <ul>
                        <li>L'IA explicative et générique</li>
                        <li>la cognition, l'apprentissage et l'inférence trans-médiatiques.</li>
                        <li>l'intelligence communautaire à partir de l'intelligence des foules basée sur l'intelligence individuelle</li>
                        <li>des systèmes autonomes et intelligents pour le développement de machines et de produits intelligents.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">5
                <a class="prev" href="#slide4"></a>
                <a class="next" href="#slide6"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide6">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Objectifs</h1>
            <figure>
                <img src="../../../../../images/art/courses/deeplearningposition.svg" height="400px" />
                <figcaption>Intelligence artificielle</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">6
                <a class="prev" href="#slide5"></a>
                <a class="next" href="#slide7"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide7">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Objectifs</h1>
            <ol>
                <li>Apprentissage machine</li>
                <li>Apprentissage profond</li>
                <li>Intelligence artificielle</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">7
                <a class="prev" href="#slide6"></a>
                <a class="next" href="#slide8"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide8">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">3 approches</h1>
            <ol>
                <li><b>Apprentissage supervisé</b>: disponibilité des données de formation labellisées</li>
                <li><b>Apprentissage non supervisé</b>: aucune donnée de formation labellisée n'est disponible</li>
                <li><b>Apprentissage semi-supervisé</b>: un petit ensemble de données de formation étiquetées et une grande quantité de données non étiquetées</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">8
                <a class="prev" href="#slide7"></a>
                <a class="next" href="#slide9"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide9">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Formalisation</h1>
            <ul>
                <li><b>Vecteur euclidien</b>: objet géométrique avec magnitude et direction</li>
                <li><b>Espace vectoriel</b>: collection de vecteurs qui peuvent être additionnés et multipliés par des nombres</li>
                <li><b>Vecteur de caractéristiques (features)</b>: vecteur n-dimensionnel</li>
                <li><b>Espace de caractéristiques</b>: Espace vectoriel associé aux vecteurs</li>
            </ul>
            <h3>Exemples de caractéristiques</h3>
            <ul>
                <li><b>Images</b>: les valeurs des pixels.</li>
                <li><b>Textes</b>: Fréquence d'apparition des phrases textuelles.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">9
                <a class="prev" href="#slide8"></a>
                <a class="next" href="#slide10"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide10">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Formalisation</h1>
            <ul>
                <li><b>Construction de caractéristiques<sup>1</sup></b>: construction de nouvelles fonctionnalités à partir de caractéristiques déjà disponibles</li>
                <li><b>Opérateurs de construction pour les caractéristiques</b>
                    <ul>
                        <li>Opérateurs d'égalité, opérateurs arithmétiques, opérateurs de tableau (min, max, moyenne, etc.)...</li>
                    </ul>
                </li>
            </ul>
            <h3>Example</h3>
            <ul>
                <li>Soit <b>Année de naissance</b> et <b>Année de décès</b> deux caractéristiques existantes.</li>
                <li>Une nouvelle caractéristique appelée <b>âge</b> est créée. <b>âge</b> = <b>Année de décès</b> - <b>Année de naissance</b></li>
            </ul>
            <ol style="font-size:2vh">
                <li>https://en.wikipedia.org/wiki/Feature_vector</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">10
                <a class="prev" href="#slide9"></a>
                <a class="next" href="#slide11"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide11">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Formalisation: Apprentissage supervisé</h1>
            <ul>
                <li>Soit \(N\) le nombre d'exemples d'entraînement</li>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>Soit \({(x_1, y_1),...,(x_N, y_N)}\) les \(N\) exemples d'entraînement, où
                    <ul>
                        <li>\(x_i\) est le vecteur de caractéristiques de <i>i<sup>ème</sup></i> exemple d'entraînement.</li>
                        <li>\(y_i\) est son label.</li>
                    </ul>
                </li>
                <li>L'objectif de l'algorithme d'apprentissage supervisé est de trouver \(g: X &#8594; Y\), où
                    <ul>
                        <li><i>g</i> est l'une des fonctions de l'ensemble des fonctions possibles <i>G</i> (espace des hypothèses)</li>
                    </ul>
                </li>
                <li><b>Fonction d'évaluation <i>F</i></b> indiquent l'espace des fonctions d'évaluation, où
                    <ul>
                        <li>\(f: X &#215; Y &#8594; R\) telle que <i>g</i> renvoie la fonction d'évaluation la plus élevée.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">11
                <a class="prev" href="#slide10"></a>
                <a class="next" href="#slide12"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide12">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Formalisation: Apprentissage non supervisé</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>L'objectif de l'algorithme d'apprentissage non supervisé est
                    <ul>
                        <li>trouver la mise en correspondance \(X &#8594; Y\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">12
                <a class="prev" href="#slide11"></a>
                <a class="next" href="#slide13"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide13">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>Soit \({(x_1, y_1),...,(x_l, y_l)}\) l'ensemble d'exemples d'exercices étiquetés</li>
                <li>Soit \({x_{l+1},...,x_{l+u}}\) sont les \(u\) ensembles des vecteurs de caractéristiques non étiquetées de \(X\).</li>
                <li>L'objectif de l'algorithme d'apprentissage semi-supervisé est de faire
                    <ul>
                        <li><b>l'apprentissage transductif</b>, c'est-à-dire trouver des étiquettes correctes pour \({x_{l+1},...,x_{l+u}}\).</li>
                        <li><b>l'apprentissage inductif</b>, c'est-à-dire trouver la bonne mise en correspondance \(X &#8594; Y\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">13
                <a class="prev" href="#slide12"></a>
                <a class="next" href="#slide14"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide14">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicheading">Classification</h1>
            <h1 class="topicsubheading">Définition formelle</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>L'objectif de l'algorithme de classification (ou classificateur) est de trouver \({(x_1, y_1),...,(x_l, y_k)}\), c'est-à-dire l'attribution d'une étiquette connue à chaque vecteur de caractéristique d'entrée, où
                    <ul>
                        <li>\(x_i &#8712; X \)</li>
                        <li>\(y_i &#8712; Y \)</li>
                        <li>\(|X| = l \)</li>
                        <li>\(|Y| = k \)</li>
                        <li>\(l &gt;= k\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">14
                <a class="prev" href="#slide13"></a>
                <a class="next" href="#slide15"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide15">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification</h2>
            <h3 class="topicsubheading">Classificateurs</h3>
            <ul>
                <li>Algorithme de classification</li>
                <li>Deux types de classificateurs:
                    <ul>
                        <li><b>Classificateurs binaires</b> attribue un objet à l'une des deux classes</li>
                        <li><b>Classificateurs multiclasses</b> attribue un objet à une ou plusieurs classes</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">15
                <a class="prev" href="#slide14"></a>
                <a class="next" href="#slide16"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide16">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification binaire</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/binaryclassifier.svg" height="400px" />
                <figcaption>Classification binaire</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">16
                <a class="prev" href="#slide15"></a>
                <a class="next" href="#slide17"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide17">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification</h2>
            <h3 class="topicsubheading">Linear Classificateurs</h3>
            <ul>
                <li>Fonction linéaire attribuant un score à chaque catégorie possible en combinant le vecteur de caractéristiques d'une instance avec un vecteur de poids, en utilisant un produit de points.</li>
                <li>Formalisation :
                    <ul>
                        <li>Soit <i><b>X</b></i> être l'espace de saisie des caractéristiques et <i><b>x</b><sub>i</sub> &#8712; <b>X</b></i></li>
                        <li>Soit <i><b>&#946;</b><sub>k</sub></i> un vecteur de poids pour la catégorie <i>k</i></li>
                        <li><i>score(<b>x</b><sub>i</sub>, k) = <b>x</b><sub>i</sub>.<b>&#946;</b><sub>k</sub></i>, score pour l'attribution de la catégorie <i>k</i> à l'instance <i><b>x</b><sub>i</sub></i>. La catégorie qui donne le score le plus élevé est
                            attribuée à la catégorie de l'instance.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">17
                <a class="prev" href="#slide16"></a>
                <a class="next" href="#slide18"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide18">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/positivenegative.svg" height="400px" />
                <figcaption>Les vrais positifs et les vrais négatifs</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">18
                <a class="prev" href="#slide17"></a>
                <a class="next" href="#slide19"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide19">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" height="400px" />
                <figcaption>Précision et rappel</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">19
                <a class="prev" href="#slide18"></a>
                <a class="next" href="#slide20"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide20">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification</h2>
            <p>Soit</p>
            <ul>
                <li><i>tp</i>: nombre de vrais postifs</li>
                <li><i>fp</i>: nombre de faux positifs</li>
                <li><i>fn</i>: nombre de faux négatifs</li>
            </ul>
            <figure class="gridcontent">
                <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" height="400px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">20
                <a class="prev" href="#slide19"></a>
                <a class="next" href="#slide21"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide21">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification</h2>
            <p>Alors</p>
            <ul>
                <li>Précision \[p = \frac{tp}{(tp + fp)}\]</li>
                <li>Rappel (Recall) \[r = \frac{tp}{(tp + fn)}\]</i>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">21
                <a class="prev" href="#slide20"></a>
                <a class="next" href="#slide22"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide22">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification</h2>
            <ul>
                <li>score F1 est la moyenne harmonique de la précision et du rappel : </li>
                <li>F1-score \[f1 = 2 * \frac{(p * r)}{(p + r)}\]</li>
                <li>F1-score: meilleure valeur à 1 (précision et rappel parfaits) et pire à 0.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">22
                <a class="prev" href="#slide21"></a>
                <a class="next" href="#slide23"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide23">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification</h2>
            <ul>
                <li>\(F_\beta\)-score utilise un facteur réel positif β, où β est choisi de telle sorte que le rappel est considéré comme β fois plus important que la précision, est : </li>
                <li>\(F_\beta\)-score \[F_\beta = (1 + \beta^2) \cdot \frac{\mathrm{p} \cdot \mathrm{r}}{(\beta^2 \cdot \mathrm{p}) + \mathrm{r}}\]</li>
                <li>Exemple: \(F_2\) score</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">23
                <a class="prev" href="#slide22"></a>
                <a class="next" href="#slide24"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide24">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Matrice de confusion</h2>
            <ul>
                <li>une matrice qui mesure la qualité d'un système de classification</li>
                <li>chaque ligne de la matrice représente les instances d'une classe prédite</li>
                <li>chaque colonne représente les instances d'une classe réelle</li>
                <li>Toutes les prédictions correctes sont situées dans la diagonale du tableau</li>
                <li>Les erreurs de prédiction seront représentées par des valeurs situées en dehors de la diagonale.</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/positivenegative.svg" height="200px" />
                <figcaption>Les vrais positifs et les vrais négatifs</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">24
                <a class="prev" href="#slide23"></a>
                <a class="next" href="#slide25"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide25">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Matrice de confusion</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix.png" height="400px" />
                <figcaption>Matrice de confusion pour un classificateur SVM pour les chiffres manuscrits (MNIST)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">25
                <a class="prev" href="#slide24"></a>
                <a class="next" href="#slide26"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide26">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Matrice de confusion</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix1.png" height="400px" />
                <figcaption>Matrice de confusion pour un perceptron pour les chiffres manuscrits (MNIST)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">26
                <a class="prev" href="#slide25"></a>
                <a class="next" href="#slide27"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide27">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification multiclasse</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg" height="400px" />
                <figcaption>Classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">27
                <a class="prev" href="#slide26"></a>
                <a class="next" href="#slide28"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide28">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification</h2>
            <h3 class="topicsubheading">Classification multiclasse [Aly 2005]</h3>
            <ul>
                <li>Transformation en classification binaire
                    <ul>
                        <li>L'approche un contre le reste (Un contre tous)</li>
                        <li>L'approche un-contre-un</li>
                    </ul>
                </li>
                <li>Extension de la classification binaire
                    <ul>
                        <li>Réseaux de neurones</li>
                        <li>k-voisins les plus proches</li>
                    </ul>
                </li>
                <li>la classification hiérarchique.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">28
                <a class="prev" href="#slide27"></a>
                <a class="next" href="#slide29"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide29">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification multiclasse</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg" height="400px" />
                <figcaption>Classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">29
                <a class="prev" href="#slide28"></a>
                <a class="next" href="#slide30"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide30">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">One-vs.-rest (One-vs.-all) strategy</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsall.svg" height="400px" />
                <figcaption>La strategie un-contre le rest pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">30
                <a class="prev" href="#slide29"></a>
                <a class="next" href="#slide31"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide31">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <ul>
                <li>Entraîner un seul classificateur par classe, avec les échantillons de cette classe comme échantillons positifs et tous les autres comme négatifs. </li>
                <li>Chaque classificateur produit un score de confiance réel pour sa décision</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsall.svg" height="300px" />
                <figcaption>La strategie un-contre le rest pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">31
                <a class="prev" href="#slide30"></a>
                <a class="next" href="#slide32"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide32">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <ul>
                <li>Entrées :
                    <ul>
                        <li>\(L\), un apprenant (algorithme d'entraînement pour les classificateurs binaires)</li>
                        <li>échantillons \(X\)</li>
                        <li>étiquettes \(y\), où \(y_i ∈ \{1,..,K \} \) est l'étiquette de l'échantillon \(X_i\)
                    </ul>
                    </li>
                    <li>Sortie :
                        <ul>
                            <li>une liste de classificateurs \(f_k\), où \(k ∈ \{1,..,K \} \)
                        </ul>
                        </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">32
                <a class="prev" href="#slide31"></a>
                <a class="next" href="#slide33"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide33">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <p>Prendre des décisions signifie appliquer tous les classificateurs à un échantillon invisible x et prédire l'étiquette k pour laquelle le classificateur correspondant rapporte le score de confiance le plus élevé : \[\hat{y} = \underset{k \in
                \{1 \ldots K\}}{\arg\!\max}\; f_k(x)\]</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">33
                <a class="prev" href="#slide32"></a>
                <a class="next" href="#slide34"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide34">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">One-vs.-one strategy</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsone.svg" height="400px" />
                <figcaption>La strategie un-contre-un pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">34
                <a class="prev" href="#slide33"></a>
                <a class="next" href="#slide35"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide35">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">One-vs.-one strategy</h3>
            <li>nécessite l'entraînement des \(\frac{K (K - 1)}{2}\) classificateurs binaires</li>
            <li>chaque classificateur reçoit les échantillons d'une paire de classes du jeu de formation original, et doit apprendre à distinguer ces deux classes.</li>
            <li>Au moment de la prédiction, un système de vote est appliqué : tous les \(\frac{K (K - 1)}{2}\) classificateurs sont appliqués à un échantillon non vu et la classe qui a obtenu le plus grand nombre de prédictions est prédite par le classificateur
                combiné.
            </li>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsone.svg" height="200px" />
                <figcaption>La strategie un-contre-un pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">35
                <a class="prev" href="#slide34"></a>
                <a class="next" href="#slide36"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide36">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Réseaux de neurones artificiels</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Colored_neural_network.svg" />
                <figcaption>Réseaux de neurones artificiels</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">36
                <a class="prev" href="#slide35"></a>
                <a class="next" href="#slide37"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide37">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Perceptron</h2>
            <ul>
                <li>Algorithme pour l'apprentissage supervisé des classificateurs binaires</li>
                <li>Le classificateur binaire est un classificateur qui décide si une entrée donnée appartient ou non à une classe particulière</li>
                <li>Inventé en 1958 par Frank Rosenblatt</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">37
                <a class="prev" href="#slide36"></a>
                <a class="next" href="#slide38"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide38">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron</h1>
            <figure>
                <img src="Perceptron_example.svg" height="350px" />
                <figcaption>Perceptron en mettant à jour sa limite linéaire à mesure que d'autres exemples de formation sont ajoutés.<sup>1</sup></figcaption>
            </figure>
            <ol style="font-size:2vh">
                <li>Source: https://en.wikipedia.org/wiki/File:Perceptron_example.svg</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">38
                <a class="prev" href="#slide37"></a>
                <a class="next" href="#slide39"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide39">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Perceptron.svg" height="400px" />
                <figcaption>Perceptron</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">39
                <a class="prev" href="#slide38"></a>
                <a class="next" href="#slide40"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide40">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Perceptron: Définition formelle</h1>
            <ul>
                <li>Soit \(y = f(z)\) la sortie du perceptron pour un vecteur d'entrée <i>z</i></li>
                <li>Soit \(N\) le nombre d'exemples d'entraînement</li>
                <li>Soit <i><b>X</b></i> l'espace de saisie des caractéristiques</li>
                <li>Soit \({(x_{1}, d_{1}),...,(x_{N}, d_{N})}\) be the <i><b>N</b></i> training examples, where
                    <ul>
                        <li>\(x_i\) est le vecteur caractéristique de <i>i<sup>ème</sup></i> exemple d'entraînement.</li>
                        <li>\(d_i\) est la valeur de sortie souhaitée</li>
                        <li>\(x_{j,i}\) est la <i>i<sup>ème</sup></i> caractéristique de <i>j<sup>ème</sup></i> exemple d'entraînement.</li>
                        <li>\(x_{j,0} = 1\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">40
                <a class="prev" href="#slide39"></a>
                <a class="next" href="#slide41"></a>est le taux d'apprentissage.
            </div>
        </div>
    </section>
    <section class="slide" id="slide41">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Perceptron: Définition formelle</h1>
            <ul>
                <li>Les poids sont représentés de la manière suivante:
                    <ul>
                        <li>\(w_i\) est la <i>i<sup>ème</sup></i> valeur du vecteur de poids.</li>
                        <li>\(w_i(t)\) est la <i>i<sup>ème</sup></i> valeur du vecteur de poids à un moment donné t.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">41
                <a class="prev" href="#slide40"></a>
                <a class="next" href="#slide42"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide42">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Perceptron : Étapes</h1>
            <ol>
                <li>Initialiser les poids et les seuils</li>
                <li>Pour chaque exemple, \((x_j, d_j)\) dans l'ensemble d'entraînement<i></i>
                    <ul>
                        <li>Calculer la sortie actuelle : \[y_j(t)= f[w(t).x_j]\] \[= f[w_0(t)x_{j,0} + w_1(t)x_{j,1} + w_2(t)x_{j,2} + \dotsb + w_n(t)x_{j,n}]\]</li>
                        <li>Calculer le poids: \[w_i(t + 1) = w_i(t) + r. (d_j-y_j(t))x_{j,i}\]</li>
                    </ul> \(r\) est le taux d'apprentissage.
                </li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">42
                <a class="prev" href="#slide41"></a>
                <a class="next" href="#slide43"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide43">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Perceptron : Étapes</h1>
            <ol start="3">
                <li>Répétez l'étape 2 jusqu'à l'erreur d'itération \[\frac{1}{s} (&#931; |d_j - y_j(t)|)\] est inférieur au seuil spécifié par l'utilisateur \(\gamma\), ou un nombre prédéterminé d'itérations ont été effectuées, où \(s\) est à nouveau la taille
                    de l'ensemble de l'échantillon.</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">43
                <a class="prev" href="#slide42"></a>
                <a class="next" href="#slide44"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide44">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: fonction d'identité</h2>
            <h4>Équation</h4>
            <p>\[f(x)=x\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=1\]</p>
            <h3></h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_identity.svg" height="380px" />
                <figcaption>Fonction d'identité</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">44
                <a class="prev" href="#slide43"></a>
                <a class="next" href="#slide45"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide45">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Fonction d'activation: pas binaire</h2>
                <h4>Équation</h4>
                <p>\[f(x) = \begin{cases} 0 & \text{for } x
                    < 0\\ 1 & \text{for } x \ge 0 \end{cases} \]</p>
                        <h4>Dérivée</h4>
                        <p>\[f'(x) = \begin{cases} 0 & \text{for } x \ne 0\\ ? & \text{for } x = 0\end{cases}\]</p>
                        <figure>
                            <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_binary_step.svg" height="380px" />
                            <figcaption>Pas binaire</figcaption>
                        </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">45
                <a class="prev" href="#slide44"></a>
                <a class="next" href="#slide46"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide46">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: fonction sigmoïde</h2>
            <h4>Équation</h4>
            <p>\[f(x)=\sigma(x)=\frac{1}{1+e^{-x}}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=f(x)(1-f(x))\]</p>
            <figure>
                <img src="Logistic-curve.svg" height="380px" />
                <figcaption>La fonction sigmoïde</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">46
                <a class="prev" href="#slide45"></a>
                <a class="next" href="#slide47"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide47">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: TanH</h2>
            <h4>Équation</h4>
            <p>\[f(x)=\tanh(x)=\frac{(e^{x} - e^{-x})}{(e^{x} + e^{-x})}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=1-f(x)^2\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_tanh.svg" height="380px" />
                <figcaption>TanH</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">47
                <a class="prev" href="#slide46"></a>
                <a class="next" href="#slide48"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide48">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: Rectified linear unit: ReLU</h2>
            <h4>Équation</h4>
            <p>\[f(x) = \begin{cases} 0 & \text{for } x \le 0\\ x & \text{for } x > 0\end{cases} = \max\{0,x\}= x \textbf{1}_{x>0}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x) = \begin{cases} 0 & \text{for } x \le 0\\ 1 & \text{for } x > 0\end{cases}\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_rectified_linear.svg" height="380px" />
                <figcaption>Unité linéaire rectifiée (ReLU)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">48
                <a class="prev" href="#slide47"></a>
                <a class="next" href="#slide49"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide49">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: Gaussien</h2>
            <h4>Équation</h4>
            <p>\[f(x)=e^{-x^2}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=-2xe^{-x^2}\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_gaussian.svg" height="380px" />
                <figcaption>Gaussien</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">49
                <a class="prev" href="#slide48"></a>
                <a class="next" href="#slide50"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide50">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Perceptron multiclasse</h2>
            <ul>
                <li>Perceptron peut être généralisé à la classification multiclasse. </li>
                <li>Une fonction de représentation d'élément \(f( x , y )\) fait correspondre chaque paire d'entrée/sortie possible à un vecteur d'élément à valeur réelle en dimension finie.</li>
                <li>le vecteur de caractéristique est multiplié par un vecteur de poids \(w\), mais le score obtenu est maintenant utilisé pour choisir parmi de nombreux résultats possibles : \[\hat y = \operatorname{argmax}_y f(x,y) \cdot w.\]</li>
                <li>La réapprentissage se fait par itération sur les exemples, en prédisant un résultat pour chacun, en laissant les poids inchangés lorsque le résultat prédit correspond à l'objectif, et en les modifiant lorsqu'il ne correspond pas. La mise
                    à jour devient : \[w_{t+1} = w_t + f(x, y) - f(x,\hat y)\].</li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">50
                <a class="prev" href="#slide49"></a>
                <a class="next" href="#slide51"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide51">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Neurones biologiques</h2>
            <figure>
                <img src="Neuron3.png" height="350px" />
                <figcaption>Neurone biologique<sup>1</sup></figcaption>
            </figure>
            <ol style="font-size:2vh">
                <li>https://en.wikipedia.org/wiki/File:Neuron3.png</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">51
                <a class="prev" href="#slide50"></a>
                <a class="next" href="#slide52"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide52">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseau de neurones artificiels</h2>
            <ul>
                <li>collection d'unités ou de nœuds connectés, appelés neurones artificiels, qui modèlent vaguement les neurones d'un cerveau biologique.</li>
                <li>Chaque connexion, comme les synapses dans un cerveau biologique, peut transmettre un signal aux autres neurones. </li>
                <li>Un neurone artificiel qui reçoit un signal le traite ensuite et peut signaler les neurones qui lui sont connectés. </li>
                <li> Le "signal" à une connexion est un nombre réel, et la sortie de chaque neurone est calculée par une fonction non linéaire de la somme de ses entrées. </li>
                <li>Les neurones et les arêtes (connexions) ont généralement un poids qui s'ajuste au fur et à mesure de l'apprentissage. </li>
                <li>Le poids augmente ou diminue la force du signal au niveau d'une connexion.</li>
                <li> Les neurones peuvent avoir un seuil tel qu'un signal n'est envoyé que si le signal global franchit ce seuil. </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">52
                <a class="prev" href="#slide51"></a>
                <a class="next" href="#slide53"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide53">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseau de neurones artificiels: les couches</h2>
            <ul>
                <li>Les neurones sont agrégés en couches.</li>
                <li>Différentes couches peuvent effectuer des transformations différentes sur leurs entrées.</li>
                <li>Les signaux passent de la première couche (la couche d'entrée) à la dernière couche (la couche de sortie), éventuellement après avoir traversé les couches plusieurs fois.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">53
                <a class="prev" href="#slide52"></a>
                <a class="next" href="#slide54"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide54">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseau de neurones artificiels: l'entraînement</h2>
            <ul>
                <li>Les réseaux neuronaux apprennent (ou sont entraînés) en traitant des exemples.</li>
                <li>chaque exemple contient une "entrée" et un "résultat" connus.</li>
                <li><b>Erreur</b>: L'entraînement d'un réseau de neurones à partir d'un exemple donné est généralement effectué en déterminant la différence entre la sortie traitée du réseau (souvent une prédiction) et une sortie cible</li>
                <li> Le réseau ajuste ensuite ses associations pondérées en fonction d'une règle d'apprentissage et en utilisant cette valeur d'erreur. </li>
                <li> Des ajustements successifs amèneront le réseau de neurones à produire un résultat de plus en plus similaire au résultat cible.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">54
                <a class="prev" href="#slide53"></a>
                <a class="next" href="#slide55"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide55">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <ul>
                <li>Neurones</li>
                <li>Connexions et poids</li>
                <li>Fonction de propagation</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">55
                <a class="prev" href="#slide54"></a>
                <a class="next" href="#slide56"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide56">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Neurones</h2>
            <ul>
                <li>Chaque neurone artificiel a des entrées et produit une seule sortie qui peut être envoyée à plusieurs autres neurones. </li>
                <li>Les entrées peuvent être les valeurs caractéristiques d'un échantillon de données externes</li>
                <li>Les sorties des neurones de sortie finale du réseau neuronal accomplissent la tâche</li>
                <li><b>Fonction d'activation</b>
                    <ul>
                        <li>Pour trouver la sortie du neurone, nous prenons d'abord la somme pondérée de tous les intrants</li>
                        <li>Nous ajoutons un terme de biais à cette somme. Cette somme pondérée est parfois appelée l'activation.</li>
                        <li>Cette somme est ensuite passée par une fonction d'activation (généralement non linéaire) pour produire le résultat.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">56
                <a class="prev" href="#slide55"></a>
                <a class="next" href="#slide57"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide57">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Connexions et poids</h2>
            <ul>
                <li>Le réseau est constitué de connexions, chaque connexion fournissant la sortie d'un neurone comme entrée à un autre neurone. </li>
                <li>Chaque connexion se voit attribuer un poids qui représente son importance relative</li>
                <li>Un neurone donné peut avoir plusieurs connexions d'entrée et de sortie.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">57
                <a class="prev" href="#slide56"></a>
                <a class="next" href="#slide58"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide58">
        <div class="header">
            <h1>2. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Fonction de propagation</h2>
            <ul>
                <li>La fonction de propagation calcule l'entrée d'un neurone à partir des sorties de ses prédécesseurs et de leurs connexions comme une somme pondérée.</li>
                <li>Un terme de biais peut être ajouté au résultat de la propagation</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">58
                <a class="prev" href="#slide57"></a>
                <a class="next" href="#slide59"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide59">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1>Apprentissage profond</h1>
            <ul>
                <li>Le mot "profond" dans l'apprentissage profond vient de l'utilisation de multiples couches dans le réseau neuronal.</li>
                <li>Un perceptron linéaire ne peut pas être un classificateur universel. Un perceptron "monocouche" ne peut pas mettre en œuvre le XOR</li>
                <li>Les réseaux d'apprentissage en profondeur permettent un nombre illimité de couches de taille limitée</li>
                <li>Il utilise plusieurs couches pour extraire progressivement des caractéristiques de l'entrée brute.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">59
                <a class="prev" href="#slide58"></a>
                <a class="next" href="#slide60"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide60">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <figure>
                <img src="Deep_Learning.jpg" height="450px" />
                <figcaption>Source: https://en.wikipedia.org/wiki/File:Deep_Learning.jpg</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">60
                <a class="prev" href="#slide59"></a>
                <a class="next" href="#slide61"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide61">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation</h2>
            <ul>
                <li>Les neurones sont généralement organisés en plusieurs couches</li>
                <li>Les neurones d'une couche se connectent uniquement aux neurones des couches immédiatement précédente et immédiatement suivante.</li>
                <li>La couche qui reçoit les données externes est la <b>couche d'entrée</b>. </li>
                <li>La couche qui produit le résultat final est la <b>couche de sortie</b>. </li>
                <li>Entre les deux, il y a zéro ou plusieurs couches cachées.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">61
                <a class="prev" href="#slide60"></a>
                <a class="next" href="#slide62"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide62">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation et connectivité</h2>
            <ul>
                <li>Les couches peuvent être <b>entièrement connectées</b>, chaque neurone d'une couche étant connecté à chaque neurone de la couche suivante. </li>
                <li>Les couches peuvent être mis en commun (pooling), c'est-à-dire qu'un groupe de neurones dans une couche se connecte à un seul neurone dans la couche suivante, réduisant ainsi le nombre de neurones dans cette couche</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">62
                <a class="prev" href="#slide61"></a>
                <a class="next" href="#slide63"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide63">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation et connectivité</h2>
            <ul>
                <li>Les réseaux qui permettent des connexions entre les neurones de la même couche ou des couches précédentes sont connus sous le nom de <b>réseaux récurrents</b>.</li>
                <li> les réseaux qui ne permettent pas de cycles entre les couches sont appelés <b>réseaux de neurones en aval</b> (Feedforward neural network)</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">63
                <a class="prev" href="#slide62"></a>
                <a class="next" href="#slide64"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide64">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <ul>
                <li>Un hyperparamètre est un paramètre constant dont la valeur est fixée avant le début du processus d'apprentissage.</li>
                <li>Les valeurs des paramètres sont obtenues par apprentissage.</li>
                <li>Exemples
                    <ul>
                        <li>le taux d'apprentissage</li>
                        <li>le nombre de couches cachées</li>
                        <li>la taille des échantillons.</li>
                        <li>...</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">64
                <a class="prev" href="#slide63"></a>
                <a class="next" href="#slide65"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide65">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <figure>
                <img src="Screenshot_2020-10-20 Tensorflow — Neural Network Playground.png" height="450px" />
                <figcaption>Source: https://playground.tensorflow.org/</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">65
                <a class="prev" href="#slide64"></a>
                <a class="next" href="#slide66"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide66">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow</h2>
            <pre class="codeexample">
            <code>
           from tensorflow.keras.models import Sequential
           from tensorflow.keras.layers import Dense
           from tensorflow.keras.optimizers import SGD

           # Créer un modèle séquentiel
           model = Sequential()
           model.add(Dense(4, activation=&#39;relu&#39;, input_shape=(3,)))
           model.add(Dense(units=2, activation=&#39;softmax&#39;))

           # Compilation du modèle
           sgd = SGD(lr=0.01)
           model.compile(loss=&#39;mean_squared_error&#39;,
                optimizer=sgd,metrics=[&#39;accuracy&#39;])
            </code>
          </pre>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">66
                <a class="prev" href="#slide65"></a>
                <a class="next" href="#slide67"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide67">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <figure>
                <img src="Screenshot_2020-10-20 Tensorflow 2 — Neural Network Playground.png" height="450px" />
                <figcaption>Source: https://playground.tensorflow.org/</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">67
                <a class="prev" href="#slide66"></a>
                <a class="next" href="#slide68"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide68">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicheading">Feedforward neural network</h1>
            <ul>
                <li>Les connexions entre les nœuds ne forment pas un cycle</li>
                <li>Les informations se déplacent des nœuds d'entrée vers les nœuds de sortie, en passant par les nœuds cachés (le cas échéant). </li>
                <li>L'information ne circule que dans un seul sens, vers l'avant</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Feed_forward_neural_net.gif" height="280px" />
                <figcaption>Réseau de neurones en aval</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">68
                <a class="prev" href="#slide67"></a>
                <a class="next" href="#slide69"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide69">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones en aval (Feedforward neural networks)</h1>
            <h1 class="topicsubheading">Perceptron simple couche</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/ArtificialNeuronModel_english.png" height="380px" />
                <figcaption>Perceptron simple couche</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">69
                <a class="prev" href="#slide68"></a>
                <a class="next" href="#slide70"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide70">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones en aval (Feedforward neural networks)</h1>
            <h1 class="topicsubheading">Perceptron multicouche</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/XOR_perceptron_net.png" height="380px" />
                <figcaption>Perceptron multicouche</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">70
                <a class="prev" href="#slide69"></a>
                <a class="next" href="#slide71"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide71">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones en aval (Feedforward neural networks) </h1>
            <h1 class="topicsubheading">Rétropropagation du gradient (Backpropagation)</h1>
            <ul>
                <li>La rétropropagation est une méthode permettant d'ajuster les poids de connexion pour compenser chaque erreur constatée lors de l'apprentissage</li>
                <li>Le montant de l'erreur est effectivement réparti entre les connexions. </li>
                <li>calcule le gradient de la fonction de perte par rapport aux poids du réseau pour un seul exemple d'entrée-sortie.</li>
                <li>fonctionne en calculant le gradient de la fonction de perte par rapport à chaque poids selon la règle de la chaîne</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">71
                <a class="prev" href="#slide70"></a>
                <a class="next" href="#slide72"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide72">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicheading">Réseau de neurones récurrents</h1>
            <ul>
                <li>Un réseau de neurones où les connexions entre les nœuds forment un graphe dirigé le long d'une séquence temporelle, lui permettant de présenter un comportement dynamique temporel. </li>
                <li>Ils peuvent utiliser leur état interne (mémoire) pour traiter des séquences d'entrées de longueur variable</li>
                <li>Applications
                    <ul>
                        <li>la reconnaissance de l'écriture manuscrite</li>
                        <li>la reconnaissance vocale</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">72
                <a class="prev" href="#slide71"></a>
                <a class="next" href="#slide73"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide73">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicheading">Réseau de neurones récurrents</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Recurrent_neural_network_unfold.svg" height="380px" />
                <figcaption>Réseau de neurones récurrents</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">73
                <a class="prev" href="#slide72"></a>
                <a class="next" href="#slide74"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide74">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau récurrent à mémoire court et long terme</h1>
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Long_Short-Term_Memory.svg " height="300px" />
                <figcaption>LSTM</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">74
                <a class="prev" href="#slide73"></a>
                <a class="next" href="#slide75"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide75">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau récurrent à mémoire court et long terme</h1>
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <ul>
                <li>LSTM a des connexions de retour d'information</li>
                <li>Une unité LSTM commune est composée d'une cellule, d'une porte d'entrée, d'une porte de sortie et d'une porte d'oubli.</li>
                <li>La cellule se souvient de valeurs sur des intervalles de temps arbitraires et les trois portes régulent le flux d'informations entrant et sortant de la cellule. </li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Long_Short-Term_Memory.svg " height="200px" />
                <figcaption>LSTM</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">75
                <a class="prev" href="#slide74"></a>
                <a class="next" href="#slide76"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide76">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau récurrent à mémoire court et long terme</h1>
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <ul>
                <li>LSTM a des connexions de retour d'information</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Long_Short-Term_Memory.svg " height="280px" />
                <figcaption>LSTM</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">76
                <a class="prev" href="#slide75"></a>
                <a class="next" href="#slide77"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide77">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1>Réseaux de neurones convolutionnels</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" height="380px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">77
                <a class="prev" href="#slide76"></a>
                <a class="next" href="#slide78"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide78">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1>Réseaux de neurones convolutionnels</h1>
            <ul>
                <li>Analyse des images</li>
                <li>Utilise la convolution, une opération mathématique linéaire</li>
                <li>Une couche d'entrée et une couche de sortie</li>
                <li>Plusieurs couches cachées, constituées de couches convolutives</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">78
                <a class="prev" href="#slide77"></a>
                <a class="next" href="#slide79"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide79">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1>Réseaux de neurones convolutionnels</h1>
            <ul>
                <li>Ils considèrent le modèle hiérarchique des données et assemblent des modèles plus complexes en utilisant des modèles plus petits et plus simples.</li>
                <li>Un réseau neuronal convolutif est constitué d'une couche d'entrée et d'une couche de sortie, ainsi que de plusieurs couches cachées. </li>
                <li>Les couches cachées d'un CNN consistent généralement en une série de couches convolutionnelles qui se convoluent avec une multiplication </li>
                <li> La fonction d'activation est généralement une couche RELU, et est ensuite suivie par des convolutions supplémentaires telles que des couches de regroupement, des couches entièrement connectées et des couches de normalisation</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" height="180px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">79
                <a class="prev" href="#slide78"></a>
                <a class="next" href="#slide80"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide80">
        <div class="header">
            <h1>2. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <h3>Identité</h3>
            <p>
                \( \begin{matrix} \ \ 0 &\ \ 0 &\ \ 0 \\ \ \ 0 &\ \ 1 &\ \ 0 \\ \ \ 0 &\ \ 0 &\ \ 0 \end{matrix} \)
            </p>
            <h3>La détection de contours</h3>
            <p>
                \( \begin{matrix} \ \ 1 & 0 & -1 \\ \ \ 0 & 0 & \ \ 0 \\ -1 & 0 & \ \ 1 \end{matrix} \)
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">80
                <a class="prev" href="#slide79"></a>
                <a class="next" href="#slide81"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide81">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <h3>Box blur</h3>
            <p>
                \( \frac{1}{9} \begin{matrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{matrix} \)
            </p>
            <h3>Flou de Gauss 3 × 3</h3>
            <p>
                \( \frac{1}{16} \begin{matrix} 1 & 2 & 1 \\ 2 & 4 & 2 \\ 1 & 2 & 1 \end{matrix} \)
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">81
                <a class="prev" href="#slide80"></a>
                <a class="next" href="#slide82"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide82">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Convolution matricielle</h2>
            <p>
                \[ \begin{bmatrix} x_{11} & x_{12} & \cdots & x_{1n} \\ x_{21} & x_{22} & \cdots & x_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ x_{m1} & x_{m2} & \cdots & x_{mn} \\ \end{bmatrix} * \begin{bmatrix} y_{11} & y_{12} & \cdots & y_{1n} \\ y_{21} & y_{22}
                & \cdots & y_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ y_{m1} & y_{m2} & \cdots & y_{mn} \\ \end{bmatrix} = \sum^{m-1}_{i=0} \sum^{n-1}_{j=0} x_{(m-i)(n-j)} y_{(1+i)(1+j)} \]
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">82
                <a class="prev" href="#slide81"></a>
                <a class="next" href="#slide83"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide83">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Max pooling</h2>
            <figure>
                <img src="../../2021/DataMining/Max_pooling.png" height="400px" />
                <figcaption>Max pooling avec un filtre 2 × 2 et un pas de 2. (Source: https://commons.wikimedia.org/wiki/File:Max_pooling.png)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">83
                <a class="prev" href="#slide82"></a>
                <a class="next" href="#slide84"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide84">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <pre class="codeexample">
            <code>
import tensorflow as tf

from tensorflow.keras import datasets, layers, models

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

# Créer un modèle séquentiel (réseaux de neurones convolutionnels)
model = models.Sequential()
model.add(layers.<span style="color:red">Conv2D</span>(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.<span style="color:red">MaxPooling2D</span>((2, 2)))
model.add(layers.<span style="color:red">Conv2D</span>(64, (3, 3), activation='relu'))
model.add(layers.<span style="color:red">MaxPooling2D</span>((2, 2)))
model.add(layers.<span style="color:red">Conv2D</span>(64, (3, 3), activation='relu'))
            </code>
          </pre>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">84
                <a class="prev" href="#slide83"></a>
                <a class="next" href="#slide85"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide85">
        <div class="header">
            <h1>3. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <pre class="codeexample">
            <code>
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10)

#Compilation du modèle
model.compile(optimizer='adam',
   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
   metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=10,
   validation_data=(test_images, test_labels))
            </code>
          </pre>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">85
                <a class="prev" href="#slide84"></a>
                <a class="next" href="#slide86"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide86">
        <div class="header">
            <h1>2. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <figure>
                <img src="../DataMining/convolutionalneuralnetwork.png" height="400vh" />
                <figcaption>Modèle: https://www.tensorflow.org/tutorials/images/cnn</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">86
                <a class="prev" href="#slide85"></a>
                <a class="next" href="#slide87"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide87">
        <div class="header">
            <h1>Références</h1>
        </div>
        <div class="content">
            <h1>Articles de recherche</h1>
            <ul>
                <li>[Aly 2005] Aly, Mohamed. Survey on Multiclass Classification Methods. 2005.</li>
                <li>[Jaakkola 2019] Jaakkola, H., et al. “Artificial Intelligence Yesterday, Today and Tomorrow.” 2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO), 2019, pp. 860–67. IEEE
                    Xplore
                </li>
                <li>[Pan 2016] Pan, Yunhe, “Heading toward Artificial Intelligence 2.0.” Engineering, vol. 2, no. 4, Dec. 2016, pp. 409–13. www.sciencedirect.com,</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">87
                <a class="prev" href="#slide86"></a>
                <a class="next" href="#slide88"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide88">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Web</h1>
            <ul>
                <li><a href="https://en.wikipedia.org/wiki/Perceptron">https://en.wikipedia.org/wiki/Perceptron</a></li>
                <li><a href="https://en.wikipedia.org/wiki/Multiclass_classification">https://en.wikipedia.org/wiki/Multiclass_classification</a></li>
                <li><a href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a></li>
                <li><a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">https://en.wikipedia.org/wiki/Multilayer_perceptron</a></li>
                <li><a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a></li>
                <li><a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">https://en.wikipedia.org/wiki/Recurrent_neural_network</a></li>
                <li><a href="https://en.wikipedia.org/wiki/Long_short-term_memory">https://en.wikipedia.org/wiki/Long_short-term_memory</a></li>
                <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html</a></li>
                <li><a href="https://en.wikipedia.org/wiki/Activation_function">https://en.wikipedia.org/wiki/Activation_function</a></li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">88
                <a class="prev" href="#slide87"></a>
                <a class="next" href="#slide89"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide89">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Couleurs</h1>
            <ul>
                <li><a href="https://material.io/color/">Color Tool - Material Design</a></li>
            </ul>
            <h1>Images</h1>
            <ul>
                <li><a href="https://commons.wikimedia.org/">Wikimedia Commons</a></li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">89
                <a class="prev" href="#slide88"></a>
            </div>
        </div>
    </section>

    <script>
        function changeCurrentURLSlideNumber(isIncrement) {
            url = window.location.href;
            position = url.indexOf("#slide");
            if (position != -1) { // Not on the first page
                slideIdString = url.substr(position + 6);
                if (!Number.isNaN(slideIdString)) {
                    slideId = parseInt(slideIdString);
                    if (isIncrement) {
                        if (slideId < 89) {
                            slideId = slideId + 1;
                        }
                    } else {
                        if (slideId > 1) {
                            slideId = slideId - 1;
                        }
                    }
                    /* regexp */
                    url = url.replace(/#slide\d+/g, "#slide" + slideId);
                    window.location.href = url;
                }
            } else {
                window.location.href = url + "#slide2";
            }
        }
        document.onkeydown = function(event) {

            event.preventDefault();
            /* This will ensure the default behavior of
													        page scroll behaviour (up, down, right, left)*/

            event = event || window.event;
            /*Codes de la touche sur le clavier: 37, 38, 39, 40*/
            if (event.keyCode == '37') {
                // left
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '38') {
                // up
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '39') {
                // right
                changeCurrentURLSlideNumber(true);
            } else if (event.keyCode == '40') {
                // down
                changeCurrentURLSlideNumber(true);
            }
        }
        document.body.onmouseup = function(event) {
            event = event || window.event;
            event.preventDefault();
            changeCurrentURLSlideNumber(true);
        }
    </script>
</body>

</html>