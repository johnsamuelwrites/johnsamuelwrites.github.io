<html>

<head>
    <meta charset="utf-8" />
    <title>Apprentissage machine (2024-2025): Cours: John Samuel</title>
    <link rel="shortcut icon" href="../../../../../images/logo/favicon.png" />
    <style type="text/css">
        body {
            height: 100%;
            width: 100%;
            background-color: white;
            margin: 0;
            overflow: hidden;
            font-family: Arial;
        }

        .slide {
            height: 100%;
            width: 100%;
        }

        .content {
            height: 79%;
            width: 95vw;
            display: flex;
            line-height: 1.7em;
            flex-direction: column;
            align-items: flex-start;
            margin: 0 auto;
            color: #000000;
            text-align: left;
            padding-left: 1.5vmax;
            padding-top: 1.5vmax;
            overflow-x: auto;
            font-size: 2.8vmin;
            flex-wrap: wrap;
        }

        .codeexample {
            background-color: #eeeeee;
        }

        /*
generated by Pygments <https://pygments.org/>
Copyright 2006-2023 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
*/
        pre {
            line-height: 125%;
        }

        td.linenos .normal {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        td.linenos .special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos.special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        body .hll {
            background-color: #ffffcc
        }

        body {
            background: #f8f8f8;
        }

        body .c {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment */
        body .err {
            border: 1px solid #FF0000
        }

        /* Error */
        body .k {
            color: #008000;
            font-weight: bold
        }

        /* Keyword */
        body .o {
            color: #666666
        }

        /* Operator */
        body .ch {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Hashbang */
        body .cm {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Multiline */
        body .cp {
            color: #9C6500
        }

        /* Comment.Preproc */
        body .cpf {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.PreprocFile */
        body .c1 {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Single */
        body .cs {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Special */
        body .gd {
            color: #A00000
        }

        /* Generic.Deleted */
        body .ge {
            font-style: italic
        }

        /* Generic.Emph */
        body .gr {
            color: #E40000
        }

        /* Generic.Error */
        body .gh {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Heading */
        body .gi {
            color: #008400
        }

        /* Generic.Inserted */
        body .go {
            color: #717171
        }

        /* Generic.Output */
        body .gp {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Prompt */
        body .gs {
            font-weight: bold
        }

        /* Generic.Strong */
        body .gu {
            color: #800080;
            font-weight: bold
        }

        /* Generic.Subheading */
        body .gt {
            color: #0044DD
        }

        /* Generic.Traceback */
        body .kc {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Constant */
        body .kd {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Declaration */
        body .kn {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Namespace */
        body .kp {
            color: #008000
        }

        /* Keyword.Pseudo */
        body .kr {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Reserved */
        body .kt {
            color: #B00040
        }

        /* Keyword.Type */
        body .m {
            color: #666666
        }

        /* Literal.Number */
        body .s {
            color: #BA2121
        }

        /* Literal.String */
        body .na {
            color: #687822
        }

        /* Name.Attribute */
        body .nb {
            color: #008000
        }

        /* Name.Builtin */
        body .nc {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Class */
        body .no {
            color: #880000
        }

        /* Name.Constant */
        body .nd {
            color: #AA22FF
        }

        /* Name.Decorator */
        body .ni {
            color: #717171;
            font-weight: bold
        }

        /* Name.Entity */
        body .ne {
            color: #CB3F38;
            font-weight: bold
        }

        /* Name.Exception */
        body .nf {
            color: #0000FF
        }

        /* Name.Function */
        body .nl {
            color: #767600
        }

        /* Name.Label */
        body .nn {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Namespace */
        body .nt {
            color: #008000;
            font-weight: bold
        }

        /* Name.Tag */
        body .nv {
            color: #19177C
        }

        /* Name.Variable */
        body .ow {
            color: #AA22FF;
            font-weight: bold
        }

        /* Operator.Word */
        body .w {
            color: #bbbbbb
        }

        /* Text.Whitespace */
        body .mb {
            color: #666666
        }

        /* Literal.Number.Bin */
        body .mf {
            color: #666666
        }

        /* Literal.Number.Float */
        body .mh {
            color: #666666
        }

        /* Literal.Number.Hex */
        body .mi {
            color: #666666
        }

        /* Literal.Number.Integer */
        body .mo {
            color: #666666
        }

        /* Literal.Number.Oct */
        body .sa {
            color: #BA2121
        }

        /* Literal.String.Affix */
        body .sb {
            color: #BA2121
        }

        /* Literal.String.Backtick */
        body .sc {
            color: #BA2121
        }

        /* Literal.String.Char */
        body .dl {
            color: #BA2121
        }

        /* Literal.String.Delimiter */
        body .sd {
            color: #BA2121;
            font-style: italic
        }

        /* Literal.String.Doc */
        body .s2 {
            color: #BA2121
        }

        /* Literal.String.Double */
        body .se {
            color: #AA5D1F;
            font-weight: bold
        }

        /* Literal.String.Escape */
        body .sh {
            color: #BA2121
        }

        /* Literal.String.Heredoc */
        body .si {
            color: #A45A77;
            font-weight: bold
        }

        /* Literal.String.Interpol */
        body .sx {
            color: #008000
        }

        /* Literal.String.Other */
        body .sr {
            color: #A45A77
        }

        /* Literal.String.Regex */
        body .s1 {
            color: #BA2121
        }

        /* Literal.String.Single */
        body .ss {
            color: #19177C
        }

        /* Literal.String.Symbol */
        body .bp {
            color: #008000
        }

        /* Name.Builtin.Pseudo */
        body .fm {
            color: #0000FF
        }

        /* Name.Function.Magic */
        body .vc {
            color: #19177C
        }

        /* Name.Variable.Class */
        body .vg {
            color: #19177C
        }

        /* Name.Variable.Global */
        body .vi {
            color: #19177C
        }

        /* Name.Variable.Instance */
        body .vm {
            color: #19177C
        }

        /* Name.Variable.Magic */
        body .il {
            color: #666666
        }

        /* Literal.Number.Integer.Long */


        .content h1,
        h2,
        h3,
        h4 {
            color: #1B80CF;
        }

        .content .topichighlight {
            background-color: #78002E;
            color: #FFFFFF;
        }

        .content .topicheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 2vmax 2vmax 0%;
            height: 4vmax;
            line-height: 4vmax;
            padding-left: 1vmax;
            margin: 0.1vmax;
            width: 50%;
            margin-bottom: 1vmax;
        }

        .content .flexcontent {
            display: flex;
            overflow-y: auto;
            font-size: 2.8vmin;
            flex-wrap: wrap;
        }

        .content .gridcontent {
            display: grid;
            grid-template-columns: auto auto auto auto;
            grid-column-gap: 0px;
            grid-row-gap: 0px;
            grid-gap: 0px;
        }

        .content .topicsubheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 1.5vmax 1.5vmax 0%;
            height: 3vmax;
            margin: 0.1vmax;
            font-size: 90%;
            line-height: 3vmax;
            padding-left: 1vmax;
            width: 40%;
            margin-bottom: 1vmax;
        }

        .content table {
            color: #000000;
            font-size: 100%;
            width: 100%;
        }

        .content a:link,
        .content a:visited {
            color: #1B80CF;
            text-decoration: none;
        }

        .content th {
            color: #FFFFFF;
            background-color: #1B80CF;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
            font-size: 120%;
            padding: 15px;
        }

        .content figure {
            max-width: 90%;
            max-height: 90%;
        }

        .content .fullwidth img {
            max-width: 90%;
            max-height: 90%;
        }

        .content figure img {
            max-width: 50vmin;
            max-height: 50vmin;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        .content figure figcaption {
            max-width: 90%;
            max-height: 90%;
            margin: 0.1vmax;
            font-size: 90%;
            text-align: center;
            padding: 0.5vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content td {
            color: #000000;
            width: 8%;
            padding-left: 3vmax;
            padding-top: 1vmax;
            padding-bottom: 1vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content li {
            line-height: 1.7em;
        }

        .header {
            color: #ffffff;
            background-color: #00549d;
            height: 5vmax;
        }

        .header h1 {
            text-align: center;
            vertical-align: middle;
            font-size: 3vmax;
            line-height: 4vmax;
            margin: 0;
        }

        .footer {
            height: 3vmax;
            line-height: 3vmax;
            vertical-align: middle;
            color: #ffffff;
            background-color: #00549d;
            margin: 0;
            padding: .3vmax;
            overflow: hidden;
        }

        .footer .contact {
            float: left;
            color: #ffffff;
            text-align: left;
            font-size: 3.2vmin;
        }

        .footer .navigation {
            float: right;
            text-align: right;
            width: 8vw;
            font-size: 3vmin;
        }

        .footer .navigation .next,
        .prev {
            font-size: 3vmin;
            color: #ffffff;
            text-decoration: none;
        }

        .footer .navigation .next::after {
            content: "| >";
        }

        .footer .navigation .prev::after {
            content: "< ";
        }


        @media (max-width: 640px),
        screen and (orientation: portrait) {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .slide {
                height: 100%;
                width: 100%;
            }

            .content {
                width: 100%;
                height: 92%;
                display: flex;
                flex-direction: row;
                text-align: left;
                padding: 1vw;
                line-height: 3.8vmax;
                font-size: 1.8vmax;
                flex-wrap: wrap;
            }

            .content .topicheading {
                width: 90%;
            }

            .content h1,
            h2,
            h3,
            h4 {
                width: 100%;
            }

            .content figure img {
                max-width: 80vmin;
                max-height: 50vmin;
            }

            .content figure figcaption {
                max-width: 90%;
                max-height: 90%;
            }
        }

        @media print {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .content {
                font-size: 2.8vmin;
            }

            .content .flexcontent {
                font-size: 2.5vmin;
            }
        }
    </style>
    <script src="../../2021/MachineLearning/tex-mml-chtml.js" id="MathJax-script"></script>
</head>

<body>
    <section class="slide" id="slide1">
        <div class="header">
        </div>
        <div class="content">
            <h1 style="font-size:2.5vw">Apprentissage machine</h1>
            <p><b>John Samuel</b><br /> CPE Lyon<br /><br />
                <b>Année</b>: 2024-2025<br />
                <b>Courriel</b>: john(dot)samuel(at)cpe(dot)fr<br /><br />
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img
                        alt="Creative Commons License" style="border-width:0"
                        src="../../../../../en/teaching/courses/2017/C/88x31.png" /></a>
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">1

                <a class="next" href="#slide2"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide2">
        <div class="header">
            <h1>A.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Intelligence Artificielle [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>La méthode d'apprentissage profond</li>
                <li>Les fusions et acquisitions d'entreprises
                    <ul>
                        <li>DNNresearch par Google en 2013 [1] : <b>vision par ordinateur</b>.</li>
                        <li>LinkedIn par Microsoft en 2016 [2] : <b>réseaux sociaux professionnels</b>.</li>
                    </ul>
                </li>
                <li>Les chatbots
                    <ul>
                        <li>Xiaobing par Microsoft: « <b>comprendre</b> » et répondre aux questions des utilisateurs en
                            <b>langage naturel</b>.
                        </li>
                    </ul>
                </li>
                <li>Les programmes de jeux
                    <ul>
                        <li>AlphaGo par Google : victoire historique contre le champion du <b>jeu de go</b> Lee Sedol en
                            2016.</li>
                    </ul>
                </li>
                <li>L'utilisation dans les hôpitaux
                    <ul>
                        <li>Watson par IBM : une plateforme d'IA qui a été utilisée dans le domaine de la santé pour
                            aider les professionnels de la santé à <b>analyser et à interpréter des données
                                médicales</b> complexes.</li>
                    </ul>
                </li>
                <li>La compréhension du langage naturel
                    <ul>
                        <li>Baidu : <b>moteur de recherche</b>.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">2
                <a class="prev" href="#slide1"></a>
                <a class="next" href="#slide3"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide3">
        <div class="header">
            <h1>A.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Intelligence Artificielle [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>1956: la definition d'IA
                    <ul>
                        <li><b>La capacité des machines à comprendre, à penser et à apprendre d'une manière similaire à
                                celle des êtres humains</b></li>
                        <li>Proposée par J. McCarthy, M. L. Minsky, H. Simon, A. Newell, C. E. Shannon, N. Rochester,...
                        </li>
                    </ul>
                </li>
                <li>1970-2000
                    <ul>
                        <li>1983: le rapport par James Lighthill : un rapport critiquant la recherche en IA au
                            Royaume-Uni, ce qui a conduit à un <b>ralentissement temporaire des financements publics</b>
                            pour l'IA, connu sous le nom de « <b>l'effet Lighthill</b> ».</li>
                        <li>1982-1992: l'échec du développement d'un <b>ordinateur intelligent</b> par le Japon</li>
                        <li>1984: la <b>construction manuelle d'une encyclopédie</b> de la connaissance (Cyc) par
                            Douglas Lenat à l'Université Stanford. Cyc est un projet d'IA visant à créer une base de
                            connaissances informatisée capable de raisonner et de répondre à des questions complexes.
                        </li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">3
                <a class="prev" href="#slide2"></a>
                <a class="next" href="#slide4"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide4">
        <div class="header">
            <h1>A.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Intelligence Artificielle 2.0 [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>1990s-présent
                    <ul>
                        <li>Popularité de <b>l'Internet</b></li>
                        <li>l'utilisation des <b>capteurs</b></li>
                        <li><b>Big Data</b></li>
                        <li>l'e-commerce</li>
                    </ul>
                </li>
                <li>Des <b>demandes sociales</b> pour IA
                    <ul>
                        <li>des <b>villes intelligentes</b></li>
                        <li>médecine</li>
                        <li>transport</li>
                        <li>les <b>automobiles sans conducteur</b></li>
                        <li>les smartphones</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">4
                <a class="prev" href="#slide3"></a>
                <a class="next" href="#slide5"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide5">
        <div class="header">
            <h1>A.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Intelligence Artificielle 2.0 [Pan 2016]</h1>
            <ul>
                <li>Les technologies à l'origine de l'IA
                    <ul>
                        <li>L'IA basée sur des <b>données massives (Big Data)</b></li>
                        <li><b>L'intelligence de la foule</b> sur Internet</li>
                        <li>Le savoir médiatique croisé</li>
                        <li>L'intelligence hybride homme-machine</li>
                        <li><b>Systèmes autonomes</b> et intelligents</li>
                    </ul>
                </li>
                <li>L'avenir
                    <ul>
                        <li>L'IA <b>explicative et générique</b></li>
                        <li>la cognition, l'apprentissage et l'inférence trans-médiatiques.</li>
                        <li><b>l'intelligence communautaire</b> à partir de l'intelligence des foules basée sur
                            l'intelligence
                            individuelle</li>
                        <li>des systèmes autonomes et intelligents pour le développement de machines et de produits
                            intelligents.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">5
                <a class="prev" href="#slide4"></a>
                <a class="next" href="#slide6"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide6">
        <div class="header">
            <h1>A.2. Introduction à l'apprentissage machine</h1>
        </div>
        <div class="content">
            <p><b>L'apprentissage machine</b>, également connu sous le nom de machine learning (ML), est un domaine de
                l'intelligence artificielle (IA) qui se concentre sur le développement de techniques permettant aux
                ordinateurs d'apprendre à partir de données. L'objectif principal de l'apprentissage machine est de
                permettre aux systèmes informatiques de prendre des décisions ou de réaliser des tâches sans être
                explicitement programmés, en s'appuyant sur des <b>modèles</b> et des <b>motifs appris à partir des
                    données</b>.</p>
            <h4>Principes fondamentaux de l'apprentissage machine</h4>
            <ul>
                <li><b>Données d'entraînement</b> : L'apprentissage machine commence par des données. Ces données,
                    appelées données d'entraînement, sont utilisées pour enseigner au modèle les modèles et les
                    relations dans lesquels il doit identifier.</li>
                <li><b>Modèles</b> : Les modèles en apprentissage machine sont des représentations mathématiques qui
                    capturent les relations entre les différentes caractéristiques des données. Ces modèles sont
                    entraînés à partir des données d'entraînement et sont capables de généraliser pour faire des
                    prédictions sur de nouvelles données non vues.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">6
                <a class="prev" href="#slide5"></a>
                <a class="next" href="#slide7"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide7">
        <div class="header">
            <h1>A.2. Introduction à l'apprentissage machine </h1>
        </div>
        <div class="content">
            <h4>Principes fondamentaux de l'apprentissage machine</h4>
            <ul>
                <li><b>Entraînement et apprentissage</b> : L'entraînement d'un modèle implique de l'exposer aux données
                    d'entraînement, lui permettant d'ajuster ses paramètres pour minimiser les erreurs de prédiction.
                    L'apprentissage se produit lorsque le modèle améliore sa capacité à faire des prédictions précises.
                </li>
                <li><b>Validation et test</b> : Après l'entraînement, le modèle est évalué sur des données de validation
                    et de test pour s'assurer qu'il généralise bien aux données non vues. Cela aide à éviter le
                    surajustement, où le modèle apprend trop spécifiquement les données d'entraînement et ne peut pas
                    généraliser correctement.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">7
                <a class="prev" href="#slide6"></a>
                <a class="next" href="#slide8"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide8">
        <div class="header">
            <h1>A.2.1. Positionnement de l'apprentissage machine</h1>
        </div>
        <div class="content">
            <p>L'apprentissage machine occupe une place centrale dans le paysage technologique actuel et a un impact
                significatif dans divers domaines. </p>
            <ul>
                <li><b>Intelligence Artificielle (IA)</b> : L'apprentissage machine est une composante essentielle de
                    l'intelligence artificielle. Il permet aux systèmes informatiques de tirer des conclusions,
                    d'apprendre à partir d'expériences passées et d'améliorer leur performance sans être explicitement
                    programmés.</li>
                <li><b>Informatique et Technologie</b> : L'apprentissage machine est largement utilisé dans les
                    applications technologiques, y compris la vision par ordinateur, la reconnaissance vocale, la
                    traduction automatique, les chatbots, et diverses autres applications qui exploitent la capacité des
                    modèles à apprendre des données.</li>
                <li><b>Santé</b> : Dans le domaine de la santé, l'apprentissage machine est utilisé pour la prédiction
                    de maladies, l'analyse d'images médicales, la personnalisation des traitements, la découverte de
                    médicaments, et la gestion des dossiers médicaux électroniques.</li>
                <li><b>Finance</b> : Les institutions financières utilisent l'apprentissage machine pour la détection de
                    fraudes, la prévision de tendances du marché, l'analyse de crédit, et l'optimisation des
                    portefeuilles d'investissement.</li>
                <li><b>Industrie</b> : Dans le secteur industriel, l'apprentissage machine est appliqué à la maintenance
                    prédictive, à l'optimisation de la chaîne d'approvisionnement, à la qualité de production, et à la
                    robotique.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">8
                <a class="prev" href="#slide7"></a>
                <a class="next" href="#slide9"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide9">
        <div class="header">
            <h1>A.2.2. Approches de l'apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Approches</h3>
            <ul>
                <li><b>Apprentissage supervisé</b> : Le modèle est entraîné sur un ensemble de données étiquetées où les
                    exemples d'entrée sont associés à des sorties désirées. Le modèle apprend à faire des prédictions
                    sur de nouvelles données en se basant sur ces associations.</li>
                <li><b>Apprentissage non supervisé</b> : Le modèle est exposé à des données non étiquetées et cherche à
                    découvrir des modèles, des structures ou des relations intrinsèques dans les données.</li>
                <li><b>Apprentissage semi-supervisé</b> : Une combinaison des deux précédents, utilisant à la fois des
                    données étiquetées et non étiquetées pour l'entraînement.</li>
                <li><b>Apprentissage par renforcement</b> : Le modèle apprend à prendre des décisions en interagissant
                    avec son environnement. Il reçoit des récompenses ou des pénalités en fonction de ses actions, ce
                    qui guide son apprentissage.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">9
                <a class="prev" href="#slide8"></a>
                <a class="next" href="#slide10"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide10">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation</h3>
            <ul>
                <li><b>Vecteur euclidien</b>:
                    <ul>
                        <li>Un vecteur euclidien est un objet géométrique caractérisé par sa magnitude (longueur) et sa
                            direction. </li>
                        <li>Les vecteurs euclidiens sont couramment utilisés pour représenter des données sous forme de
                            points dans un espace multidimensionnel, où chaque dimension correspond à une
                            caractéristique ou une variable.</li>
                    </ul>
                </li>
                <li><b>Espace vectoriel</b>:
                    <ul>
                        <li>Un espace vectoriel est une collection de vecteurs qui peuvent être additionnés entre eux et
                            multipliés par des nombres (scalaires).</li>
                    </ul>
                </li>
                <li><b>Vecteur de caractéristiques (features)</b>:
                    <ul>
                        <li>Un vecteur de caractéristiques est un vecteur n-dimensionnel qui représente les
                            caractéristiques ou les attributs d'une entité. </li>
                    </ul>
                </li>
                <li><b>Espace de caractéristiques</b>:
                    <ul>
                        <li>L'espace de caractéristiques est l'espace vectoriel associé aux vecteurs de
                            caractéristiques.</li>
                        <li>Chaque dimension de cet espace représente une caractéristique particulière, et les vecteurs
                            sont utilisés pour positionner les données dans cet espace en fonction de leurs
                            caractéristiques.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">10
                <a class="prev" href="#slide9"></a>
                <a class="next" href="#slide11"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide11">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Exemples de caractéristiques</h3>
            <ul>
                <li><b>Images</b>: Dans le contexte des images, les vecteurs de caractéristiques peuvent être construits
                    à partir des valeurs des pixels. Chaque pixel peut être considéré comme une dimension, et un vecteur
                    de caractéristiques contiendra les valeurs de tous les pixels, permettant ainsi de représenter une
                    image sous forme de vecteur.</li>
                <li><b>Textes</b>: Pour les textes, les vecteurs de caractéristiques sont souvent construits à partir de
                    la fréquence d'apparition des mots, des phrases, ou des tokens dans un document. Cela permet de
                    représenter le contenu textuel en utilisant des valeurs numériques, ce qui est essentiel pour
                    l'analyse de texte et la recherche d'informations.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">11
                <a class="prev" href="#slide10"></a>
                <a class="next" href="#slide12"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide12">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation</h1>
            <ul>
                <li><b>Construction de caractéristiques<sup>1</sup></b>:
                    <ul>
                        <li>La construction de caractéristiques consiste à créer de nouvelles variables ou attributs à
                            partir de celles déjà présentes dans les données.</li>
                        <li>Cette étape peut être cruciale pour améliorer les performances des modèles d'apprentissage
                            machine en introduisant des informations pertinentes et en éliminant du bruit.</li>
                    </ul>
                </li>
                <li><b>Opérateurs de construction pour les caractéristiques</b>
                    <ul>
                        <li>Les opérateurs de construction sont des fonctions ou des opérations mathématiques qui
                            permettent de créer de nouvelles caractéristiques à partir de celles existantes. </li>
                        <li>Parmi les opérateurs couramment utilisés, on trouve les opérateurs d'égalité (comparaisons),
                            les opérateurs arithmétiques (addition, soustraction, multiplication, division), les
                            opérateurs de tableau (min, max, moyenne, médiane, etc.), les fonctions de transformation,
                            etc.</li>
                    </ul>
                </li>
            </ul>
            <ol style="font-size:2vh">
                <li>https://en.wikipedia.org/wiki/Feature_vector</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">12
                <a class="prev" href="#slide11"></a>
                <a class="next" href="#slide13"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide13">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Exemple</h3>
            <ul>
                <li>Soit <b>Année de naissance</b> et <b>Année de décès</b> deux caractéristiques existantes.</li>
                <li>Une nouvelle caractéristique appelée <b>âge</b> est créée. <b>âge</b> = <b>Année de décès</b> -
                    <b>Année de naissance</b>
                </li>
            </ul>
            <p>La construction de caractéristiques est une étape essentielle dans le pipeline de prétraitement des
                données en apprentissage machine, car elle peut aider à rendre les données plus informatives pour les
                algorithmes d'apprentissage.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">13
                <a class="prev" href="#slide12"></a>
                <a class="next" href="#slide14"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide14">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <ul>
                    <li><b>Le nombre d'exemples d'entraînement (N)</b> : Cela représente la quantité d'exemples de
                        données que vous avez pour entraîner un modèle supervisé. Chaque exemple d'entraînement se
                        compose d'un vecteur de caractéristiques (x) et de son label (y).</li>
                    <li><b>L'espace de saisie des caractéristiques (X)</b> : C'est l'ensemble de toutes les combinaisons
                        possibles de vecteurs de caractéristiques qui peuvent être utilisées comme entrée pour le
                        modèle. Cet espace est défini par les caractéristiques que vous avez extraites des données.</li>
                    <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble de toutes les
                        valeurs possibles que peuvent prendre les étiquettes ou les labels. </li>
                    <li><b>Exemples d'entraînement (D)</b> : C'est votre ensemble de données d'entraînement, composé de
                        paires (x, y) où x est le vecteur de caractéristiques et y est le label correspondant.</li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">14
                <a class="prev" href="#slide13"></a>
                <a class="next" href="#slide15"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide15">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <ul>
                    <li><b>Objectif de l'algorithme d'apprentissage supervisé</b> : Il s'agit de trouver une fonction
                        (g) qui associe un vecteur de caractéristiques (x) à un label (y). L'ensemble des fonctions
                        possibles est appelé espace des hypothèses (G). L'objectif est de choisir la fonction (g) qui
                        minimise l'erreur de prédiction sur les exemples d'entraînement et généralise bien sur de
                        nouvelles données.</li>
                    <li><b>Fonction d'évaluation (F)</b> : Elle indique l'espace des fonctions d'évaluation utilisées
                        pour évaluer la performance des fonctions hypothétiques. L'objectif est de trouver la fonction
                        (g) qui renvoie la fonction d'évaluation (f) la plus élevée, c'est-à-dire celle qui donne les
                        prédictions les plus précises.</li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">15
                <a class="prev" href="#slide14"></a>
                <a class="next" href="#slide16"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide16">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <p>Cette formalisation est au cœur de l'apprentissage supervisé, où l'objectif est d'apprendre à partir
                    d'exemples étiquetés et de trouver une fonction qui puisse prédire de manière précise les étiquettes
                    pour de nouvelles données non vues.</p>
                <ul>
                    <li>Soit \(N\) le nombre d'exemples d'entraînement</li>
                    <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                    <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                    <li>Soit \({(x_1, y_1),...,(x_N, y_N)}\) les \(N\) exemples d'entraînement, où
                        <ul>
                            <li>\(x_i\) est le vecteur de caractéristiques de <i>i<sup>ème</sup></i> exemple
                                d'entraînement.
                            </li>
                            <li>\(y_i\) est son label.</li>
                        </ul>
                    </li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">16
                <a class="prev" href="#slide15"></a>
                <a class="next" href="#slide17"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide17">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <ul>
                    <li>L'objectif de l'algorithme d'apprentissage supervisé est de trouver \(g: X &#8594; Y\), où
                        <ul>
                            <li><i>g</i> est l'une des fonctions de l'ensemble des fonctions possibles <i>G</i> (espace
                                des
                                hypothèses)</li>
                        </ul>
                    </li>
                    <li><b>Fonction d'évaluation <i>F</i></b> indiquent l'espace des fonctions d'évaluation, où
                        <ul>
                            <li>\(f: X &#215; Y &#8594; R\) telle que <i>g</i> renvoie la fonction d'évaluation la plus
                                élevée.</li>
                        </ul>
                    </li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">17
                <a class="prev" href="#slide16"></a>
                <a class="next" href="#slide18"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide18">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage non supervisé</h1>
            <ul>
                <li><b>L'espace de saisie des caractéristiques (X)</b> : C'est l'ensemble de toutes les combinaisons
                    possibles de vecteurs de caractéristiques qui peuvent être utilisées comme entrée pour le modèle en
                    apprentissage non supervisé. Cet espace est défini par les caractéristiques que vous avez extraites
                    des données.</li>
                <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble des caractéristiques
                    de sortie potentielles. Contrairement à l'apprentissage supervisé, en apprentissage non supervisé, Y
                    ne consiste pas en des étiquettes ou des labels prédéfinis, mais plutôt en des transformations, des
                    représentations, ou des caractéristiques extraites des données d'entrée.</li>
                <li><b>Objectif de l'algorithme d'apprentissage non supervisé</b> : L'objectif est de trouver une
                    correspondance entre l'espace de saisie des caractéristiques (X) et l'espace des caractéristiques de
                    sortie (Y). Cela peut impliquer diverses tâches, telles que la réduction de la dimensionnalité, la
                    classification automatique de données non étiquetées, la détection d'anomalies, la segmentation, ou
                    la représentation latente des données.</li>
                <li><b>Mise en correspondance X → Y</b> : Cette mise en correspondance peut être réalisée de différentes
                    manières, selon la tâche d'apprentissage non supervisé spécifique. Par exemple, dans la réduction de
                    la dimensionnalité, X peut être une représentation à haute dimension des données, tandis que Y
                    représente la version réduite de ces données, souvent avec moins de dimensions.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">18
                <a class="prev" href="#slide17"></a>
                <a class="next" href="#slide19"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide19">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage non supervisé</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>L'objectif de l'algorithme d'apprentissage non supervisé est
                    <ul>
                        <li>trouver la mise en correspondance \(X &#8594; Y\)</li>
                    </ul>
                </li>
            </ul>
            <p>L'apprentissage non supervisé est utilisé pour explorer et découvrir des modèles, des structures ou des
                caractéristiques inhérentes aux données, sans l'utilisation d'étiquettes ou de labels préalables. Il est
                couramment utilisé dans des domaines tels que la clustering, l'analyse de composantes principales (PCA),
                l'analyse en composantes indépendantes (ICA), et bien d'autres.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">19
                <a class="prev" href="#slide18"></a>
                <a class="next" href="#slide20"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide20">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li><b>L'espace de saisie des caractéristiques (X)</b> : Il s'agit de l'ensemble de toutes les
                    combinaisons possibles de vecteurs de caractéristiques qui peuvent être utilisés comme entrée pour
                    le modèle en apprentissage semi-supervisé.</li>
                <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble des caractéristiques
                    de sortie potentielles, mais contrairement à l'apprentissage supervisé, il n'est pas nécessairement
                    constitué d'étiquettes ou de labels prédéfinis.</li>
                <li><b>Ensemble d'exemples d'exercices étiquetés (l)</b> : Cela correspond à un sous-ensemble d'exemples
                    qui ont été annotés ou étiquetés avec des valeurs de sortie connues.</li>
                <li><b>Ensembles des vecteurs de caractéristiques non étiquetées (u)</b> : Il s'agit des exemples non
                    étiquetés, où les valeurs de sortie ne sont pas connues.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">20
                <a class="prev" href="#slide19"></a>
                <a class="next" href="#slide21"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide21">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li><b>Objectif de l'algorithme d'apprentissage semi-supervisé</b> : L'objectif principal est de trouver
                    des étiquettes correctes pour les exemples non étiquetés (apprentissage transductif), ainsi que de
                    trouver la bonne mise en correspondance entre les caractéristiques d'entrée et les caractéristiques
                    de sortie (apprentissage inductif).
                    <ul>
                        <li><b>Apprentissage transductif</b> : Il s'agit de trouver des étiquettes correctes pour les
                            exemples non étiquetés. Cela revient à prédire les valeurs de sortie pour les exemples non
                            étiquetés sans nécessairement chercher à généraliser à de nouvelles données.</li>
                        <li><b>Apprentissage inductif</b> : Cela concerne la recherche de la bonne mise en
                            correspondance entre les vecteurs de caractéristiques d'entrée et les caractéristiques de
                            sortie. Cela peut inclure la généralisation à de nouvelles données en utilisant le modèle
                            appris.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">21
                <a class="prev" href="#slide20"></a>
                <a class="next" href="#slide22"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide22">
        <div class="header">
            <h1>A.2.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>Soit \({(x_1, y_1),...,(x_l, y_l)}\) l'ensemble d'exemples d'exercices étiquetés</li>
                <li>Soit \({x_{l+1},...,x_{l+u}}\) sont les \(u\) ensembles des vecteurs de caractéristiques non
                    étiquetées de \(X\).</li>
                <li>L'objectif de l'algorithme d'apprentissage semi-supervisé est de faire
                    <ul>
                        <li><b>l'apprentissage transductif</b>, c'est-à-dire trouver des étiquettes correctes pour
                            \({x_{l+1},...,x_{l+u}}\).</li>
                        <li><b>l'apprentissage inductif</b>, c'est-à-dire trouver la bonne mise en correspondance \(X
                            &#8594; Y\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">22
                <a class="prev" href="#slide21"></a>
                <a class="next" href="#slide23"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide23">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Classification: Définition formelle</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>L'objectif de l'algorithme de classification (ou classificateur) est de trouver \({(x_1,
                    y_1),...,(x_l, y_k)}\), c'est-à-dire l'attribution d'une étiquette connue à chaque vecteur de
                    caractéristique d'entrée, où
                    <ul>
                        <li>\(x_i &#8712; X \)</li>
                        <li>\(y_i &#8712; Y \)</li>
                        <li>\(|X| = l \)</li>
                        <li>\(|Y| = k \)</li>
                        <li>\(l &gt;= k\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">23
                <a class="prev" href="#slide22"></a>
                <a class="next" href="#slide24"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide24">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classificateurs</h3>
            <ul>
                <li>Algorithme de classification</li>
                <li>Deux types de classificateurs:
                    <ul>
                        <li><b>Classificateurs binaires</b> attribue un objet à l'une des deux classes</li>
                        <li><b>Classificateurs multiclasses</b> attribue un objet à une ou plusieurs classes</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">24
                <a class="prev" href="#slide23"></a>
                <a class="next" href="#slide25"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide25">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Classification binaire</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/binaryclassifier.svg"
                    height="400px" />
                <figcaption>Classification binaire</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">25
                <a class="prev" href="#slide24"></a>
                <a class="next" href="#slide26"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide26">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Linear Classificateurs</h3>
            <ul>
                <li>Fonction linéaire attribuant un score à chaque catégorie possible en combinant le vecteur de
                    caractéristiques d'une instance avec un vecteur de poids, en utilisant un produit de points.</li>
                <li>Formalisation :
                    <ul>
                        <li>Soit <i><b>X</b></i> être l'espace de saisie des caractéristiques et <i><b>x</b><sub>i</sub>
                                &#8712; <b>X</b></i></li>
                        <li>Soit <i><b>&#946;</b><sub>k</sub></i> un vecteur de poids pour la catégorie <i>k</i></li>
                        <li><i>score(<b>x</b><sub>i</sub>, k) = <b>x</b><sub>i</sub>.<b>&#946;</b><sub>k</sub></i>,
                            score pour l'attribution de la catégorie <i>k</i> à l'instance <i><b>x</b><sub>i</sub></i>.
                            La catégorie qui donne le score le plus élevé est
                            attribuée à la catégorie de l'instance.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">26
                <a class="prev" href="#slide25"></a>
                <a class="next" href="#slide27"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide27">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>Dans le contexte de la classification en apprentissage machine, l'évaluation des performances d'un modèle
                implique la compréhension de différents types de prédictions qu'il peut faire par rapport à la réalité.
                Les vrais positifs (VP) et les vrais négatifs (VN) sont deux de ces éléments.</p>
            <ul>
                <li><b>Vrais Positifs (VP/TP)</b> : Les vrais positifs représentent les cas où le modèle prédit
                    correctement la classe positive. En d'autres termes, il a correctement identifié les exemples qui
                    appartiennent réellement à la classe que le modèle essaie de prédire.</li>
                <li><b>Vrais Négatifs (VN/FN)</b> : Les vrais négatifs représentent les cas où le modèle prédit
                    correctement la classe négative. Cela signifie qu'il a correctement identifié les exemples qui
                    n'appartiennent pas à la classe que le modèle essaie de prédire.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">27
                <a class="prev" href="#slide26"></a>
                <a class="next" href="#slide28"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide28">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/positivenegative.svg" width="400vw" />
                <figcaption>Les vrais positifs et les vrais négatifs</figcaption>
            </figure>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" width="400vw" />
                <figcaption>Précision et rappel</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">28
                <a class="prev" href="#slide27"></a>
                <a class="next" href="#slide29"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide29">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>Soit</p>
            <ul>
                <li><i>tp</i>: nombre de vrais postifs</li>
                <li><i>fp</i>: nombre de faux positifs</li>
                <li><i>fn</i>: nombre de faux négatifs</li>
            </ul>
            <figure class="gridcontent">
                <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" height="400px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">29
                <a class="prev" href="#slide28"></a>
                <a class="next" href="#slide30"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide30">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>La <b>précision</b> mesure la proportion de prédictions positives faites par le modèle qui étaient
                <b>effectivement correctes</b>, tandis que le <b>rappel</b> mesure la proportion d'exemples positifs
                réels qui ont été correctement identifiés par le modèle. Alors</p>
            <ul>
                <li>Précision \[p = \frac{tp}{(tp + fp)}\]</li>
                <li>Rappel (Recall) \[r = \frac{tp}{(tp + fn)}\]</i>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">30
                <a class="prev" href="#slide29"></a>
                <a class="next" href="#slide31"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide31">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>Le F1-score est la moyenne harmonique de la précision et du rappel. Il fournit une mesure globale de la
                performance d'un modèle de classification, tenant compte à la fois de la précision et du rappel. Il est
                particulièrement utile lorsque les classes sont déséquilibrées.</p>
            <ul>
                <li>F1-score \[f1 = 2 * \frac{(p * r)}{(p + r)}\]</li>
                <li>F1-score: meilleure valeur à 1 (précision et rappel parfaits) et pire à 0.</li>
            </ul>
            <p>Le F1-score tient compte à la fois des <b>erreurs de type I (faux positifs)</b> et des <b>erreurs de type
                    II (faux négatifs)</b>, fournissant ainsi une mesure équilibrée de la performance du modèle.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">31
                <a class="prev" href="#slide30"></a>
                <a class="next" href="#slide32"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide32">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <ul>
                <li>\(F_\beta\)-score utilise un facteur réel positif β, où β est choisi de telle sorte que le rappel
                    est considéré comme β fois plus important que la précision, est : </li>
                <li>\(F_\beta\)-score \[F_\beta = (1 + \beta^2) \cdot \frac{\mathrm{p} \cdot \mathrm{r}}{(\beta^2 \cdot
                    \mathrm{p}) + \mathrm{r}}\]</li>
                <li>Exemple: <b>\(F_2\) score</b>: Cette métrique est souvent utilisée dans des situations où le rappel
                    est jugé plus critique que la précision, par exemple, dans des tâches où la détection des exemples
                    positifs est particulièrement importante, même si cela entraîne un nombre plus élevé de faux
                    positifs.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">32
                <a class="prev" href="#slide31"></a>
                <a class="next" href="#slide33"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide33">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <p>Le \(F_2\)-score est souvent utilisé dans des domaines où le rappel est considéré comme plus critique que
                la précision. </p>
            <ul>
                <li><b>Détection de Maladies</b> : Dans le domaine médical, en particulier pour la détection de maladies
                    graves, le F2-score peut être utilisé pour évaluer la performance des modèles. Il est crucial
                    d'identifier correctement autant de cas positifs que possible, même si cela conduit à quelques faux
                    positifs.</li>
                <li><b>Sécurité et Détection d'Intrusion</b> : Lors de la détection d'intrusions dans les systèmes
                    informatiques, il est souvent plus important de minimiser les faux négatifs (intrusions manquées) au
                    profit de quelques faux positifs, d'où l'utilisation du F2-score.</li>
                <li><b>Recherche Biomédicale</b> : Dans des domaines de recherche biomédicale où la découverte de
                    certaines caractéristiques ou protéines spécifiques est critique, le F2-score peut être privilégié
                    pour s'assurer que ces éléments sont correctement identifiés.</li>
                <li><b>Prévision de Catastrophes Naturelles</b> : Lors de la prévision de catastrophes naturelles comme
                    les tremblements de terre ou les tsunamis, il est essentiel de minimiser les faux négatifs pour
                    garantir que le maximum d'avertissements est donné, même au prix de quelques alertes erronées.</li>
                <li><b>Recherche en Astronomie</b> : Dans la recherche astronomique, la découverte de nouveaux objets
                    célestes ou de phénomènes rares peut être cruciale. Le F2-score peut être utilisé pour évaluer les
                    performances des algorithmes de détection.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">33
                <a class="prev" href="#slide32"></a>
                <a class="next" href="#slide34"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide34">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Évaluation: matrice de confusion</h2>
            <p>La matrice de confusion est un outil essentiel dans l'évaluation des performances d'un système de
                classification. Elle fournit une vue détaillée des prédictions faites par le modèle par rapport aux
                classes réelles.</p>
            <ul>
                <li>Chaque ligne de la matrice représente les instances d'une classe prédite.</li>
                <li>Chaque colonne représente les instances d'une classe réelle.</li>
                <li>Toutes les prédictions correctes sont situées dans la diagonale du tableau.</li>
                <li>Les erreurs de prédiction sont représentées par des valeurs situées en dehors de la diagonale
                    principale.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">34
                <a class="prev" href="#slide33"></a>
                <a class="next" href="#slide35"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide35">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation: matrice de confusion</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix.png" height="400px" />
                <figcaption>Matrice de confusion pour un classificateur SVM pour les chiffres manuscrits (MNIST)
                </figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">35
                <a class="prev" href="#slide34"></a>
                <a class="next" href="#slide36"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide36">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation: matrice de confusion</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix1.png" height="400px" />
                <figcaption>Matrice de confusion pour un perceptron pour les chiffres manuscrits (MNIST)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">36
                <a class="prev" href="#slide35"></a>
                <a class="next" href="#slide37"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide37">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg"
                    height="400px" />
                <figcaption>Classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">37
                <a class="prev" href="#slide36"></a>
                <a class="next" href="#slide38"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide38">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse [Aly 2005]</h3>
            <ul>
                <li>Transformation en classification binaire
                    <ul>
                        <li>L'approche un contre le reste (Un contre tous)</li>
                        <li>L'approche un-contre-un</li>
                    </ul>
                </li>
                <li>Extension de la classification binaire
                    <ul>
                        <li>Réseaux de neurones</li>
                        <li>k-voisins les plus proches</li>
                    </ul>
                </li>
                <li>la classification hiérarchique.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">38
                <a class="prev" href="#slide37"></a>
                <a class="next" href="#slide39"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide39">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg"
                    height="400px" />
                <figcaption>Classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">39
                <a class="prev" href="#slide38"></a>
                <a class="next" href="#slide40"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide40">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest (One-vs.-all) strategy</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsall.svg" height="350px" />
                <figcaption>La strategie un-contre le rest pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">40
                <a class="prev" href="#slide39"></a>
                <a class="next" href="#slide41"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide41">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <ul>
                <li>Entraîner un seul classificateur par classe, avec les échantillons de cette classe comme
                    échantillons positifs et tous les autres comme négatifs. </li>
                <li>Chaque classificateur produit un score de confiance réel pour sa décision</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsall.svg" height="200px" />
                <figcaption>La strategie un-contre le rest pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">41
                <a class="prev" href="#slide40"></a>
                <a class="next" href="#slide42"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide42">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <ul>
                <li>Entrées :
                    <ul>
                        <li>\(L\), un apprenant (algorithme d'entraînement pour les classificateurs binaires)</li>
                        <li>échantillons \(X\)</li>
                        <li>étiquettes \(y\), où \(y_i ∈ \{1,..,K \} \) est l'étiquette de l'échantillon \(X_i\)
                    </ul>
                </li>
                <li>Sortie :
                    <ul>
                        <li>une liste de classificateurs \(f_k\), où \(k ∈ \{1,..,K \} \)
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">42
                <a class="prev" href="#slide41"></a>
                <a class="next" href="#slide43"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide43">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <p>Prendre des décisions signifie appliquer tous les classificateurs à un échantillon invisible x et prédire
                l'étiquette k pour laquelle le classificateur correspondant rapporte le score de confiance le plus élevé
                : \[\hat{y} = \underset{k \in
                \{1 \ldots K\}}{\arg\!\max}\; f_k(x)\]</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">43
                <a class="prev" href="#slide42"></a>
                <a class="next" href="#slide44"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide44">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-one strategy</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsone.svg" height="300px" />
                <figcaption>La strategie un-contre-un pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">44
                <a class="prev" href="#slide43"></a>
                <a class="next" href="#slide45"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide45">
        <div class="header">
            <h1>A.3. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-one strategy</h3>
            <li>nécessite l'entraînement des \(\frac{K (K - 1)}{2}\) classificateurs binaires</li>
            <li>chaque classificateur reçoit les échantillons d'une paire de classes du jeu de formation original, et
                doit apprendre à distinguer ces deux classes.</li>
            <li>Au moment de la prédiction, un système de vote est appliqué : tous les \(\frac{K (K - 1)}{2}\)
                classificateurs sont appliqués à un échantillon non vu et la classe qui a obtenu le plus grand nombre de
                prédictions est prédite par le classificateur
                combiné.
            </li>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsone.svg" width="200vw" />
                <figcaption>La strategie un-contre-un pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">45
                <a class="prev" href="#slide44"></a>
                <a class="next" href="#slide46"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide46">
        <div class="header">
            <h1>Références</h1>
        </div>
        <div class="content">
            <h1>Articles de recherche</h1>
            <ul>
                <li>[Aly 2005] Aly, Mohamed. Survey on Multiclass Classification Methods. 2005.</li>
                <li>[Jaakkola 2019] Jaakkola, H., et al. “Artificial Intelligence Yesterday, Today and Tomorrow.” 2019
                    42nd International Convention on Information and Communication Technology, Electronics and
                    Microelectronics (MIPRO), 2019, pp. 860–67. IEEE
                    Xplore
                </li>
                <li>[Pan 2016] Pan, Yunhe, “Heading toward Artificial Intelligence 2.0.” Engineering, vol. 2, no. 4,
                    Dec. 2016, pp. 409–13. www.sciencedirect.com,</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">46
                <a class="prev" href="#slide45"></a>
                <a class="next" href="#slide47"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide47">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Web</h1>
            <ol>
                <li>Google acquiert DNNresearch, spécialisé dans les réseaux de neurones profonds: <a
                        href="https://www.lemondeinformatique.fr/actualites/lire-google-acquiert-dnnresearch-specialise-dans-les-reseaux-de-neurones-profonds-52829.html">https://www.lemondeinformatique.fr/actualites/lire-google-acquiert-dnnresearch-specialise-dans-les-reseaux-de-neurones-profonds-52829.html</a>
                </li>
                <li>Pourquoi Microsoft rachète Linkedin: <a
                        href="https://www.lemondeinformatique.fr/actualites/lire-pourquoi-microsoft-rachete-linkedin-65136.html">https://www.lemondeinformatique.fr/actualites/lire-pourquoi-microsoft-rachete-linkedin-65136.html</a>
                </li>
                <li>Scikit-learn: <a href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a></li>
                <li>Perceptron: <a
                        href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html</a>
                </li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">47
                <a class="prev" href="#slide46"></a>
                <a class="next" href="#slide48"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide48">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Wikipédia</h1>
            <ul>
                <li>Perceptron: <a
                        href="https://en.wikipedia.org/wiki/Perceptron">https://en.wikipedia.org/wiki/Perceptron</a>
                </li>
                <li>Multiclass Classification: <a
                        href="https://en.wikipedia.org/wiki/Multiclass_classification">https://en.wikipedia.org/wiki/Multiclass_classification</a>
                </li>
                <li>Multilayer Perceptron: <a
                        href="https://en.wikipedia.org/wiki/Multilayer_perceptron">https://en.wikipedia.org/wiki/Multilayer_perceptron</a>
                </li>
                <li>Feedforward Neural Network: <a
                        href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
                </li>
                <li>Recurrent Neural Network: <a
                        href="https://en.wikipedia.org/wiki/Recurrent_neural_network">https://en.wikipedia.org/wiki/Recurrent_neural_network</a>
                </li>
                <li>Long Short-Term Memory: <a
                        href="https://en.wikipedia.org/wiki/Long_short-term_memory">https://en.wikipedia.org/wiki/Long_short-term_memory</a>
                </li>
                <li>Activation Function: <a
                        href="https://en.wikipedia.org/wiki/Activation_function">https://en.wikipedia.org/wiki/Activation_function</a>
                </li>
                <li>Logique et Raisonnement Mathématique: <a
                        href="https://fr.wikipedia.org/wiki/Logique_et_raisonnement_math%C3%A9matique">https://fr.wikipedia.org/wiki/Logique_et_raisonnement_math%C3%A9matique</a>
                </li>
                <li>Représentation des Connaissances: <a
                        href="https://fr.wikipedia.org/wiki/Repr%C3%A9sentation_des_connaissances">https://fr.wikipedia.org/wiki/Repr%C3%A9sentation_des_connaissances</a>
                </li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">48
                <a class="prev" href="#slide47"></a>
                <a class="next" href="#slide49"></a>
            </div>
        </div>
    </section>

    <section class="slide" id="slide49">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Wikipédia</h1>
            <ul>
                <li>Agent Intelligent: <a
                        href="https://fr.wikipedia.org/wiki/Agent_intelligent">https://fr.wikipedia.org/wiki/Agent_intelligent</a>
                </li>
                <li>Calcul des Propositions: <a
                        href="https://fr.wikipedia.org/wiki/Calcul_des_propositions">https://fr.wikipedia.org/wiki/Calcul_des_propositions</a>
                </li>
                <li>Calcul des Prédicats: <a
                        href="https://fr.wikipedia.org/wiki/Calcul_des_pr%C3%A9dicats">https://fr.wikipedia.org/wiki/Calcul_des_pr%C3%A9dicats</a>
                </li>
                <li>Logique Modale: <a
                        href="https://fr.wikipedia.org/wiki/Logique_modale">https://fr.wikipedia.org/wiki/Logique_modale</a>
                </li>
                <li>Raisonnement Automatisé: <a
                        href="https://fr.wikipedia.org/wiki/Raisonnement_automatis%C3%A9">https://fr.wikipedia.org/wiki/Raisonnement_automatis%C3%A9</a>
                </li>
                <li>Connaissance: <a
                        href="https://fr.wikipedia.org/wiki/Connaissance">https://fr.wikipedia.org/wiki/Connaissance</a>
                </li>
                <li>Gestion des connaissances: <a
                        href="https://fr.wikipedia.org/wiki/Gestion_des_connaissances">https://fr.wikipedia.org/wiki/Gestion_des_connaissances</a>
                </li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">49
                <a class="prev" href="#slide48"></a>
                <a class="next" href="#slide50"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide50">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Couleurs</h1>
            <ul>
                <li><a href="https://material.io/color/">Color Tool - Material Design</a></li>
            </ul>
            <h1>Images</h1>
            <ul>
                <li><a href="https://commons.wikimedia.org/">Wikimedia Commons</a></li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">50
                <a class="prev" href="#slide49"></a>
            </div>
        </div>
    </section>

    <script>
        function changeCurrentURLSlideNumber(isIncrement) {
            url = window.location.href;
            position = url.indexOf("#slide");
            if (position != -1) { // Not on the first page
                slideIdString = url.substr(position + 6);
                if (!Number.isNaN(slideIdString)) {
                    slideId = parseInt(slideIdString);
                    if (isIncrement) {
                        if (slideId < 50) {
                            slideId = slideId + 1;
                        }
                    } else {
                        if (slideId > 1) {
                            slideId = slideId - 1;
                        }
                    }
                    /* regexp */
                    url = url.replace(/#slide\d+/g, "#slide" + slideId);
                    window.location.href = url;
                }
            } else {
                window.location.href = url + "#slide2";
            }
        }
        document.onkeydown = function (event) {

            event.preventDefault();
            /* This will ensure the default behavior of
                                                            page scroll behaviour (up, down, right, left)*/

            event = event || window.event;
            /*Codes de la touche sur le clavier: 37, 38, 39, 40*/
            if (event.keyCode == '37') {
                // left
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '38') {
                // up
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '39') {
                // right
                changeCurrentURLSlideNumber(true);
            } else if (event.keyCode == '40') {
                // down
                changeCurrentURLSlideNumber(true);
            }
        }
        document.body.onmouseup = function (event) {
            event = event || window.event;
            event.preventDefault();
            changeCurrentURLSlideNumber(true);
        }
    </script>
</body>

</html>
