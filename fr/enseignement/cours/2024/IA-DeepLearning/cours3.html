<html>

<head>
    <meta charset="utf-8" />
    <title>Apprentissage profond (2024-2025): John Samuel</title>
    <link rel="shortcut icon" href="../../../../../images/logo/favicon.png" />
    <style type="text/css">
        body {
            height: 100%;
            width: 100%;
            background-color: white;
            margin: 0;
            overflow: hidden;
            font-family: Arial;
        }

        .slide {
            height: 100%;
            width: 100%;
        }

        .content {
            height: 79%;
            width: 95vw;
            display: flex;
            line-height: 1.7em;
            flex-direction: column;
            align-items: flex-start;
            margin: 0 auto;
            color: #000000;
            text-align: left;
            padding-left: 1.5vmax;
            padding-top: 1.5vmax;
            overflow-x: auto;
            font-size: 2.8vmin;
            flex-wrap: wrap;
        }

        .codeexample {
            background-color: #eeeeee;
        }

        /*
generated by Pygments <https://pygments.org/>
Copyright 2006-2023 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
*/
        pre {
            line-height: 125%;
        }

        td.linenos .normal {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        td.linenos .special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos.special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        body .hll {
            background-color: #ffffcc
        }

        body {
            background: #f8f8f8;
        }

        body .c {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment */
        body .err {
            border: 1px solid #FF0000
        }

        /* Error */
        body .k {
            color: #008000;
            font-weight: bold
        }

        /* Keyword */
        body .o {
            color: #666666
        }

        /* Operator */
        body .ch {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Hashbang */
        body .cm {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Multiline */
        body .cp {
            color: #9C6500
        }

        /* Comment.Preproc */
        body .cpf {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.PreprocFile */
        body .c1 {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Single */
        body .cs {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Special */
        body .gd {
            color: #A00000
        }

        /* Generic.Deleted */
        body .ge {
            font-style: italic
        }

        /* Generic.Emph */
        body .gr {
            color: #E40000
        }

        /* Generic.Error */
        body .gh {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Heading */
        body .gi {
            color: #008400
        }

        /* Generic.Inserted */
        body .go {
            color: #717171
        }

        /* Generic.Output */
        body .gp {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Prompt */
        body .gs {
            font-weight: bold
        }

        /* Generic.Strong */
        body .gu {
            color: #800080;
            font-weight: bold
        }

        /* Generic.Subheading */
        body .gt {
            color: #0044DD
        }

        /* Generic.Traceback */
        body .kc {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Constant */
        body .kd {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Declaration */
        body .kn {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Namespace */
        body .kp {
            color: #008000
        }

        /* Keyword.Pseudo */
        body .kr {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Reserved */
        body .kt {
            color: #B00040
        }

        /* Keyword.Type */
        body .m {
            color: #666666
        }

        /* Literal.Number */
        body .s {
            color: #BA2121
        }

        /* Literal.String */
        body .na {
            color: #687822
        }

        /* Name.Attribute */
        body .nb {
            color: #008000
        }

        /* Name.Builtin */
        body .nc {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Class */
        body .no {
            color: #880000
        }

        /* Name.Constant */
        body .nd {
            color: #AA22FF
        }

        /* Name.Decorator */
        body .ni {
            color: #717171;
            font-weight: bold
        }

        /* Name.Entity */
        body .ne {
            color: #CB3F38;
            font-weight: bold
        }

        /* Name.Exception */
        body .nf {
            color: #0000FF
        }

        /* Name.Function */
        body .nl {
            color: #767600
        }

        /* Name.Label */
        body .nn {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Namespace */
        body .nt {
            color: #008000;
            font-weight: bold
        }

        /* Name.Tag */
        body .nv {
            color: #19177C
        }

        /* Name.Variable */
        body .ow {
            color: #AA22FF;
            font-weight: bold
        }

        /* Operator.Word */
        body .w {
            color: #bbbbbb
        }

        /* Text.Whitespace */
        body .mb {
            color: #666666
        }

        /* Literal.Number.Bin */
        body .mf {
            color: #666666
        }

        /* Literal.Number.Float */
        body .mh {
            color: #666666
        }

        /* Literal.Number.Hex */
        body .mi {
            color: #666666
        }

        /* Literal.Number.Integer */
        body .mo {
            color: #666666
        }

        /* Literal.Number.Oct */
        body .sa {
            color: #BA2121
        }

        /* Literal.String.Affix */
        body .sb {
            color: #BA2121
        }

        /* Literal.String.Backtick */
        body .sc {
            color: #BA2121
        }

        /* Literal.String.Char */
        body .dl {
            color: #BA2121
        }

        /* Literal.String.Delimiter */
        body .sd {
            color: #BA2121;
            font-style: italic
        }

        /* Literal.String.Doc */
        body .s2 {
            color: #BA2121
        }

        /* Literal.String.Double */
        body .se {
            color: #AA5D1F;
            font-weight: bold
        }

        /* Literal.String.Escape */
        body .sh {
            color: #BA2121
        }

        /* Literal.String.Heredoc */
        body .si {
            color: #A45A77;
            font-weight: bold
        }

        /* Literal.String.Interpol */
        body .sx {
            color: #008000
        }

        /* Literal.String.Other */
        body .sr {
            color: #A45A77
        }

        /* Literal.String.Regex */
        body .s1 {
            color: #BA2121
        }

        /* Literal.String.Single */
        body .ss {
            color: #19177C
        }

        /* Literal.String.Symbol */
        body .bp {
            color: #008000
        }

        /* Name.Builtin.Pseudo */
        body .fm {
            color: #0000FF
        }

        /* Name.Function.Magic */
        body .vc {
            color: #19177C
        }

        /* Name.Variable.Class */
        body .vg {
            color: #19177C
        }

        /* Name.Variable.Global */
        body .vi {
            color: #19177C
        }

        /* Name.Variable.Instance */
        body .vm {
            color: #19177C
        }

        /* Name.Variable.Magic */
        body .il {
            color: #666666
        }

        /* Literal.Number.Integer.Long */


        .content h1,
        h2,
        h3,
        h4 {
            color: #1B80CF;
        }

        .content .topichighlight {
            background-color: #78002E;
            color: #FFFFFF;
        }

        .content .topicsubheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 2vmax 2vmax 0%;
            height: 4vmax;
            line-height: 4vmax;
            padding-left: 1vmax;
            margin: 0.1vmax;
            width: 50%;
            margin-bottom: 1vmax;
        }

        .content .flexcontent {
            display: flex;
            overflow-y: auto;
            font-size: 2.8vmin;
            flex-wrap: wrap;
        }

        .content .gridcontent {
            display: grid;
            grid-template-columns: auto auto auto auto;
            grid-column-gap: 0px;
            grid-row-gap: 0px;
            grid-gap: 0px;
        }

        .content .topicsubheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 1.5vmax 1.5vmax 0%;
            height: 3vmax;
            margin: 0.1vmax;
            font-size: 90%;
            line-height: 3vmax;
            padding-left: 1vmax;
            width: 40%;
            margin-bottom: 1vmax;
        }

        .content table {
            color: #000000;
            font-size: 100%;
            width: 100%;
        }

        .content a:link,
        .content a:visited {
            color: #1B80CF;
            text-decoration: none;
        }

        .content th {
            color: #FFFFFF;
            background-color: #1B80CF;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
            font-size: 120%;
            padding: 15px;
        }

        .content figure {
            max-width: 90%;
            max-height: 90%;
        }

        .content .fullwidth img {
            max-width: 90%;
            max-height: 90%;
        }

        .content figure img {
            max-width: 50vmin;
            max-height: 50vmin;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        .content figure figcaption {
            max-width: 90%;
            max-height: 90%;
            margin: 0.1vmax;
            font-size: 90%;
            text-align: center;
            padding: 0.5vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content td {
            color: #000000;
            width: 8%;
            padding-left: 3vmax;
            padding-top: 1vmax;
            padding-bottom: 1vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content li {
            line-height: 1.7em;
        }

        .header {
            color: #ffffff;
            background-color: #00549d;
            height: 5vmax;
        }

        .header h1 {
            text-align: center;
            vertical-align: middle;
            font-size: 3vmax;
            line-height: 4vmax;
            margin: 0;
        }

        .footer {
            height: 3vmax;
            line-height: 3vmax;
            vertical-align: middle;
            color: #ffffff;
            background-color: #00549d;
            margin: 0;
            padding: .3vmax;
            overflow: hidden;
        }

        .footer .contact {
            float: left;
            color: #ffffff;
            text-align: left;
            font-size: 3.2vmin;
        }

        .footer .navigation {
            float: right;
            text-align: right;
            width: 8vw;
            font-size: 3vmin;
        }

        .footer .navigation .next,
        .prev {
            font-size: 3vmin;
            color: #ffffff;
            text-decoration: none;
        }

        .footer .navigation .next::after {
            content: "| >";
        }

        .footer .navigation .prev::after {
            content: "< ";
        }


        @media (max-width: 640px),
        screen and (orientation: portrait) {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .slide {
                height: 100%;
                width: 100%;
            }

            .content {
                width: 100%;
                height: 92%;
                display: flex;
                flex-direction: row;
                text-align: left;
                padding: 1vw;
                line-height: 3.8vmax;
                font-size: 1.8vmax;
                flex-wrap: wrap;
            }

            .content .topicsubheading {
                width: 90%;
            }

            .content h1,
            h2,
            h3,
            h4 {
                width: 100%;
            }

            .content figure img {
                max-width: 80vmin;
                max-height: 50vmin;
            }

            .content figure figcaption {
                max-width: 90%;
                max-height: 90%;
            }
        }

        @media print {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .content {
                font-size: 2.8vmin;
            }

            .content .flexcontent {
                font-size: 2.5vmin;
            }
        }
    </style>
    <script src="../../2021/MachineLearning/tex-mml-chtml.js" id="MathJax-script"></script>
</head>

<body>
    <section class="slide" id="slide1">
        <div class="header">
        </div>
        <div class="content">
            <h1 style="font-size:2.5vw">Apprentissage profond</h1>
            <p><b>John Samuel</b><br /> CPE Lyon<br /><br />
                <b>Année</b>: 2024-2025<br />
                <b>Courriel</b>: john(dot)samuel(at)cpe(dot)fr<br /><br />
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img
                        alt="Creative Commons License" style="border-width:0"
                        src="../../../../../en/teaching/courses/2017/C/88x31.png" /></a>
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">1

                <a class="next" href="#slide2"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide2">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron simple couche</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/ArtificialNeuronModel_english.png"
                    height="380px" />
                <figcaption>Perceptron simple couche</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">2
                <a class="prev" href="#slide1"></a>
                <a class="next" href="#slide3"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide3">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron simple couche</h1>
            <p>Le perceptron à simple couche, bien qu'il ait été une avancée significative dans le développement des
                réseaux de neurones artificiels, présente certaines limites importantes qui restreignent sa capacité à
                résoudre des problèmes complexes. Voici quelques-unes des principales limitations du perceptron à simple
                couche :</p>
            <ul>
                <li><b>Linéarité</b> : Le perceptron à simple couche ne peut apprendre que des fonctions linéaires. Il
                    ne peut pas capturer des relations non linéaires complexes dans les données. Les problèmes qui ne
                    peuvent pas être résolus avec des frontières de décision linéaires dépassent les capacités du
                    perceptron à simple couche.</li>
                <li><b>Incapacité à résoudre le problème XOR</b> : L'une des limitations emblématiques du perceptron à
                    simple couche est son incapacité à résoudre le problème XOR (ou des problèmes similaires non
                    linéaires). En raison de sa nature linéaire, il ne peut pas séparer correctement les exemples
                    positifs et négatifs du XOR.</li>
                <li><b>Sensibilité aux données déséquilibrées</b> : Le perceptron à simple couche peut être sensible aux
                    données déséquilibrées, où une classe a significativement plus d'exemples que l'autre. Cela peut
                    conduire à des difficultés lors de l'apprentissage, surtout si la classe minoritaire est mal
                    représentée.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">3
                <a class="prev" href="#slide2"></a>
                <a class="next" href="#slide4"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide4">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron simple couche</h1>
            <ul>
                <li><b>Uniquement pour des tâches de classification binaire</b> : Le perceptron à simple couche est
                    limité à des tâches de classification binaire. Il ne peut pas être directement étendu pour traiter
                    des tâches de classification multiclasse sans des modifications supplémentaires.</li>
                <li><b>Dépendance aux caractéristiques linéaires</b> : Les résultats du perceptron dépendent fortement
                    de la linéarité des caractéristiques. Si les caractéristiques ne sont pas linéaires, le perceptron
                    ne peut pas les exploiter efficacement pour faire des prédictions précises.</li>
                <li><b>Manque de capacité d'apprentissage hiérarchique</b> : Le perceptron à simple couche ne peut pas
                    apprendre des représentations hiérarchiques des données. Les réseaux de neurones profonds, avec
                    plusieurs couches cachées, sont capables de capturer des caractéristiques à différents niveaux
                    d'abstraction.</li>
                <li><b>Sensibilité aux valeurs aberrantes</b> : Le perceptron simple couche peut être sensible aux
                    valeurs aberrantes (outliers) dans les données, ce qui peut affecter négativement ses performances.
                </li>
            </ul>

            <p>Pour surmonter ces limitations, des architectures plus complexes telles que les réseaux de neurones
                profonds avec plusieurs couches cachées ont été développées. Ces réseaux permettent une représentation
                plus riche et non linéaire des données, rendant possible la résolution de problèmes plus complexes.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">4
                <a class="prev" href="#slide3"></a>
                <a class="next" href="#slide5"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide5">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron multicouche</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/XOR_perceptron_net.png"
                    height="380px" />
                <figcaption>Perceptron multicouche</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">5
                <a class="prev" href="#slide4"></a>
                <a class="next" href="#slide6"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide6">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron multicouche</h1>
            <p>Le perceptron multicouche, également appelé réseau de neurones à plusieurs couches, surmonte plusieurs
                des limitations du perceptron à simple couche en introduisant des couches cachées et des fonctions
                d'activation non linéaires.</p>
            <ul>
                <li><b>Capacité à modéliser des relations non linéaires</b> : Contrairement au perceptron à simple
                    couche, le perceptron multicouche est capable de capturer des relations non linéaires complexes dans
                    les données. Les couches cachées et les fonctions d'activation non linéaires permettent d'apprendre
                    des représentations plus riches.</li>
                <li><b>Apprentissage hiérarchique</b> : Le perceptron multicouche a la capacité d'apprendre des
                    représentations hiérarchiques des données. Les différentes couches cachées peuvent extraire des
                    caractéristiques à différents niveaux d'abstraction.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">6
                <a class="prev" href="#slide5"></a>
                <a class="next" href="#slide7"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide7">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron multicouche</h1>
            <ul>
                <li><b>Adaptabilité à des tâches complexes</b> : Il est plus adapté pour des tâches complexes telles que
                    la vision par ordinateur, la reconnaissance vocale, la traduction automatique, etc., où les
                    relations dans les données sont souvent non linéaires.</li>
                <li><b>Gestion de données déséquilibrées</b> : Le perceptron multicouche peut mieux gérer les problèmes
                    de données déséquilibrées en raison de sa capacité à apprendre des représentations complexes.</li>
                <li><b>Tâches de classification multiclasse</b> : Il peut être utilisé pour des tâches de classification
                    multiclasse sans modification majeure.</li>
                <li><b>Adaptabilité à diverses fonctions d'activation</b> : Il peut utiliser différentes fonctions
                    d'activation dans différentes couches, ce qui augmente sa flexibilité pour modéliser des relations
                    complexes.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">7
                <a class="prev" href="#slide6"></a>
                <a class="next" href="#slide8"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide8">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de Neurones Profond</h1>
            <ul>
                <li>Le terme "profond" se réfère à un réseau qui a un grand nombre de couches, généralement plus de
                    trois.</li>
                <li>Ces réseaux sont également appelés "réseaux de neurones profonds" ou "réseaux neuronaux profonds".
                </li>
                <li>Les réseaux de neurones profonds ont été rendus populaires par leurs capacités à apprendre des
                    représentations hiérarchiques complexes.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">8
                <a class="prev" href="#slide7"></a>
                <a class="next" href="#slide9"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide9">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow</h2>
            <div class="highlight">
                <pre><span></span><span class="c1"># Importation des bibliothèques nécessaires de TensorFlow</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>

<span class="c1"># Étape 1: Création d&#39;un modèle séquentiel</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># Étape 2: Ajout d&#39;une couche dense avec une fonction d&#39;activation ReLU</span>
<span class="c1"># La couche a 4 neurones, une fonction d&#39;activation &#39;relu&#39;, et prend une entrée de forme (3,)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)))</span>
</pre>
            </div>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">9
                <a class="prev" href="#slide8"></a>
                <a class="next" href="#slide10"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide10">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow</h2>
            <div class="highlight">
                <pre><span class="c1"># Étape 3: Ajout d&#39;une couche dense de sortie avec une fonction d&#39;activation softmax</span>
<span class="c1"># La couche a 2 neurones pour une tâche de classification binaire, et softmax est utilisé</span>
<span class="c1"># pour obtenir des probabilités</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="c1"># Étape 4: Compilation du modèle</span>
<span class="c1"># Utilisation de la descente de gradient stochastique (SGD) comme optimiseur avec un taux d&#39;apprentissage de 0.01</span>
<span class="c1"># La fonction de perte est &#39;mean_squared_error&#39; pour un problème de régression</span>
<span class="c1"># Les performances du modèle seront mesurées en termes de &#39;accuracy&#39; (précision)</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">sgd</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre>
            </div>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">10
                <a class="prev" href="#slide9"></a>
                <a class="next" href="#slide11"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide11">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <ul>
                <li><b>Étape 1</b>: On crée un modèle séquentiel, qui est une pile linéaire de couches.</li>
                <li><b>Étape 2</b>: On ajoute une couche dense avec 4 neurones utilisant la fonction d'activation ReLU.
                    La couche prend une entrée de forme (3,) - cela signifie que chaque exemple d'entraînement a trois
                    caractéristiques.</li>
                <li><b>Étape 3</b>: On ajoute une couche dense de sortie avec 2 neurones utilisant la fonction
                    d'activation softmax. Cela est couramment utilisé pour les tâches de classification binaire,
                    fournissant des probabilités pour chaque classe.</li>
                <li><b>Étape 4</b>: On compile le modèle en spécifiant l'optimiseur (SGD avec un taux d'apprentissage de
                    0.01), la fonction de perte ('mean_squared_error' pour une tâche de régression), et les métriques de
                    performance ('accuracy' pour mesurer la précision du modèle).</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">11
                <a class="prev" href="#slide10"></a>
                <a class="next" href="#slide12"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide12">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <figure>
                <img src="../../2021/MachineLearning/Screenshot_2020-10-20 Tensorflow — Neural Network Playground.png"
                    height="450px" />
                <figcaption>Source: https://playground.tensorflow.org/</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">12
                <a class="prev" href="#slide11"></a>
                <a class="next" href="#slide13"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide13">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <figure>
                <img src="../../2021/MachineLearning/Screenshot_2020-10-20 Tensorflow 2 — Neural Network Playground.png"
                    height="450px" />
                <figcaption>Source: https://playground.tensorflow.org/</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">13
                <a class="prev" href="#slide12"></a>
                <a class="next" href="#slide14"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide14">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation</h2>
            <p>Un réseau de neurones profond est une architecture complexe où l'information circule de la couche
                d'entrée à travers les couches cachées jusqu'à la couche de sortie. Chaque connexion entre les neurones
                est associée à un poids qui est ajusté pendant le processus d'apprentissage pour optimiser les
                performances du modèle sur la tâche spécifique. L'utilisation de plusieurs couches cachées permet au
                réseau d'apprendre des représentations de plus en plus abstraites et complexes des données.</p>
            <ul>
                <li><b>Organisation en plusieurs couches</b> : Un réseau de neurones profond est structuré en plusieurs
                    couches, généralement composées d'une couche d'entrée, de plusieurs couches cachées et d'une couche
                    de sortie. Chaque couche est composée de neurones, également appelés nœuds ou unités.</li>
                <li><b>Connexions entre les neurones</b> : Les neurones d'une couche sont connectés aux neurones de la
                    couche immédiatement précédente et de la couche immédiatement suivante. Chaque connexion est
                    associée à un poids qui est ajusté pendant l'apprentissage.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">14
                <a class="prev" href="#slide13"></a>
                <a class="next" href="#slide15"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide15">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation</h2>
            <ul>
                <li><b>Couche d'entrée</b> : La couche d'entrée est la première couche du réseau. Elle reçoit les
                    données externes, souvent représentées par des caractéristiques d'un ensemble de données. Chaque
                    neurone dans la couche d'entrée correspond à une caractéristique spécifique.</li>
                <li><b>Couche de sortie</b> : La couche de sortie est la dernière couche du réseau. Elle produit le
                    résultat final du modèle en fonction de la tâche spécifique, telle que la classification d'une
                    image, la prédiction d'une valeur, etc. Le nombre de neurones dans cette couche dépend du type de
                    problème (par exemple, un neurone pour chaque classe dans une tâche de classification).</li>
                <li><b>Couches cachées</b> : Entre la couche d'entrée et la couche de sortie, il peut y avoir zéro ou
                    plusieurs couches cachées. Ces couches sont responsables de l'extraction de caractéristiques
                    complexes à partir des données d'entrée. Chaque neurone dans une couche cachée combine les
                    informations des neurones de la couche précédente pour apprendre des représentations hiérarchiques.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">15
                <a class="prev" href="#slide14"></a>
                <a class="next" href="#slide16"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide16">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation et connectivité</h2>
            <p><b>Connectivité entièrement connectée</b>: Dans une connectivité entièrement connectée, chaque neurone
                d'une couche est connecté à chaque neurone de la couche suivante. Cela signifie que toutes les
                informations de la couche précédente sont transmises à chaque neurone de la couche suivante. C'est la
                configuration la plus courante dans les couches totalement connectées, généralement présentes dans les
                parties du réseau proches de la sortie.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">16
                <a class="prev" href="#slide15"></a>
                <a class="next" href="#slide17"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide17">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation et connectivité</h2>
            <p><b>Connectivité par le biais de la mise en commun (Pooling)</b></p>
            <ul>
                <li>Le pooling est une opération souvent utilisée pour réduire la dimension des cartes de
                    caractéristiques tout en préservant les informations essentielles. Dans le contexte de la
                    connectivité, un groupe de neurones dans une couche peut être connecté à un seul neurone dans la
                    couche suivante.</li>
                <li>Il existe différents types de pooling, comme le <b>pooling max</b> et le <b>pooling moyen</b>. Dans
                    le pooling max, par exemple, chaque groupe de neurones transmet uniquement l'activation maximale à
                    un neurone dans la couche suivante. Cela réduit le nombre de neurones, ce qui peut être utile pour
                    la gestion de la complexité computationnelle et la réduction du surapprentissage.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">17
                <a class="prev" href="#slide16"></a>
                <a class="next" href="#slide18"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide18">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation et connectivité</h2>
            <p><b>Réseaux de Neurones en Aval (Feedforward Neural Networks) :</b></p>
            <ul>
                <li>Les réseaux de neurones en aval, également appelés réseaux feedforward, <b>ne permettent pas de
                        cycles entre les couches</b>. L'information circule dans une seule direction, de la couche
                    d'entrée à la couche de sortie, sans boucles récurrentes. Chaque couche traite indépendamment les
                    données et transmet les résultats à la couche suivante.</li>
                <li>Ces réseaux sont couramment utilisés pour des tâches où les données peuvent être <b>traitées de
                        manière indépendante</b>, comme la classification d'images, la reconnaissance vocale, etc.</li>
            </ul>
            <p>Les réseaux de neurones en aval, sont plus adaptés à des tâches où chaque exemple de données peut être
                traité de manière indépendante.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">18
                <a class="prev" href="#slide17"></a>
                <a class="next" href="#slide19"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide19">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation et connectivité</h2>
            <p><b>Réseaux Récurrents</b></p>
            <ul>
                <li>Les réseaux récurrents permettent des connexions entre les neurones de la même couche ou des couches
                    précédentes. Cela signifie qu'ils ont des <b>boucles ou des connexions récurrentes</b>, permettant
                    aux informations de circuler à travers le réseau de manière répétée. Ces connexions récurrentes
                    permettent aux réseaux récurrents de prendre en compte les séquences et les dépendances temporelles
                    dans les données.</li>
                <li>Les réseaux récurrents sont souvent utilisés pour traiter des <b>données séquentielles</b> telles
                    que des séquences temporelles, des phrases dans le traitement du langage naturel (NLP), etc.</li>
            </ul>
            <p>La connectivité récurrente dans les réseaux récurrents permet aux informations de persister et d'être
                mises à jour à chaque itération ou pas de temps, ce qui les rend adaptés à des tâches séquentielles.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">19
                <a class="prev" href="#slide18"></a>
                <a class="next" href="#slide20"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide20">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <p>Les hyperparamètres sont des paramètres constants dont <b>la valeur est fixée avant le début du processus
                    d'apprentissage</b> d'un réseau de neurones artificiels. Contrairement aux paramètres du modèle, qui
                sont appris pendant l'entraînement, les hyperparamètres sont des choix de conception qui influencent la
                manière dont le modèle est formé. Voici quelques exemples d'hyperparamètres couramment utilisés dans les
                réseaux de neurones :</p>
            <ol>
                <li><b>Taux d'apprentissage</b> : Le taux d'apprentissage contrôle la taille des pas que l'algorithme
                    d'optimisation prend pour ajuster les poids du modèle. Un taux d'apprentissage trop élevé peut
                    entraîner une convergence rapide mais peut sauter le minimum global, tandis qu'un taux
                    d'apprentissage trop bas peut rendre l'apprentissage lent ou susceptible de rester coincé dans des
                    minima locaux.</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">20
                <a class="prev" href="#slide19"></a>
                <a class="next" href="#slide21"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide21">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <ol start="2">
                <li><b>Nombre de couches cachées</b> : Le nombre de couches cachées dans le réseau de neurones est un
                    choix de conception important. Il influe sur la capacité du modèle à apprendre des représentations
                    complexes. Un modèle avec plus de couches cachées peut capturer des caractéristiques plus
                    abstraites, mais cela peut également augmenter la complexité du modèle et entraîner un
                    surapprentissage.</li>
                <li><b>Taille des échantillons (Batch Size)</b> : La taille des échantillons détermine le nombre
                    d'exemples d'entraînement utilisés pour mettre à jour les poids du modèle à chaque itération. Un
                    choix judicieux de la taille des échantillons peut influencer l'efficacité de l'entraînement et la
                    stabilité du modèle.</li>
                <li><b>Fonction d'activation</b> : La fonction d'activation est utilisée pour introduire de la
                    non-linéarité dans le modèle. Des choix courants incluent ReLU, Sigmoid, et Tanh. Le choix de la
                    fonction d'activation peut affecter la capacité du modèle à apprendre des relations complexes.</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">21
                <a class="prev" href="#slide20"></a>
                <a class="next" href="#slide22"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide22">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <ol start="5">
                <li><b>Régularisation</b> : Les techniques de régularisation, telles que la régularisation L1 ou L2,
                    ajoutent des termes de pénalité aux poids du modèle pour prévenir le surapprentissage. Le choix et
                    la force de la régularisation sont des hyperparamètres importants.</li>
                <li><b>Nombre de neurones par couche</b> : Le nombre de neurones dans chaque couche, en particulier dans
                    les couches cachées, influence la capacité du modèle à apprendre des représentations spécifiques. Un
                    choix judicieux peut aider à contrôler la complexité du modèle.</li>
                <li><b>Optimiseur (Optimizer)</b> : L'algorithme d'optimisation qui ajuste les poids du réseau lors de
                    la rétropropagation. Des exemples incluent SGD, Adam, RMSprop.</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">22
                <a class="prev" href="#slide21"></a>
                <a class="next" href="#slide23"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide23">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <ol start="8">
                <li><b>Initialisation des poids</b> : Méthode utilisée pour initialiser les poids du réseau avant
                    l'entraînement. Des méthodes courantes incluent l'initialisation aléatoire et l'initialisation
                    Xavier/Glorot.</li>
                <li><b>Fonction de perte (Loss Function)</b> : La fonction qui mesure la différence entre les
                    prédictions du modèle et les vraies valeurs. Elle guide l'ajustement des poids lors de
                    l'entraînement.</li>
                <li><b>Taux de drop-out (Dropout Rate)</b> : Le nombre de fois que l'ensemble de données complet est
                    passé à travers le réseau pendant l'entraînement.</li>
                <li><b>Nombre d'époques (Epochs)</b> : Le nombre de neurones dans chaque couche, en particulier dans les
                    couches cachées, influence la capacité du modèle à apprendre des représentations spécifiques. Un
                    choix judicieux peut aider à contrôler la complexité du modèle.</li>
                <li><b>Moments (Momentum)</b> : Paramètre qui accélère l'optimisation en ajoutant une fraction de
                    l'itération précédente au poids actuel lors de la mise à jour.</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">23
                <a class="prev" href="#slide22"></a>
                <a class="next" href="#slide24"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide24">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <ol start="13">
                <li><b>Taille de la fenêtre de convolution (Convolutional Window Size) </b> : Pour les réseaux de
                    neurones convolutifs (CNN), la taille de la fenêtre utilisée pour la convolution.</li>
                <li><b>Pas de la fenêtre de convolution (Convolutional Stride) :</b> : Le nombre d'unités entre chaque
                    opération de convolution dans un CNN.</li>
                <li><b>Taille de la fenêtre de pooling (Pooling Window Size) :</b> : Pour les CNN, la taille de la
                    fenêtre utilisée pour l'opération de pooling.</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">24
                <a class="prev" href="#slide23"></a>
                <a class="next" href="#slide25"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide25">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <ol start="16">
                <li><b>Arrêt anticipé (Early Stopping)</b> : Une technique qui consiste à arrêter l'entraînement du
                    modèle dès que la performance sur un ensemble de validation cesse de s'améliorer, afin d'éviter le
                    surajustement.</li>
                <li><b>Répartition Entraînement vs. Validation (Training vs. Validation Split)</b> : La division de
                    l'ensemble de données en ensembles distincts d'entraînement et de validation pour évaluer les
                    performances du modèle pendant l'entraînement.</li>
                <li><b>Augmentation de données (Data Augmentation)</b> : La création de nouvelles données d'entraînement
                    en appliquant des transformations telles que la rotation, le redimensionnement, le décalage, etc.,
                    pour augmenter la diversité de l'ensemble de données.</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">25
                <a class="prev" href="#slide24"></a>
                <a class="next" href="#slide26"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide26">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <ol start="19">
                <li><b>Prétraitement des données (Data Preprocessing)</b> : Les transformations appliquées aux données
                    d'entrée avant de les fournir au réseau, telles que la normalisation, la standardisation, le
                    redimensionnement, etc.</li>
                <li><b>Modèles pré-entraînés (Pretrained Models)</b> : L'utilisation de modèles déjà entraînés sur de
                    grandes bases de données (comme ImageNet pour les modèles de vision par ordinateur) comme point de
                    départ pour des tâches spécifiques.</li>
            </ol>
            <p>Le réglage judicieux de ces hyperparamètres est souvent crucial pour obtenir des performances optimales
                d'un modèle de réseau de neurones. Il implique souvent des expérimentations et des ajustements itératifs
                pour trouver la combinaison optimale pour une tâche d'apprentissage spécifique.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">26
                <a class="prev" href="#slide25"></a>
                <a class="next" href="#slide27"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide27">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <table>
                <tr>
                    <th>Réseaux</th>
                    <th>Nombre de couches</th>
                </tr>
                <tr>
                    <td>AlexNet</td>
                    <td>8</td>
                </tr>
                <tr>
                    <td>VGGNet</td>
                    <td>16</td>
                </tr>
                <tr>
                    <td>InceptionNet</td>
                    <td>27</td>
                </tr>
                <tr>
                    <td>GoogleNet</td>
                    <td>22</td>
                </tr>
                <tr>
                    <td>ResNet</td>
                    <td>50, 101, 152, 200, 345</td>
                </tr>
                <tr>
                    <td>DenseNet</td>
                    <td>121, 169, 201</td>
                </tr>
                <tr>
                    <td>MobileNetV2</td>
                    <td>13, 16, 23</td>
                </tr>
            </table>

        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">27
                <a class="prev" href="#slide26"></a>
                <a class="next" href="#slide28"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide28">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <h4>Fonctions d'activation pour les réseaux de neurones profonds</h4>
            <p><b>ReLU (Rectified Linear Unit)</b> :La fonction ReLU est largement utilisée en raison de sa simplicité
                et de sa capacité à introduire une non-linéarité. Elle remplace les valeurs négatives par zéro,
                permettant au réseau d'apprendre des représentations complexes.
                \[f(x) = \max(0, x)\]
            </p>

            <p><b>Sigmoid</b> : Souvent utilisée en couche de sortie pour les problèmes de classification binaire, car
                elle ramène les valeurs à l'intervalle [0, 1], pouvant être interprétées comme des probabilités.
                \[f(x) = \frac{1}{1 + e^{-x}}\]
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">28
                <a class="prev" href="#slide27"></a>
                <a class="next" href="#slide29"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide29">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <h4>Fonctions d'activation pour les réseaux de neurones profonds</h4>
            <p><b>Tanh (Tangente hyperbolique)</b> : Similaire à la fonction sigmoïde, mais ramène les valeurs à
                l'intervalle [-1, 1]. Elle est souvent utilisée en tant que fonction d'activation pour les couches
                cachées.
                \[f(x) = \frac{e^{2x} - 1}{e^{2x} + 1}\]
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">29
                <a class="prev" href="#slide28"></a>
                <a class="next" href="#slide30"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide30">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <h4>Fonctions d'activation pour les réseaux de neurones profonds</h4>
            <p><b>Softmax</b> : Principalement utilisée en couche de sortie pour les problèmes de classification
                multiclasse. Elle transforme les scores en probabilités.
                \[f(x)_i = \frac{e^{x_i}}{\sum_{j}e^{x_j}}\] pour chaque \(i\)-ème élément du vecteur \(x\)
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">30
                <a class="prev" href="#slide29"></a>
                <a class="next" href="#slide31"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide31">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <h4>Fonctions d'activation pour les réseaux de neurones convolutifs (CNN)</h4>
            <ul>
                <li><b>ReLU (Rectified Linear Unit)</b> : La fonction ReLU est également largement utilisée dans les CNN
                    en raison de sa non-linéarité et de sa facilité de calcul</li>
                <li><b>Leaky ReLU</b> : Une variation de ReLU qui permet un petit gradient pour les valeurs négatives,
                    aidant à atténuer certains problèmes liés à ReLU (neuron death).
                    \[f(x) = \max(\alpha x, x)\] avec \(\alpha > 0\) (un petit coefficient)</li>

                <li><b>Sigmoid et Tanh</b> : Utilisées dans certaines situations, notamment en couche de sortie pour la
                    classification binaire.</li>
                <li><b>Softmax</b> : Comme pour les DNN, elle est souvent utilisée en couche de sortie pour la
                    classification multiclasse dans les CNN.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">31
                <a class="prev" href="#slide30"></a>
                <a class="next" href="#slide32"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide32">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <h4>Fonctions de perte</h4>
            <p>Les fonctions de perte (loss functions) sont des métriques qui mesurent à quel point les prédictions d'un
                modèle diffèrent des valeurs réelles attendues. Choisir la bonne fonction de perte dépend du type de
                problème que vous essayez de résoudre, qu'il s'agisse d'une tâche de classification, de régression, ou
                autre.</p>
            <table>
                <tr>
                    <th>Fonction de Perte</th>
                    <th>Type de Problème</th>
                    <th>Utilisation</th>
                </tr>
                <tr>
                    <td>Mean Squared Error (MSE)</td>
                    <td>Régression</td>
                    <td>\( \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \) - Mesure l'erreur quadratique moyenne entre
                        les prédictions (\( \hat{y}_i \)) et les valeurs réelles (\( y_i \)). Utile lorsque les erreurs
                        doivent être pénalisées de manière significative.</td>
                </tr>
            </table>

        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">32
                <a class="prev" href="#slide31"></a>
                <a class="next" href="#slide33"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide33">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <h4>Fonctions de perte</h4>
            <table>
                <tr>
                    <th>Fonction de Perte</th>
                    <th>Type de Problème</th>
                    <th>Utilisation</th>
                </tr>
                <tr>
                    <td>Mean Absolute Error (MAE)</td>
                    <td>Régression</td>
                    <td>\( \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i| \) - Mesure l'erreur absolue moyenne entre les
                        prédictions (\( \hat{y}_i \)) et les valeurs réelles (\( y_i \)). Moins sensible aux valeurs
                        aberrantes que le MSE.</td>
                </tr>
                <td>Binary Crossentropy</td>
                <td>Classification Binaire</td>
                <td>\( -\frac{1}{n} \sum_{i=1}^{n} \left(y_i \cdot \log(\hat{y}_i) + (1-y_i) \cdot
                    \log(1-\hat{y}_i)\right) \) - Fonction de perte pour la classification binaire. Convient lorsque
                    chaque exemple d'entraînement appartient à une seule classe.</td>
                </tr>
            </table>

        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">33
                <a class="prev" href="#slide32"></a>
                <a class="next" href="#slide34"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide34">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <h4>Fonctions de perte</h4>
            <table>
                <tr>
                    <th>Fonction de Perte</th>
                    <th>Type de Problème</th>
                    <th>Utilisation</th>
                </tr>
                <tr>
                    <td>Categorical Crossentropy</td>
                    <td>Classification Multiclasse</td>
                    <td>\( -\frac{1}{n} \sum_{i=1}^{n} \sum_{j=1}^{m} y_{i,j} \cdot \log(\hat{y}_{i,j}) \) - Fonction de
                        perte pour la classification multiclasse. Convient lorsque chaque exemple d'entraînement peut
                        appartenir à plusieurs classes.</td>
                </tr>
                <tr>
                    <td>Hinge Loss</td>
                    <td>SVM (Support Vector Machine)</td>
                    <td>\( \frac{1}{n} \sum_{i=1}^{n} \max(0, 1 - y_i \cdot \hat{y}_i) \) - Utilisé pour les machines à
                        vecteurs de support. Pénalise les erreurs lorsque la prédiction (\( \hat{y}_i \)) n'est pas du
                        bon côté de la marge.</td>
                </tr>
            </table>

        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">34
                <a class="prev" href="#slide33"></a>
                <a class="next" href="#slide35"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide35">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <h4>Fonctions de perte</h4>
            <table>
                <tr>
                    <th>Fonction de Perte</th>
                    <th>Type de Problème</th>
                    <th>Utilisation</th>
                </tr>
                <tr>
                    <td>Huber Loss</td>
                    <td>Régression</td>
                    <td>\( \frac{1}{n} \sum_{i=1}^{n} L_{\delta}(y_i - \hat{y}_i) \) - Une combinaison de MSE et MAE.
                        Moins sensible aux valeurs aberrantes que MSE et moins impacté par celles-ci que MAE.</td>
                </tr>
                <tr>
                    <td>Poisson Loss</td>
                    <td>Régression (Poisson)</td>
                    <td>\( \frac{1}{n} \sum_{i=1}^{n} \left(\hat{y}_i - y_i \cdot \log(\hat{y}_i) \right) \) - Utilisé
                        pour des tâches de régression où les valeurs suivent une distribution de Poisson.</td>
                </tr>
            </table>

        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">35
                <a class="prev" href="#slide34"></a>
                <a class="next" href="#slide36"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide36">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <h4>Optimiseurs</h4>
            <table>
                <tr>
                    <th>Optimiseur</th>
                    <th>Description</th>
                </tr>
                <tr>
                    <td>Stochastic Gradient Descent (SGD)</td>
                    <td>L'optimiseur de descente de gradient stochastique classique. Il met à jour les poids du modèle
                        en se déplaçant dans la direction opposée du gradient moyen calculé sur un petit lot de données
                        d'entraînement à la fois.</td>
                </tr>
                <tr>
                    <td>Adam (Adaptive Moment Estimation)</td>
                    <td>Un optimiseur qui combine des idées de RMSprop et de Momentum. Il adapte les taux
                        d'apprentissage des paramètres en fonction de leurs gradients moyens et de leurs moments moyens.
                        Très populaire et souvent recommandé pour de nombreuses tâches.</td>
                </tr>
            </table>

        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">36
                <a class="prev" href="#slide35"></a>
                <a class="next" href="#slide37"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide37">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <h4>Optimiseurs</h4>
            <table>
                <tr>
                    <th>Optimiseur</th>
                    <th>Description</th>
                </tr>
                <tr>
                    <td>RMSprop (Root Mean Square Propagation)</td>
                    <td>Ajuste les taux d'apprentissage pour chaque paramètre individuellement en utilisant une moyenne
                        pondérée exponentielle des carrés des gradients. Cela aide à atténuer les problèmes liés aux
                        taux d'apprentissage dans la descente de gradient stochastique.</td>
                </tr>
            </table>

        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">37
                <a class="prev" href="#slide36"></a>
                <a class="next" href="#slide38"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide38">
        <div class="header">
            <h1>3.1. Apprentissage profond: réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <p>Un <b>réseau de neurones profond</b>, également connu sous le nom de réseau de neurones profondément
                hiérarchisé ou réseau neuronal profond (DNN pour Deep Neural Network en anglais), est un type de réseau
                de neurones artificiels qui comprend plusieurs couches de traitement, généralement plus de deux. Ces
                réseaux sont appelés "profonds" en raison de leur architecture empilée de couches, permettant la
                création de représentations hiérarchiques complexes des données.</p>
            <p><b>Architecture en couches</b> : Les réseaux de neurones profonds sont composés de multiples couches,
                généralement divisées en trois types principaux :</p>
            <ul>
                <li><b>Couche d'Entrée</b> : Reçoit les données brutes ou caractéristiques en entrée.</li>
                <li><b>Couches Cachées</b> : Effectuent des transformations non linéaires et apprennent des
                    représentations hiérarchiques des données.</li>
                <li><b>Couche de Sortie</b> : Produit la sortie du réseau, adaptée à la tâche spécifique
                    (classification, régression, etc.).</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">38
                <a class="prev" href="#slide37"></a>
                <a class="next" href="#slide39"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide39">
        <div class="header">
            <h1>3.1. Apprentissage profond: réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <ul>
                <li><b>Apprentissage Hiérarchique</b> : Les couches cachées d'un réseau de neurones profond apprennent
                    des caractéristiques de plus en plus abstraites et complexes à mesure que l'on progresse en
                    profondeur. Chaque couche représente une abstraction des caractéristiques extraites par les couches
                    précédentes.</li>
                <li><b>Fonctions d'Activation</b> : Des fonctions d'activation non linéaires, telles que ReLU (Rectified
                    Linear Unit) ou ses variantes, sont couramment utilisées dans les couches cachées pour permettre au
                    réseau d'apprendre des relations non linéaires.</li>
                <li><b>Apprentissage Profond</b> : L'apprentissage profond implique l'ajustement simultané des poids de
                    toutes les couches du réseau pour minimiser l'erreur de prédiction. Cela est généralement réalisé en
                    utilisant des techniques de rétropropagation et de descente de gradient.</li>
                <li><b>Utilisations</b> : Les réseaux de neurones profonds sont utilisés dans une variété de tâches,
                    notamment la vision par ordinateur, la reconnaissance vocale, le traitement du langage naturel, la
                    traduction automatique, la recommandation de contenu, et bien d'autres. Leur capacité à apprendre
                    des représentations complexes a conduit à des avancées significatives dans de nombreux domaines de
                    l'intelligence artificielle.</li>
            </ul>
            <p>L'entraînement de réseaux de neurones profonds peut nécessiter des volumes importants de données et de
                puissance de calcul. </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">39
                <a class="prev" href="#slide38"></a>
                <a class="next" href="#slide40"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide40">
        <div class="header">
            <h1>3.1. Apprentissage profond: réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <p>Il existe plusieurs types de réseaux de neurones profonds.</p>
            <ul>
                <li><b style="color:#1B80CF">Réseaux de Neurones Convolutionnels (CNN)</b> :
                    <ul>
                        <li><b>Utilisation Principale</b> : Vision par ordinateur, reconnaissance d'images.</li>
                        <li><b>Caractéristiques</b> : Les CNN sont efficaces pour extraire des motifs spatiaux à partir
                            d'images en utilisant des opérations de convolution. Ils sont largement utilisés dans des
                            applications telles que la classification d'images, la détection d'objets et la segmentation
                            d'images.</li>
                    </ul>
                </li>
                <li><b style="color:#1B80CF">Réseaux de Neurones Récurrents (RNN)</b> :
                    <ul>
                        <li><b>Utilisation Principale</b> : Traitement de séquences, traitement du langage naturel.</li>
                        <li><b> Caractéristiques</b> : Les RNN sont conçus pour traiter des données séquentielles en
                            utilisant des connexions récurrentes qui leur permettent de conserver une mémoire à long
                            terme. Ils sont utilisés pour des tâches telles que la traduction automatique, la génération
                            de texte et l'analyse de séquences temporelles.</li>
                    </ul>
                </li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">40
                <a class="prev" href="#slide39"></a>
                <a class="next" href="#slide41"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide41">
        <div class="header">
            <h1>3.1. Apprentissage profond: réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <ul>
                <li><b style="color:#1B80CF">Réseaux de Neurones Générateurs Adverses (GAN)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Génération d'images réalistes.</li>
                        <li><b> Caractéristiques</b> : Les GAN sont composés de deux réseaux, un générateur et un
                            discriminateur, qui s'entraînent de manière adversaire. Les GAN sont utilisés pour générer
                            des données réalistes, y compris des images, des vidéos et du son.</li>
                    </ul>
                </li>
                <li><b style="color:#1B80CF">Réseaux de Neurones Résiduels (ResNet)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Classification d'images profondes.</li>
                        <li><b> Caractéristiques</b> : Les architectures ResNet utilisent des connexions résiduelles
                            pour faciliter l'apprentissage profond en surmontant le problème du "vanishing gradient".
                            Ils sont fréquemment utilisés dans des compétitions de classification d'images.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">41
                <a class="prev" href="#slide40"></a>
                <a class="next" href="#slide42"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide42">
        <div class="header">
            <h1>3.1. Apprentissage profond: réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <ul>

                <li><b style="color:#1B80CF">Autoencodeurs et Variational Autoencoders (VAE)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Compression et génération de données.
                        <li><b> Caractéristiques</b> : Les autoencodeurs sont utilisés pour apprendre des
                            représentations compactes de données en comprimant et en reconstruisant les informations.
                            Les VAE introduisent des composants probabilistes, permettant de générer de nouvelles
                            données similaires aux données d'entraînement.
                    </ul>
                </li>

                <li><b style="color:#1B80CF">Réseaux de Neurones de Mémoire à Long Terme (LSTM)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Traitement du langage naturel, séquences temporelles.</li>
                        <li><b> Caractéristiques</b> : Les LSTMs sont une variation des RNN qui intègrent des mécanismes
                            de portes pour mieux gérer le problème du gradient qui s'estompe sur de longues séquences.
                            Ils sont couramment utilisés dans la génération de texte et d'autres tâches basées sur des
                            séquences.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">42
                <a class="prev" href="#slide41"></a>
                <a class="next" href="#slide43"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide43">
        <div class="header">
            <h1>3.2. Feedforward neural network</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Feedforward neural network</h1>
            <p>Les réseaux de neurones en aval, également appelés réseaux de neurones à propagation avant (Feedforward
                Neural Networks), se caractérisent par une architecture où les connexions entre les nœuds ne forment pas
                de cycles. L'information se déplace de manière <b>unidirectionnelle</b>, des nœuds d'entrée vers les
                nœuds de sortie, <b>sans boucles</b> récurrentes. </p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Feed_forward_neural_net.gif"
                    width="200vw" />
                <figcaption>Réseau de neurones en aval</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">43
                <a class="prev" href="#slide42"></a>
                <a class="next" href="#slide44"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide44">
        <div class="header">
            <h1>3.2. Feedforward neural network</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Feedforward neural network</h1>
            <ul>
                <li><b>Pas de connexions cycliques</b> : Contrairement aux réseaux récurrents, les réseaux de neurones
                    en aval n'ont pas de connexions cycliques. Cela signifie qu'il n'y a pas de boucles ou de connexions
                    récurrentes entre les couches, et l'information circule dans une seule direction.</li>
                <li><b>Déplacement de l'information</b> : L'information se déplace des nœuds d'entrée vers les nœuds de
                    sortie en passant éventuellement par des nœuds cachés. Chaque couche de nœuds traite les données
                    indépendamment, et les résultats sont transmis à la couche suivante.</li>
                <li><b>Propagation avant (Forward Propagation)</b> : La propagation avant est le processus par lequel
                    les données sont transmises à travers le réseau, couche par couche, jusqu'à la couche de sortie.
                    Chaque connexion entre les nœuds a un poids associé qui est ajusté pendant l'apprentissage.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">44
                <a class="prev" href="#slide43"></a>
                <a class="next" href="#slide45"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide45">
        <div class="header">
            <h1>3.2. Feedforward neural network</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Feedforward neural network</h1>
            <ul>
                <li><b>Apprentissage par rétropropagation (Backpropagation)</b> : L'apprentissage dans les réseaux de
                    neurones en aval se fait souvent par rétropropagation. Après la propagation avant, l'erreur entre la
                    sortie prédite et la sortie réelle est calculée, puis cette erreur est rétropropagée à travers le
                    réseau pour ajuster les poids et minimiser l'erreur.</li>
                <li><b>Utilisation courante</b> : Les réseaux de neurones en aval sont couramment utilisés pour des
                    tâches telles que la classification, la régression, et d'autres problèmes où chaque exemple de
                    données peut être traité de manière indépendante des autres.</li>
                <li><b>Exemple d'application</b> : Les réseaux de neurones en aval sont utilisés dans divers domaines
                    tels que la vision par ordinateur, le traitement du langage naturel, la reconnaissance vocale, etc.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">45
                <a class="prev" href="#slide44"></a>
                <a class="next" href="#slide46"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide46">
        <div class="header">
            <h1>3.2. Feedforward neural network</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Rétropropagation du gradient (Backpropagation)</h1>
            <p>La rétropropagation du gradient, également appelée backpropagation, est une technique clé utilisée dans
                l'apprentissage des réseaux de neurones pour ajuster les poids des connexions afin de minimiser l'erreur
                globale du modèle. </p>
            <ul>
                <li><b>Ajustement des poids pour compenser l'erreur</b> : La rétropropagation ajuste les poids des
                    connexions du réseau pour compenser chaque erreur constatée lors de l'apprentissage. L'objectif est
                    de minimiser la différence entre les prédictions du modèle et les valeurs réelles de sortie.</li>
                <li><b>Répartition de l'erreur entre les connexions</b> : Le montant de l'erreur est réparti entre les
                    connexions du réseau. Cela signifie que chaque poids contribue proportionnellement à l'erreur
                    totale, et l'ajustement des poids est effectué en fonction de cette contribution.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">46
                <a class="prev" href="#slide45"></a>
                <a class="next" href="#slide47"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide47">
        <div class="header">
            <h1>3.2. Feedforward neural network</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Rétropropagation du gradient (Backpropagation)</h1>
            <ul>
                <li><b>Calcul du gradient de la fonction de perte</b> : La rétropropagation calcule le gradient de la
                    fonction de perte par rapport aux poids du réseau pour un seul exemple d'entrée-sortie. Le gradient
                    représente la pente de la fonction de perte par rapport à chaque poids.</li>
                <li><b>Règle de la chaîne</b> : La rétropropagation fonctionne en utilisant la règle de la chaîne du
                    calcul différentiel. Elle permet de décomposer la dérivée d'une fonction composée en une série de
                    dérivées partielles. Dans le contexte de la rétropropagation, cela signifie calculer le gradient de
                    la fonction de perte par rapport à chaque poids en remontant à travers le réseau.</li>
                <li><b>Optimisation des poids par l'algorithme d'optimisation</b> : Une fois que les gradients sont
                    calculés, un algorithme d'optimisation, tel que la descente de gradient, est utilisé pour ajuster
                    les poids dans la direction qui minimise la fonction de perte.</li>
            </ul>
            <p>La rétropropagation est un processus itératif qui se déroule sur plusieurs cycles (itérations ou époques)
                d'entraînement du modèle. Elle contribue de manière significative à l'apprentissage des représentations
                et à l'amélioration des performances du réseau de neurones.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">47
                <a class="prev" href="#slide46"></a>
                <a class="next" href="#slide48"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide48">
        <div class="header">
            <h1>3.2. Feedforward neural network</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Rétropropagation du gradient (Backpropagation)</h1>
            <p>La rétropropagation du gradient implique le calcul des gradients de la fonction de perte par rapport aux
                poids du réseau. Pour expliquer le processus plus en détail, nous allons utiliser quelques notations
                courantes. Supposons que \(L\) soit la fonction de perte, \(w_{ij}^{(k)}\) soit le poids entre le
                neurone \(i\) dans la couche \(k-1\) et le neurone \(j\) dans la couche \(k\), et \(a_{i}^{(k)}\) soit
                l'activation du neurone \(i\) dans la couche \(k\).</p>
            <ul>
                <li><b>Calcul de l'erreur</b> : Supposons que \(y\) soit la sortie attendue et \(\hat{y}\) la sortie
                    prédite. L'erreur pour un exemple donné est souvent mesurée par une fonction de perte, notée \(L\).
                    \[ L = \text{fonction_de_perte}(y, \hat{y}) \]</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">48
                <a class="prev" href="#slide47"></a>
                <a class="next" href="#slide49"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide49">
        <div class="header">
            <h1>3.2. Feedforward neural network</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Rétropropagation du gradient (Backpropagation)</h1>
            <ul>
                <li><b>Calcul du gradient de la fonction de perte par rapport à la sortie</b> : \[ \frac{\partial
                    L}{\partial \hat{y}} \]</li>
                <li><b>Propagation arrière - règle de la chaîne</b> : Pour chaque couche \(k\) en partant de la sortie
                    jusqu'à l'entrée :
                    \[ \delta_{i}^{(k)} = \frac{\partial L}{\partial a_{i}^{(k)}} \]
                    \[ \frac{\partial L}{\partial w_{ij}^{(k)}} = a_{j}^{(k-1)} \cdot \delta_{i}^{(k)} \]</li>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">49
                <a class="prev" href="#slide48"></a>
                <a class="next" href="#slide50"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide50">
        <div class="header">
            <h1>3.2. Feedforward neural network</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Rétropropagation du gradient (Backpropagation)</h1>
            <ul>
                <li><b>Mise à jour des poids avec un algorithme d'optimisation (e.g., descente de gradient)</b> :
                    \[ w_{ij}^{(k)} = w_{ij}^{(k)} - \eta \cdot \frac{\partial L}{\partial w_{ij}^{(k)}} \]
                    \(\eta\) est le taux d'apprentissage.</li>
            </ul>
            <p>Ces calculs sont effectués pour chaque exemple d'entraînement dans un lot (batch), et l'algorithme
                d'optimisation ajuste les poids pour minimiser la fonction de perte sur l'ensemble des données
                d'entraînement. Le processus est répété sur plusieurs époques jusqu'à ce que le modèle atteigne une
                performance souhaitée.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">50
                <a class="prev" href="#slide49"></a>
                <a class="next" href="#slide51"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide51">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones récurrents</h1>
            <p>Les réseaux de neurones récurrents (RNN) sont un type de réseau de neurones où les connexions entre les
                nœuds forment un graphe dirigé le long d'une séquence temporelle. Cela leur permet de présenter un
                comportement dynamique temporel, ce qui les rend particulièrement adaptés au traitement de séquences de
                données. </p>
            <ul>
                <li><b>Connexions Temporelles</b> : Les connexions entre les nœuds d'un RNN forment un graphe dirigé qui
                    suit une séquence temporelle. Chaque nœud prend en compte l'entrée actuelle ainsi que l'état interne
                    (mémoire) du réseau provenant de l'instant temporel précédent.</li>
                <li><b>État Interne (Mémoire)</b> : Les RNN utilisent leur état interne ou mémoire pour traiter des
                    séquences d'entrées de longueur variable. Cela permet au réseau de mémoriser des informations
                    importantes provenant des instants temporels précédents et de les utiliser pour influencer les
                    prédictions actuelles.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">51
                <a class="prev" href="#slide50"></a>
                <a class="next" href="#slide52"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide52">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones récurrents</h1>
            <p>Les RNN sont largement utilisés dans des applications qui impliquent des données séquentielles, notamment
                :</p>
            <ul>
                <li><b>Reconnaissance de l'écriture manuscrite</b> : Les RNN peuvent être utilisés pour reconnaître des
                    séquences de caractères dans une séquence d'écriture manuscrite.</li>
                <li><b>Reconnaissance vocale</b> : En traitant des séquences temporelles de signaux audio, les RNN
                    peuvent être employés pour la reconnaissance vocale.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">52
                <a class="prev" href="#slide51"></a>
                <a class="next" href="#slide53"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide53">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones récurrents</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Recurrent_neural_network_unfold.svg"
                    height="480vh" />
                <figcaption>Réseau de neurones récurrents</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">53
                <a class="prev" href="#slide52"></a>
                <a class="next" href="#slide54"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide54">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones récurrents</h1>
            <p>Dans un réseau de neurones récurrents (RNN), le neurone, également appelé unité récurrente, est l'élément
                de base qui permet au réseau de traiter des données séquentielles en maintenant un état interne ou une
                mémoire.</p>
            <p><b>Entrées :</b> Le neurone RNN reçoit deux types d'entrées :</p>
            <ul>
                <li><b>Entrée courante</b> (\(x_t\)) : L'entrée actuelle à l'instant temporel \(t\). Elle peut
                    représenter une caractéristique spécifique d'une séquence à cet instant.</li>
                <li><b>État caché précédent</b> (\(h_{t-1}\)) : L'état caché provenant de l'instant temporel précédent
                    (\(t-1\)). Cet état représente la mémoire du réseau et est essentiel pour capturer les informations
                    passées.</li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">54
                <a class="prev" href="#slide53"></a>
                <a class="next" href="#slide55"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide55">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones récurrents</h1>
            <ul>
                <li><b>Poids</b> : Chaque connexion entre l'entrée courante, l'état caché précédent et le neurone a un
                    poids associé (\(w\)). Ces poids déterminent l'importance respective des différentes entrées pour le
                    neurone.</li>
                <li><b>Fonction d'activation</b> : Le neurone RNN utilise une fonction d'activation pour combiner les
                    entrées et générer une sortie. La fonction d'activation est généralement non linéaire et permet au
                    réseau d'apprendre des relations complexes dans les données séquentielles.</li>
                <li><b>État caché (Mémoire)</b> : La sortie du neurone à l'instant \(t\), souvent notée \(h_t\), devient
                    l'état caché qui sera utilisé pour influencer la sortie à l'instant suivant (\(t+1\)). Cet état
                    caché représente la mémoire du réseau et permet de conserver des informations importantes sur la
                    séquence.</li>
                <ul>

        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">55
                <a class="prev" href="#slide54"></a>
                <a class="next" href="#slide56"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide56">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones récurrents</h1>

            <p><b>Formule Générale</b> : La sortie du neurone à l'instant \(t\) est calculée comme suit :</p>
            <p>
                \[ h_t = \text{fonction_activation}(w_{hx} \cdot x_t + w_{hh} \cdot h_{t-1} + b_h) \]
                \(w_{hx}\) et \(w_{hh}\) sont les poids associés aux entrées actuelles et à l'état caché précédent,
                respectivement.
                \(b_h\) est le terme de biais.
            </p>
            <p>Le rôle principal du neurone dans un RNN est de traiter séquentiellement les données en maintenant une
                mémoire du passé à travers l'état caché. Cette capacité à conserver des informations antérieures permet
                au RNN de modéliser des dépendances à long terme dans les séquences temporelles, ce qui est crucial pour
                des tâches telles que la reconnaissance de la parole, la traduction automatique, etc.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">56
                <a class="prev" href="#slide55"></a>
                <a class="next" href="#slide57"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide57">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones récurrents</h1>
            <p><b>Avantages</b></p>
            <li><b>Traitement séquentiel</b> : Les RNN sont spécialement conçus pour traiter des données séquentielles,
                ce qui en fait un choix naturel pour des tâches telles que la reconnaissance vocale, la traduction
                automatique et la prédiction temporelle.</li>
            <li><b>Capacité à gérer les dépendances temporelles</b> : Les RNN peuvent modéliser les dépendances à long
                terme dans les séquences temporelles en utilisant leur mémoire interne. Cela les rend adaptés à des
                problèmes où la compréhension du contexte temporel est essentielle.</li>
            <li><b>Architecture réutilisable</b> : La même architecture neuronale peut être utilisée à chaque instant
                temporel, facilitant ainsi la réutilisation des paramètres du modèle.</li>
            <li><b>Flexibilité dans la taille des séquences</b> : Les RNN peuvent traiter des séquences de longueurs
                variables, ce qui les rend adaptés à des données où la longueur de la séquence peut varier.</li>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">57
                <a class="prev" href="#slide56"></a>
                <a class="next" href="#slide58"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide58">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones récurrents</h1>
            <p><b>Limites</b></p>
            <li><b>Problème du gradient qui disparaît ou explose</b> : L'entraînement de RNN sur de longues séquences
                peut entraîner des problèmes de gradients qui disparaissent ou explosent, ce qui rend l'apprentissage
                difficile.</li>
            <li><b>Manque de captation de dépendances à très long terme</b> : Malgré la capacité à gérer des dépendances
                à long terme, les RNN peuvent avoir du mal à capturer des dépendances très à long terme dans les
                séquences.</li>
            <li><b>Calculs séquentiels</b> : Les RNN effectuent des calculs de manière séquentielle, ce qui peut
                entraîner une lenteur dans le traitement par rapport à certaines architectures parallèles.</li>
            <li><b>Sensibilité à l'ordre des éléments</b> : Les RNN sont sensibles à l'ordre des éléments dans une
                séquence, et des permutations peuvent affecter le résultat du modèle.</li>
            <li><b>Architectures améliorées nécessaires</b> : Des architectures améliorées, telles que les LSTM (Long
                Short-Term Memory) et les GRU (Gated Recurrent Unit), sont souvent nécessaires pour atténuer les
                problèmes de gradient et améliorer la capacité du modèle à conserver des informations sur de longues
                séquences.</li>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">58
                <a class="prev" href="#slide57"></a>
                <a class="next" href="#slide59"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide59">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau récurrent à mémoire court et long terme</h1>
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <p>Les unités LSTM sont une variation de l'architecture des réseaux neuronaux récurrents (RNN) conçue pour
                résoudre le problème du gradient qui disparaît ou explose lors de l'entraînement de séquences à long
                terme. Elles sont particulièrement utiles pour modéliser les dépendances à long terme dans les séquences
                temporelles, telles que des séquences de mots dans le langage naturel.</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Long_Short-Term_Memory.svg "
                    height="200px" />
                <figcaption>LSTM</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">59
                <a class="prev" href="#slide58"></a>
                <a class="next" href="#slide60"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide60">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <ul>
                <li><b>Connexions de retour d'information</b> : Les connexions de retour d'information font référence à
                    la capacité d'une unité LSTM à maintenir une mémoire à long terme en conservant des informations
                    provenant d'itérations précédentes dans la séquence temporelle. Cette capacité à conserver des
                    informations sur des intervalles de temps arbitraires est ce qui permet aux LSTM de gérer
                    efficacement les dépendances à long terme dans les données séquentielles.</li>
                <li><b>Cellule LSTM</b> : La cellule LSTM est l'unité de mémoire principale. Elle stocke et régule
                    l'information sur des intervalles de temps arbitraires. La cellule peut être considérée comme une
                    mémoire à long terme qui peut être écrite, lue et modifiée.</li>
                <li><b>Porte d'entrée (Input Gate)</b>: La porte d'entrée détermine quels éléments de la nouvelle
                    information doivent être ajoutés à la cellule. Elle utilise une fonction d'activation pour contrôler
                    cet ajout.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">60
                <a class="prev" href="#slide59"></a>
                <a class="next" href="#slide61"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide61">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <ul>
                <li><b>Porte de sortie (Output Gate)</b> : La porte de sortie décide quelle partie de l'information
                    stockée dans la cellule doit être exposée à la sortie du LSTM. Elle utilise une fonction
                    d'activation pour effectuer cette sélection.</li>
                <li><b>Porte d'oubli (Forget Gate)</b> : La porte d'oubli permet au LSTM de supprimer des informations
                    de la cellule. Elle détermine quelles parties de l'information existante dans la cellule doivent
                    être oubliées.</li>
            </ul>
            <p>Ensemble, ces composants permettent à une unité LSTM de maintenir et de gérer des informations sur des
                périodes de temps étendues, ce qui en fait un choix puissant pour la modélisation de séquences
                temporelles complexes. Les portes d'entrée, de sortie et d'oubli fournissent un mécanisme de régulation
                fin pour contrôler le flux d'informations à travers la cellule.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">61
                <a class="prev" href="#slide60"></a>
                <a class="next" href="#slide62"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide62">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <p>Supposons que \(x_t\) soit l'entrée à l'instant de temps \(t\), \(h_{t-1}\) soit la sortie de la couche
                LSTM à l'instant de temps précédent \(t-1\), et \(c_{t-1}\) soit l'état de la cellule à l'instant de
                temps précédent \(t-1\).</p>

            <p><b>Porte d'entrée (Input Gate)</b> :</p>
            <ul>
                <li> \(i_t = \sigma(W_{ii} \cdot x_t + b_{ii} + W_{hi} \cdot h_{t-1} + b_{hi})\) (Activation)</li>
                <li>\(\tilde{c}_t = \tanh(W_{ic} \cdot x_t + b_{ic} + W_{hc} \cdot h_{t-1} + b_{hc})\) (Nouvelles
                    données de cellule proposées)</li>
                <li>\(f_t = \sigma(W_{if} \cdot x_t + b_{if} + W_{hf} \cdot h_{t-1} + b_{hf})\) (Porte d'Oubli)</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">62
                <a class="prev" href="#slide61"></a>
                <a class="next" href="#slide63"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide63">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <p><b>Mise à jour de la cellule</b> :</p>
            <ul>
                <li>\(c_t = f_t \cdot c_{t-1} + i_t \cdot \tilde{c}_t\) (Mise à jour de l'état de la cellule)</li>
            </ul>
            <p><b>Porte de sortie (Output Gate)</b> :</p>
            <ul>
                <li>\(o_t = \sigma(W_{io} \cdot x_t + b_{io} + W_{ho} \cdot h_{t-1} + b_{ho})\) (Activation)</li>
                <li>\(h_t = o_t \cdot \tanh(c_t)\) (Sortie)</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">63
                <a class="prev" href="#slide62"></a>
                <a class="next" href="#slide64"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide64">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <p>Dans ces équations :</p>
            <ul>
                <li>\(\sigma\) est la fonction sigmoïde.</li>
                <li>\(\tanh\) est la fonction tangente hyperbolique.</li>
                <li>\(W\) et \(b\) représentent les poids et les biais, respectivement, associés à différentes portes et
                    entrées.</li>
                <li>Les indices \(ii, ic, if, io\) indiquent les poids spécifiques pour les différentes portes.</li>
            </ul>

            <p>Ces équations décrivent le flux d'information à travers une unité LSTM, avec des portes d'entrée, de
                sortie et d'oubli régulant l'interaction entre l'entrée, l'état de la cellule et la sortie. Ces formules
                permettent aux LSTM de maintenir et de gérer l'information sur des intervalles de temps arbitraires, ce
                qui les rend efficaces pour la modélisation de séquences temporelles complexes.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">64
                <a class="prev" href="#slide63"></a>
                <a class="next" href="#slide65"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide65">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h1>Réseaux de neurones convolutionnels</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" height="380px" />
            </figure>
            <figure>
                <img src="../../2021/MachineLearning/Deep_Learning.jpg" height="450px" />
                <figcaption>Source: https://en.wikipedia.org/wiki/File:Deep_Learning.jpg</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">65
                <a class="prev" href="#slide64"></a>
                <a class="next" href="#slide66"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide66">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" width="900vw"
                    height="400vh" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">66
                <a class="prev" href="#slide65"></a>
                <a class="next" href="#slide67"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide67">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
            <p>Les réseaux de neurones convolutionnels (CNN) sont une classe d'architectures de réseaux neuronaux
                conçues principalement pour l'analyse des images. Ils ont été particulièrement efficaces dans des tâches
                telles que la classification d'images, la détection d'objets, et la segmentation d'images. </p>
            <ul>
                <li><b>Analyse des Images</b> : Les CNN sont spécifiquement conçus pour travailler avec des données
                    structurées en grilles, comme les images. Ils sont capables de capturer des motifs et des
                    caractéristiques spatiales importantes dans les images.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">67
                <a class="prev" href="#slide66"></a>
                <a class="next" href="#slide68"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide68">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
            <ul>
                <li><b>Utilise la convolution</b> La convolution est une opération mathématique linéaire utilisée pour
                    extraire des caractéristiques locales à partir de l'image. Les filtres de convolution sont appliqués
                    à l'image pour détecter des motifs tels que des bords, des textures, ou des formes.</li>
                <li><b>Architecture en couches</b> : Les CNN suivent généralement une architecture en couches. Ils ont
                    une couche d'entrée pour recevoir l'image, une ou plusieurs couches cachées composées principalement
                    de couches convolutives, et une couche de sortie pour produire les résultats finaux.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">68
                <a class="prev" href="#slide67"></a>
                <a class="next" href="#slide69"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide69">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
            <ul>
                <li><b>Couches convolutives</b> : Les couches convolutives sont responsables de l'extraction des
                    caractéristiques de l'image. Chaque couche peut avoir plusieurs filtres de convolution qui
                    apprennent à détecter des motifs spécifiques. Ces couches sont souvent suivies de couches de pooling
                    pour réduire la dimensionnalité de la représentation tout en préservant les caractéristiques
                    importantes.</li>
                <li><b>Applications</b> : Les CNN sont largement utilisés dans des applications telles que la
                    classification d'images (par exemple, reconnaître des animaux dans des photos), la détection
                    d'objets (localiser et identifier des objets spécifiques), et la segmentation d'images (diviser une
                    image en régions sémantiquement significatives)..</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">69
                <a class="prev" href="#slide68"></a>
                <a class="next" href="#slide70"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide70">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Réseaux de neurones convolutionnels: architecture</h3>
            <ul>
                <li><b>Modèle hiérarchique des données</b> : Les réseaux neuronaux convolutifs (CNN) sont en effet
                    conçus pour capturer des caractéristiques hiérarchiques dans les données, en particulier dans le
                    contexte de l'analyse d'images. Cela signifie qu'ils peuvent apprendre des motifs simples dans les
                    premières couches, puis combiner ces motifs pour former des caractéristiques plus complexes dans les
                    couches suivantes.</li>
                <li><b>Architecture d'un CNN</b> : Un réseau neuronal convolutif est généralement composé d'une couche
                    d'entrée, de plusieurs couches cachées et d'une couche de sortie. Les couches cachées consistent
                    principalement en couches convolutionnelles, mais peuvent également inclure d'autres types de
                    couches telles que des couches de regroupement (pooling), des couches entièrement connectées, et des
                    couches de normalisation.</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" height="180px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">70
                <a class="prev" href="#slide69"></a>
                <a class="next" href="#slide71"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide71">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Réseaux de neurones convolutionnels: architecture</h3>
            <ul>
                <li><b>Couches convolutionnelles et fonction d'activation</b> : Les couches convolutionnelles appliquent
                    des filtres pour extraire des caractéristiques de l'image. La multiplication est effectuée par la
                    convolution. La fonction d'activation la plus couramment utilisée est ReLU (Rectified Linear Unit),
                    qui introduit une non-linéarité dans le modèle. Cette non-linéarité est importante pour permettre au
                    réseau d'apprendre des relations complexes dans les données.</li>
                <li><b>Couches supplémentaires</b> : Après les couches de convolution, on peut avoir des couches de
                    regroupement pour réduire la dimensionnalité, des couches entièrement connectées pour combiner des
                    caractéristiques globales, et des couches de normalisation pour améliorer la stabilité de
                    l'apprentissage.</li>
            </ul>
            <p>En résumé, les CNN suivent une architecture hiérarchique, où les couches convolutives apprennent des
                caractéristiques locales, et ces caractéristiques sont ensuite combinées dans les couches suivantes pour
                former des représentations plus complexes. La non-linéarité introduite par la fonction d'activation ReLU
                est cruciale pour permettre au modèle d'apprendre des relations non linéaires dans les données.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">71
                <a class="prev" href="#slide70"></a>
                <a class="next" href="#slide72"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide72">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <p>Un noyau dans le contexte du traitement d'images, également appelé filtre ou masque, est une petite
                matrice qui est appliquée sur une image à l'aide d'une opération de convolution. L'objectif de
                l'application de ces noyaux est de réaliser diverses opérations de filtrage sur l'image, telles que la
                détection de contours, l'amélioration des détails, la mise en évidence de certaines caractéristiques,
                etc.</p>
            <ul>
                <li><b>Convolution dans les CNN</b> : Dans les CNN, la convolution est une opération clé qui consiste à
                    appliquer un ensemble de filtres (noyaux) à une image d'entrée. Chaque filtre est conçu pour
                    extraire des caractéristiques spécifiques de l'image, comme des bords, des textures, ou d'autres
                    motifs.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">72
                <a class="prev" href="#slide71"></a>
                <a class="next" href="#slide73"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide73">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <ul>
                <li><b>Apprentissage des noyaux</b> : L'une des caractéristiques importantes des CNN est la capacité
                    d'apprendre les filtres (noyaux) de manière automatique pendant l'entraînement. Au lieu de définir
                    manuellement les filtres comme dans le traitement d'images traditionnel, les CNN ajustent les poids
                    des filtres pendant la phase d'apprentissage en fonction des caractéristiques qui sont importantes
                    pour la tâche à accomplir.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">73
                <a class="prev" href="#slide72"></a>
                <a class="next" href="#slide74"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide74">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <ul>
                <li><b>Rôle dans la hiérarchie des caractéristiques</b> : Les premières couches d'un CNN apprennent
                    généralement des filtres simples qui détectent des contours ou des textures de base. À mesure que
                    l'on progresse dans les couches du réseau, les filtres deviennent plus complexes, capturant des
                    caractéristiques de niveau supérieur, jusqu'à ce que la sortie finale représente des
                    caractéristiques abstraites de l'image d'entrée.</li>
                <li><b>Réduction de dimension avec le pooling</b> : Après la convolution, les CNN utilisent souvent des
                    couches de pooling pour réduire la dimension de la représentation, tout en préservant les
                    caractéristiques importantes extraites par les filtres. Cela permet d'économiser des ressources
                    computationnelles tout en maintenant les informations cruciales.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">74
                <a class="prev" href="#slide73"></a>
                <a class="next" href="#slide75"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide75">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <h3>Noyau d'identité</h3>
            <p>Il s'agit d'un noyau simple qui conserve l'image d'origine sans apporter de modifications. Lorsque ce
                noyau est appliqué à une image, il laisse l'image inchangée.</p>
            <p>
                \( \begin{matrix} \ \ 0 &\ \ 0 &\ \ 0 \\ \ \ 0 &\ \ 1 &\ \ 0 \\ \ \ 0 &\ \ 0 &\ \ 0 \end{matrix} \)
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">75
                <a class="prev" href="#slide74"></a>
                <a class="next" href="#slide76"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide76">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <h3>Noyau de détection de contours</h3>
            <p>Ce noyau est conçu pour détecter les contours dans une image. Il est également connu sous le nom de
                filtre de Sobel. Lorsqu'il est appliqué à une image, ce noyau met en évidence les variations d'intensité
                qui indiquent la présence de contours. </p>
            <p>
                \( \begin{matrix} \ \ 1 & 0 & -1 \\ \ \ 0 & 0 & \ \ 0 \\ -1 & 0 & \ \ 1 \end{matrix} \)
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">76
                <a class="prev" href="#slide75"></a>
                <a class="next" href="#slide77"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide77">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <h3>Box blur</h3>
            <p>Ce noyau est utilisé pour réaliser une opération de flou simple. Il est également connu sous le nom de
                flou moyen. Lorsqu'il est appliqué à une image, ce noyau attribue à chaque pixel la moyenne des valeurs
                de ses voisins, ce qui produit un effet de flou.</p>
            <p>
                \( \frac{1}{9} \begin{matrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{matrix} \)
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">77
                <a class="prev" href="#slide76"></a>
                <a class="next" href="#slide78"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide78">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <h3>Flou de Gauss 3 × 3</h3>
            <p>Ce noyau est basé sur une distribution gaussienne et est utilisé pour réaliser un flou plus doux et plus
                esthétique. L'idée ici est que les pixels du centre ont un poids plus élevé, créant ainsi un effet de
                flou qui ressemble à celui généré par une lentille de caméra.</p>
            <p>
                \( \frac{1}{16} \begin{matrix} 1 & 2 & 1 \\ 2 & 4 & 2 \\ 1 & 2 & 1 \end{matrix} \)
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">78
                <a class="prev" href="#slide77"></a>
                <a class="next" href="#slide79"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide79">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Convolution matricielle</h2>
            <p>La convolution est le processus central qui consiste à appliquer un noyau (aussi appelé filtre) sur une
                image. Cela se fait en déplaçant le noyau sur l'ensemble de l'image, multipliant les valeurs des pixels
                correspondants et produisant une nouvelle image appelée carte de caractéristiques.</p>
            <p>
                \[ \begin{bmatrix} x_{11} & x_{12} & \cdots & x_{1n} \\ x_{21} & x_{22} & \cdots & x_{2n} \\ \vdots &
                \vdots & \ddots & \vdots \\ x_{m1} & x_{m2} & \cdots & x_{mn} \\ \end{bmatrix} * \begin{bmatrix} y_{11}
                & y_{12} & \cdots & y_{1n} \\ y_{21} & y_{22}
                & \cdots & y_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ y_{m1} & y_{m2} & \cdots & y_{mn} \\
                \end{bmatrix} = \sum^{m-1}_{i=0} \sum^{n-1}_{j=0} x_{(m-i)(n-j)} y_{(1+i)(1+j)} \]
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">79
                <a class="prev" href="#slide78"></a>
                <a class="next" href="#slide80"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide80">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Max pooling</h2>
            <p>Après la convolution, des opérations de pooling (souvent max pooling ou moyenne pooling) sont effectuées
                pour réduire la dimension de la carte de caractéristiques en préservant les informations importantes.
            </p>
            <figure>
                <img src="../../2021/DataMining/Max_pooling.png" height="300px" />
                <figcaption>Max pooling avec un filtre 2 × 2 et un pas de 2. (Source:
                    https://commons.wikimedia.org/wiki/File:Max_pooling.png)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">80
                <a class="prev" href="#slide79"></a>
                <a class="next" href="#slide81"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide81">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Stride et Padding</h2>
            <p><b>Stride</b> : Contrôle le déplacement du noyau sur l'image. Un stride de 1 signifie un déplacement
                pixel par pixel, tandis qu'un stride plus grand réduit la taille de la carte de caractéristiques.</p>
            <p><b>Padding</b> : Ajoute des pixels autour de l'image d'entrée pour maintenir la taille de la sortie après
                la convolution.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">81
                <a class="prev" href="#slide80"></a>
                <a class="next" href="#slide82"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide82">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <pre class="codeexample">
            <code>
import tensorflow as tf

from tensorflow.keras import datasets, layers, models

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

# Créer un modèle séquentiel (réseaux de neurones convolutionnels)
model = models.Sequential()
model.add(layers.<span style="color:red">Conv2D</span>(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.<span style="color:red">MaxPooling2D</span>((2, 2)))
model.add(layers.<span style="color:red">Conv2D</span>(64, (3, 3), activation='relu'))
model.add(layers.<span style="color:red">MaxPooling2D</span>((2, 2)))
model.add(layers.<span style="color:red">Conv2D</span>(64, (3, 3), activation='relu'))
            </code>
          </pre>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">82
                <a class="prev" href="#slide81"></a>
                <a class="next" href="#slide83"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide83">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <pre class="codeexample">
            <code>
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10)

#Compilation du modèle
model.compile(optimizer='adam',
   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
   metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=10,
   validation_data=(test_images, test_labels))
            </code>
          </pre>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">83
                <a class="prev" href="#slide82"></a>
                <a class="next" href="#slide84"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide84">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <figure>
                <img src="../../2021/DataMining/convolutionalneuralnetwork.png" height="400vh" />
                <figcaption>Modèle: https://www.tensorflow.org/tutorials/images/cnn</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">84
                <a class="prev" href="#slide83"></a>
                <a class="next" href="#slide85"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide85">
        <div class="header">
            <h1>3.5. Réseaux de neurones récurrents convolutifs (RCNN)</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">RCNN [Girshick 2014]</h2>
            <p>Les réseaux de neurones récurrents convolutifs (RCNN) sont une famille de modèles d'apprentissage
                automatique pour la vision par ordinateur, en particulier la détection d'objets. Ils combinent les
                avantages des réseaux de neurones récurrents (RNN) et des réseaux de neurones convolutifs (CNN).</p>
            <ul>
                <li><b>Génération de propositions de régions</b> : Une étape préliminaire consiste à générer un ensemble
                    de propositions de régions, qui sont des régions de l'image qui pourraient contenir un objet. Cette
                    étape est généralement effectuée en utilisant un algorithme bottom-up, tel que Selective Search.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">85
                <a class="prev" href="#slide84"></a>
                <a class="next" href="#slide86"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide86">
        <div class="header">
            <h1>3.5. Réseaux de neurones récurrents convolutifs (RCNN)</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">RCNN [Girshick 2014]</h2>
            <ul>
                <li><b>Extraction de caractéristiques</b> : Pour chaque proposition de région, un CNN est utilisé pour
                    extraire des caractéristiques. Ces caractéristiques sont utilisées pour classifier la proposition de
                    région en tant qu'objet ou non.</li>
                <li><b>Classification </b> : Enfin, un modèle de classification est utilisé pour classer chaque
                    proposition de région en tant qu'objet ou non. Ce modèle peut être un classificateur SVM ou un
                    classificateur à forêts aléatoires.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">86
                <a class="prev" href="#slide85"></a>
                <a class="next" href="#slide87"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide87">
        <div class="header">
            <h1>3.6. Réseaux de neurones récurrents convolutifs bidirectionnels </h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Bi-RCNN [Cai 2016,Wang 2020]</h2>
            <p>Bi-RCNN est une variante de RCNN qui utilise des réseaux de neurones récurrents bidirectionnels (Bi-RNN)
                pour améliorer la précision de la détection d'objets. Les Bi-RNN sont des modèles qui peuvent traiter
                des séquences de données dans les deux sens. Ils sont capables de capturer la dépendance entre les
                éléments d'une séquence, tant dans le passé que dans le futur. Dans le contexte de la détection
                d'objets, les Bi-RNN peuvent être utilisés pour capturer la relation entre les objets dans une image.
                Par exemple, un Bi-RNN peut être utilisé pour déterminer si deux objets sont proches l'un de l'autre, ou
                s'ils sont de la même classe.</p>
            <ul>
                <li><b>Génération de propositions de régions</b> : Une étape préliminaire consiste à générer un ensemble
                    de propositions de régions, qui sont des régions de l'image qui pourraient contenir un objet. Cette
                    étape est généralement effectuée en utilisant un algorithme bottom-up, tel que Selective Search.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">87
                <a class="prev" href="#slide86"></a>
                <a class="next" href="#slide88"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide88">
        <div class="header">
            <h1>3.6. Réseaux de neurones récurrents convolutifs bidirectionnels </h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Bi-RCNN [Cai 2016]</h2>
            <ul>
                <li><b>Extraction de caractéristiques</b> : Pour chaque proposition de région, un CNN est utilisé pour
                    extraire des caractéristiques. Ces caractéristiques sont ensuite transmises à un Bi-RNN.</li>
                <li><b>Classification </b> : Enfin, le Bi-RNN utilise les caractéristiques extraites pour classer la
                    proposition de région en tant qu'objet ou non.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">88
                <a class="prev" href="#slide87"></a>
                <a class="next" href="#slide89"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide89">
        <div class="header">
            <h1>3.6. Réseaux de neurones récurrents convolutifs bidirectionnels </h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Bi-RCNN [Cai 2016]</h2>
            <p>Bi-RCNN est une méthode prometteuse pour améliorer la précision de la détection d'objets. Elle a été
                utilisée avec succès dans une variété de tâches, telles que la détection de personnes, la détection de
                véhicules et la détection de visages.</p>
            <ul>
                <li><b>Détection de personnes</b> : Bi-RCNN peut être utilisé pour capturer la relation entre les
                    différentes parties du corps. Par exemple, Bi-RCNN peut être utilisé pour déterminer si les jambes
                    d'une personne sont proches l'une de l'autre, ou si les bras d'une personne sont croisés.</li>
                <li><b>Détection de véhicules</b> : Bi-RCNN peut être utilisé pour capturer la relation entre les
                    différents composants du véhicule. Par exemple, Bi-RCNN peut être utilisé pour déterminer si les
                    phares d'une voiture sont allumés, ou si les roues d'une voiture sont tournantes.</li>
                <li><b>Détection de visages</b> : Bi-RCNN peut être utilisé pour capturer la relation entre les
                    différents traits du visage. Par exemple, Bi-RCNN peut être utilisé pour déterminer si les yeux
                    d'une personne sont ouverts, ou si la bouche d'une personne est souriante.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">89
                <a class="prev" href="#slide88"></a>
                <a class="next" href="#slide90"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide90">
        <div class="header">
            <h1>Références</h1>
        </div>
        <div class="content">
            <h1>Articles de recherche</h1>
            <ul>
                <li>[Aly 2005] Aly, Mohamed. Survey on Multiclass Classification Methods. 2005.</li>
                <li>[Cai 2016] Cai, Rui, et al. « Bidirectional Recurrent Convolutional Neural Network for Relation
                    Classification ». Proceedings of the 54th Annual Meeting of the Association for Computational
                    Linguistics (Volume 1: Long Papers), édité par Katrin Erk et Noah A. Smith, Association for
                    Computational Linguistics, 2016, p. 756‑65. ACLWeb, https://doi.org/10.18653/v1/P16-1072.</li>
                <li>[Girshick 2014] Girshick, Ross, et al. Rich feature hierarchies for accurate object detection and
                    semantic segmentation. arXiv:1311.2524, arXiv, 22 octobre 2014. arXiv.org,
                    https://doi.org/10.48550/arXiv.1311.2524.</li>
                <li>[Jaakkola 2019] Jaakkola, H., et al. “Artificial Intelligence Yesterday, Today and Tomorrow.” 2019
                    42nd International Convention on Information and Communication Technology, Electronics and
                    Microelectronics (MIPRO), 2019, pp. 860–67. IEEE
                    Xplore
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">90
                <a class="prev" href="#slide89"></a>
                <a class="next" href="#slide91"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide91">
        <div class="header">
            <h1>Références</h1>
        </div>
        <div class="content">
            <h1>Articles de recherche</h1>
            <ul>
                <li>[Krizhevsky 2012] Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with deep
                    convolutional neural networks. Advances in neural information processing systems. 2012;25.</li>
                <li>[Pan 2016] Pan, Yunhe, “Heading toward Artificial Intelligence 2.0.” Engineering, vol. 2, no. 4,
                    Dec. 2016, pp. 409–13. www.sciencedirect.com,</li>
                <li>[Simonyani 2015] Simonyani K., Zisserman A., Very Deep Convolutional Networks for Large-Scale Image
                    Recognition. International Conference on Learning Representations, 2015 </li>
                <li>[Wang 2020] Wang, Hongbo, et al. « A Comprehensive Overview of Person Re-Identification Approaches
                    ». IEEE Access, vol. 8, 2020, p. 45556‑83. IEEE Xplore, https://doi.org/10.1109/ACCESS.2020.2978344.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">91
                <a class="prev" href="#slide90"></a>
                <a class="next" href="#slide92"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide92">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Web</h1>
            <ul>
                <li><a href="https://en.wikipedia.org/wiki/Perceptron">https://en.wikipedia.org/wiki/Perceptron</a></li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Multiclass_classification">https://en.wikipedia.org/wiki/Multiclass_classification</a>
                </li>
                <li><a href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a></li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Multilayer_perceptron">https://en.wikipedia.org/wiki/Multilayer_perceptron</a>
                </li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
                </li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Recurrent_neural_network">https://en.wikipedia.org/wiki/Recurrent_neural_network</a>
                </li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Long_short-term_memory">https://en.wikipedia.org/wiki/Long_short-term_memory</a>
                </li>
                <li><a
                        href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html</a>
                </li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Activation_function">https://en.wikipedia.org/wiki/Activation_function</a>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">92
                <a class="prev" href="#slide91"></a>
                <a class="next" href="#slide93"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide93">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Web</h1>
            <ul>
                <li>Réglage des hyperparamètres avec le tableau de bord HParams
                    <a
                        href="https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams?hl=fr">https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams?hl=fr</a>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">93
                <a class="prev" href="#slide92"></a>
                <a class="next" href="#slide94"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide94">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Couleurs</h1>
            <ul>
                <li><a href="https://material.io/color/">Color Tool - Material Design</a></li>
            </ul>
            <h1>Images</h1>
            <ul>
                <li><a href="https://commons.wikimedia.org/">Wikimedia Commons</a></li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">94
                <a class="prev" href="#slide93"></a>
            </div>
        </div>
    </section>

    <script>
        function changeCurrentURLSlideNumber(isIncrement) {
            url = window.location.href;
            position = url.indexOf("#slide");
            if (position != -1) { // Not on the first page
                slideIdString = url.substr(position + 6);
                if (!Number.isNaN(slideIdString)) {
                    slideId = parseInt(slideIdString);
                    if (isIncrement) {
                        if (slideId < 94) {
                            slideId = slideId + 1;
                        }
                    } else {
                        if (slideId > 1) {
                            slideId = slideId - 1;
                        }
                    }
                    /* regexp */
                    url = url.replace(/#slide\d+/g, "#slide" + slideId);
                    window.location.href = url;
                }
            } else {
                window.location.href = url + "#slide2";
            }
        }
        document.onkeydown = function (event) {

            event.preventDefault();
            /* This will ensure the default behavior of
                                                            page scroll behaviour (up, down, right, left)*/

            event = event || window.event;
            /*Codes de la touche sur le clavier: 37, 38, 39, 40*/
            if (event.keyCode == '37') {
                // left
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '38') {
                // up
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '39') {
                // right
                changeCurrentURLSlideNumber(true);
            } else if (event.keyCode == '40') {
                // down
                changeCurrentURLSlideNumber(true);
            }
        }
        document.body.onmouseup = function (event) {
            event = event || window.event;
            event.preventDefault();
            changeCurrentURLSlideNumber(true);
        }
    </script>
</body>

</html>
