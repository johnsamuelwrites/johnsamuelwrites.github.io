<html>

<head>
    <meta charset="utf-8" />
    <title>Apprentissage machine (2024-2025): Cours: John Samuel</title>
    <link rel="shortcut icon" href="../../../../../images/logo/favicon.png" />
    <style type="text/css">
        body {
            height: 100%;
            width: 100%;
            background-color: white;
            margin: 0;
            overflow: hidden;
            font-family: Arial;
        }

        .slide {
            height: 100%;
            width: 100%;
        }

        .content {
            height: 79%;
            width: 95vw;
            display: flex;
            line-height: 1.7em;
            flex-direction: column;
            align-items: flex-start;
            margin: 0 auto;
            color: #000000;
            text-align: left;
            padding-left: 1.5vmax;
            padding-top: 1.5vmax;
            overflow-x: auto;
            font-size: 2.8vmin;
            flex-wrap: wrap;
        }

        .codeexample {
            background-color: #eeeeee;
        }

        /*
generated by Pygments <https://pygments.org/>
Copyright 2006-2023 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
*/
        pre {
            line-height: 125%;
        }

        td.linenos .normal {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        td.linenos .special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos.special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        body .hll {
            background-color: #ffffcc
        }

        body {
            background: #f8f8f8;
        }

        body .c {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment */
        body .err {
            border: 1px solid #FF0000
        }

        /* Error */
        body .k {
            color: #008000;
            font-weight: bold
        }

        /* Keyword */
        body .o {
            color: #666666
        }

        /* Operator */
        body .ch {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Hashbang */
        body .cm {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Multiline */
        body .cp {
            color: #9C6500
        }

        /* Comment.Preproc */
        body .cpf {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.PreprocFile */
        body .c1 {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Single */
        body .cs {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Special */
        body .gd {
            color: #A00000
        }

        /* Generic.Deleted */
        body .ge {
            font-style: italic
        }

        /* Generic.Emph */
        body .gr {
            color: #E40000
        }

        /* Generic.Error */
        body .gh {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Heading */
        body .gi {
            color: #008400
        }

        /* Generic.Inserted */
        body .go {
            color: #717171
        }

        /* Generic.Output */
        body .gp {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Prompt */
        body .gs {
            font-weight: bold
        }

        /* Generic.Strong */
        body .gu {
            color: #800080;
            font-weight: bold
        }

        /* Generic.Subheading */
        body .gt {
            color: #0044DD
        }

        /* Generic.Traceback */
        body .kc {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Constant */
        body .kd {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Declaration */
        body .kn {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Namespace */
        body .kp {
            color: #008000
        }

        /* Keyword.Pseudo */
        body .kr {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Reserved */
        body .kt {
            color: #B00040
        }

        /* Keyword.Type */
        body .m {
            color: #666666
        }

        /* Literal.Number */
        body .s {
            color: #BA2121
        }

        /* Literal.String */
        body .na {
            color: #687822
        }

        /* Name.Attribute */
        body .nb {
            color: #008000
        }

        /* Name.Builtin */
        body .nc {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Class */
        body .no {
            color: #880000
        }

        /* Name.Constant */
        body .nd {
            color: #AA22FF
        }

        /* Name.Decorator */
        body .ni {
            color: #717171;
            font-weight: bold
        }

        /* Name.Entity */
        body .ne {
            color: #CB3F38;
            font-weight: bold
        }

        /* Name.Exception */
        body .nf {
            color: #0000FF
        }

        /* Name.Function */
        body .nl {
            color: #767600
        }

        /* Name.Label */
        body .nn {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Namespace */
        body .nt {
            color: #008000;
            font-weight: bold
        }

        /* Name.Tag */
        body .nv {
            color: #19177C
        }

        /* Name.Variable */
        body .ow {
            color: #AA22FF;
            font-weight: bold
        }

        /* Operator.Word */
        body .w {
            color: #bbbbbb
        }

        /* Text.Whitespace */
        body .mb {
            color: #666666
        }

        /* Literal.Number.Bin */
        body .mf {
            color: #666666
        }

        /* Literal.Number.Float */
        body .mh {
            color: #666666
        }

        /* Literal.Number.Hex */
        body .mi {
            color: #666666
        }

        /* Literal.Number.Integer */
        body .mo {
            color: #666666
        }

        /* Literal.Number.Oct */
        body .sa {
            color: #BA2121
        }

        /* Literal.String.Affix */
        body .sb {
            color: #BA2121
        }

        /* Literal.String.Backtick */
        body .sc {
            color: #BA2121
        }

        /* Literal.String.Char */
        body .dl {
            color: #BA2121
        }

        /* Literal.String.Delimiter */
        body .sd {
            color: #BA2121;
            font-style: italic
        }

        /* Literal.String.Doc */
        body .s2 {
            color: #BA2121
        }

        /* Literal.String.Double */
        body .se {
            color: #AA5D1F;
            font-weight: bold
        }

        /* Literal.String.Escape */
        body .sh {
            color: #BA2121
        }

        /* Literal.String.Heredoc */
        body .si {
            color: #A45A77;
            font-weight: bold
        }

        /* Literal.String.Interpol */
        body .sx {
            color: #008000
        }

        /* Literal.String.Other */
        body .sr {
            color: #A45A77
        }

        /* Literal.String.Regex */
        body .s1 {
            color: #BA2121
        }

        /* Literal.String.Single */
        body .ss {
            color: #19177C
        }

        /* Literal.String.Symbol */
        body .bp {
            color: #008000
        }

        /* Name.Builtin.Pseudo */
        body .fm {
            color: #0000FF
        }

        /* Name.Function.Magic */
        body .vc {
            color: #19177C
        }

        /* Name.Variable.Class */
        body .vg {
            color: #19177C
        }

        /* Name.Variable.Global */
        body .vi {
            color: #19177C
        }

        /* Name.Variable.Instance */
        body .vm {
            color: #19177C
        }

        /* Name.Variable.Magic */
        body .il {
            color: #666666
        }

        /* Literal.Number.Integer.Long */


        .content h1,
        h2,
        h3,
        h4 {
            color: #1B80CF;
        }

        .content .topichighlight {
            background-color: #78002E;
            color: #FFFFFF;
        }

        .content .topicheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 2vmax 2vmax 0%;
            height: 4vmax;
            line-height: 4vmax;
            padding-left: 1vmax;
            margin: 0.1vmax;
            width: 50%;
            margin-bottom: 1vmax;
        }

        .content .flexcontent {
            display: flex;
            overflow-y: auto;
            font-size: 2.8vmin;
            flex-wrap: wrap;
        }

        .content .gridcontent {
            display: grid;
            grid-template-columns: auto auto auto auto;
            grid-column-gap: 0px;
            grid-row-gap: 0px;
            grid-gap: 0px;
        }

        .content .topicsubheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 1.5vmax 1.5vmax 0%;
            height: 3vmax;
            margin: 0.1vmax;
            font-size: 90%;
            line-height: 3vmax;
            padding-left: 1vmax;
            width: 40%;
            margin-bottom: 1vmax;
        }

        .content table {
            color: #000000;
            font-size: 100%;
            width: 100%;
        }

        .content a:link,
        .content a:visited {
            color: #1B80CF;
            text-decoration: none;
        }

        .content th {
            color: #FFFFFF;
            background-color: #1B80CF;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
            font-size: 120%;
            padding: 15px;
        }

        .content figure {
            max-width: 90%;
            max-height: 90%;
        }

        .content .fullwidth img {
            max-width: 90%;
            max-height: 90%;
        }

        .content figure img {
            max-width: 50vmin;
            max-height: 50vmin;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        .content figure figcaption {
            max-width: 90%;
            max-height: 90%;
            margin: 0.1vmax;
            font-size: 90%;
            text-align: center;
            padding: 0.5vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content td {
            color: #000000;
            width: 8%;
            padding-left: 3vmax;
            padding-top: 1vmax;
            padding-bottom: 1vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content li {
            line-height: 1.7em;
        }

        .header {
            color: #ffffff;
            background-color: #00549d;
            height: 5vmax;
        }

        .header h1 {
            text-align: center;
            vertical-align: middle;
            font-size: 3vmax;
            line-height: 4vmax;
            margin: 0;
        }

        .footer {
            height: 3vmax;
            line-height: 3vmax;
            vertical-align: middle;
            color: #ffffff;
            background-color: #00549d;
            margin: 0;
            padding: .3vmax;
            overflow: hidden;
        }

        .footer .contact {
            float: left;
            color: #ffffff;
            text-align: left;
            font-size: 3.2vmin;
        }

        .footer .navigation {
            float: right;
            text-align: right;
            width: 8vw;
            font-size: 3vmin;
        }

        .footer .navigation .next,
        .prev {
            font-size: 3vmin;
            color: #ffffff;
            text-decoration: none;
        }

        .footer .navigation .next::after {
            content: "| >";
        }

        .footer .navigation .prev::after {
            content: "< ";
        }


        @media (max-width: 640px),
        screen and (orientation: portrait) {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .slide {
                height: 100%;
                width: 100%;
            }

            .content {
                width: 100%;
                height: 92%;
                display: flex;
                flex-direction: row;
                text-align: left;
                padding: 1vw;
                line-height: 3.8vmax;
                font-size: 1.8vmax;
                flex-wrap: wrap;
            }

            .content .topicheading {
                width: 90%;
            }

            .content h1,
            h2,
            h3,
            h4 {
                width: 100%;
            }

            .content figure img {
                max-width: 80vmin;
                max-height: 50vmin;
            }

            .content figure figcaption {
                max-width: 90%;
                max-height: 90%;
            }
        }

        @media print {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .content {
                font-size: 2.8vmin;
            }

            .content .flexcontent {
                font-size: 2.5vmin;
            }
        }
    </style>
    <script src="../../2021/MachineLearning/tex-mml-chtml.js" id="MathJax-script"></script>
</head>

<body>
    <section class="slide" id="slide1">
        <div class="header">
        </div>
        <div class="content">
            <h1 style="font-size:2.5vw">Apprentissage machine</h1>
            <p><b>John Samuel</b><br /> CPE Lyon<br /><br />
                <b>Année</b>: 2024-2025<br />
                <b>Courriel</b>: john(dot)samuel(at)cpe(dot)fr<br /><br />
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img
                        alt="Creative Commons License" style="border-width:0"
                        src="../../../../../en/teaching/courses/2017/C/88x31.png" /></a>
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">1

                <a class="next" href="#slide2"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide2">
        <div class="header">
            <h1>2.1. Introduction à l'apprentissage machine</h1>
        </div>
        <div class="content">
            <p><b>L'apprentissage machine</b>, également connu sous le nom de machine learning (ML), est un domaine de
                l'intelligence artificielle (IA) qui se concentre sur le développement de techniques permettant aux
                ordinateurs d'apprendre à partir de données. L'objectif principal de l'apprentissage machine est de
                permettre aux systèmes informatiques de prendre des décisions ou de réaliser des tâches sans être
                explicitement programmés, en s'appuyant sur des <b>modèles</b> et des <b>motifs appris à partir des
                    données</b>.</p>
            <h4>Principes fondamentaux de l'apprentissage machine</h4>
            <ul>
                <li><b>Données d'entraînement</b> : L'apprentissage machine commence par des données. Ces données,
                    appelées données d'entraînement, sont utilisées pour enseigner au modèle les modèles et les
                    relations dans lesquels il doit identifier.</li>
                <li><b>Modèles</b> : Les modèles en apprentissage machine sont des représentations mathématiques qui
                    capturent les relations entre les différentes caractéristiques des données. Ces modèles sont
                    entraînés à partir des données d'entraînement et sont capables de généraliser pour faire des
                    prédictions sur de nouvelles données non vues.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">2
                <a class="prev" href="#slide1"></a>
                <a class="next" href="#slide3"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide3">
        <div class="header">
            <h1>2.1. Introduction à l'apprentissage machine </h1>
        </div>
        <div class="content">
            <h4>Principes fondamentaux de l'apprentissage machine</h4>
            <ul>
                <li><b>Entraînement et apprentissage</b> : L'entraînement d'un modèle implique de l'exposer aux données
                    d'entraînement, lui permettant d'ajuster ses paramètres pour minimiser les erreurs de prédiction.
                    L'apprentissage se produit lorsque le modèle améliore sa capacité à faire des prédictions précises.
                </li>
                <li><b>Validation et test</b> : Après l'entraînement, le modèle est évalué sur des données de validation
                    et de test pour s'assurer qu'il généralise bien aux données non vues. Cela aide à éviter le
                    surajustement, où le modèle apprend trop spécifiquement les données d'entraînement et ne peut pas
                    généraliser correctement.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">3
                <a class="prev" href="#slide2"></a>
                <a class="next" href="#slide4"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide4">
        <div class="header">
            <h1>2.1.1. Positionnement de l'apprentissage machine</h1>
        </div>
        <div class="content">
            <p>L'apprentissage machine occupe une place centrale dans le paysage technologique actuel et a un impact
                significatif dans divers domaines. </p>
            <ul>
                <li><b>Intelligence Artificielle (IA)</b> : L'apprentissage machine est une composante essentielle de
                    l'intelligence artificielle. Il permet aux systèmes informatiques de tirer des conclusions,
                    d'apprendre à partir d'expériences passées et d'améliorer leur performance sans être explicitement
                    programmés.</li>
                <li><b>Informatique et Technologie</b> : L'apprentissage machine est largement utilisé dans les
                    applications technologiques, y compris la vision par ordinateur, la reconnaissance vocale, la
                    traduction automatique, les chatbots, et diverses autres applications qui exploitent la capacité des
                    modèles à apprendre des données.</li>
                <li><b>Santé</b> : Dans le domaine de la santé, l'apprentissage machine est utilisé pour la prédiction
                    de maladies, l'analyse d'images médicales, la personnalisation des traitements, la découverte de
                    médicaments, et la gestion des dossiers médicaux électroniques.</li>
                <li><b>Finance</b> : Les institutions financières utilisent l'apprentissage machine pour la détection de
                    fraudes, la prévision de tendances du marché, l'analyse de crédit, et l'optimisation des
                    portefeuilles d'investissement.</li>
                <li><b>Industrie</b> : Dans le secteur industriel, l'apprentissage machine est appliqué à la maintenance
                    prédictive, à l'optimisation de la chaîne d'approvisionnement, à la qualité de production, et à la
                    robotique.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">4
                <a class="prev" href="#slide3"></a>
                <a class="next" href="#slide5"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide5">
        <div class="header">
            <h1>2.1.2. Approches de l'apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Approches</h3>
            <ul>
                <li><b>Apprentissage supervisé</b> : Le modèle est entraîné sur un ensemble de données étiquetées où les
                    exemples d'entrée sont associés à des sorties désirées. Le modèle apprend à faire des prédictions
                    sur de nouvelles données en se basant sur ces associations.</li>
                <li><b>Apprentissage non supervisé</b> : Le modèle est exposé à des données non étiquetées et cherche à
                    découvrir des modèles, des structures ou des relations intrinsèques dans les données.</li>
                <li><b>Apprentissage semi-supervisé</b> : Une combinaison des deux précédents, utilisant à la fois des
                    données étiquetées et non étiquetées pour l'entraînement.</li>
                <li><b>Apprentissage par renforcement</b> : Le modèle apprend à prendre des décisions en interagissant
                    avec son environnement. Il reçoit des récompenses ou des pénalités en fonction de ses actions, ce
                    qui guide son apprentissage.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">5
                <a class="prev" href="#slide4"></a>
                <a class="next" href="#slide6"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide6">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation</h3>
            <ul>
                <li><b>Vecteur euclidien</b>:
                    <ul>
                        <li>Un vecteur euclidien est un objet géométrique caractérisé par sa magnitude (longueur) et sa
                            direction. </li>
                        <li>Les vecteurs euclidiens sont couramment utilisés pour représenter des données sous forme de
                            points dans un espace multidimensionnel, où chaque dimension correspond à une
                            caractéristique ou une variable.</li>
                    </ul>
                </li>
                <li><b>Espace vectoriel</b>:
                    <ul>
                        <li>Un espace vectoriel est une collection de vecteurs qui peuvent être additionnés entre eux et
                            multipliés par des nombres (scalaires).</li>
                    </ul>
                </li>
                <li><b>Vecteur de caractéristiques (features)</b>:
                    <ul>
                        <li>Un vecteur de caractéristiques est un vecteur n-dimensionnel qui représente les
                            caractéristiques ou les attributs d'une entité. </li>
                    </ul>
                </li>
                <li><b>Espace de caractéristiques</b>:
                    <ul>
                        <li>L'espace de caractéristiques est l'espace vectoriel associé aux vecteurs de
                            caractéristiques.</li>
                        <li>Chaque dimension de cet espace représente une caractéristique particulière, et les vecteurs
                            sont utilisés pour positionner les données dans cet espace en fonction de leurs
                            caractéristiques.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">6
                <a class="prev" href="#slide5"></a>
                <a class="next" href="#slide7"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide7">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Exemples de caractéristiques</h3>
            <ul>
                <li><b>Images</b>: Dans le contexte des images, les vecteurs de caractéristiques peuvent être construits
                    à partir des valeurs des pixels. Chaque pixel peut être considéré comme une dimension, et un vecteur
                    de caractéristiques contiendra les valeurs de tous les pixels, permettant ainsi de représenter une
                    image sous forme de vecteur.</li>
                <li><b>Textes</b>: Pour les textes, les vecteurs de caractéristiques sont souvent construits à partir de
                    la fréquence d'apparition des mots, des phrases, ou des tokens dans un document. Cela permet de
                    représenter le contenu textuel en utilisant des valeurs numériques, ce qui est essentiel pour
                    l'analyse de texte et la recherche d'informations.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">7
                <a class="prev" href="#slide6"></a>
                <a class="next" href="#slide8"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide8">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation</h1>
            <ul>
                <li><b>Construction de caractéristiques<sup>1</sup></b>:
                    <ul>
                        <li>La construction de caractéristiques consiste à créer de nouvelles variables ou attributs à
                            partir de celles déjà présentes dans les données.</li>
                        <li>Cette étape peut être cruciale pour améliorer les performances des modèles d'apprentissage
                            machine en introduisant des informations pertinentes et en éliminant du bruit.</li>
                    </ul>
                </li>
                <li><b>Opérateurs de construction pour les caractéristiques</b>
                    <ul>
                        <li>Les opérateurs de construction sont des fonctions ou des opérations mathématiques qui
                            permettent de créer de nouvelles caractéristiques à partir de celles existantes. </li>
                        <li>Parmi les opérateurs couramment utilisés, on trouve les opérateurs d'égalité (comparaisons),
                            les opérateurs arithmétiques (addition, soustraction, multiplication, division), les
                            opérateurs de tableau (min, max, moyenne, médiane, etc.), les fonctions de transformation,
                            etc.</li>
                    </ul>
                </li>
            </ul>
            <ol style="font-size:2vh">
                <li>https://en.wikipedia.org/wiki/Feature_vector</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">8
                <a class="prev" href="#slide7"></a>
                <a class="next" href="#slide9"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide9">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Exemple</h3>
            <ul>
                <li>Soit <b>Année de naissance</b> et <b>Année de décès</b> deux caractéristiques existantes.</li>
                <li>Une nouvelle caractéristique appelée <b>âge</b> est créée. <b>âge</b> = <b>Année de décès</b> -
                    <b>Année de naissance</b>
                </li>
            </ul>
            <p>La construction de caractéristiques est une étape essentielle dans le pipeline de prétraitement des
                données en apprentissage machine, car elle peut aider à rendre les données plus informatives pour les
                algorithmes d'apprentissage.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">9
                <a class="prev" href="#slide8"></a>
                <a class="next" href="#slide10"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide10">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <ul>
                    <li><b>Le nombre d'exemples d'entraînement (N)</b> : Cela représente la quantité d'exemples de
                        données que vous avez pour entraîner un modèle supervisé. Chaque exemple d'entraînement se
                        compose d'un vecteur de caractéristiques (x) et de son label (y).</li>
                    <li><b>L'espace de saisie des caractéristiques (X)</b> : C'est l'ensemble de toutes les combinaisons
                        possibles de vecteurs de caractéristiques qui peuvent être utilisées comme entrée pour le
                        modèle. Cet espace est défini par les caractéristiques que vous avez extraites des données.</li>
                    <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble de toutes les
                        valeurs possibles que peuvent prendre les étiquettes ou les labels. </li>
                    <li><b>Exemples d'entraînement (D)</b> : C'est votre ensemble de données d'entraînement, composé de
                        paires (x, y) où x est le vecteur de caractéristiques et y est le label correspondant.</li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">10
                <a class="prev" href="#slide9"></a>
                <a class="next" href="#slide11"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide11">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <ul>
                    <li><b>Objectif de l'algorithme d'apprentissage supervisé</b> : Il s'agit de trouver une fonction
                        (g) qui associe un vecteur de caractéristiques (x) à un label (y). L'ensemble des fonctions
                        possibles est appelé espace des hypothèses (G). L'objectif est de choisir la fonction (g) qui
                        minimise l'erreur de prédiction sur les exemples d'entraînement et généralise bien sur de
                        nouvelles données.</li>
                    <li><b>Fonction d'évaluation (F)</b> : Elle indique l'espace des fonctions d'évaluation utilisées
                        pour évaluer la performance des fonctions hypothétiques. L'objectif est de trouver la fonction
                        (g) qui renvoie la fonction d'évaluation (f) la plus élevée, c'est-à-dire celle qui donne les
                        prédictions les plus précises.</li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">11
                <a class="prev" href="#slide10"></a>
                <a class="next" href="#slide12"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide12">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <p>Cette formalisation est au cœur de l'apprentissage supervisé, où l'objectif est d'apprendre à partir
                    d'exemples étiquetés et de trouver une fonction qui puisse prédire de manière précise les étiquettes
                    pour de nouvelles données non vues.</p>
                <ul>
                    <li>Soit \(N\) le nombre d'exemples d'entraînement</li>
                    <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                    <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                    <li>Soit \({(x_1, y_1),...,(x_N, y_N)}\) les \(N\) exemples d'entraînement, où
                        <ul>
                            <li>\(x_i\) est le vecteur de caractéristiques de <i>i<sup>ème</sup></i> exemple
                                d'entraînement.
                            </li>
                            <li>\(y_i\) est son label.</li>
                        </ul>
                    </li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">12
                <a class="prev" href="#slide11"></a>
                <a class="next" href="#slide13"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide13">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <ul>
                    <li>L'objectif de l'algorithme d'apprentissage supervisé est de trouver \(g: X &#8594; Y\), où
                        <ul>
                            <li><i>g</i> est l'une des fonctions de l'ensemble des fonctions possibles <i>G</i> (espace
                                des
                                hypothèses)</li>
                        </ul>
                    </li>
                    <li><b>Fonction d'évaluation <i>F</i></b> indiquent l'espace des fonctions d'évaluation, où
                        <ul>
                            <li>\(f: X &#215; Y &#8594; R\) telle que <i>g</i> renvoie la fonction d'évaluation la plus
                                élevée.</li>
                        </ul>
                    </li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">13
                <a class="prev" href="#slide12"></a>
                <a class="next" href="#slide14"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide14">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage non supervisé</h1>
            <ul>
                <li><b>L'espace de saisie des caractéristiques (X)</b> : C'est l'ensemble de toutes les combinaisons
                    possibles de vecteurs de caractéristiques qui peuvent être utilisées comme entrée pour le modèle en
                    apprentissage non supervisé. Cet espace est défini par les caractéristiques que vous avez extraites
                    des données.</li>
                <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble des caractéristiques
                    de sortie potentielles. Contrairement à l'apprentissage supervisé, en apprentissage non supervisé, Y
                    ne consiste pas en des étiquettes ou des labels prédéfinis, mais plutôt en des transformations, des
                    représentations, ou des caractéristiques extraites des données d'entrée.</li>
                <li><b>Objectif de l'algorithme d'apprentissage non supervisé</b> : L'objectif est de trouver une
                    correspondance entre l'espace de saisie des caractéristiques (X) et l'espace des caractéristiques de
                    sortie (Y). Cela peut impliquer diverses tâches, telles que la réduction de la dimensionnalité, la
                    classification automatique de données non étiquetées, la détection d'anomalies, la segmentation, ou
                    la représentation latente des données.</li>
                <li><b>Mise en correspondance X → Y</b> : Cette mise en correspondance peut être réalisée de différentes
                    manières, selon la tâche d'apprentissage non supervisé spécifique. Par exemple, dans la réduction de
                    la dimensionnalité, X peut être une représentation à haute dimension des données, tandis que Y
                    représente la version réduite de ces données, souvent avec moins de dimensions.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">14
                <a class="prev" href="#slide13"></a>
                <a class="next" href="#slide15"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide15">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage non supervisé</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>L'objectif de l'algorithme d'apprentissage non supervisé est
                    <ul>
                        <li>trouver la mise en correspondance \(X &#8594; Y\)</li>
                    </ul>
                </li>
            </ul>
            <p>L'apprentissage non supervisé est utilisé pour explorer et découvrir des modèles, des structures ou des
                caractéristiques inhérentes aux données, sans l'utilisation d'étiquettes ou de labels préalables. Il est
                couramment utilisé dans des domaines tels que la clustering, l'analyse de composantes principales (PCA),
                l'analyse en composantes indépendantes (ICA), et bien d'autres.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">15
                <a class="prev" href="#slide14"></a>
                <a class="next" href="#slide16"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide16">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li><b>L'espace de saisie des caractéristiques (X)</b> : Il s'agit de l'ensemble de toutes les
                    combinaisons possibles de vecteurs de caractéristiques qui peuvent être utilisés comme entrée pour
                    le modèle en apprentissage semi-supervisé.</li>
                <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble des caractéristiques
                    de sortie potentielles, mais contrairement à l'apprentissage supervisé, il n'est pas nécessairement
                    constitué d'étiquettes ou de labels prédéfinis.</li>
                <li><b>Ensemble d'exemples d'exercices étiquetés (l)</b> : Cela correspond à un sous-ensemble d'exemples
                    qui ont été annotés ou étiquetés avec des valeurs de sortie connues.</li>
                <li><b>Ensembles des vecteurs de caractéristiques non étiquetées (u)</b> : Il s'agit des exemples non
                    étiquetés, où les valeurs de sortie ne sont pas connues.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">16
                <a class="prev" href="#slide15"></a>
                <a class="next" href="#slide17"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide17">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li><b>Objectif de l'algorithme d'apprentissage semi-supervisé</b> : L'objectif principal est de trouver
                    des étiquettes correctes pour les exemples non étiquetés (apprentissage transductif), ainsi que de
                    trouver la bonne mise en correspondance entre les caractéristiques d'entrée et les caractéristiques
                    de sortie (apprentissage inductif).
                    <ul>
                        <li><b>Apprentissage transductif</b> : Il s'agit de trouver des étiquettes correctes pour les
                            exemples non étiquetés. Cela revient à prédire les valeurs de sortie pour les exemples non
                            étiquetés sans nécessairement chercher à généraliser à de nouvelles données.</li>
                        <li><b>Apprentissage inductif</b> : Cela concerne la recherche de la bonne mise en
                            correspondance entre les vecteurs de caractéristiques d'entrée et les caractéristiques de
                            sortie. Cela peut inclure la généralisation à de nouvelles données en utilisant le modèle
                            appris.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">17
                <a class="prev" href="#slide16"></a>
                <a class="next" href="#slide18"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide18">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>Soit \({(x_1, y_1),...,(x_l, y_l)}\) l'ensemble d'exemples d'exercices étiquetés</li>
                <li>Soit \({x_{l+1},...,x_{l+u}}\) sont les \(u\) ensembles des vecteurs de caractéristiques non
                    étiquetées de \(X\).</li>
                <li>L'objectif de l'algorithme d'apprentissage semi-supervisé est de faire
                    <ul>
                        <li><b>l'apprentissage transductif</b>, c'est-à-dire trouver des étiquettes correctes pour
                            \({x_{l+1},...,x_{l+u}}\).</li>
                        <li><b>l'apprentissage inductif</b>, c'est-à-dire trouver la bonne mise en correspondance \(X
                            &#8594; Y\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">18
                <a class="prev" href="#slide17"></a>
                <a class="next" href="#slide19"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide19">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Classification: Définition formelle</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>L'objectif de l'algorithme de classification (ou classificateur) est de trouver \({(x_1,
                    y_1),...,(x_l, y_k)}\), c'est-à-dire l'attribution d'une étiquette connue à chaque vecteur de
                    caractéristique d'entrée, où
                    <ul>
                        <li>\(x_i &#8712; X \)</li>
                        <li>\(y_i &#8712; Y \)</li>
                        <li>\(|X| = l \)</li>
                        <li>\(|Y| = k \)</li>
                        <li>\(l &gt;= k\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">19
                <a class="prev" href="#slide18"></a>
                <a class="next" href="#slide20"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide20">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classificateurs</h3>
            <ul>
                <li>Algorithme de classification</li>
                <li>Deux types de classificateurs:
                    <ul>
                        <li><b>Classificateurs binaires</b> attribue un objet à l'une des deux classes</li>
                        <li><b>Classificateurs multiclasses</b> attribue un objet à une ou plusieurs classes</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">20
                <a class="prev" href="#slide19"></a>
                <a class="next" href="#slide21"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide21">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Classification binaire</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/binaryclassifier.svg"
                    height="400px" />
                <figcaption>Classification binaire</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">21
                <a class="prev" href="#slide20"></a>
                <a class="next" href="#slide22"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide22">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Linear Classificateurs</h3>
            <ul>
                <li>Fonction linéaire attribuant un score à chaque catégorie possible en combinant le vecteur de
                    caractéristiques d'une instance avec un vecteur de poids, en utilisant un produit de points.</li>
                <li>Formalisation :
                    <ul>
                        <li>Soit <i><b>X</b></i> être l'espace de saisie des caractéristiques et <i><b>x</b><sub>i</sub>
                                &#8712; <b>X</b></i></li>
                        <li>Soit <i><b>&#946;</b><sub>k</sub></i> un vecteur de poids pour la catégorie <i>k</i></li>
                        <li><i>score(<b>x</b><sub>i</sub>, k) = <b>x</b><sub>i</sub>.<b>&#946;</b><sub>k</sub></i>,
                            score pour l'attribution de la catégorie <i>k</i> à l'instance <i><b>x</b><sub>i</sub></i>.
                            La catégorie qui donne le score le plus élevé est
                            attribuée à la catégorie de l'instance.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">22
                <a class="prev" href="#slide21"></a>
                <a class="next" href="#slide23"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide23">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>Dans le contexte de la classification en apprentissage machine, l'évaluation des performances d'un modèle
                implique la compréhension de différents types de prédictions qu'il peut faire par rapport à la réalité.
                Les vrais positifs (VP) et les vrais négatifs (VN) sont deux de ces éléments.</p>
            <ul>
                <li><b>Vrais Positifs (VP/TP)</b> : Les vrais positifs représentent les cas où le modèle prédit
                    correctement la classe positive. En d'autres termes, il a correctement identifié les exemples qui
                    appartiennent réellement à la classe que le modèle essaie de prédire.</li>
                <li><b>Vrais Négatifs (VN/FN)</b> : Les vrais négatifs représentent les cas où le modèle prédit
                    correctement la classe négative. Cela signifie qu'il a correctement identifié les exemples qui
                    n'appartiennent pas à la classe que le modèle essaie de prédire.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">23
                <a class="prev" href="#slide22"></a>
                <a class="next" href="#slide24"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide24">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/positivenegative.svg" width="400vw" />
                <figcaption>Les vrais positifs et les vrais négatifs</figcaption>
            </figure>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" width="400vw" />
                <figcaption>Précision et rappel</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">24
                <a class="prev" href="#slide23"></a>
                <a class="next" href="#slide25"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide25">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>Soit</p>
            <ul>
                <li><i>tp</i>: nombre de vrais postifs</li>
                <li><i>fp</i>: nombre de faux positifs</li>
                <li><i>fn</i>: nombre de faux négatifs</li>
            </ul>
            <figure class="gridcontent">
                <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" height="400px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">25
                <a class="prev" href="#slide24"></a>
                <a class="next" href="#slide26"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide26">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>La <b>précision</b> mesure la proportion de prédictions positives faites par le modèle qui étaient
                <b>effectivement correctes</b>, tandis que le <b>rappel</b> mesure la proportion d'exemples positifs
                réels qui ont été correctement identifiés par le modèle. Alors</p>
            <ul>
                <li>Précision \[p = \frac{tp}{(tp + fp)}\]</li>
                <li>Rappel (Recall) \[r = \frac{tp}{(tp + fn)}\]</i>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">26
                <a class="prev" href="#slide25"></a>
                <a class="next" href="#slide27"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide27">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>Le F1-score est la moyenne harmonique de la précision et du rappel. Il fournit une mesure globale de la
                performance d'un modèle de classification, tenant compte à la fois de la précision et du rappel. Il est
                particulièrement utile lorsque les classes sont déséquilibrées.</p>
            <ul>
                <li>F1-score \[f1 = 2 * \frac{(p * r)}{(p + r)}\]</li>
                <li>F1-score: meilleure valeur à 1 (précision et rappel parfaits) et pire à 0.</li>
            </ul>
            <p>Le F1-score tient compte à la fois des <b>erreurs de type I (faux positifs)</b> et des <b>erreurs de type
                    II (faux négatifs)</b>, fournissant ainsi une mesure équilibrée de la performance du modèle.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">27
                <a class="prev" href="#slide26"></a>
                <a class="next" href="#slide28"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide28">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <ul>
                <li>\(F_\beta\)-score utilise un facteur réel positif β, où β est choisi de telle sorte que le rappel
                    est considéré comme β fois plus important que la précision, est : </li>
                <li>\(F_\beta\)-score \[F_\beta = (1 + \beta^2) \cdot \frac{\mathrm{p} \cdot \mathrm{r}}{(\beta^2 \cdot
                    \mathrm{p}) + \mathrm{r}}\]</li>
                <li>Exemple: <b>\(F_2\) score</b>: Cette métrique est souvent utilisée dans des situations où le rappel
                    est jugé plus critique que la précision, par exemple, dans des tâches où la détection des exemples
                    positifs est particulièrement importante, même si cela entraîne un nombre plus élevé de faux
                    positifs.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">28
                <a class="prev" href="#slide27"></a>
                <a class="next" href="#slide29"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide29">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <p>Le \(F_2\)-score est souvent utilisé dans des domaines où le rappel est considéré comme plus critique que
                la précision. </p>
            <ul>
                <li><b>Détection de Maladies</b> : Dans le domaine médical, en particulier pour la détection de maladies
                    graves, le F2-score peut être utilisé pour évaluer la performance des modèles. Il est crucial
                    d'identifier correctement autant de cas positifs que possible, même si cela conduit à quelques faux
                    positifs.</li>
                <li><b>Sécurité et Détection d'Intrusion</b> : Lors de la détection d'intrusions dans les systèmes
                    informatiques, il est souvent plus important de minimiser les faux négatifs (intrusions manquées) au
                    profit de quelques faux positifs, d'où l'utilisation du F2-score.</li>
                <li><b>Recherche Biomédicale</b> : Dans des domaines de recherche biomédicale où la découverte de
                    certaines caractéristiques ou protéines spécifiques est critique, le F2-score peut être privilégié
                    pour s'assurer que ces éléments sont correctement identifiés.</li>
                <li><b>Prévision de Catastrophes Naturelles</b> : Lors de la prévision de catastrophes naturelles comme
                    les tremblements de terre ou les tsunamis, il est essentiel de minimiser les faux négatifs pour
                    garantir que le maximum d'avertissements est donné, même au prix de quelques alertes erronées.</li>
                <li><b>Recherche en Astronomie</b> : Dans la recherche astronomique, la découverte de nouveaux objets
                    célestes ou de phénomènes rares peut être cruciale. Le F2-score peut être utilisé pour évaluer les
                    performances des algorithmes de détection.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">29
                <a class="prev" href="#slide28"></a>
                <a class="next" href="#slide30"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide30">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Évaluation: matrice de confusion</h2>
            <p>La matrice de confusion est un outil essentiel dans l'évaluation des performances d'un système de
                classification. Elle fournit une vue détaillée des prédictions faites par le modèle par rapport aux
                classes réelles.</p>
            <ul>
                <li>Chaque ligne de la matrice représente les instances d'une classe prédite.</li>
                <li>Chaque colonne représente les instances d'une classe réelle.</li>
                <li>Toutes les prédictions correctes sont situées dans la diagonale du tableau.</li>
                <li>Les erreurs de prédiction sont représentées par des valeurs situées en dehors de la diagonale
                    principale.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">30
                <a class="prev" href="#slide29"></a>
                <a class="next" href="#slide31"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide31">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation: matrice de confusion</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix.png" height="400px" />
                <figcaption>Matrice de confusion pour un classificateur SVM pour les chiffres manuscrits (MNIST)
                </figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">31
                <a class="prev" href="#slide30"></a>
                <a class="next" href="#slide32"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide32">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation: matrice de confusion</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix1.png" height="400px" />
                <figcaption>Matrice de confusion pour un perceptron pour les chiffres manuscrits (MNIST)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">32
                <a class="prev" href="#slide31"></a>
                <a class="next" href="#slide33"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide33">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg"
                    height="400px" />
                <figcaption>Classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">33
                <a class="prev" href="#slide32"></a>
                <a class="next" href="#slide34"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide34">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse [Aly 2005]</h3>
            <ul>
                <li>Transformation en classification binaire
                    <ul>
                        <li>L'approche un contre le reste (Un contre tous)</li>
                        <li>L'approche un-contre-un</li>
                    </ul>
                </li>
                <li>Extension de la classification binaire
                    <ul>
                        <li>Réseaux de neurones</li>
                        <li>k-voisins les plus proches</li>
                    </ul>
                </li>
                <li>la classification hiérarchique.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">34
                <a class="prev" href="#slide33"></a>
                <a class="next" href="#slide35"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide35">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg"
                    height="400px" />
                <figcaption>Classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">35
                <a class="prev" href="#slide34"></a>
                <a class="next" href="#slide36"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide36">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest (One-vs.-all) strategy</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsall.svg" height="350px" />
                <figcaption>La strategie un-contre le rest pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">36
                <a class="prev" href="#slide35"></a>
                <a class="next" href="#slide37"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide37">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <ul>
                <li>Entraîner un seul classificateur par classe, avec les échantillons de cette classe comme
                    échantillons positifs et tous les autres comme négatifs. </li>
                <li>Chaque classificateur produit un score de confiance réel pour sa décision</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsall.svg" height="200px" />
                <figcaption>La strategie un-contre le rest pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">37
                <a class="prev" href="#slide36"></a>
                <a class="next" href="#slide38"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide38">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <ul>
                <li>Entrées :
                    <ul>
                        <li>\(L\), un apprenant (algorithme d'entraînement pour les classificateurs binaires)</li>
                        <li>échantillons \(X\)</li>
                        <li>étiquettes \(y\), où \(y_i ∈ \{1,..,K \} \) est l'étiquette de l'échantillon \(X_i\)
                    </ul>
                </li>
                <li>Sortie :
                    <ul>
                        <li>une liste de classificateurs \(f_k\), où \(k ∈ \{1,..,K \} \)
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">38
                <a class="prev" href="#slide37"></a>
                <a class="next" href="#slide39"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide39">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <p>Prendre des décisions signifie appliquer tous les classificateurs à un échantillon invisible x et prédire
                l'étiquette k pour laquelle le classificateur correspondant rapporte le score de confiance le plus élevé
                : \[\hat{y} = \underset{k \in
                \{1 \ldots K\}}{\arg\!\max}\; f_k(x)\]</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">39
                <a class="prev" href="#slide38"></a>
                <a class="next" href="#slide40"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide40">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-one strategy</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsone.svg" height="300px" />
                <figcaption>La strategie un-contre-un pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">40
                <a class="prev" href="#slide39"></a>
                <a class="next" href="#slide41"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide41">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-one strategy</h3>
            <li>nécessite l'entraînement des \(\frac{K (K - 1)}{2}\) classificateurs binaires</li>
            <li>chaque classificateur reçoit les échantillons d'une paire de classes du jeu de formation original, et
                doit apprendre à distinguer ces deux classes.</li>
            <li>Au moment de la prédiction, un système de vote est appliqué : tous les \(\frac{K (K - 1)}{2}\)
                classificateurs sont appliqués à un échantillon non vu et la classe qui a obtenu le plus grand nombre de
                prédictions est prédite par le classificateur
                combiné.
            </li>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsone.svg" width="200vw" />
                <figcaption>La strategie un-contre-un pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">41
                <a class="prev" href="#slide40"></a>
                <a class="next" href="#slide42"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide42">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Neurones biologiques</h2>
            <figure>
                <img src="../../2021/MachineLearning/Neuron3.png" height="350px" />
                <figcaption>Neurone biologique<sup>1</sup></figcaption>
            </figure>
            <ol style="font-size:2vh">
                <li>https://en.wikipedia.org/wiki/File:Neuron3.png</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">42
                <a class="prev" href="#slide41"></a>
                <a class="next" href="#slide43"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide43">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Introduction</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Colored_neural_network.svg" />
                <figcaption>Réseaux de neurones artificiels</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">43
                <a class="prev" href="#slide42"></a>
                <a class="next" href="#slide44"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide44">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseau de neurones</h2>
            <p>Les réseaux de neurones sont couramment utilisés dans le domaine de l'apprentissage machine, en
                particulier dans des tâches telles que la classification, la régression, la reconnaissance d'images, le
                traitement du langage naturel, et bien d'autres. Un réseau de neurones artificiels est une collection
                d'unités interconnectées appelées neurones artificiels. Ces réseaux sont inspirés de la structure du
                cerveau biologique</p>
            <ul>
                <li><b>Connexions</b> : Chaque connexion entre les neurones, similaire aux synapses dans le cerveau
                    biologique, peut transmettre un signal aux autres neurones.</li>
                <li><b>Transmission de signal</b> : Un neurone artificiel reçoit un signal, le traite à l'aide d'une
                    fonction non linéaire, et peut ensuite transmettre un signal aux neurones qui lui sont connectés.
                </li>
                <li><b>Fonction d'activation</b> : La sortie de chaque neurone est calculée par une fonction non
                    linéaire appliquée à la somme pondérée de ses entrées. Cette fonction d'activation introduit une
                    non-linéarité dans le réseau, permettant de modéliser des relations complexes.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">44
                <a class="prev" href="#slide43"></a>
                <a class="next" href="#slide45"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide45">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseau de neurones</h2>
            <ul>
                <li><b>Poids ajustables</b> : Les neurones et les connexions ont généralement des poids qui sont ajustés
                    au fur et à mesure de l'apprentissage. Ces poids déterminent l'importance relative des différentes
                    entrées pour chaque neurone.</li>
                <li><b>Ajustement des poids</b> : Les poids peuvent être ajustés pour augmenter ou diminuer la force du
                    signal au niveau d'une connexion, influençant ainsi la contribution de cette connexion aux calculs
                    du réseau.</li>
                <li><b>Seuil</b> : Les neurones peuvent avoir un seuil, de sorte qu'un signal n'est envoyé que si la
                    somme pondérée de ses entrées dépasse ce seuil. Cela permet au réseau de moduler sa sensibilité aux
                    entrées.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">45
                <a class="prev" href="#slide44"></a>
                <a class="next" href="#slide46"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide46">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Les couches</h2>
            <p>Les neurones sont organisés en couches. Il existe généralement trois types de couches dans un réseau de
                neurones :</p>
            <ul>
                <li><b>Couche d'Entrée (Input Layer)</b> : Cette couche reçoit les signaux initiaux ou les données en
                    entrée. Chaque neurone dans cette couche représente une caractéristique ou une variable d'entrée.
                </li>
                <li><b>Couches Cachées (Hidden Layers)</b> : Ces couches effectuent des transformations non linéaires
                    sur les entrées. Elles sont responsables de l'extraction et de la représentation des
                    caractéristiques importantes des données. Un réseau de neurones peut avoir une ou plusieurs couches
                    cachées.</li>
                <li><b>Couche de Sortie (Output Layer)</b> : Cette couche génère la sortie du réseau. Le nombre de
                    neurones dans cette couche dépend de la nature de la tâche, par exemple, une classification binaire
                    aurait un neurone de sortie, tandis qu'une classification multi-classes en aurait plusieurs.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">46
                <a class="prev" href="#slide45"></a>
                <a class="next" href="#slide47"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide47">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Les couches</h2>
            <ul>
                <li><b>Transformations</b> : Chaque couche, y compris la couche d'entrée, effectue des transformations
                    sur les signaux qu'elle reçoit. Ces transformations sont déterminées par les poids des connexions
                    entre les neurones.</li>
                <li><b>Propagation des signaux</b> : Les signaux passent de la première couche (l'entrée) à la dernière
                    couche (la sortie) à travers les connexions pondérées entre les neurones. Ce processus est souvent
                    appelé la propagation avant (forward propagation). Pendant l'apprentissage, la rétropropagation
                    (backpropagation) est utilisée pour ajuster les poids afin de minimiser l'erreur de prédiction.</li>
                <li><b>Architecture</b> : La manière dont les couches sont organisées et connectées dans le réseau
                    constitue son architecture. Les réseaux de neurones peuvent avoir des architectures diverses, y
                    compris des réseaux profonds (avec de nombreuses couches cachées) ou des architectures plus simples.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">47
                <a class="prev" href="#slide46"></a>
                <a class="next" href="#slide48"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide48">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">L'entraînement</h2>
            <p>L'objectif global de l'entraînement est d'ajuster les poids du réseau de manière à ce qu'il puisse
                généraliser à de nouvelles données, produisant des résultats précis pour des exemples qu'il n'a pas vu
                pendant l'entraînement.</p>
            <ul>
                <li><b>Données d'entraînement</b> : Les réseaux neuronaux apprennent à partir d'exemples. Chaque exemple
                    se compose d'une "entrée" (les caractéristiques) et d'un "résultat" connu (l'étiquette ou la sortie
                    attendue).</li>
                <li><b>Calcul de l'erreur</b> : Lorsque le réseau produit une sortie pour une entrée donnée, l'erreur
                    est calculée en comparant cette sortie à la sortie cible (le résultat connu). Il existe différentes
                    mesures d'erreur, mais la somme des carrés des différences (Mean Squared Error, MSE) est couramment
                    utilisée.</li>
                <li><b>Rétropropagation (Backpropagation)</b> : Le réseau ajuste ses poids en utilisant la
                    rétropropagation. Cette technique minimise l'erreur en modifiant les poids à partir de la couche de
                    sortie jusqu'à la couche d'entrée. La règle de la chaîne du calcul différentiel est appliquée pour
                    propager l'erreur à travers le réseau.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">48
                <a class="prev" href="#slide47"></a>
                <a class="next" href="#slide49"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide49">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">L'entraînement</h2>
            <ul>
                <li><b>Descente de gradient</b> : La règle d'apprentissage souvent utilisée pour ajuster les poids est
                    la descente de gradient. Elle utilise le gradient de l'erreur par rapport aux poids pour mettre à
                    jour les poids dans la direction qui minimise l'erreur.</li>
                <li><b>Itérations</b> : Le processus d'ajustement des poids en fonction de l'erreur est répété pour de
                    nombreux exemples du jeu de données d'entraînement. Chaque itération est appelée une "époque".
                    Plusieurs époques peuvent être nécessaires pour que le réseau converge vers un état où l'erreur est
                    suffisamment basse.</li>
                <li><b>Optimisation</b> : Différentes techniques d'optimisation peuvent être utilisées pour améliorer la
                    convergence du réseau, telles que l'ajustement adaptatif du taux d'apprentissage.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">49
                <a class="prev" href="#slide48"></a>
                <a class="next" href="#slide50"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide50">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <ul>
                <li><b>Neurones</b> : Les neurones artificiels sont les unités de base d'un réseau de neurones. Chaque
                    neurone reçoit des signaux d'entrée, effectue un calcul sur ces signaux à l'aide d'une fonction
                    d'activation, et produit une sortie. Les neurones sont organisés en couches, à savoir la couche
                    d'entrée, les couches cachées, et la couche de sortie.</li>
                <li><b>Connexions et Poids</b> : Les connexions entre les neurones sont représentées par des poids.
                    Chaque connexion a un poids associé, qui détermine l'importance relative de cette connexion dans le
                    calcul du neurone de sortie. Pendant l'entraînement, ces poids sont ajustés pour minimiser l'erreur
                    de prédiction du réseau.</li>
                <li><b>Fonction de Propagation (Propagation avant)</b> : La fonction de propagation, également appelée
                    propagation avant, décrit le processus par lequel les signaux se propagent à travers le réseau
                    depuis la couche d'entrée jusqu'à la couche de sortie. Chaque neurone effectue une transformation
                    sur les signaux qu'il reçoit, et ces signaux modifiés sont transmis aux neurones de la couche
                    suivante.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">50
                <a class="prev" href="#slide49"></a>
                <a class="next" href="#slide51"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide51">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Neurones</h2>
            <p>Chaque neurone artificiel a des entrées, qui peuvent être les valeurs caractéristiques d'un échantillon
                de données externe, et produit une seule sortie. Cette sortie peut être envoyée à plusieurs autres
                neurones, formant ainsi la structure interconnectée du réseau neuronal. La <b>fonction d'activation</b>
                joue un rôle crucial dans le calcul de la sortie d'un neurone. Le processus comprend les étapes
                suivantes :</p>
            <ul>
                <li><b>Somme pondérée</b> : Pour trouver la sortie du neurone, on prend la somme pondérée de tous les
                    intrants (entrées). Chaque entrée est multipliée par le poids correspondant à la connexion.</li>
                <li><b>Ajout d'un terme de biais</b> : Un terme de biais est ajouté à la somme pondérée. Le terme de
                    biais est un paramètre supplémentaire qui permet au modèle d'apprendre un décalage ou une
                    translation.</li>
                <li><b>Activation</b> : La somme pondérée, parfois appelée activation, est ensuite passée par une
                    fonction d'activation. Cette fonction est généralement non linéaire et introduit de la complexité
                    dans le modèle, permettant au réseau de capturer des relations non linéaires dans les données</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">51
                <a class="prev" href="#slide50"></a>
                <a class="next" href="#slide52"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide52">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Connexions et poids</h2>
            <p>Le réseau de neurones est constitué de connexions, où chaque connexion transmet la sortie d'un neurone
                comme entrée à un autre neurone. Chaque connexion possède un poids qui représente son importance
                relative dans la transmission du signal.</p>
            <ul>
                <li>Un neurone donné peut avoir <b>plusieurs connexions d'entrée</b>, recevant des signaux de différents
                    neurones, et plusieurs connexions de sortie, transmettant des signaux à d'autres neurones. Les poids
                    associés à ces connexions permettent au réseau de moduler l'influence de chaque neurone sur les
                    autres, ajustant ainsi la force et la direction des signaux transmis à travers le réseau.</li>
                <li>Cette structure de connexion et de pondération est fondamentale dans le fonctionnement des réseaux
                    de neurones, car elle permet au réseau d'apprendre des représentations complexes des données et
                    d'ajuster ses paramètres pendant l'entraînement pour accomplir des tâches spécifiques.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">52
                <a class="prev" href="#slide51"></a>
                <a class="next" href="#slide53"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide53">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Fonction de propagation</h2>
            <p><b>Calcul de l'entrée d'un neurone</b> : La fonction de propagation calcule l'entrée d'un neurone en
                prenant la somme pondérée des sorties de ses prédécesseurs, où chaque sortie est multipliée par le poids
                de la connexion correspondante. Cela peut être représenté mathématiquement comme suit :</p>
            <p>\[ \text{Entrée du Neurone} = \sum_{i=1}^{n} (\text{Sortie du Prédécesseur}_i \times \text{Poids}_i) \]
                où \(n\) est le nombre de connexions d'entrée.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">53
                <a class="prev" href="#slide52"></a>
                <a class="next" href="#slide54"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide54">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Fonction de propagation</h2>
            <p><b>Ajout d'un terme de biais</b> : Un terme de biais peut être ajouté au résultat de la propagation. Le
                terme de biais est un paramètre supplémentaire, souvent représenté par \(b\) dans les équations, qui
                permet au modèle d'apprendre un décalage ou une translation. Cela donne la forme finale de l'entrée du
                neurone :</p>

            <p>\[ \text{Entrée du Neurone} = \sum_{i=1}^{n} (\text{Sortie du Prédécesseur}_i \times \text{Poids}_i) +
                \text{Biais} \]</p>

        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">54
                <a class="prev" href="#slide53"></a>
                <a class="next" href="#slide55"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide55">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Fonction de propagation</h2>
            <p><b>Fonction d'Activation</b> : Après avoir calculé l'entrée du neurone, celle-ci est passée à travers une
                fonction d'activation. Cette fonction introduit une non-linéarité dans le modèle, permettant au réseau
                de neurones de capturer des relations complexes et d'apprendre des modèles non linéaires. Certaines des
                fonctions d'activation couramment utilisées comprennent :</p>
            <ul>
                <li><b>Sigmoïde</b> : \( \sigma(x) = \frac{1}{1 + e^{-x}} \)</li>
                <li><b>Tangente hyperbolique (tanh)</b> : \( \text{tanh}(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} \)
                </li>
                <li><b>ReLU (Rectified Linear Unit)</b> : \( \text{ReLU}(x) = \max(0, x) \)</li>
                <li><b>Softmax</b> (pour la couche de sortie dans la classification) : \( \text{Softmax}(x)_i =
                    \frac{e^{x_i}}{\sum_{j} e^{x_j}} \)</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">55
                <a class="prev" href="#slide54"></a>
                <a class="next" href="#slide56"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide56">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Perceptron</h3>
            <p>Le perceptron est un <b>algorithme d'apprentissage supervisé</b> utilisé pour la <b>classification
                    binaire</b>. Il est conçu pour résoudre des problèmes où l'objectif est de déterminer si une entrée
                donnée appartient ou non à une classe particulière.</p>
            <ul>
                <li>Le perceptron a été inventé par <b>Frank Rosenblatt</b> en 1958. L'idée était de créer un modèle
                    simple de neurone artificiel inspiré du fonctionnement des neurones biologiques. Rosenblatt a
                    formulé un algorithme d'apprentissage qui permet au perceptron d'ajuster ses poids en fonction des
                    erreurs de classification, améliorant ainsi ses performances au fil du temps.</li>
                <li><b>Fonctionnement</b> : Le perceptron prend plusieurs entrées pondérées et les combine en une somme.
                    Ensuite, cette somme est soumise à une fonction d'activation, généralement une fonction échelon
                    (step function), qui produit la sortie binaire du perceptron.</li>
                <li><b>Limitations</b> : Le perceptron a des limitations, notamment sa capacité à résoudre des problèmes
                    non linéaires et son incapacité à apprendre des modèles complexes. Cependant, il a jeté les bases
                    pour le développement de réseaux de neurones plus avancés, en particulier les réseaux multicouches
                    qui peuvent apprendre des représentations hiérarchiques.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">56
                <a class="prev" href="#slide55"></a>
                <a class="next" href="#slide57"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide57">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron</h1>
            <figure>
                <img src="../../2021/MachineLearning/Perceptron_example.svg" height="350px" />
                <figcaption>Perceptron en mettant à jour sa limite linéaire à mesure que d'autres exemples de formation
                    sont ajoutés.<sup>1</sup></figcaption>
            </figure>
            <ol style="font-size:2vh">
                <li>Source: https://en.wikipedia.org/wiki/File:Perceptron_example.svg</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">57
                <a class="prev" href="#slide56"></a>
                <a class="next" href="#slide58"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide58">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Perceptron.svg" height="400px" />
                <figcaption>Perceptron</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">58
                <a class="prev" href="#slide57"></a>
                <a class="next" href="#slide59"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide59">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron: Définition formelle</h1>
            <ul>
                <li>Soit \(y = f(z)\) la sortie du perceptron pour un vecteur d'entrée <i>z</i></li>
                <li>Soit \(N\) le nombre d'exemples d'entraînement</li>
                <li>Soit <i><b>X</b></i> l'espace de saisie des caractéristiques</li>
                <li>Soit \({(x_{1}, d_{1}),...,(x_{N}, d_{N})}\) be the <i><b>N</b></i> training examples, where
                    <ul>
                        <li>\(x_i\) est le vecteur caractéristique de <i>i<sup>ème</sup></i> exemple d'entraînement.
                        </li>
                        <li>\(d_i\) est la valeur de sortie souhaitée</li>
                        <li>\(x_{j,i}\) est la <i>i<sup>ème</sup></i> caractéristique de <i>j<sup>ème</sup></i> exemple
                            d'entraînement.</li>
                        <li>\(x_{j,0} = 1\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">59
                <a class="prev" href="#slide58"></a>
                <a class="next" href="#slide60"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide60">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1>Perceptron: Définition formelle</h1>
            <ul>
                <li>Les poids sont représentés de la manière suivante:
                    <ul>
                        <li>\(w_i\) est la <i>i<sup>ème</sup></i> valeur du vecteur de poids.</li>
                        <li>\(w_i(t)\) est la <i>i<sup>ème</sup></i> valeur du vecteur de poids à un moment donné t.
                        </li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">60
                <a class="prev" href="#slide59"></a>
                <a class="next" href="#slide61"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide61">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1>Perceptron : Étapes</h1>
            <ol>
                <li>Initialiser les poids et les seuils</li>
                <li>Pour chaque exemple, \((x_j, d_j)\) dans l'ensemble d'entraînement<i></i>
                    <ul>
                        <li>Calculer la sortie actuelle : \[y_j(t)= f[w(t).x_j]\] \[= f[w_0(t)x_{j,0} + w_1(t)x_{j,1} +
                            w_2(t)x_{j,2} + \dotsb + w_n(t)x_{j,n}]\]</li>
                        <li>Calculer le poids: \[w_i(t + 1) = w_i(t) + r. (d_j-y_j(t))x_{j,i}\]</li>
                    </ul> \(r\) est le taux d'apprentissage.
                </li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">61
                <a class="prev" href="#slide60"></a>
                <a class="next" href="#slide62"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide62">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1>Perceptron : Étapes</h1>
            <ol start="3">
                <li>Répétez l'étape 2 jusqu'à l'erreur d'itération \[\frac{1}{s} (&#931; |d_j - y_j(t)|)\] est inférieur
                    au seuil spécifié par l'utilisateur \(\gamma\), ou un nombre prédéterminé d'itérations ont été
                    effectuées, où \(s\) est à nouveau la taille
                    de l'ensemble de l'échantillon.</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">62
                <a class="prev" href="#slide61"></a>
                <a class="next" href="#slide63"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide63">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'Échelon (Step Function)</h2>
            <p>Le perceptron utilise généralement une fonction d'activation simple, et la fonction d'échelon (step
                function) est fréquemment choisie pour cette tâche. </p>
            <h4>Définition</h4>
            <p>La fonction d'échelon attribue une sortie de 1 si la somme pondérée des entrées dépasse un certain seuil,
                et 0 sinon.</p>
            <p>\( f(x) = \begin{cases} 1 & \text{si } x \geq \text{seuil} \\ 0 & \text{sinon} \end{cases} \)</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">63
                <a class="prev" href="#slide62"></a>
                <a class="next" href="#slide64"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide64">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: fonction d'identité</h2>
            <h4>Équation</h4>
            <p>\[f(x)=x\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=1\]</p>
            <h3></h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_identity.svg"
                    height="380px" />
                <figcaption>Fonction d'identité</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">64
                <a class="prev" href="#slide63"></a>
                <a class="next" href="#slide65"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide65">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Fonction d'activation: pas binaire</h2>
                <h4>Équation</h4>
                <p>\[f(x) = \begin{cases} 0 & \text{for } x
                    < 0\\ 1 & \text{for } x \ge 0 \end{cases} \]</p>
                        <h4>Dérivée</h4>
                        <p>\[f'(x) = \begin{cases} 0 & \text{for } x \ne 0\\ ? & \text{for } x = 0\end{cases}\]</p>
                        <figure>
                            <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_binary_step.svg"
                                height="380px" />
                            <figcaption>Pas binaire</figcaption>
                        </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">65
                <a class="prev" href="#slide64"></a>
                <a class="next" href="#slide66"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide66">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: fonction sigmoïde</h2>
            <h4>Équation</h4>
            <p>\[f(x)=\sigma(x)=\frac{1}{1+e^{-x}}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=f(x)(1-f(x))\]</p>
            <figure>
                <img src="../../2021/MachineLearning/Logistic-curve.svg" height="380px" />
                <figcaption>La fonction sigmoïde</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">66
                <a class="prev" href="#slide65"></a>
                <a class="next" href="#slide67"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide67">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: TanH</h2>
            <h4>Équation</h4>
            <p>\[f(x)=\tanh(x)=\frac{(e^{x} - e^{-x})}{(e^{x} + e^{-x})}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=1-f(x)^2\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_tanh.svg" height="380px" />
                <figcaption>TanH</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">67
                <a class="prev" href="#slide66"></a>
                <a class="next" href="#slide68"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide68">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: Rectified linear unit: ReLU</h2>
            <h4>Équation</h4>
            <p>\[f(x) = \begin{cases} 0 & \text{for } x \le 0\\ x & \text{for } x > 0\end{cases} = \max\{0,x\}= x
                \textbf{1}_{x>0}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x) = \begin{cases} 0 & \text{for } x \le 0\\ 1 & \text{for } x > 0\end{cases}\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_rectified_linear.svg"
                    height="380px" />
                <figcaption>Unité linéaire rectifiée (ReLU)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">68
                <a class="prev" href="#slide67"></a>
                <a class="next" href="#slide69"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide69">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: Gaussien</h2>
            <h4>Équation</h4>
            <p>\[f(x)=e^{-x^2}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=-2xe^{-x^2}\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_gaussian.svg"
                    height="380px" />
                <figcaption>Gaussien</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">69
                <a class="prev" href="#slide68"></a>
                <a class="next" href="#slide70"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide70">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Perceptron multiclasse</h2>
            <ul>
                <li>Perceptron peut être généralisé à la classification multiclasse. </li>
                <li>Une fonction de représentation d'élément \(f( x , y )\) fait correspondre chaque paire
                    d'entrée/sortie possible à un vecteur d'élément à valeur réelle en dimension finie.</li>
                <li>le vecteur de caractéristique est multiplié par un vecteur de poids \(w\), mais le score obtenu est
                    maintenant utilisé pour choisir parmi de nombreux résultats possibles : \[\hat y =
                    \operatorname{argmax}_y f(x,y) \cdot w.\]</li>
                <li>La réapprentissage se fait par itération sur les exemples, en prédisant un résultat pour chacun, en
                    laissant les poids inchangés lorsque le résultat prédit correspond à l'objectif, et en les modifiant
                    lorsqu'il ne correspond pas. La mise
                    à jour devient : \[w_{t+1} = w_t + f(x, y) - f(x,\hat y)\].</li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">70
                <a class="prev" href="#slide69"></a>
                <a class="next" href="#slide71"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide71">
        <div class="header">
            <h1>2.4. Réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <p>Un <b>réseau de neurones profond</b>, également connu sous le nom de réseau de neurones profondément
                hiérarchisé ou réseau neuronal profond (DNN pour Deep Neural Network en anglais), est un type de réseau
                de neurones artificiels qui comprend plusieurs couches de traitement, généralement plus de deux. Ces
                réseaux sont appelés "profonds" en raison de leur architecture empilée de couches, permettant la
                création de représentations hiérarchiques complexes des données.</p>
            <p><b>Architecture en couches</b> : Les réseaux de neurones profonds sont composés de multiples couches,
                généralement divisées en trois types principaux :</p>
            <ul>
                <li><b>Couche d'Entrée</b> : Reçoit les données brutes ou caractéristiques en entrée.</li>
                <li><b>Couches Cachées</b> : Effectuent des transformations non linéaires et apprennent des
                    représentations hiérarchiques des données.</li>
                <li><b>Couche de Sortie</b> : Produit la sortie du réseau, adaptée à la tâche spécifique
                    (classification, régression, etc.).</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">71
                <a class="prev" href="#slide70"></a>
                <a class="next" href="#slide72"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide72">
        <div class="header">
            <h1>2.4. Réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <ul>
                <li><b>Apprentissage Hiérarchique</b> : Les couches cachées d'un réseau de neurones profond apprennent
                    des caractéristiques de plus en plus abstraites et complexes à mesure que l'on progresse en
                    profondeur. Chaque couche représente une abstraction des caractéristiques extraites par les couches
                    précédentes.</li>
                <li><b>Fonctions d'Activation</b> : Des fonctions d'activation non linéaires, telles que ReLU (Rectified
                    Linear Unit) ou ses variantes, sont couramment utilisées dans les couches cachées pour permettre au
                    réseau d'apprendre des relations non linéaires.</li>
                <li><b>Apprentissage Profond</b> : L'apprentissage profond implique l'ajustement simultané des poids de
                    toutes les couches du réseau pour minimiser l'erreur de prédiction. Cela est généralement réalisé en
                    utilisant des techniques de rétropropagation et de descente de gradient.</li>
                <li><b>Utilisations</b> : Les réseaux de neurones profonds sont utilisés dans une variété de tâches,
                    notamment la vision par ordinateur, la reconnaissance vocale, le traitement du langage naturel, la
                    traduction automatique, la recommandation de contenu, et bien d'autres. Leur capacité à apprendre
                    des représentations complexes a conduit à des avancées significatives dans de nombreux domaines de
                    l'intelligence artificielle.</li>
            </ul>
            <p>L'entraînement de réseaux de neurones profonds peut nécessiter des volumes importants de données et de
                puissance de calcul. </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">72
                <a class="prev" href="#slide71"></a>
                <a class="next" href="#slide73"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide73">
        <div class="header">
            <h1>2.4. Réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <p>Il existe plusieurs types de réseaux de neurones profonds.</p>
            <ul>
                <li><b style="color:#1B80CF">Réseaux de Neurones Convolutionnels (CNN)</b> :
                    <ul>
                        <li><b>Utilisation Principale</b> : Vision par ordinateur, reconnaissance d'images.</li>
                        <li><b>Caractéristiques</b> : Les CNN sont efficaces pour extraire des motifs spatiaux à partir
                            d'images en utilisant des opérations de convolution. Ils sont largement utilisés dans des
                            applications telles que la classification d'images, la détection d'objets et la segmentation
                            d'images.</li>
                    </ul>
                </li>
                <li><b style="color:#1B80CF">Réseaux de Neurones Récurrents (RNN)</b> :
                    <ul>
                        <li><b>Utilisation Principale</b> : Traitement de séquences, traitement du langage naturel.</li>
                        <li><b> Caractéristiques</b> : Les RNN sont conçus pour traiter des données séquentielles en
                            utilisant des connexions récurrentes qui leur permettent de conserver une mémoire à long
                            terme. Ils sont utilisés pour des tâches telles que la traduction automatique, la génération
                            de texte et l'analyse de séquences temporelles.</li>
                    </ul>
                </li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">73
                <a class="prev" href="#slide72"></a>
                <a class="next" href="#slide74"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide74">
        <div class="header">
            <h1>2.4. Réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <ul>
                <li><b style="color:#1B80CF">Réseaux de Neurones Générateurs Adverses (GAN)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Génération d'images réalistes.</li>
                        <li><b> Caractéristiques</b> : Les GAN sont composés de deux réseaux, un générateur et un
                            discriminateur, qui s'entraînent de manière adversaire. Les GAN sont utilisés pour générer
                            des données réalistes, y compris des images, des vidéos et du son.</li>
                    </ul>
                </li>
                <li><b style="color:#1B80CF">Réseaux de Neurones Résiduels (ResNet)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Classification d'images profondes.</li>
                        <li><b> Caractéristiques</b> : Les architectures ResNet utilisent des connexions résiduelles
                            pour faciliter l'apprentissage profond en surmontant le problème du "vanishing gradient".
                            Ils sont fréquemment utilisés dans des compétitions de classification d'images.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">74
                <a class="prev" href="#slide73"></a>
                <a class="next" href="#slide75"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide75">
        <div class="header">
            <h1>2.4. Réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <ul>

                <li><b style="color:#1B80CF">Autoencodeurs et Variational Autoencoders (VAE)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Compression et génération de données.
                        <li><b> Caractéristiques</b> : Les autoencodeurs sont utilisés pour apprendre des
                            représentations compactes de données en comprimant et en reconstruisant les informations.
                            Les VAE introduisent des composants probabilistes, permettant de générer de nouvelles
                            données similaires aux données d'entraînement.
                    </ul>
                </li>

                <li><b style="color:#1B80CF">Réseaux de Neurones de Mémoire à Long Terme (LSTM)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Traitement du langage naturel, séquences temporelles.</li>
                        <li><b> Caractéristiques</b> : Les LSTMs sont une variation des RNN qui intègrent des mécanismes
                            de portes pour mieux gérer le problème du gradient qui s'estompe sur de longues séquences.
                            Ils sont couramment utilisés dans la génération de texte et d'autres tâches basées sur des
                            séquences.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">75
                <a class="prev" href="#slide74"></a>
                <a class="next" href="#slide76"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide76">
        <div class="header">
            <h1>Références</h1>
        </div>
        <div class="content">
            <h1>Articles de recherche</h1>
            <ul>
                <li>[Aly 2005] Aly, Mohamed. Survey on Multiclass Classification Methods. 2005.</li>
                <li>[Jaakkola 2019] Jaakkola, H., et al. “Artificial Intelligence Yesterday, Today and Tomorrow.” 2019
                    42nd International Convention on Information and Communication Technology, Electronics and
                    Microelectronics (MIPRO), 2019, pp. 860–67. IEEE
                    Xplore
                </li>
                <li>[Pan 2016] Pan, Yunhe, “Heading toward Artificial Intelligence 2.0.” Engineering, vol. 2, no. 4,
                    Dec. 2016, pp. 409–13. www.sciencedirect.com,</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">76
                <a class="prev" href="#slide75"></a>
                <a class="next" href="#slide77"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide77">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Web</h1>
            <ol>
                <li>Google acquiert DNNresearch, spécialisé dans les réseaux de neurones profonds: <a
                        href="https://www.lemondeinformatique.fr/actualites/lire-google-acquiert-dnnresearch-specialise-dans-les-reseaux-de-neurones-profonds-52829.html">https://www.lemondeinformatique.fr/actualites/lire-google-acquiert-dnnresearch-specialise-dans-les-reseaux-de-neurones-profonds-52829.html</a>
                </li>
                <li>Pourquoi Microsoft rachète Linkedin: <a
                        href="https://www.lemondeinformatique.fr/actualites/lire-pourquoi-microsoft-rachete-linkedin-65136.html">https://www.lemondeinformatique.fr/actualites/lire-pourquoi-microsoft-rachete-linkedin-65136.html</a>
                </li>
                <li>Scikit-learn: <a href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a></li>
                <li>Perceptron: <a
                        href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html</a>
                </li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">77
                <a class="prev" href="#slide76"></a>
                <a class="next" href="#slide78"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide78">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Wikipédia</h1>
            <ul>
                <li>Perceptron: <a
                        href="https://en.wikipedia.org/wiki/Perceptron">https://en.wikipedia.org/wiki/Perceptron</a>
                </li>
                <li>Multiclass Classification: <a
                        href="https://en.wikipedia.org/wiki/Multiclass_classification">https://en.wikipedia.org/wiki/Multiclass_classification</a>
                </li>
                <li>Multilayer Perceptron: <a
                        href="https://en.wikipedia.org/wiki/Multilayer_perceptron">https://en.wikipedia.org/wiki/Multilayer_perceptron</a>
                </li>
                <li>Feedforward Neural Network: <a
                        href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
                </li>
                <li>Recurrent Neural Network: <a
                        href="https://en.wikipedia.org/wiki/Recurrent_neural_network">https://en.wikipedia.org/wiki/Recurrent_neural_network</a>
                </li>
                <li>Long Short-Term Memory: <a
                        href="https://en.wikipedia.org/wiki/Long_short-term_memory">https://en.wikipedia.org/wiki/Long_short-term_memory</a>
                </li>
                <li>Activation Function: <a
                        href="https://en.wikipedia.org/wiki/Activation_function">https://en.wikipedia.org/wiki/Activation_function</a>
                </li>
                <li>Logique et Raisonnement Mathématique: <a
                        href="https://fr.wikipedia.org/wiki/Logique_et_raisonnement_math%C3%A9matique">https://fr.wikipedia.org/wiki/Logique_et_raisonnement_math%C3%A9matique</a>
                </li>
                <li>Représentation des Connaissances: <a
                        href="https://fr.wikipedia.org/wiki/Repr%C3%A9sentation_des_connaissances">https://fr.wikipedia.org/wiki/Repr%C3%A9sentation_des_connaissances</a>
                </li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">78
                <a class="prev" href="#slide77"></a>
                <a class="next" href="#slide79"></a>
            </div>
        </div>
    </section>

    <section class="slide" id="slide79">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Wikipédia</h1>
            <ul>
                <li>Agent Intelligent: <a
                        href="https://fr.wikipedia.org/wiki/Agent_intelligent">https://fr.wikipedia.org/wiki/Agent_intelligent</a>
                </li>
                <li>Calcul des Propositions: <a
                        href="https://fr.wikipedia.org/wiki/Calcul_des_propositions">https://fr.wikipedia.org/wiki/Calcul_des_propositions</a>
                </li>
                <li>Calcul des Prédicats: <a
                        href="https://fr.wikipedia.org/wiki/Calcul_des_pr%C3%A9dicats">https://fr.wikipedia.org/wiki/Calcul_des_pr%C3%A9dicats</a>
                </li>
                <li>Logique Modale: <a
                        href="https://fr.wikipedia.org/wiki/Logique_modale">https://fr.wikipedia.org/wiki/Logique_modale</a>
                </li>
                <li>Raisonnement Automatisé: <a
                        href="https://fr.wikipedia.org/wiki/Raisonnement_automatis%C3%A9">https://fr.wikipedia.org/wiki/Raisonnement_automatis%C3%A9</a>
                </li>
                <li>Connaissance: <a
                        href="https://fr.wikipedia.org/wiki/Connaissance">https://fr.wikipedia.org/wiki/Connaissance</a>
                </li>
                <li>Gestion des connaissances: <a
                        href="https://fr.wikipedia.org/wiki/Gestion_des_connaissances">https://fr.wikipedia.org/wiki/Gestion_des_connaissances</a>
                </li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">79
                <a class="prev" href="#slide78"></a>
                <a class="next" href="#slide80"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide80">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Couleurs</h1>
            <ul>
                <li><a href="https://material.io/color/">Color Tool - Material Design</a></li>
            </ul>
            <h1>Images</h1>
            <ul>
                <li><a href="https://commons.wikimedia.org/">Wikimedia Commons</a></li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">80
                <a class="prev" href="#slide79"></a>
            </div>
        </div>
    </section>

    <script>
        function changeCurrentURLSlideNumber(isIncrement) {
            url = window.location.href;
            position = url.indexOf("#slide");
            if (position != -1) { // Not on the first page
                slideIdString = url.substr(position + 6);
                if (!Number.isNaN(slideIdString)) {
                    slideId = parseInt(slideIdString);
                    if (isIncrement) {
                        if (slideId < 80) {
                            slideId = slideId + 1;
                        }
                    } else {
                        if (slideId > 1) {
                            slideId = slideId - 1;
                        }
                    }
                    /* regexp */
                    url = url.replace(/#slide\d+/g, "#slide" + slideId);
                    window.location.href = url;
                }
            } else {
                window.location.href = url + "#slide2";
            }
        }
        document.onkeydown = function (event) {

            event.preventDefault();
            /* This will ensure the default behavior of
                                                            page scroll behaviour (up, down, right, left)*/

            event = event || window.event;
            /*Codes de la touche sur le clavier: 37, 38, 39, 40*/
            if (event.keyCode == '37') {
                // left
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '38') {
                // up
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '39') {
                // right
                changeCurrentURLSlideNumber(true);
            } else if (event.keyCode == '40') {
                // down
                changeCurrentURLSlideNumber(true);
            }
        }
        document.body.onmouseup = function (event) {
            event = event || window.event;
            event.preventDefault();
            changeCurrentURLSlideNumber(true);
        }
    </script>
</body>

</html>
