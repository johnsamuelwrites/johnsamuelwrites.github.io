<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta http-equiv="Content-Language" content="en" />
  <link rel="shortcut icon" href="../.../../2017/DataMining/images/logo/favicon.png" />
  <title>Mini-projet: IA-Deep Learning (2021-2022): John Samuel</title>
  <style type="text/css">
    body {
      background-color: #FFFFFF;
    }

    #sidebar {
      position: fixed;
      background-color: #00363a;
      top: 0;
      left: 0;
      bottom: 0;
      width: 25vw;
    }

    #sidebar .title {
      position: relative;
      text-align: center;
      line-height: 5vmax;
      font-size: 1.4vmax;
      font-family: 'Arial';
      margin-top: 30vh;
    }

    #sidebar .title a:link,
    #sidebar .title a:visited {
      color: #FFFFFF;
      text-decoration: none;
    }

    .subtitle {
      top: 50vh;
      text-align: center;
      line-height: 1.3vmax;
      font-family: 'Arial';
      font-size: 1.5vmax;
      color: #FFFFFF;
    }

    a:link,
    a:visited {
      color: #00363a;
    }

    .subtitle a:link,
    .subtitle a:visited {
      color: #FFFFFF;
      text-decoration: none;
    }

    .licence {
      position: fixed;
      text-align: right;
      bottom: 0;
      right: 0;
    }

    .home {
      position: fixed;
      text-align: left;
      font-family: 'Arial';
      color: #D3D3D3;
      z-index: 100;
      width: 100%;
      background-color: #FFFFFF;
      top: 0px;
      margin-bottom: 10px;
      padding-bottom: 10px;
    }

    .codeexample {
      background-color: #eeeeee;
      width: 100%;
      overflow: scroll;
    }

    .home ul {
      margin: 0;
      padding: 0;
      text-align: left;
      list-style: none;
    }

    .home li {
      position: relative;
      float: left;
      padding-top: 15px;
      margin-right: 1em;
      font-family: 'Arial';
    }

    .home li:hover {
      display: block;
    }

    .home a:link,
    .home a:visited {
      color: #D3D3D3;
    }

    .home li:hover a:link,
    .home li:hover a:visited {
      text-decoration: none;
      padding: 15px;
      color: #FFFFFF;
      background-color: #00363a;
    }

    .content {
      line-height: 1.8vmax;
      font-size: 1.2vmax;
      font-family: 'Arial';
      margin-top: 15vh;
      width: 90%;
    }

    .content h2,
    h3,
    h4 {
      color: #00363a;
    }

    .content a:link,
    .content a:visited {
      color: #00363a;
    }

    .content h2::before,
    .content h3::before {
      display: block;
      content: " ";
      visibility: hidden;
      height: 50px;
      margin-top: -50px;
      pointer-events: none;
      background-color: #FFFFFF;
    }

    .content a:link,
    .content a:visited {
      color: #00363a;
    }

    .content li {
      margin: 5px;
    }

    .exercise {
      margin-left: 2vw;
    }

    .exercise p {
      margin-left: 1vw;
    }

    .exercise img {
      width: 100%;
    }

    .content a:link,
    .content a:visited {
      color: #00363a;
    }

    .home a:link,
    .home a:visited {
      color: #D3D3D3;
    }

    .page {
      width: 65vw;
      height: 100%;
      margin-left: 25vw;
      overflow: auto;
      padding: 0 1em;
    }

    table td,
    tr {
      text-align: center;
    }

    img {
      max-width: 100%;
      max-height: 100%;
    }

    /* Using same Jupyter CSS
     */
    .highlight {
      background: #f8f8f8;
    }

    .highlight .c {
      color: #408080;
      font-style: italic
    }

    /* Comment */
    .highlight .err {
      border: 1px solid #FF0000
    }

    /* Error */
    .highlight .k {
      color: #008000;
      font-weight: bold
    }

    /* Keyword */
    .highlight .o {
      color: #666666
    }

    /* Operator */
    .highlight .ch {
      color: #408080;
      font-style: italic
    }

    /* Comment.Hashbang */
    .highlight .c1 {
      color: #408080;
      font-style: italic
    }

    /* Comment.Single */
    .highlight .cs {
      color: #408080;
      font-style: italic
    }

    /* Comment.Special */
    .highlight .cm {
      color: #408080;
      font-style: italic
    }

    /* Comment.Multiline */
    .highlight .nn {
      color: #0000FF;
      font-weight: bold
    }

    /* Name.Namespace */
    .highlight .k {
      color: #008000;
      font-weight: bold
    }

    /* Keyword */
    .highlight .s2 {
      color: #BA2121
    }

    /* Literal.String.Double */
    .highlight .s1 {
      color: #BA2121
    }

    /* Literal.String.Single */
    .highlight .kn {
      color: #008000;
      font-weight: bold
    }

    /* Keyword.Namespace */
    .highlight .nb {
      color: #008000
    }

    /* Name.Builtin */
    .highlight .mb {
      color: #666666
    }

    /* Literal.Number.Bin */
    .highlight .mf {
      color: #666666
    }

    /* Literal.Number.Float */
    .highlight .mh {
      color: #666666
    }

    /* Literal.Number.Hex */
    .highlight .mi {
      color: #666666
    }

    /* Literal.Number.Integer */
    .highlight .mo {
      color: #666666
    }

    /* Literal.Number.Oct */
    @media (max-width: 640px),
    screen and (orientation: portrait) {
      body {
        max-width: 100%;
        max-height: 100%;
      }

      #sidebar {
        position: fixed;
        background-color: #00363a;
        top: 0;
        left: 0;
        bottom: 80vh;
        width: 100vw;
      }

      #sidebar .title {
        text-align: center;
        position: fixed;
        margin-top: 6vh;
        left: 0px;
        right: 0px;
        line-height: 3.5vmax;
        font-size: 1.5vmax;
        font-family: 'Arial';
      }

      #sidebar .subtitle {
        text-align: center;
        top: 5vh;
        left: 0px;
        right: 0px;
        position: fixed;
        margin-top: 10vh;
        font-size: 1.5vmax;
      }

      #sidebar .title a:link,
      #sidebar .title a:visited {
        text-align: center;
        color: #FFFFFF;
      }

      #sidebar .subtitle a:link,
      #sidebar .subtitle a:visited {
        text-align: center;
        color: #FFFFFF;
      }

      .home {
        z-index: 100;
        width: 100%;
        background-color: #00363a;
        font-size: 1.5vmax;
      }

      .home a:link,
      .home a:visited {
        text-decoration: none;
        color: #FFFFFF;
      }

      .content {
        line-height: 3.8vmax;
        font-size: 1.8vmax;
        font-family: 'Arial';
        margin-top: 22vh;
      }

      .content a:link,
      .content a:visited {
        color: #00363a;
      }

      .page {
        top: 40vh;
        width: 99%;
        margin-left: 0vw;
      }

      .page img {
        max-width: 100%;
        max-height: 100%;
        border: 0;
      }
    }

    @media print {
      #sidebar {
        width: 100%;
        top: 0;
        position: relative;
        padding-bottom: 3vh;
      }

      #sidebar .title {
        margin-top: 0;
      }

      .home {
        display: none;
      }

      .page {
        margin-left: 5vw;
        width: 90%;
      }
    }
  </style>
</head>

<body vocab="http://schema.org/">
  <div id="sidebar">
    <div class="title">
      <h1><a href="./index.html">Mini-projet: IA-Deep Learning</a></h1>
    </div>
    <div class="subtitle">
      <h3><a href="../../../../about.html">John Samuel</a></h3>
    </div>
  </div>
  <div class="licence"><a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img
        alt="Creative Commons License" style="border-width:0" src="../../../../../images/license.png" /></a>
  </div>
  <div class="page">
    <div class="home">
      <ul typeof="BreadcrumbList">
        <li property="itemListElement" typeof="ListItem">
          <a property="item" typeof="WebPage" href="../../../../index.html">
            <span property="name">Accueil</span>
          </a>
        </li>
        <li property="itemListElement" typeof="ListItem">
          <a property="item" typeof="WebPage" href="index.html">
            <span property="name">Deep Learning</span>
          </a>
        </li>
        <li property="itemListElement" typeof="ListItem">
          <a property="item" typeof="WebPage" href="../../../index.html">
            <span property="name">Enseignement</span>
          </a>
        </li>
      </ul>
    </div>
    <div class="content">
      <h2 id="année-2021-2022">Année: 2021-2022</h2>
      <h3 id="projet">Mini-Projet</h3>
      <h3 id="objectifs">Objectifs</h3>
      <ul>
        <li>Comprendre le mode de traduction</li>
      </ul>
      <h3 id="exercice-1.1">Exercice 1.1</h3>
      <h4 id="download">Download</h3>
        <p>Téléchargez les données à partir de <a href="https://zenodo.org/record/3271358"
            class="uri">https://zenodo.org/record/3271358</a>.</p>
        <p>Voir le contenu des données. Comme vous pouvez le voir dans les résultats, il y a quatre colonnes :
          horodatage,
          propriété, langue et type.</p>
        <p>Prenons un exemple de ligne de cet ensemble de données,</p>
        <pre class="codeexample"><code>              2013-09-10T22:43:54Z,P856,en,label             </code></pre>
        <p>correspond à l’action qu’un label anglais de la propriété P856 ajouté pour la première fois à
          2013-09-10T22:43:54Z.</p>
        <p>Vous trouverez ci-dessous une description de chaque colonne.</p>
        <ol type="1">
          <li>horodatage : l’heure à laquelle une action a été effectuée. Par exemple, 2013-09-10T22:43:54Z</li>
          <li>la propriété : Identificateur de propriété Wikidata. Il utilise le numéro P, par exemple, P856</li>
          <li>langue : la langue dans laquelle une étiquette/description/alias a été rédigée en premier traduit</li>
          <li>type : Il peut s’agir de l’une des valeurs suivantes : label(étiquette), description et alias</li>
        </ol>
        <h3 id="création-de-dataframe">Création de dataframe</h3>
        <pre class="codeexample"><code>                import pandas as pd
                dataframe = pd.read_csv(&quot;multilingual_wikidata_translation_flow.csv&quot;)
                # remove duplicates
                dataframe = dataframe.drop_duplicates()

                # remove rows with missing values
                dataframe = dataframe.dropna()
                print(dataframe)</code></pre>
        <p>Obtenez une information détaillée du dataframe</p>
        <pre class="codeexample"><code>               dataframe.describe()</code></pre>
        <p>Examinons maintenant la traduction des étiquettes dans différents langues pour une propriété donnée.</p>
        <pre
          class="codeexample"><code>               dataframe.loc[(dataframe[&quot;property&quot;]==&quot;P856&quot;) &amp; (dataframe[&quot;type&quot;]==&quot;label&quot;)]             </code></pre>
        <p>Nous allons vérifier les données disponibles pour une propriété comme P856.</p>
        <pre class="codeexample"><code>              ptranslation = dataframe.loc[(dataframe[&quot;property&quot;]==&quot;P856&quot;)]
              print(ptranslation)             </code></pre>
        <p>Vous pouvez également ajouter des conditions supplémentaires pour filtrer toute information. Le code
          ci-dessous
          permet de filtrer la traduction des étiquettes de la propriété P856. Veuillez copier le code ci-dessous et
          créer
          de nouvelles cellules pour les tests avec différentes propriétés et voir les résultats pour la traduction des
          descriptions et des alias. Quelles sont vos premières observations ? Veuillez les noter comme commentaires
          dans
          votre notebook.</p>
        <pre class="codeexample"><code>             ptranslation = dataframe.loc[(dataframe[&quot;property&quot;]==&quot;P856&quot;) &amp; (dataframe[&quot;type&quot;]==&quot;label&quot;)]
             print(ptranslation)             </code></pre>
        <h3 id="visualisation-de-la-traduction">Visualisation de la traduction</h3>
        <p>Notre prochain objectif est de tracer la traduction d’une propriété et de voir si nous pouvons observer
          n’importe quel mode de traduction. Veuillez copier le code ci-dessous et créer de nouvelles cellules pour les
          tests avec des propriétés différentes et tracer la résultats. Dans ce graphique, nous traçons le temps sur
          l’axe
          des x et la traduction tapez sur l’axe des y.</p>
        <pre class="codeexample"><code>import matplotlib 
import  matplotlib.pyplot as plot 
from  dateutil import parser 
import  numpy as np  
ptranslation  = dataframe.loc[(dataframe[&quot;property&quot;]==&quot;P856&quot;)]  
x  = [] 
y  = [] 
z  = [] 
for  i in range(0, len(ptranslation[&#39;timestamp&#39;])):
    #parsing the date in string and converting it to datetime
    try:
        value = parser.parse(ptranslation[&#39;timestamp&#39;].iloc[i])
        x.append(value)
    except Exception:
        continue
    y.append(ptranslation[&#39;type&#39;].iloc[i])
    z.append(ptranslation[&#39;language&#39;].iloc[i])
    
#creating  a plot
plot.rcParams[&quot;figure.figsize&quot;]  = (25, 9) 
colors  = matplotlib.cm.rainbow(np.linspace(0, 1, 3))
tcolors  = {&#39;label&#39;: colors[0],
      &#39;description&#39;:colors[1],
      &#39;alias&#39;:colors[2]
     }
cs  = [tcolors[i] for i in y]  
fig,  ax = plot.subplots() 
ax.scatter(x, y, s=30, color=cs)  

plot.xlabel(&quot;Time&quot;) 
plot.ylabel(&quot;Translation type&quot;)  

#annotating  the points 
for i, txt in enumerate(z):
   ax.annotate(txt, (x[i], y[i]))

fig.show()             </code></pre>
        <p>Maintenant, nous traçons un autre graphique, cette fois-ci, la langue sur l’axe des y et le temps sur l’axe
          des
          x.</p>
        <pre class="codeexample"><code>import matplotlib 
import matplotlib.pyplot as plot 
from dateutil import parser 
import numpy as np  

ptranslation = dataframe.loc[(dataframe[&quot;property&quot;]==&quot;P279&quot;)]  
x = [] 
y = [] 
z = [] 

for i in range(0, len(ptranslation[&#39;timestamp&#39;])):
    try:
      #parsing the date in string and converting it to datetime
      value = parser.parse(ptranslation[&#39;timestamp&#39;].iloc[i])
      x.append(value)
    except Exception:
      continue
    y.append(ptranslation[&#39;type&#39;].iloc[i])
    z.append(ptranslation[&#39;language&#39;].iloc[i])  

#creating a plot 
colors = matplotlib.cm.rainbow(np.linspace(0, 1, 3)) 
tcolors = {&#39;label&#39;: colors[0],
               &#39;description&#39;:colors[1],
               &#39;alias&#39;:colors[2]
            } 

cs = [tcolors[i] for i in y]   

plot.rcParams[&quot;figure.figsize&quot;] = (25, 25)  
fig, ax = plot.subplots() 
ax.scatter(x, z, s=50, color=cs)   

plot.xlabel(&quot;Time&quot;) 
plot.ylabel(&quot;Language&quot;)  

# saving the plot in a file 
plot.savefig(&#39;translation.png&#39;) 
fig.show()             </code></pre>
        <p>Voici trois graphiques concernant les propriétés : P31, P279 et P856 respectivement. Quelles sont vos
          observations sur les valeurs sur l’axe des y ? Veuillez les noter en tant que commentaires sur le notebook.
          Vous
          pouvez également constater que certains traductions peuvent même être effectuées en une seule fois. Veuillez
          vérifier une colonne de lignes rouges dans le premier graphique (P31).</p>
        <figure>
          <img src="../../../../../en/teaching/courses/2019/MachineLearning/p31.png" alt="Translation plot of property P31" />
          <figcaption>Translation plot of property P31</figcaption>
        </figure>
        <figure>
          <img src="../../../../../en/teaching/courses/2019/MachineLearning/p279.png" alt="Translation plot of property P279" />
          <figcaption>Translation plot of property P279</figcaption>
        </figure>
        <figure>
          <img src="../../../../../en/teaching/courses/2019/MachineLearning/p856.png" alt="Translation plot of property P856" />
          <figcaption>Translation plot of property P856</figcaption>
        </figure>
        <p>Dans le code donné ci-dessous, nous sélectionnons quelques langues et voyons l’ordre de traduction. Copiez le
          code ci-dessous et tracez les graphiques pour les différents propriétés. Veuillez noter vos observations.</p>
        <pre class="codeexample"><code>import matplotlib 
import matplotlib.pyplot as plot 
from dateutil import parser 
import numpy as np  

#list of languages under consideration 
langlist  = [&quot;fr&quot;, &quot;es&quot;, &quot;en&quot;, &quot;de&quot;, &quot;it&quot;, &quot;pt&quot;, &quot;ja&quot;] 
ptranslation  = dataframe.loc[(dataframe[&quot;property&quot;]==&quot;P18&quot;) &amp; (dataframe[&quot;language&quot;].isin (langlist))] 
print(ptranslation)  

x= [] 
y= [] 
z= [] 

for i in range(0, len(ptranslation[&#39;timestamp&#39;])):
    try:
        #parsing the date in string and converting it to datetime
        value = parser.parse(ptranslation[&#39;timestamp&#39;].iloc[i])
      x.append(value)
    except Exception:
      continue
    y.append(ptranslation[&#39;type&#39;].iloc[i])
    z.append(ptranslation[&#39;language&#39;].iloc[i])  

#creating  a plot 
colors  = matplotlib.cm.rainbow(np.linspace(0, 1, 3)) 
tcolors  = {&#39;label&#39;: colors[0],
               &#39;description&#39;:colors[1],
               &#39;alias&#39;:colors[2]
             } 

cs  = [tcolors[i] for i in y]   
plot.rcParams[&quot;figure.figsize&quot;]  = (10, 5)  
fig,  ax = plot.subplots() 
ax.scatter(x,  z, s=50, color=cs)  

plot.savefig(&#39;translation.png&#39;) 
fig.show()             </code></pre>
        <h3 id="exercice-1.2">Exercice 1.2</h3>
        <p>Nous avons utilisé des techniques de traçage pour détecter manuellement certains modes de traduction. Nous
          utilisons maintenant d’autres algorithmes pour voir si des groupes de les langues sont toujours présentes
          ensemble</p>
        <p>Avant de continuer, nous devons installer la bibliothèque <em>mlxtend</em>.</p>
        <pre class="codeexample"><code>             !pip install mlxtend               </code></pre>
        <p>Ensuite, nous préparons l’ensemble des données linguistiques. Nous nous concentrerons sur la traduction de
          labels de propriété. Nous créons une liste des traductions disponibles d’étiquettes de toutes les propriétés
          de
          notre base de données</p>
        <pre class="codeexample"><code>#prepare dataset of languages 
languageorder = [] 
labeldataframe = dataframe.loc[(dataframe[&quot;type&quot;] == &quot;label&quot;)] 
groups = labeldataframe.groupby([&quot;property&quot;]) 

for k, group in groups:
   languageorder.append(list(groups.get_group((k))[&quot;language&quot;])) 
print(languageorder)</code></pre>
        <p>Cela nous donnera le résultat suivant.</p>
        <pre class="codeexample"><code>
               [[&#39;en&#39;, &#39;it&#39;, &#39;fi&#39;, &#39;fr&#39;, &#39;de&#39;, &#39;zh-hans&#39;, &#39;ru&#39;, &#39;hu&#39;, &#39;he&#39;, &#39;nl&#39;, &#39;pt&#39;, &#39;pl&#39;, &#39;ca&#39;, &#39;cs&#39;, &#39;ilo&#39;, &#39;zh&#39;, &#39;nb&#39;, &#39;ko&#39;,..        
</code></pre>
        <p>Maintenant, nous calculons les ensembles d’éléments fréquents en utilisant l’algorithme <em>apriori</em>.
          Veuillez décommenter la ligne print pour voir le dataframe intermédiaire.</p>
        <pre class="codeexample"><code>from mlxtend.preprocessing import TransactionEncoder  
from mlxtend.frequent_patterns import apriori  

te = TransactionEncoder()  
te_ary = te.fit(languageorder).transform(languageorder)  

# preparation of data frame 
df = pd.DataFrame(te_ary, columns=te.columns_) 

#print(df)  
#use of apriori algorithm 
frequent_itemsets = apriori(df, min_support=0.75, use_colnames=True)  
print (frequent_itemsets)             </code></pre>
        <p>Le programme utilise un soutien minimum de 0,75. On voit que les labels anglais sont présents pour toutes les
          propriétés, alors que les labels français ne sont disponible pour 93% des propriétés. Sur la prise en compte
          des
          paires de langues, on constate que l’anglais et l’arabe sont présents dans 93% des traductions. En allant plus
          loin, nous constatons des combinaisons de 3, 4, 5 langues, etc.</p>
        <p>Veuillez changer cette valeur entre 0 et 1 et voyez le résultat.</p>
        <pre class="codeexample"><code>  S.No.              support                itemsets
  ------- ---------- ---------------------- ----------
  0       0.998424   (ar)                   
  1       0.759414   (ca)                   
  2       1.000000   (en)                   
  3       0.932409   (fr)                   
  4       0.993540   (nl)                   
  5       0.985978   (uk)                   
  6       0.758626   (ar, ca)               
  7       0.998424   (en, ar)               
  8       0.931621   (ar, fr)               
  9       0.992752   (nl, ar)               
  10      0.985663   (ar, uk)               
  11      0.759414   (en, ca)               
  12      0.759256   (nl, ca)               
  13      0.754215   (uk, ca)               
  14      0.932409   (en, fr)               
  15      0.993540   (nl, en)               
  16      0.985978   (en, uk)               
  17      0.931779   (nl, fr)               
  18      0.928155   (uk, fr)               
  19      0.985663   (nl, uk)               
  20      0.758626   (en, ar, ca)           
  21      0.758469   (nl, ar, ca)           
  22      0.753899   (ar, uk, ca)           
  23      0.931621   (en, ar, fr)           
  24      0.992752   (nl, en, ar)           
  25      0.985663   (en, ar, uk)           
  26      0.931149   (nl, ar, fr)           
  27      0.927997   (ar, uk, fr)           
  28      0.985347   (nl, ar, uk)           
  29      0.759256   (nl, en, ca)           
  30      0.754215   (en, uk, ca)           
  31      0.754057   (nl, uk, ca)           
  32      0.931779   (nl, en, fr)           
  33      0.928155   (en, uk, fr)           
  34      0.985663   (nl, en, uk)           
  35      0.927840   (nl, uk, fr)           
  36      0.758469   (nl, en, ar, ca)       
  37      0.753899   (en, ar, uk, ca)       
  38      0.753742   (nl, ar, uk, ca)       
  39      0.931149   (nl, en, ar, fr)       
  40      0.927997   (en, ar, uk, fr)       
  41      0.985347   (nl, en, ar, uk)       
  42      0.927682   (nl, ar, uk, fr)       
  43      0.754057   (nl, en, uk, ca)       
  44      0.927840   (nl, en, uk, fr)       
  45      0.753742   (ar, en, ca, nl, uk)   
  46      0.927682   (ar, en, fr, nl, uk)   </code></pre>
        <p>Répétez l’expérience ci-dessus pour les descriptions et les alias. Quels sont vos observations. Veuillez les
          noter dans le notebook en tant que commentaires.</p>
        <h3 id="exercice-1.3">Exercice 1.3</h3>
        <p>Notre prochain objectif est de générer les règles d’association, c’est-à-dire les règles de la forme: <em>A
            -&gt; C</em>, où A est l’antécédent et C est la conséquence.</p>
        <pre class="codeexample"><code>from mlxtend.frequent_patterns import association_rules  
association_rules(frequent_itemsets, metric=&quot;confidence&quot;, min_threshold=0.95)             </code></pre>
        <p>Cela nous donnera le résultat suivant.</p>
        <pre
          class="codeexample"><code>  S.No.   antecedents   consequents   antecedent support   consequent support   support    confidence   lift       leverage   conviction
  ------- ------------- ------------- -------------------- -------------------- ---------- ------------ ---------- ---------- ------------
  0       (de)          (en)          0.479193             0.988966             0.477932   0.997368     1.008496   0.004026   4.192938
  1       (de)          (uk)          0.479193             0.960277             0.468789   0.978289     1.018757   0.008631   1.829646
  2       (es)          (en)          0.389975             0.988966             0.388556   0.996362     1.007479   0.002884   3.033137
  3       (fr)          (en)          0.713272             0.988966             0.708859   0.993812     1.004900   0.003457   1.783181
  4       (it)          (en)          0.413934             0.988966             0.413146   0.998096     1.009232   0.003779   5.795082
  5       (ru)          (en)          0.301387             0.988966             0.300441   0.996862     1.007984   0.002380   3.516183
  6       (en)          (uk)          0.988966             0.960277             0.950189   0.960791     1.000534   0.000507   1.013087
  7       (uk)          (en)          0.960277             0.988966             0.950189   0.989494     1.000534   0.000507   1.050303
  8       (es)          (uk)          0.389975             0.960277             0.383039   0.982215     1.022845   0.008555   2.233492
  9       (fr)          (uk)          0.713272             0.960277             0.689470   0.966630     1.006615   0.004531   1.190362
  10      (it)          (uk)          0.413934             0.960277             0.405738   0.980198     1.020745   0.008246   2.005990
  11      (ru)          (uk)          0.301387             0.960277             0.300126   0.995816     1.037009   0.010711   9.493695
  12      (de, fr)      (en)          0.391393             0.988966             0.391078   0.999195     1.010343   0.004003   13.698770
  13      (de, uk)      (en)          0.468789             0.988966             0.467686   0.997646     1.008777   0.004069   4.687894</code></pre>
        <p>Examinons l’une des règles d’association <em>(de, fr)-&gt;(en)</em>. Le score de confiance est de 0,999195.
          Mais cette règle stipule que lorsque nous avons des traductions en français et en allemand seront disponibles,
          nous aurons également la traduction anglaise.</p>
        <p>Vous pouvez changer la métrique “lift” et tester.</p>
        <p>Nous allons maintenant ajouter deux colonnes qui contiendront la longueur des antécédents et ses
          conséquences.
          Comme vous l’avez peut-être remarqué, les règles d’association sont des dataframes. Nous pouvons donc
          facilement
          écrire des conditions de filtrage pour obtenir des antécédents et les conséquences d’une longueur supérieure à
          1.</p>
        <pre class="codeexample"><code>from mlxtend.frequent_patterns import association_rules  
arules = association_rules(frequent_itemsets, metric=&quot;confidence&quot;, min_threshold=0.95) 

arules[&quot;antecedent_len&quot;] = arules[&quot;antecedents&quot;].apply(lambda x: len(x)) 
arules[&quot;consequent_len&quot;] = arules[&quot;consequents&quot;].apply(lambda x: len(x))  

arules.loc[(arules[&quot;antecedent_len&quot;]&gt;1) &amp;                  
   (arules[&quot;consequent_len&quot;]&gt;1)]             </code></pre>
        <pre
          class="codeexample"><code>  S.No.   antecedents   consequents   antecedent support   consequent support   support    confidence   lift       leverage   conviction   antecedent\_len   consequent\_len
  ------- ------------- ------------- -------------------- -------------------- ---------- ------------ ---------- ---------- ------------ ----------------- -----------------
  32      (de, fr)      (en, uk)      0.391393             0.950189             0.383670   0.980266     1.031653   0.011772   2.524088     2                 2
  35      (fr, es)      (en, uk)      0.332755             0.950189             0.326765   0.981999     1.033477   0.010585   2.767124     2                 2
  38      (fr, it)      (en, uk)      0.345523             0.950189             0.338430   0.979471     1.030817   0.010117   2.426342     2                 2</code></pre>
        <p>Répétez l’expérience ci-dessus pour la traduction des descriptions et des alias. Veuillez noter vos
          observations sous forme de commentaires.</p>
        <h3 id="exercice-1.4">Exercice 1.4</h3>
        <p>Notre prochain objectif est de visualiser le flux de traduction. À cette fin, nous installons des packages
          holoviews et bokeh.</p>
        <pre class="codeexample"><code>!pip install holoviews bokeh --upgrade             </code></pre>
        <p>Tout d’abord, nous créons des groupes pour différentes traductions.</p>
        <pre class="codeexample"><code>languageorder = [] 
labeldataframe = dataframe.loc[(dataframe[&quot;type&quot;] == &quot;label&quot;)] 

groups = labeldataframe.groupby([&quot;property&quot;]) 

for k, group in groups:
     languageorder.append(list(groups.get_group((k))[&quot;language&quot;]))  

languagepairs = [] 
for lo in languageorder:
     for i in range(0, len(lo)-1):
        languagepairs.append([lo[i], lo[i+1], 1])

lpdataframe = pd.DataFrame(languagepairs) 
lpdataframe.columns = [&#39;source&#39;, &#39;target&#39;, &#39;count&#39;]  

groups = lpdataframe.groupby([&quot;source&quot;,&quot;target&quot;]).count().reset_index() 

print(groups)             </code></pre>
        <p>Ensuite, nous les visualisons en utilisant un graphique circulaire. Notez le code ci-dessous, nous n’ont pris
          que 500 combinaisons de paires de langues.</p>
        <pre class="codeexample"><code>import networkx as nx 
import matplotlib.pyplot as plot  

G = nx.from_pandas_edgelist(groups[:500], &#39;source&#39;, &#39;target&#39;)  

plot.rcParams[&quot;figure.figsize&quot;] = (15,15)  

pos = nx.circular_layout(G) 

nx.draw(G, pos, with_labels=True)             </code></pre>
        <p>Copiez le code ci-dessus et vérifiez le flux des traductions pour toutes les langues de votre choix (nombre
          de
          langues &gt; 20).</p>
        <p>Utilisez également la disposition des chords de Bokeh/Holoviews pour visualiser les poids.</p>
        <h3 id="exercice-1.5">Exercice 1.5</h3>
        <h3 id="prévision">Prévision</h3>
        <p>Notre objectif final est de prévoir la ou les prochaine(s) langue(s) qui seront traduit, compte tenu d’une
          séquence de traductions disponibles.</p>
        <p>Prenons par exemple, supposons que nous ayons vu les séquences suivantes de traduction.</p>
        <pre class="codeexample"><code>              [[&#39;en&#39;, &#39;it&#39;, &#39;fi&#39;, &#39;fr&#39;, &#39;de&#39;, &#39;nl&#39;, &#39;pt&#39;, &#39;pl&#39;, &#39;ca&#39;, &#39;cs&#39;]
                [&#39;en&#39;, &#39;it&#39;, &#39;fi&#39;, &#39;fr&#39;, &#39;de&#39;, &#39;ilo&#39;, &#39;zh&#39;, &#39;nb&#39;]
                [&#39;ru&#39;, &#39;hu&#39;, &#39;he&#39;, &#39;nl&#39;, &#39;pt&#39;, &#39;pl&#39;, &#39;ca&#39;, &#39;cs&#39;],
                ...              ]            
</code></pre>
        <p>Une fois que votre modèle a été formé à l’utilisation de ces données, il peut être en mesure prévoir la ou
          les
          prochaine(s) traduction(s) possibles.</p>
        <p><strong>Exemple 1</strong> : Si l’utilisateur saisit la séquence suivante,</p>
        <pre class="codeexample"><code>              [&#39;pt&#39;]             </code></pre>
        <p>votre modèle peut renvoyer la langue suivante</p>
        <pre class="codeexample"><code>              [&#39;pl&#39;]             </code></pre>
        <p><strong>Exemple 2</strong>: Si l’utilisateur saisit la séquence suivante,</p>
        <pre class="codeexample"><code>              [&#39;it&#39;, &#39;fi&#39;]             </code></pre>
        <p>votre modèle peut renvoyer la langue suivante</p>
        <pre class="codeexample"><code>              [&#39;fr&#39;]</code></pre>
        <p><strong>Exemple 3</strong>: Si l’utilisateur saisit la séquence suivante,</p>
        <pre
          class="codeexample"><code>              [&#39;nl&#39;, &#39;pt&#39;, &#39;pl&#39;]             </code></pre>
        <p>votre modèle peut renvoyer les langues suivantes</p>
        <pre class="codeexample"><code>              [&#39;ca&#39;, &#39;cs&#39;]             </code></pre>
        <p>Votre objectif dans cet exercice est de former un modèle de réseau neuronal qui peut prévoir la ou les
          prochaine(s) traduction(s) probables des étiquettes (ou descriptions ou alias).</p>
        <p>Pour créer ce modèle, vous devez utiliser la séquence de traduction des propriétés de Wikidata vues
          ci-dessus.
          Vous devez séparer les séquences de traduction dans des séquences d’entraînement et de test. Veuillez indiquer
          les mesures de précision de votre modèle.</p>
        <p>Il est important de faire la distinction entre les séquences de traduction des étiquettes, des descriptions
          et
          des alias, c’est-à-dire que l’utilisateur peut demander la prochaine langue(s) probable(s) pour l’une des
          trois.
        </p>
        <p>Veuillez commenter votre code et noter vos observations. Par exemple, quelle est la longueur maximale de la
          séquence d’entrée et de la séquence de sortie ? Quelle est la métrique de précision ? Pourquoi avez-vous
          choisi
          un réseau de neurones donné modèle ? ...</p>
        <p><strong>Indice:</strong> Vous pouvez utiliser un réseau neuronal récurrent avec LSTM (Long mémoire à court
          terme) ou des modèles de ‘word embeddings’.</p>
        <h3 id="dépôt">Dépôt</h2>
          <ul>
            <li>Renommez votre carnet en Nom1_Nom2_[Nom3].ipynb, où Nom1, Nom2 sont vos noms.</li>
            <li>Déposez votre notebook en ligne.</li>
            <li>Veuillez ne pas soumettre vos fichiers JSON, TSV et CSV.</li>
          </ul>
    </div>
  </div>
</body>

</html>
