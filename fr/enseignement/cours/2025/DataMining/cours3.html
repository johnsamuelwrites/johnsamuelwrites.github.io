<!DOCTYPE html>
<html lang="fr">

    <head>
        <meta charset="utf-8" />
        <title>Data Mining (2025-2026): Construction des modèles de traitement: John Samuel</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="shortcut icon" href="../../../../../images/logo/favicon.png" />
        <style type="text/css">
            /* ========================================
           SOLARIZED FUTURE THEME
           Clean, Scientific, Forward-Looking
           Royal Blue + Warm Amber Accents
           ======================================== */

            :root {
                /* Light Theme - Clean & Scientific */
                --bg-primary: #F8FAFC;
                --bg-secondary: #E2E8F0;
                --bg-tertiary: #FFFFFF;
                --text-primary: #0F172A;
                --text-secondary: #475569;
                --text-muted: #64748B;
                --accent-primary: #2563EB;
                --accent-secondary: #3B82F6;
                --accent-tertiary: #F59E0B;
                --accent-gradient: linear-gradient(135deg, #0E7490 0%, #3B82F6 52%, #6366F1 100%);
                --header-bg: linear-gradient(135deg, #0F766E 0%, #155E75 45%, #1E3A8A 100%);
                --footer-bg: linear-gradient(135deg, #134E4A 0%, #1E3A8A 100%);
                --card-bg: rgba(255, 255, 255, 0.85);
                --card-border: rgba(37, 99, 235, 0.2);
                --table-header-bg: linear-gradient(135deg, #2563EB, #1D4ED8);
                --table-cell-bg: rgba(226, 232, 240, 0.6);
                --code-bg: #F1F5F9;
                --shadow-color: rgba(15, 23, 42, 0.08);
                --glow-color: rgba(37, 99, 235, 0.25);
                --highlight-color: #F59E0B;
                --highlight-bg: #FEF3C7;
                --figcaption-bg: rgba(226, 232, 240, 0.9);
            }

            [data-theme="dark"] {
                /* Dark Theme - Deep Navy & Electric Blue */
                --bg-primary: #0F172A;
                --bg-secondary: #1E293B;
                --bg-tertiary: #334155;
                --text-primary: #F1F5F9;
                --text-secondary: #CBD5E1;
                --text-muted: #94A3B8;
                --accent-primary: #3B82F6;
                --accent-secondary: #60A5FA;
                --accent-tertiary: #FBBF24;
                --accent-gradient: linear-gradient(135deg, #0E7490 0%, #60A5FA 52%, #818CF8 100%);
                --header-bg: linear-gradient(135deg, #022C22 0%, #0F3D56 45%, #1E2A78 100%);
                --footer-bg: linear-gradient(135deg, #022C22 0%, #1E2A78 100%);
                --card-bg: rgba(30, 41, 59, 0.8);
                --card-border: rgba(59, 130, 246, 0.3);
                --table-header-bg: linear-gradient(135deg, #2563EB, #1E40AF);
                --table-cell-bg: rgba(51, 65, 85, 0.7);
                --code-bg: #1E293B;
                --shadow-color: rgba(0, 0, 0, 0.3);
                --glow-color: rgba(59, 130, 246, 0.3);
                --highlight-color: #FBBF24;
                --highlight-bg: rgba(251, 191, 36, 0.15);
                --figcaption-bg: rgba(30, 41, 59, 0.95);
            }

            /* Base Styles */
            * {
                box-sizing: border-box;
            }

            html {
                height: 100%;
                scroll-behavior: smooth;
            }

            body {
                height: 100%;
                width: 100%;
                background: var(--bg-primary);
                margin: 0;
                overflow: hidden;
                font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
                color: var(--text-primary);
                transition: background-color 0.4s ease, color 0.4s ease;
            }

            /* Animated Background */
            body::before {
                content: '';
                position: fixed;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                background:
                    radial-gradient(ellipse at 20% 20%, var(--glow-color) 0%, transparent 50%),
                    radial-gradient(ellipse at 80% 80%, rgba(37, 99, 235, 0.15) 0%, transparent 50%),
                    radial-gradient(ellipse at 50% 50%, rgba(245, 158, 11, 0.08) 0%, transparent 70%);
                pointer-events: none;
                z-index: -1;
                animation: backgroundPulse 8s ease-in-out infinite;
            }

            @keyframes backgroundPulse {

                0%,
                100% {
                    opacity: 0.6;
                }

                50% {
                    opacity: 1;
                }
            }

            /* Theme Toggle Button */
            .theme-toggle {
                position: fixed;
                top: 1rem;
                right: 1rem;
                z-index: 1000;
                background: var(--card-bg);
                -webkit-backdrop-filter: blur(10px);
                backdrop-filter: blur(10px);
                border: 1px solid var(--card-border);
                border-radius: 50%;
                width: 48px;
                height: 48px;
                cursor: pointer;
                display: flex;
                align-items: center;
                justify-content: center;
                box-shadow: 0 4px 20px var(--shadow-color);
                transition: all 0.3s ease;
            }

            .theme-toggle:hover {
                transform: scale(1.1);
                box-shadow: 0 6px 30px var(--glow-color);
            }

            .theme-toggle svg {
                width: 24px;
                height: 24px;
                fill: var(--accent-primary);
                transition: fill 0.3s ease;
            }

            .theme-toggle .sun-icon {
                display: none;
            }

            .theme-toggle .moon-icon {
                display: block;
            }

            [data-theme="dark"] .theme-toggle .sun-icon {
                display: block;
            }

            [data-theme="dark"] .theme-toggle .moon-icon {
                display: none;
            }

            /* Slide Styles */
            .slide {
                height: 100vh;
                width: 100%;
                display: flex;
                flex-direction: column;
                animation: fadeIn 0.5s ease-out;
            }

            @keyframes fadeIn {
                from {
                    opacity: 0;
                    transform: translateY(10px);
                }

                to {
                    opacity: 1;
                    transform: translateY(0);
                }
            }

            /* Header Styles */
            .header {
                background: var(--header-bg);
                height: 5.5vmax;
                display: flex;
                align-items: center;
                justify-content: center;
                position: relative;
                overflow: hidden;
                box-shadow: 0 4px 20px var(--shadow-color);
            }

            .header::before {
                content: '';
                position: absolute;
                top: 0;
                left: -100%;
                width: 200%;
                height: 100%;
                background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.1), transparent);
                animation: headerShine 4s ease-in-out infinite;
            }

            @keyframes headerShine {
                0% {
                    transform: translateX(-50%);
                }

                100% {
                    transform: translateX(50%);
                }
            }

            .header h1 {
                color: #ffffff;
                text-align: center;
                font-size: 3vmax;
                line-height: 1.3;
                margin: 0;
                padding: 0 2rem;
                text-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
                font-weight: 600;
                letter-spacing: 0.5px;
                position: relative;
                z-index: 1;
            }

            /* Content Styles */
            .content {
                height: calc(100vh - 5.5vmax - 3.2vmax - 0.6vmax);
                width: 95vw;
                max-width: 95vw;
                display: flex;
                line-height: 1.8em;
                flex-direction: column;
                align-items: flex-start;
                margin: 0 auto;
                color: var(--text-primary);
                text-align: left;
                padding: 1.5vmax;
                overflow-x: hidden;
                overflow-y: auto;
                font-size: 2.8vmin;
                flex-wrap: wrap;
                background: var(--card-bg);
                -webkit-backdrop-filter: blur(10px);
                backdrop-filter: blur(10px);
                overflow-wrap: anywhere;
                word-break: break-word;
            }

            .content h1,
            .content h2,
            .content h3,
            .content h4 {
                color: var(--accent-primary);
                font-weight: 600;
                margin-top: 0.5em;
                margin-bottom: 0.5em;
                text-shadow: 0 1px 2px var(--shadow-color);
            }

            .content h1 {
                font-size: 2.2em;
                background: var(--accent-gradient);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                background-clip: text;
            }

            .content h2 {
                font-size: 1.6em;
            }

            .content h3 {
                font-size: 1.3em;
            }

            .content h4 {
                font-size: 1.1em;
            }

            .content p {
                margin: 0.6em 0;
                line-height: 1.9;
                padding: 0.3em 0;
                max-width: 100%;
            }

            .content ul,
            .content ol,
            .content li,
            .content figure,
            .content img {
                max-width: 100%;
            }

            /* Bold/Strong terms - Key terminology highlighting */
            .content b,
            .content strong {
                color: var(--accent-primary);
                font-weight: 700;
                background: linear-gradient(120deg, var(--table-cell-bg) 0%, var(--table-cell-bg) 100%);
                background-size: 100% 0.3em;
                background-repeat: no-repeat;
                background-position: 0 88%;
                padding: 0 0.2em;
                border-radius: 0.2em;
                transition: all 0.3s ease;
            }

            .content li>b:first-child,
            .content li>strong:first-child {
                display: inline-block;
                background: var(--accent-gradient);
                color: white;
                padding: 0.1em 0.3em;
                border-radius: 0.4em;
                margin-right: 0.3em;
                font-size: 0.85em;
                box-shadow: 0 2px 6px var(--shadow-color);
                text-shadow: 0 1px 2px rgba(0, 0, 0, 0.2);
            }

            /* Superscript styling for references */
            .content sup {
                color: var(--accent-tertiary);
                font-weight: 600;
            }

            .content sup a {
                color: var(--accent-tertiary);
                font-weight: 600;
            }

            /* Divs with width styling (two-column layouts) */
            .content>div[style*="width"] {
                background: var(--card-bg);
                border-radius: 1rem;
                padding: 1rem;
                margin: 0.5rem;
                box-shadow: 0 2px 10px var(--shadow-color);
                border: 1px solid var(--card-border);
            }

            /* Topic Headings */
            .content .topichighlight {
                background: linear-gradient(135deg, #D97706, #F59E0B);
                color: #FFFFFF;
                padding: 0.5em 1em;
                border-radius: 0.5em;
                display: inline-block;
                box-shadow: 0 2px 8px rgba(245, 158, 11, 0.3);
            }

            .content .topicheading {
                background: var(--accent-gradient);
                color: #FFFFFF;
                vertical-align: middle;
                border-radius: 0 2vmax 2vmax 0;
                height: 4vmax;
                line-height: 4vmax;
                padding-left: 1.5vmax;
                padding-right: 1vmax;
                margin: 0.1vmax 0 1vmax 0;
                width: 55%;
                font-weight: 600;
                box-shadow: 0 4px 15px var(--shadow-color);
                position: relative;
                overflow: hidden;
            }

            .content .topicheading::after {
                content: '';
                position: absolute;
                top: 0;
                right: 0;
                width: 30%;
                height: 100%;
                background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2));
            }

            .content .topicsubheading {
                background: var(--accent-gradient);
                color: #FFFFFF;
                vertical-align: middle;
                border-radius: 0 1.5vmax 1.5vmax 0;
                height: 3vmax;
                margin: 0.1vmax 0 1vmax 0;
                font-size: 95%;
                line-height: 3vmax;
                padding-left: 1.5vmax;
                padding-right: 1vmax;
                width: 48%;
                font-weight: 600;
                box-shadow: 0 3px 12px var(--shadow-color);
            }

            /* Flex and Grid Content */
            .content .flexcontent {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
                gap: 0.9rem;
                align-items: center;
                justify-items: center;
                width: 100%;
                max-width: 100%;
                margin: 0.4rem auto;
                padding: 0.4rem;
                font-size: 2.8vmin;
            }

            .content .gridcontent {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                grid-gap: 1rem;
            }

            /* Lists - Enhanced Visual Styling */
            .content ul,
            .content ol {
                padding-left: 0.5em;
                margin: 0.8em 0;
                list-style: none;
            }

            .content li {
                line-height: 1.5em;
                margin-bottom: 0.6em;
                position: relative;
                padding-left: 1.8em;
                padding-right: 0.5em;
                padding-top: 0.1em;
                padding-bottom: 0.1em;
                border-radius: 0.5em;
                transition: all 0.3s ease;
            }

            /* Unordered list custom bullet */
            .content ul>li::before {
                content: '';
                position: absolute;
                left: 0.4em;
                top: 0.85em;
                width: 0.5em;
                height: 0.5em;
                background: var(--accent-gradient);
                border-radius: 50%;
                box-shadow: 0 0 6px var(--glow-color);
            }

            /* Ordered list custom numbers */
            .content ol {
                counter-reset: item;
            }

            .content ol>li {
                counter-increment: item;
            }

            .content ol>li::before {
                content: counter(item);
                position: absolute;
                left: 0.2em;
                top: 0.3em;
                width: 1.4em;
                height: 1.4em;
                background: var(--accent-gradient);
                color: white;
                border-radius: 50%;
                font-size: 0.75em;
                font-weight: 700;
                display: flex;
                align-items: center;
                justify-content: center;
                box-shadow: 0 2px 8px var(--shadow-color);
            }

            /* Nested lists */
            .content ul ul,
            .content ol ul,
            .content ul ol,
            .content ol ol {
                margin: 0.4em 0 0.4em 0.5em;
                padding-left: 0.3em;
            }

            .content ul ul>li::before,
            .content ol ul>li::before {
                width: 0.4em;
                height: 0.4em;
                background: var(--accent-secondary);
                top: 0.9em;
            }

            .content ol ol>li::before,
            .content ul ol>li::before {
                width: 1.2em;
                height: 1.2em;
                font-size: 0.65em;
                background: var(--accent-secondary);
            }

            /* List item hover effect */
            .content li:hover {
                background: var(--table-cell-bg);
                border-radius: 0.5em;
            }

            /* Links */
            .content a:link,
            .content a:visited {
                color: var(--accent-tertiary);
                text-decoration: none;
                border-bottom: 1px dashed var(--accent-tertiary);
                transition: all 0.3s ease;
            }

            .content a:hover {
                color: var(--accent-secondary);
                border-bottom-style: solid;
            }

            /* Tables - Enhanced Visual Styling */
            .content table {
                color: var(--text-primary);
                font-size: 100%;
                width: 100%;
                border-collapse: separate;
                border-spacing: 0.4rem;
                margin: 1em 0;
                background: var(--card-bg);
                border-radius: 1rem;
                padding: 0.5rem;
                box-shadow: 0 4px 20px var(--shadow-color);
            }

            .content th {
                color: #FFFFFF;
                background: var(--table-header-bg);
                border-radius: 0.8rem;
                font-size: 105%;
                padding: 0.8em 1em;
                font-weight: 600;
                text-shadow: 0 1px 2px rgba(0, 0, 0, 0.2);
                position: relative;
                overflow: hidden;
            }

            .content th::after {
                content: '';
                position: absolute;
                top: 0;
                right: 0;
                width: 30%;
                height: 100%;
                background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.15));
                pointer-events: none;
            }

            .content td {
                color: var(--text-primary);
                padding: 0.7em 1em;
                background: var(--table-cell-bg);
                border-radius: 0.6rem;
                -webkit-backdrop-filter: blur(5px);
                backdrop-filter: blur(5px);
                transition: all 0.3s ease;
                border-left: 3px solid transparent;
            }

            .content tr:hover td {
                background: var(--card-border);
                border-left-color: var(--accent-primary);
                transform: translateX(3px);
            }

            /* Figures and Images - Enhanced */
            .content figure {
                max-width: 90%;
                max-height: 90%;
                margin: 1em auto;
                text-align: center;
                padding: 0.8rem;
                background: var(--card-bg);
                border-radius: 1.2rem;
                box-shadow: 0 4px 20px var(--shadow-color);
                border: 1px solid var(--card-border);
            }

            .content .fullwidth img {
                max-width: 90%;
                max-height: 90%;
            }

            .content figure img {
                max-width: 50vmin;
                max-height: 50vmin;
                display: block;
                margin: 0 auto;
                border-radius: 0.8rem;
                box-shadow: 0 4px 15px var(--shadow-color);
                transition: transform 0.3s ease, box-shadow 0.3s ease;
            }

            .content figure img:hover {
                transform: scale(1.02);
                box-shadow: 0 8px 25px var(--glow-color);
            }

            .content figure figcaption {
                max-width: 95%;
                margin: 0.8rem auto 0;
                font-size: 90%;
                text-align: center;
                padding: 0.5rem 1rem;
                background: var(--accent-gradient);
                color: white;
                border-radius: 2rem;
                font-weight: 500;
                font-style: normal;
                box-shadow: 0 2px 10px var(--shadow-color);
            }

            /* Flexcontent images (multiple images) */
            .content .flexcontent {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
                gap: 0.9rem;
                align-items: center;
                justify-items: center;
                width: 100%;
                max-width: 100%;
                margin: 0.4rem auto;
                padding: 0.4rem;
                overflow: hidden;
            }

            .content .flexcontent img {
                border-radius: 0.8rem;
                box-shadow: 0 4px 15px var(--shadow-color);
                transition: all 0.3s ease;
                border: 2px solid var(--card-border);
                width: clamp(220px, 36vmin, 420px);
                max-width: 100%;
                height: auto;
                max-height: 36vmin;
                object-fit: contain;
            }

            .content .flexcontent img:hover {
                transform: scale(1.03) rotate(1deg);
                box-shadow: 0 8px 25px var(--glow-color);
                border-color: var(--accent-primary);
            }

            /* Code and Pre - Enhanced */
            .content pre {
                background: var(--code-bg);
                border: 1px solid var(--card-border);
                border-left: 4px solid var(--accent-primary);
                border-radius: 0 0.8rem 0.8rem 0;
                padding: 1.2rem 1.5rem;
                overflow-x: auto;
                font-family: 'Consolas', 'Monaco', 'Fira Code', monospace;
                font-size: 85%;
                line-height: 1.6;
                box-shadow: 0 4px 15px var(--shadow-color);
                position: relative;
            }

            .content pre::before {
                content: 'CODE';
                position: absolute;
                top: 0;
                right: 0;
                background: var(--accent-gradient);
                color: white;
                font-size: 0.6em;
                padding: 0.2em 0.8em;
                border-radius: 0 0.8rem 0 0.5rem;
                font-weight: 600;
                letter-spacing: 0.5px;
            }

            .content code {
                font-family: 'Consolas', 'Monaco', 'Fira Code', monospace;
                background: var(--table-cell-bg);
                padding: 0.15em 0.4em;
                border-radius: 0.3em;
                font-size: 90%;
                color: var(--accent-primary);
                border: 1px solid var(--card-border);
            }

            /* Inline code in pre should not have extra styling */
            .content pre code {
                background: transparent;
                padding: 0;
                border: none;
                color: inherit;
            }

            /* Footer Styles */
            .footer {
                height: 3.2vmax;
                line-height: 3.2vmax;
                background: var(--footer-bg);
                margin: 0;
                padding: 0 1vmax;
                display: flex;
                align-items: center;
                justify-content: space-between;
                box-shadow: 0 -4px 20px var(--shadow-color);
            }

            .footer .contact {
                color: #ffffff;
                text-align: left;
                font-size: 2.8vmin;
                font-weight: 500;
                text-shadow: 0 1px 3px rgba(0, 0, 0, 0.2);
            }

            .footer .navigation {
                display: flex;
                align-items: center;
                gap: 0.5rem;
                font-size: 2.8vmin;
                color: #ffffff;
                font-weight: 600;
            }

            .footer .navigation a {
                color: #ffffff;
                text-decoration: none;
                padding: 0.3rem 0.6rem;
                border-radius: 0.5rem;
                transition: all 0.3s ease;
                display: inline-flex;
                align-items: center;
            }

            .footer .navigation a:hover {
                background: rgba(255, 255, 255, 0.2);
            }

            .footer .navigation .next::after {
                content: " >";
                margin-left: 0.2rem;
            }

            .footer .navigation .prev::after {
                content: "< ";
                margin-right: 0.2rem;
            }

            /* Jupyter/Highlight Styles - Enhanced */
            .highlight {
                background: var(--code-bg);
                border-radius: 0.8rem;
                padding: 1rem;
                border: 1px solid var(--card-border);
                border-left: 4px solid var(--accent-tertiary);
                box-shadow: 0 4px 15px var(--shadow-color);
                position: relative;
                margin: 0.5em 0;
            }

            .highlight::before {
                content: 'PYTHON';
                position: absolute;
                top: 0;
                right: 0;
                background: linear-gradient(135deg, #1D4ED8, #3B82F6);
                color: white;
                font-size: 0.55em;
                padding: 0.2em 0.8em;
                border-radius: 0 0.8rem 0 0.5rem;
                font-weight: 600;
                letter-spacing: 0.5px;
            }

            .highlight pre {
                margin: 0;
                padding: 0;
                background: transparent;
                border: none;
                box-shadow: none;
            }

            .highlight pre::before {
                display: none;
            }

            .highlight .c {
                color: #6b7280;
                font-style: italic
            }

            .highlight .err {
                border: 1px solid #ef4444;
                border-radius: 2px;
            }

            .highlight .k {
                color: var(--accent-primary);
                font-weight: bold
            }

            .highlight .o {
                color: var(--text-secondary)
            }

            .highlight .ch {
                color: #6b7280;
                font-style: italic
            }

            .highlight .c1 {
                color: #6b7280;
                font-style: italic
            }

            .highlight .cs {
                color: #6b7280;
                font-style: italic
            }

            .highlight .cm {
                color: #6b7280;
                font-style: italic
            }

            .highlight .nn {
                color: var(--accent-tertiary);
                font-weight: bold
            }

            .highlight .s2 {
                color: var(--highlight-color)
            }

            .highlight .s1 {
                color: var(--highlight-color)
            }

            .highlight .kn {
                color: var(--accent-primary);
                font-weight: bold
            }

            .highlight .nb {
                color: var(--accent-secondary)
            }

            .highlight .n {
                color: var(--text-primary)
            }

            .highlight .p {
                color: var(--text-secondary)
            }

            .highlight .mb {
                color: var(--highlight-color)
            }

            .highlight .mf {
                color: var(--highlight-color)
            }

            .highlight .mh {
                color: var(--highlight-color)
            }

            .highlight .mi {
                color: var(--highlight-color)
            }

            .highlight .mo {
                color: var(--highlight-color)
            }

            /* Title slide (slide 1) special styling */
            #slide1 .content {
                display: flex;
                flex-direction: column;
                justify-content: center;
                align-items: center;
                text-align: center;
            }

            #slide1 .content h1 {
                font-size: 3vw;
                line-height: 1.2;
                padding-bottom: 0.2em;
                margin-bottom: 2rem;
                animation: titleGlow 3s ease-in-out infinite alternate;
            }

            @keyframes titleGlow {
                from {
                    text-shadow: 0 0 20px var(--glow-color);
                }

                to {
                    text-shadow: 0 0 40px var(--glow-color), 0 0 60px var(--accent-tertiary);
                }
            }

            #slide1 .content p {
                font-size: 1.2em;
                max-width: 600px;
                background: var(--card-bg);
                padding: 1.5rem 2rem;
                border-radius: 1rem;
                box-shadow: 0 8px 30px var(--shadow-color);
                border: 1px solid var(--card-border);
            }

            #slide1 .content img {
                margin-top: 1rem;
                border-radius: 0.5rem;
                box-shadow: 0 4px 15px var(--shadow-color);
            }

            /* Responsive Styles */
            @media (max-width: 640px),
            screen and (orientation: portrait) {
                body {
                    max-width: 100%;
                    max-height: 100%;
                }

                .slide {
                    height: 100vh;
                    width: 100%;
                }

                .content {
                    height: calc(100vh - 5.5vmax - 3.2vmax - 0.6vmax);
                    width: 100%;
                    padding: 1vw;
                    line-height: 3.5vmax;
                    font-size: 1.8vmax;
                }

                .content .topicheading,
                .content .topicsubheading {
                    width: 95%;
                }

                .content h1,
                .content h2,
                .content h3,
                .content h4 {
                    width: 100%;
                }

                .content figure img {
                    max-width: 80vmin;
                    max-height: 50vmin;
                }

                .header h1 {
                    font-size: 2.5vmax;
                    padding: 0 1rem;
                }

                .theme-toggle {
                    width: 40px;
                    height: 40px;
                    top: 0.5rem;
                    right: 0.5rem;
                }
            }

            @media print {
                body {
                    max-width: 100%;
                    max-height: 100%;
                    background: white;
                }

                body::before {
                    display: none;
                }

                .theme-toggle {
                    display: none;
                }

                .content {
                    font-size: 2.8vmin;
                    background: white;
                }

                .content .flexcontent {
                    font-size: 2.5vmin;
                }

                .header,
                .footer {
                    background: #2563EB !important;
                    -webkit-print-color-adjust: exact;
                    print-color-adjust: exact;
                }
            }

            /* Smooth scrollbar */
            ::-webkit-scrollbar {
                width: 8px;
                height: 8px;
            }

            ::-webkit-scrollbar-track {
                background: var(--bg-secondary);
                border-radius: 4px;
            }

            ::-webkit-scrollbar-thumb {
                background: var(--accent-primary);
                border-radius: 4px;
            }

            ::-webkit-scrollbar-thumb:hover {
                background: var(--accent-secondary);
            }
        </style>
        <script src="../../../../../fr/enseignement/cours/scripts/tex-mml-chtml.js" id="MathJax-script"></script>
    </head>

    <body>
        <!-- Theme Toggle Button -->
        <button class="theme-toggle" onclick="toggleTheme()" aria-label="Toggle theme">
            <svg class="sun-icon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 3V1m0 22v-2M4.22 4.22l1.42 1.42m12.72 12.72l1.42 1.42M1 12h2m18 0h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42M12 6a6 6 0 100 12 6 6 0 000-12z" />
            </svg>
            <svg class="moon-icon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z" />
            </svg>
        </button>
        <section class="slide" id="slide1">
            <div class="header">
            </div>
            <div class="content">
                <h1 style="font-size:3.5vw">Data Mining</h1>
                <p><b>John Samuel</b></br>
                    CPE Lyon<br /><br />
                    <b>Année</b>: 2025-2026<br />
                    <b>Courriel</b>: john.samuel@cpe.fr</br>
                    </br>
                    <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img
                            alt="Creative Commons License" style="border-width:0"
                            src="../../../../../en/teaching/courses/2017/C/88x31.png" /></a>
                </p>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">1

                    <a class="next" href="#slide2"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide2">
            <div class="header">
                <h1>Data Mining</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Objectifs</h3>
                <ol>
                    <li>Apprentissage machine</li>
                    <li>Apprentissage profond</li>
                    <li>Apprentissage par renforcement</li>
                    <li>Licences de données, éthique et vie privée</li>
                </ol>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">2
                    <a class="prev" href="#slide1"></a>
                    <a class="next" href="#slide3"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide3">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Neurones biologiques</h3>
                <ul style="flex:1 1 47%; max-width:47%; min-width:220px;">
                    <li><b>Inspiration biologique</b> : Les réseaux de neurones artificiels s'inspirent du cerveau
                        humain.</li>
                    <li><b>Unité de base</b> : Le neurone est l'unité fondamentale qui traite et transmet l'information
                        via des signaux électrochimiques.</li>
                    <li><b>Composants clés</b> : Il est composé de dendrites (entrées), d'un soma (traitement) et d'un
                        axone (sortie), qui communiquent via des synapses.</li>
                </ul>
                <ol style="font-size:2vh">
                    <li>https://en.wikipedia.org/wiki/File:Neuron3.png</li>
                </ol>
                <figure style="width:42%">
                    <img src="../../2021/MachineLearning/Neuron3.png" height="350px"
                        alt="Biological neuron structure" />
                    <figcaption>Neurone biologique<sup>1</sup></figcaption>
                </figure>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">3
                    <a class="prev" href="#slide2"></a>
                    <a class="next" href="#slide4"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide4">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Introduction</h3>
                <ul style="flex:1 1 47%; max-width:47%; min-width:220px;">
                    <li><b>Apprentissage à partir de données</b> : Les algorithmes construisent un modèle mathématique
                        basé sur des données d'échantillon, appelées "données d'entraînement".</li>
                    <li><b>Prise de décision</b> : Le modèle est utilisé pour faire des prédictions ou prendre des
                        décisions sans être explicitement programmé pour effectuer la tâche.</li>
                    <li><b>Amélioration continue</b> : Les systèmes peuvent apprendre et s'améliorer automatiquement
                        avec l'expérience.</li>
                </ul>
                <figure style="width:42%">
                    <img src="../../../../../en/teaching/courses/2017/DataMining/images/Colored_neural_network.svg"
                        alt="Colored artificial neural network diagram" />
                    <figcaption>Réseaux de neurones artificiels</figcaption>
                </figure>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">4
                    <a class="prev" href="#slide3"></a>
                    <a class="next" href="#slide5"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide5">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Réseau de neurones</h3>
                <p>Les réseaux de neurones sont couramment utilisés dans le domaine de l'apprentissage machine, en
                    particulier dans des tâches telles que la classification, la régression, la reconnaissance d'images,
                    le
                    traitement du langage naturel, et bien d'autres. Un réseau de neurones artificiels est une
                    collection
                    d'unités interconnectées appelées neurones artificiels. Ces réseaux sont inspirés de la structure du
                    cerveau biologique</p>
                <ul>
                    <li><b>Connexions</b> : Chaque connexion entre les neurones, similaire aux synapses dans le cerveau
                        biologique, peut transmettre un signal aux autres neurones.</li>
                    <li><b>Transmission de signal</b> : Un neurone artificiel reçoit un signal, le traite à l'aide d'une
                        fonction non linéaire, et peut ensuite transmettre un signal aux neurones qui lui sont
                        connectés.
                    </li>
                    <li><b>Fonction d'activation</b> : La sortie de chaque neurone est calculée par une fonction non
                        linéaire appliquée à la somme pondérée de ses entrées. Cette fonction d'activation introduit une
                        non-linéarité dans le réseau, permettant de modéliser des relations complexes.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">5
                    <a class="prev" href="#slide4"></a>
                    <a class="next" href="#slide6"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide6">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Réseau de neurones</h3>
                <ul>
                    <li><b>Poids ajustables</b> : Les neurones et les connexions ont généralement des poids qui sont
                        ajustés
                        au fur et à mesure de l'apprentissage. Ces poids déterminent l'importance relative des
                        différentes
                        entrées pour chaque neurone.</li>
                    <li><b>Ajustement des poids</b> : Les poids peuvent être ajustés pour augmenter ou diminuer la force
                        du
                        signal au niveau d'une connexion, influençant ainsi la contribution de cette connexion aux
                        calculs
                        du réseau.</li>
                    <li><b>Seuil</b> : Les neurones peuvent avoir un seuil, de sorte qu'un signal n'est envoyé que si la
                        somme pondérée de ses entrées dépasse ce seuil. Cela permet au réseau de moduler sa sensibilité
                        aux
                        entrées.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">6
                    <a class="prev" href="#slide5"></a>
                    <a class="next" href="#slide7"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide7">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Les couches</h3>
                <p>Les neurones sont organisés en couches. Il existe généralement trois types de couches dans un réseau
                    de
                    neurones :</p>
                <ul>
                    <li><b>Couche d'Entrée (Input Layer)</b> : Cette couche reçoit les signaux initiaux ou les données
                        en
                        entrée. Chaque neurone dans cette couche représente une caractéristique ou une variable
                        d'entrée.
                    </li>
                    <li><b>Couches Cachées (Hidden Layers)</b> : Ces couches effectuent des transformations non
                        linéaires
                        sur les entrées. Elles sont responsables de l'extraction et de la représentation des
                        caractéristiques importantes des données. Un réseau de neurones peut avoir une ou plusieurs
                        couches
                        cachées.</li>
                    <li><b>Couche de Sortie (Output Layer)</b> : Cette couche génère la sortie du réseau. Le nombre de
                        neurones dans cette couche dépend de la nature de la tâche, par exemple, une classification
                        binaire
                        aurait un neurone de sortie, tandis qu'une classification multi-classes en aurait plusieurs.
                    </li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">7
                    <a class="prev" href="#slide6"></a>
                    <a class="next" href="#slide8"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide8">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Les couches</h3>
                <ul>
                    <li><b>Transformations</b> : Chaque couche, y compris la couche d'entrée, effectue des
                        transformations
                        sur les signaux qu'elle reçoit. Ces transformations sont déterminées par les poids des
                        connexions
                        entre les neurones.</li>
                    <li><b>Propagation des signaux</b> : Les signaux passent de la première couche (l'entrée) à la
                        dernière
                        couche (la sortie) à travers les connexions pondérées entre les neurones. Ce processus est
                        souvent
                        appelé la propagation avant (forward propagation). Pendant l'apprentissage, la rétropropagation
                        (backpropagation) est utilisée pour ajuster les poids afin de minimiser l'erreur de prédiction.
                    </li>
                    <li><b>Architecture</b> : La manière dont les couches sont organisées et connectées dans le réseau
                        constitue son architecture. Les réseaux de neurones peuvent avoir des architectures diverses, y
                        compris des réseaux profonds (avec de nombreuses couches cachées) ou des architectures plus
                        simples.
                    </li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">8
                    <a class="prev" href="#slide7"></a>
                    <a class="next" href="#slide9"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide9">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">L'entraînement</h3>
                <p>L'objectif global de l'entraînement est d'ajuster les poids du réseau de manière à ce qu'il puisse
                    généraliser à de nouvelles données, produisant des résultats précis pour des exemples qu'il n'a pas
                    vu
                    pendant l'entraînement.</p>
                <ul>
                    <li><b>Données d'entraînement</b> : Les réseaux neuronaux apprennent à partir d'exemples. Chaque
                        exemple
                        se compose d'une "entrée" (les caractéristiques) et d'un "résultat" connu (l'étiquette ou la
                        sortie
                        attendue).</li>
                    <li><b>Calcul de l'erreur</b> : Lorsque le réseau produit une sortie pour une entrée donnée,
                        l'erreur
                        est calculée en comparant cette sortie à la sortie cible (le résultat connu). Il existe
                        différentes
                        mesures d'erreur, mais la somme des carrés des différences (Mean Squared Error, MSE) est
                        couramment
                        utilisée.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">9
                    <a class="prev" href="#slide8"></a>
                    <a class="next" href="#slide10"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide10">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">L'entraînement</h3>
                <ul>
                    <li><b>Rétropropagation (Backpropagation)</b> : Le réseau ajuste ses poids en utilisant la
                        rétropropagation. Cette technique minimise l'erreur en modifiant les poids à partir de la couche
                        de
                        sortie jusqu'à la couche d'entrée. La règle de la chaîne du calcul différentiel est appliquée
                        pour
                        propager l'erreur à travers le réseau.</li>
                    <li><b>Descente de gradient</b> : La règle d'apprentissage souvent utilisée pour ajuster les poids
                        est
                        la descente de gradient. Elle utilise le gradient de l'erreur par rapport aux poids pour mettre
                        à
                        jour les poids dans la direction qui minimise l'erreur.</li>
                    <li><b>Itérations</b> : Le processus d'ajustement des poids en fonction de l'erreur est répété pour
                        de
                        nombreux exemples du jeu de données d'entraînement. Chaque itération est appelée une "époque".
                        Plusieurs époques peuvent être nécessaires pour que le réseau converge vers un état où l'erreur
                        est
                        suffisamment basse.</li>
                    <li><b>Optimisation</b> : Différentes techniques d'optimisation peuvent être utilisées pour
                        améliorer la
                        convergence du réseau, telles que l'ajustement adaptatif du taux d'apprentissage.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">10
                    <a class="prev" href="#slide9"></a>
                    <a class="next" href="#slide11"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide11">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Composants des réseaux de neurones artificiels</h3>
                <ul>
                    <li><b>Neurones</b> : Les neurones artificiels sont les unités de base d'un réseau de neurones.
                        Chaque
                        neurone reçoit des signaux d'entrée, effectue un calcul sur ces signaux à l'aide d'une fonction
                        d'activation, et produit une sortie. Les neurones sont organisés en couches, à savoir la couche
                        d'entrée, les couches cachées, et la couche de sortie.</li>
                    <li><b>Connexions et Poids</b> : Les connexions entre les neurones sont représentées par des poids.
                        Chaque connexion a un poids associé, qui détermine l'importance relative de cette connexion dans
                        le
                        calcul du neurone de sortie. Pendant l'entraînement, ces poids sont ajustés pour minimiser
                        l'erreur
                        de prédiction du réseau.</li>
                    <li><b>Fonction de Propagation (Propagation avant)</b> : La fonction de propagation, également
                        appelée
                        propagation avant, décrit le processus par lequel les signaux se propagent à travers le réseau
                        depuis la couche d'entrée jusqu'à la couche de sortie. Chaque neurone effectue une
                        transformation
                        sur les signaux qu'il reçoit, et ces signaux modifiés sont transmis aux neurones de la couche
                        suivante.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">11
                    <a class="prev" href="#slide10"></a>
                    <a class="next" href="#slide12"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide12">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Composants des réseaux de neurones artificiels</h3>
                <h3 class="topicsubheading">Neurones</h3>
                <p>Chaque neurone artificiel a des entrées, qui peuvent être les valeurs caractéristiques d'un
                    échantillon
                    de données externe, et produit une seule sortie. Cette sortie peut être envoyée à plusieurs autres
                    neurones, formant ainsi la structure interconnectée du réseau neuronal. La <b>fonction
                        d'activation</b>
                    joue un rôle crucial dans le calcul de la sortie d'un neurone. Le processus comprend les étapes
                    suivantes :</p>
                <ul>
                    <li><b>Somme pondérée</b> : Pour trouver la sortie du neurone, on prend la somme pondérée de tous
                        les
                        intrants (entrées). Chaque entrée est multipliée par le poids correspondant à la connexion.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">12
                    <a class="prev" href="#slide11"></a>
                    <a class="next" href="#slide13"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide13">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Composants des réseaux de neurones artificiels</h3>
                <h3 class="topicsubheading">Neurones</h3>
                <ul>
                    <li><b>Ajout d'un terme de biais</b> : Un terme de biais est ajouté à la somme pondérée. Le terme de
                        biais est un paramètre supplémentaire qui permet au modèle d'apprendre un décalage ou une
                        translation.</li>
                    <li><b>Activation</b> : La somme pondérée, parfois appelée activation, est ensuite passée par une
                        fonction d'activation. Cette fonction est généralement non linéaire et introduit de la
                        complexité
                        dans le modèle, permettant au réseau de capturer des relations non linéaires dans les données
                    </li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">13
                    <a class="prev" href="#slide12"></a>
                    <a class="next" href="#slide14"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide14">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Composants des réseaux de neurones artificiels</h3>
                <p><b>Connexions et poids</b>: Le réseau de neurones est constitué de connexions, où chaque connexion
                    transmet la sortie d'un neurone
                    comme entrée à un autre neurone. Chaque connexion possède un poids qui représente son importance
                    relative dans la transmission du signal.</p>
                <ul>
                    <li>Un neurone donné peut avoir <b>plusieurs connexions d'entrée</b>, recevant des signaux de
                        différents
                        neurones, et plusieurs connexions de sortie, transmettant des signaux à d'autres neurones. Les
                        poids
                        associés à ces connexions permettent au réseau de moduler l'influence de chaque neurone sur les
                        autres, ajustant ainsi la force et la direction des signaux transmis à travers le réseau.</li>
                    <li>Cette structure de connexion et de pondération est fondamentale dans le fonctionnement des
                        réseaux
                        de neurones, car elle permet au réseau d'apprendre des représentations complexes des données et
                        d'ajuster ses paramètres pendant l'entraînement pour accomplir des tâches spécifiques.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">14
                    <a class="prev" href="#slide13"></a>
                    <a class="next" href="#slide15"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide15">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Composants des réseaux de neurones artificiels</h3>
                <h3 class="topicsubheading">Fonction de propagation</h3>
                <p><b>Calcul de l'entrée d'un neurone</b> : La fonction de propagation calcule l'entrée d'un neurone en
                    prenant la somme pondérée des sorties de ses prédécesseurs, où chaque sortie est multipliée par le
                    poids
                    de la connexion correspondante. Cela peut être représenté mathématiquement comme suit :</p>
                <p>\[ \text{Entrée du Neurone} = \sum_{i=1}^{n} (\text{Sortie du Prédécesseur}_i \times \text{Poids}_i)
                    \]
                    où \(n\) est le nombre de connexions d'entrée.</p>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">15
                    <a class="prev" href="#slide14"></a>
                    <a class="next" href="#slide16"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide16">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Composants des réseaux de neurones artificiels</h3>
                <h3 class="topicsubheading">Fonction de propagation</h3>
                <p><b>Ajout d'un terme de biais</b> : Un terme de biais peut être ajouté au résultat de la propagation.
                    Le
                    terme de biais est un paramètre supplémentaire, souvent représenté par \(b\) dans les équations, qui
                    permet au modèle d'apprendre un décalage ou une translation. Cela donne la forme finale de l'entrée
                    du
                    neurone :</p>

                <p>\[ \text{Entrée du Neurone} = \sum_{i=1}^{n} (\text{Sortie du Prédécesseur}_i \times \text{Poids}_i)
                    +
                    \text{Biais} \]</p>

            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">16
                    <a class="prev" href="#slide15"></a>
                    <a class="next" href="#slide17"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide17">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Composants des réseaux de neurones artificiels</h3>
                <h3 class="topicsubheading">Fonction de propagation</h3>
                <p><b>Fonction d'Activation</b> : Après avoir calculé l'entrée du neurone, celle-ci est passée à travers
                    une
                    fonction d'activation. Cette fonction introduit une non-linéarité dans le modèle, permettant au
                    réseau
                    de neurones de capturer des relations complexes et d'apprendre des modèles non linéaires. Certaines
                    des
                    fonctions d'activation couramment utilisées comprennent :</p>
                <ul>
                    <li><b>Sigmoïde</b> : \( \sigma(x) = \frac{1}{1 + e^{-x}} \)</li>
                    <li><b>Tangente hyperbolique (tanh)</b> : \( \text{tanh}(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}
                        \)
                    </li>
                    <li><b>ReLU (Rectified Linear Unit)</b> : \( \text{ReLU}(x) = \max(0, x) \)</li>
                    <li><b>Softmax</b> (pour la couche de sortie dans la classification) : \( \text{Softmax}(x)_i =
                        \frac{e^{x_i}}{\sum_{j} e^{x_j}} \)</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">17
                    <a class="prev" href="#slide16"></a>
                    <a class="next" href="#slide18"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide18">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Perceptron</h3>
                <p>Le perceptron est un <b>algorithme d'apprentissage supervisé</b> utilisé pour la <b>classification
                        binaire</b>. Il est conçu pour résoudre des problèmes où l'objectif est de déterminer si une
                    entrée
                    donnée appartient ou non à une classe particulière.</p>
                <ul>
                    <li>Le perceptron a été inventé par <b>Frank Rosenblatt</b> en 1958. L'idée était de créer un modèle
                        simple de neurone artificiel inspiré du fonctionnement des neurones biologiques. Rosenblatt a
                        formulé un algorithme d'apprentissage qui permet au perceptron d'ajuster ses poids en fonction
                        des
                        erreurs de classification, améliorant ainsi ses performances au fil du temps.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">18
                    <a class="prev" href="#slide17"></a>
                    <a class="next" href="#slide19"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide19">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Perceptron</h3>
                <ul>
                    <li><b>Fonctionnement</b> : Le perceptron prend plusieurs entrées pondérées et les combine en une
                        somme.
                        Ensuite, cette somme est soumise à une fonction d'activation, généralement une fonction échelon
                        (step function), qui produit la sortie binaire du perceptron.</li>
                    <li><b>Limitations</b> : Le perceptron a des limitations, notamment sa capacité à résoudre des
                        problèmes
                        non linéaires et son incapacité à apprendre des modèles complexes. Cependant, il a jeté les
                        bases
                        pour le développement de réseaux de neurones plus avancés, en particulier les réseaux
                        multicouches
                        qui peuvent apprendre des représentations hiérarchiques.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">19
                    <a class="prev" href="#slide18"></a>
                    <a class="next" href="#slide20"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide20">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Perceptron</h3>
                <figure class="fullwidth" style="height:400px;">
                    <img src=" ../../2021/MachineLearning/Perceptron_example.svg"
                        alt="Perceptron example with linear boundary" />
                    <figcaption>Mise à jour de la frontière linéaire d'un perceptron.</figcaption>
                    <ol style="font-size:2vh">
                        <li>Source: https://en.wikipedia.org/wiki/File:Perceptron_example.svg</li>
                    </ol>
                </figure>

            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">20
                    <a class="prev" href="#slide19"></a>
                    <a class="next" href="#slide21"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide21">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Perceptron</h3>
                <figure>
                    <img src="../../../../../en/teaching/courses/2017/DataMining/images/Perceptron.svg" height="400px"
                        alt="Perceptron neural network diagram" />
                    <figcaption>Perceptron</figcaption>
                </figure>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">21
                    <a class="prev" href="#slide20"></a>
                    <a class="next" href="#slide22"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide22">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Perceptron: Définition formelle</h3>
                <ul>
                    <li>Soit \(y = f(z)\) la sortie du perceptron pour un vecteur d'entrée <i>z</i></li>
                    <li>Soit \(N\) le nombre d'exemples d'entraînement</li>
                    <li>Soit <i><b>X</b></i> l'espace de saisie des caractéristiques</li>
                    <li>Soit \({(x_{1}, d_{1}),...,(x_{N}, d_{N})}\) be the <i><b>N</b></i> training examples, where
                        <ul>
                            <li>\(x_i\) est le vecteur caractéristique de <i>i<sup>ème</sup></i> exemple d'entraînement.
                            </li>
                            <li>\(d_i\) est la valeur de sortie souhaitée</li>
                            <li>\(x_{j,i}\) est la <i>i<sup>ème</sup></i> caractéristique de <i>j<sup>ème</sup></i>
                                exemple
                                d'entraînement.</li>
                            <li>\(x_{j,0} = 1\)</li>
                        </ul>
                    </li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">22
                    <a class="prev" href="#slide21"></a>
                    <a class="next" href="#slide23"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide23">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Perceptron: Définition formelle</h3>
                <ul>
                    <li>Les poids sont représentés de la manière suivante:
                        <ul>
                            <li>\(w_i\) est la <i>i<sup>ème</sup></i> valeur du vecteur de poids.</li>
                            <li>\(w_i(t)\) est la <i>i<sup>ème</sup></i> valeur du vecteur de poids à un moment donné t.
                            </li>
                        </ul>
                    </li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">23
                    <a class="prev" href="#slide22"></a>
                    <a class="next" href="#slide24"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide24">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Perceptron : Étapes</h3>
                <ol>
                    <li>Initialiser les poids et les seuils</li>
                    <li>Pour chaque exemple, \((x_j, d_j)\) dans l'ensemble d'entraînement<i></i>
                        <ul>
                            <li>Calculer la sortie actuelle : \[y_j(t)= f[w(t).x_j]\] \[= f[w_0(t)x_{j,0} +
                                w_1(t)x_{j,1} +
                                w_2(t)x_{j,2} + \dotsb + w_n(t)x_{j,n}]\]</li>
                            <li>Calculer le poids: \[w_i(t + 1) = w_i(t) + r. (d_j-y_j(t))x_{j,i}\]</li>
                        </ul> \(r\) est le taux d'apprentissage.
                    </li>
                </ol>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">24
                    <a class="prev" href="#slide23"></a>
                    <a class="next" href="#slide25"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide25">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Perceptron : Étapes</h3>
                <ol start="3">
                    <li>Répétez l'étape 2 jusqu'à l'erreur d'itération \[\frac{1}{s} (&#931; |d_j - y_j(t)|)\] est
                        inférieur
                        au seuil spécifié par l'utilisateur \(\gamma\), ou un nombre prédéterminé d'itérations ont été
                        effectuées, où \(s\) est à nouveau la taille
                        de l'ensemble de l'échantillon.</li>
                </ol>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">25
                    <a class="prev" href="#slide24"></a>
                    <a class="next" href="#slide26"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide26">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Fonction d'Échelon (Step Function)</h3>
                <p>Le perceptron utilise généralement une fonction d'activation simple, et la fonction d'échelon (step
                    function) est fréquemment choisie pour cette tâche. </p>
                <div style="display:flex; flex-wrap:wrap; gap:0.8rem; align-items:flex-start;">
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Définition</h4>
                        <p>La fonction d'échelon attribue une sortie de 1 si la somme pondérée des entrées dépasse un
                            certain
                            seuil,
                            et 0 sinon.</p>
                        <p>\( f(x) = \begin{cases} 1 & \text{si } x \geq \text{seuil} \\ 0 & \text{sinon} \end{cases} \)
                        </p>
                    </div>
                    <div style="flex:1 1 48%; min-width:220px; font-size:0.9em;">
                        <h4>Points clés</h4>
                        <ul>
                            <li><b>Perceptron</b> : décision binaire nette (step) pour séparer des classes linéaires.
                            </li>
                            <li><b>Limite</b> : la fonction n'est pas dérivable → pas de rétropropagation classique.
                            </li>
                            <li><b>Réseaux profonds</b> : préfèrent des activations dérivables (sigmoïde, tanh, ReLU).
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">26
                    <a class="prev" href="#slide25"></a>
                    <a class="next" href="#slide27"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide27">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Fonction d'activation: fonction d'identité</h3>
                <div style="display:flex; flex-wrap:wrap; gap:0.8rem; align-items:flex-start;">
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Équation</h4>
                        <p>\[f(x)=x\]</p>
                        <h4>Dérivée</h4>
                        <p>\[f'(x)=1\]</p>
                    </div>
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Points clés</h4>
                        <ul>
                            <li><b>Sortie</b> : conserve la valeur réelle (pas de non-linéarité).</li>
                            <li><b>Usage</b> : sortie de régression (prédire une valeur continue).</li>
                        </ul>
                        <figure style="margin:0;">
                            <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_identity.svg"
                                style="max-height:300px; width:100%; height:auto;" alt="Identity activation function" />
                            <figcaption>Fonction d'identité</figcaption>
                        </figure>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">27
                    <a class="prev" href="#slide26"></a>
                    <a class="next" href="#slide28"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide28">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Fonction d'activation: pas binaire</h3>
                <div style="display:flex; flex-wrap:wrap; gap:0.8rem; align-items:flex-start;">
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Équation</h4>
                        <p>\[f(x) = \begin{cases} 0 & \text{for } x
                            < 0\\ 1 & \text{for } x \ge 0 \end{cases} \]</p>
                                <h4>Dérivée</h4>
                                <p>\[f'(x) = \begin{cases} 0 & \text{for } x \ne 0\\ ? & \text{for } x =
                                    0\end{cases}\]</p>
                    </div>
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Points clés</h4>
                        <ul>
                            <li><b>Décision</b> : classe 0/1 nette (seuil).</li>
                            <li><b>Limite</b> : non dérivable → difficile à entraîner par gradient.</li>
                        </ul>
                        <figure style="margin:0;">
                            <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_binary_step.svg"
                                style="max-height:300px; width:100%; height:auto;"
                                alt="Binary step activation function" />
                            <figcaption>Pas binaire</figcaption>
                        </figure>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">28
                    <a class="prev" href="#slide27"></a>
                    <a class="next" href="#slide29"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide29">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Fonction d'activation: fonction sigmoïde</h3>
                <div style="display:flex; flex-wrap:wrap; gap:0.8rem; align-items:flex-start;">
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Équation</h4>
                        <p>\[f(x)=\sigma(x)=\frac{1}{1+e^{-x}}\]</p>
                        <h4>Dérivée</h4>
                        <p>\[f'(x)=f(x)(1-f(x))\]</p>
                    </div>
                    <div style="flex:1 1 48%; min-width:220px; font-size:0.85em;">
                        <h4>Points clés</h4>
                        <ul>
                            <li><b>Sortie</b> : entre 0 et 1 → interprétable comme probabilité.</li>
                            <li><b>Usage</b> : sortie binaire, mais saturations possibles aux extrêmes.</li>
                        </ul>
                        <figure style="margin:0;">
                            <img src="../../2021/MachineLearning/Logistic-curve.svg"
                                style="max-height:220px; width:100%; height:auto;" alt="Sigmoid logistic curve" />
                            <figcaption>La fonction sigmoïde</figcaption>
                        </figure>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">29
                    <a class="prev" href="#slide28"></a>
                    <a class="next" href="#slide30"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide30">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Fonction d'activation: TanH</h3>
                <div style="display:flex; flex-wrap:wrap; gap:0.8rem; align-items:flex-start;">
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Équation</h4>
                        <p>\[f(x)=\tanh(x)=\frac{(e^{x} - e^{-x})}{(e^{x} + e^{-x})}\]</p>
                        <h4>Dérivée</h4>
                        <p>\[f'(x)=1-f(x)^2\]</p>
                    </div>
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Points clés</h4>
                        <ul>
                            <li><b>Sortie</b> : entre -1 et 1 → centrée, utile en couches cachées.</li>
                            <li><b>Limite</b> : saturation possible pour |x| grand.</li>
                        </ul>
                        <figure style="margin:0;">
                            <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_tanh.svg"
                                style="max-height:300px; width:100%; height:auto;" alt="Tanh activation function" />
                            <figcaption>TanH</figcaption>
                        </figure>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">30
                    <a class="prev" href="#slide29"></a>
                    <a class="next" href="#slide31"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide31">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Fonction d'activation: Rectified linear unit: ReLU</h3>
                <div style="display:flex; flex-wrap:wrap; gap:0.8rem; align-items:flex-start;">
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Équation</h4>
                        <p>\[f(x) = \begin{cases} 0 & \text{for } x \le 0\\ x & \text{for } x > 0\end{cases} =
                            \max\{0,x\}= x
                            \textbf{1}_{x>0}\]</p>
                        <h4>Dérivée</h4>
                        <p>\[f'(x) = \begin{cases} 0 & \text{for } x \le 0\\ 1 & \text{for } x > 0\end{cases}\]</p>
                    </div>
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Points clés</h4>
                        <ul>
                            <li><b>Avantage</b> : gradients simples, apprentissage rapide.</li>
                            <li><b>Risque</b> : neurones morts si x ≤ 0 trop souvent.</li>
                        </ul>
                        <figure style="margin:0;">
                            <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_rectified_linear.svg"
                                style="max-height:300px; width:100%; height:auto;" alt="ReLU activation function" />
                            <figcaption>Unité linéaire rectifiée (ReLU)</figcaption>
                        </figure>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">31
                    <a class="prev" href="#slide30"></a>
                    <a class="next" href="#slide32"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide32">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Fonction d'activation: Gaussien</h3>
                <div style="display:flex; flex-wrap:wrap; gap:0.8rem; align-items:flex-start;">
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Équation</h4>
                        <p>\[f(x)=e^{-x^2}\]</p>
                        <h4>Dérivée</h4>
                        <p>\[f'(x)=-2xe^{-x^2}\]</p>
                    </div>
                    <div style="flex:1 1 48%; min-width:220px;">
                        <h4>Points clés</h4>
                        <ul>
                            <li><b>Sortie</b> : centrée sur 0, décroît vite → réponse locale.</li>
                            <li><b>Usage</b> : réseaux à fonctions de base radiale (RBF).</li>
                        </ul>
                        <figure style="margin:0;">
                            <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_gaussian.svg"
                                style="max-height:300px; width:100%; height:auto;" alt="Gaussian activation function" />
                            <figcaption>Gaussien</figcaption>
                        </figure>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">32
                    <a class="prev" href="#slide31"></a>
                    <a class="next" href="#slide33"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide33">
            <div class="header">
                <h1>3.1. Apprentissage machine</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Perceptron multiclasse</h3>
                <ul>
                    <li>Perceptron peut être généralisé à la classification multiclasse. </li>
                    <li>Une fonction de représentation d'élément \(f( x , y )\) fait correspondre chaque paire
                        d'entrée/sortie possible à un vecteur d'élément à valeur réelle en dimension finie.</li>
                    <li>le vecteur de caractéristique est multiplié par un vecteur de poids \(w\), mais le score obtenu
                        est
                        maintenant utilisé pour choisir parmi de nombreux résultats possibles : \[\hat y =
                        \operatorname{argmax}_y f(x,y) \cdot w.\]</li>
                    <li>La réapprentissage se fait par itération sur les exemples, en prédisant un résultat pour chacun,
                        en
                        laissant les poids inchangés lorsque le résultat prédit correspond à l'objectif, et en les
                        modifiant
                        lorsqu'il ne correspond pas. La mise
                        à jour devient : \[w_{t+1} = w_t + f(x, y) - f(x,\hat y)\].</li>

                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">33
                    <a class="prev" href="#slide32"></a>
                    <a class="next" href="#slide34"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide34">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <p>Un <b>réseau de neurones profond</b>, également connu sous le nom de réseau de neurones profondément
                    hiérarchisé ou réseau neuronal profond (DNN pour Deep Neural Network en anglais), est un type de
                    réseau
                    de neurones artificiels qui comprend plusieurs couches de traitement, généralement plus de deux. Ces
                    réseaux sont appelés "profonds" en raison de leur architecture empilée de couches, permettant la
                    création de représentations hiérarchiques complexes des données.</p>
                <p><b>Architecture en couches</b> : Les réseaux de neurones profonds sont composés de multiples couches,
                    généralement divisées en trois types principaux :</p>
                <ul>
                    <li><b>Couche d'Entrée</b> : Reçoit les données brutes ou caractéristiques en entrée.</li>
                    <li><b>Couches Cachées</b> : Effectuent des transformations non linéaires et apprennent des
                        représentations hiérarchiques des données.</li>
                    <li><b>Couche de Sortie</b> : Produit la sortie du réseau, adaptée à la tâche spécifique
                        (classification, régression, etc.).</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">34
                    <a class="prev" href="#slide33"></a>
                    <a class="next" href="#slide35"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide35">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <ul>
                    <li><b>Idée clé</b> : plusieurs couches apprennent des représentations de plus en plus abstraites.</li>
                    <li><b>Non-linéarité</b> : ReLU/tanh en couches cachées pour modéliser des relations complexes.</li>
                    <li><b>Apprentissage</b> : rétropropagation + descente de gradient pour ajuster les poids.</li>
                    <li><b>Choix de sortie</b> : sigmoïde (binaire), softmax (multiclasse), identité (régression).</li>
                    <li><b>Généralisation</b> : régularisation (dropout, data augmentation) pour réduire l'overfitting.</li>
                    <li><b>Usage</b> : vision, audio, langage, recommandation.</li>
                    <li><b>Coût</b> : besoin de données et de calcul, parfois GPU.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">35
                    <a class="prev" href="#slide34"></a>
                    <a class="next" href="#slide36"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide36">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Apprentissage profond</h3>
                <ul>
                    <li><b>Définition</b> : un réseau dit <b>profond</b> possède plusieurs couches cachées (souvent &gt; 3)
                        pour empiler des transformations successives.</li>
                    <li><b>Synonymes</b> : DNN = réseau de neurones profond.</li>
                    <li><b>Idée clé</b> : apprentissage de <b>représentations hiérarchiques</b> (bords → formes →
                        concepts).</li>
                    <li><b>Signal</b> : gradient propagé de la sortie vers les couches internes (rétropropagation).</li>
                    <li><b>Apports</b> : performances élevées quand on a assez de données et d'architecture.</li>
                    <li><b>Limites</b> : besoin de données, réglage d'hyperparamètres, risque d'overfitting.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">36
                    <a class="prev" href="#slide35"></a>
                    <a class="next" href="#slide37"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide37">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Exemple: Tensorflow</h3>
                <ul style="font-size:0.95em; margin:0.2rem 0 0.5rem;">
                    <li><b>Objectif</b> : construire un petit réseau dense (exemple minimal).</li>
                    <li><b>Étape 1</b> : créer un modèle séquentiel.</li>
                    <li><b>Étape 2</b> : ajouter une couche ReLU avec 4 neurones.</li>
                </ul>
                <div class="highlight" style="font-size:0.85em;">
                    <pre><span></span><span class="c1"># Importation des bibliothèques nécessaires de TensorFlow</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>

<span class="c1"># Étape 1: Création d&#39;un modèle séquentiel</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># Étape 2: Ajout d&#39;une couche dense avec une fonction d&#39;activation ReLU</span>
<span class="c1"># La couche a 4 neurones, une fonction d&#39;activation &#39;relu&#39;, et prend une entrée de forme (3,)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)))</span>
</pre>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">37
                    <a class="prev" href="#slide36"></a>
                    <a class="next" href="#slide38"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide38">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Exemple: Tensorflow</h3>
                <ul style="font-size:0.95em; margin:0.2rem 0 0.5rem;">
                    <li><b>Étape 3</b> : couche de sortie avec <b>softmax</b> (probabilités).</li>
                    <li><b>Étape 4</b> : compilation avec optimiseur et taux d'apprentissage.</li>
                    <li><b>Point clé</b> : la <b>fonction de perte</b> doit correspondre à la tâche.</li>
                </ul>
                <div class="highlight" style="font-size:0.85em;">
                    <pre><span class="c1"># Étape 3: Ajout d&#39;une couche dense de sortie avec une fonction d&#39;activation softmax</span>
<span class="c1"># La couche a 2 neurones pour une tâche de classification binaire, et softmax est utilisé</span>
<span class="c1"># pour obtenir des probabilités</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="c1"># Étape 4: Compilation du modèle</span>
<span class="c1"># Utilisation de la descente de gradient stochastique (SGD) comme optimiseur avec un taux d&#39;apprentissage de 0.01</span>
<span class="c1"># La fonction de perte est &#39;mean_squared_error&#39; pour un problème de régression</span>
<span class="c1"># Les performances du modèle seront mesurées en termes de &#39;accuracy&#39; (précision)</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">sgd</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">38
                    <a class="prev" href="#slide37"></a>
                    <a class="next" href="#slide39"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide39">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <ul>
                    <li><b>Étape 1</b> : modèle séquentiel = pile linéaire de couches.</li>
                    <li><b>Étape 2</b> : couche dense (4 neurones, ReLU), entrée de dimension 3.</li>
                    <li><b>Étape 3</b> : sortie softmax (2 neurones) → distribution de probabilités.</li>
                    <li><b>Étape 4</b> : compilation = optimiser + perte + métriques.</li>
                    <li><b>Attention</b> : pour la classification, préférer <b>cross‑entropy</b> plutôt que MSE.</li>
                    <li><b>Astuce</b> : normaliser les entrées aide la convergence.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">39
                    <a class="prev" href="#slide38"></a>
                    <a class="next" href="#slide40"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide40">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <ul>
                    <li><b>Playground</b> : visualiser l'effet des couches et des activations.</li>
                    <li><b>Paramètres</b> : profondeur, taux d'apprentissage, régularisation.</li>
                    <li><b>Observation</b> : frontière de décision évolue pendant l'entraînement.</li>
                    <li><b>Lecture</b> : zones colorées = classes prédites.</li>
                </ul>
                <figure>
                    <img src="../../2021/MachineLearning/Screenshot_2020-10-20 Tensorflow — Neural Network Playground.png"
                        height="380px" alt="Tensorflow Neural Network Playground" />
                    <figcaption>Source: https://playground.tensorflow.org/</figcaption>
                </figure>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">40
                    <a class="prev" href="#slide39"></a>
                    <a class="next" href="#slide41"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide41">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <ul>
                    <li><b>Comparaison</b> : tester plusieurs activations et régularisations.</li>
                    <li><b>Surapprentissage</b> : visible si la validation diverge.</li>
                    <li><b>Stabilité</b> : batch norm peut accélérer l'entraînement.</li>
                </ul>
                <figure>
                    <img src="../../2021/MachineLearning/Screenshot_2020-10-20 Tensorflow 2 — Neural Network Playground.png"
                        height="380px" alt="Tensorflow Neural Network Playground example 2" />
                    <figcaption>Source: https://playground.tensorflow.org/</figcaption>
                </figure>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">41
                    <a class="prev" href="#slide40"></a>
                    <a class="next" href="#slide42"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide42">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Composants des réseaux de neurones artificiels</h3>
                <h3 class="topicsubheading">Organisation</h3>
                <p><b>Principe</b> : l'information circule de l'entrée vers la sortie via des couches cachées, avec des
                    poids ajustés pendant l'apprentissage.</p>
                <ul>
                    <li><b>Organisation en plusieurs couches</b> : Un réseau de neurones profond est structuré en
                        plusieurs
                        couches, généralement composées d'une couche d'entrée, de plusieurs couches cachées et d'une
                        couche
                        de sortie. Chaque couche est composée de neurones, également appelés nœuds ou unités.</li>
                    <li><b>Connexions entre les neurones</b> : Les neurones d'une couche sont connectés aux neurones de
                        la
                        couche immédiatement précédente et de la couche immédiatement suivante. Chaque connexion est
                        associée à un poids qui est ajusté pendant l'apprentissage.</li>
                    <li><b>Biais</b> : terme ajouté pour déplacer l'activation (flexibilité du modèle).</li>
                    <li><b>Paramètres</b> : poids + biais constituent ce qui est appris.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">42
                    <a class="prev" href="#slide41"></a>
                    <a class="next" href="#slide43"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide43">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Composants des réseaux de neurones artificiels</h3>
                <h3 class="topicsubheading">Organisation</h3>
                <ul>
                    <li><b>Couche d'entrée</b> : La couche d'entrée est la première couche du réseau. Elle reçoit les
                        données externes, souvent représentées par des caractéristiques d'un ensemble de données. Chaque
                        neurone dans la couche d'entrée correspond à une caractéristique spécifique.</li>
                    <li><b>Couche de sortie</b> : La couche de sortie est la dernière couche du réseau. Elle produit le
                        résultat final du modèle en fonction de la tâche spécifique, telle que la classification d'une
                        image, la prédiction d'une valeur, etc. Le nombre de neurones dans cette couche dépend du type
                        de
                        problème (par exemple, un neurone pour chaque classe dans une tâche de classification).</li>
                    <li><b>Couches cachées</b> : Entre la couche d'entrée et la couche de sortie, il peut y avoir zéro
                        ou
                        plusieurs couches cachées. Ces couches sont responsables de l'extraction de caractéristiques
                        complexes à partir des données d'entrée. Chaque neurone dans une couche cachée combine les
                        informations des neurones de la couche précédente pour apprendre des représentations
                        hiérarchiques.
                    </li>
                    <li><b>Activation</b> : transforme la somme pondérée en sortie non linéaire.</li>
                    <li><b>Dimension</b> : la taille des couches contrôle la capacité du modèle.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">43
                    <a class="prev" href="#slide42"></a>
                    <a class="next" href="#slide44"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide44">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Composants des réseaux de neurones artificiels</h3>
                <h3 class="topicsubheading">Organisation et connectivité</h3>
                <ul>
                    <li><b>Connectivité entièrement connectée</b> : chaque neurone d'une couche est relié à tous ceux de
                        la couche suivante.</li>
                    <li><b>Avantage</b> : grande capacité d'expression.</li>
                    <li><b>Coût</b> : beaucoup de paramètres → risque d'overfitting.</li>
                    <li><b>Usage</b> : souvent en fin de réseau (lecture finale).</li>
                    <li><b>Alternative</b> : connexions locales (CNN) pour réduire les paramètres.</li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">44
                    <a class="prev" href="#slide43"></a>
                    <a class="next" href="#slide45"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide45">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
                <ul>
                    <li><b>But</b> : exploiter la structure spatiale des images.</li>
                    <li><b>Idée</b> : filtres locaux + partage de poids.</li>
                    <li><b>Effet</b> : moins de paramètres, meilleure généralisation.</li>
                    <li><b>Architecture</b> : convolution → pooling → couches denses.</li>
                </ul>
                <figure class="fullwidth" style="height:400px;">
                    <img src="../../2021/MachineLearning/Deep_Learning.jpg"
                        alt="Deep learning convolutional neural network" />
                    <figcaption>Réseaux de neurones convolutionnels</figcaption>
                </figure>
                <ol style="font-size:2vh">
                    <p>Source: https://en.wikipedia.org/wiki/File:Deep_Learning.jpg</p>
                </ol>

            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">45
                    <a class="prev" href="#slide44"></a>
                    <a class="next" href="#slide46"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide46">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content" style="display:flex; flex-wrap:wrap; align-items:flex-start; gap:1rem;">
                <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
                <ul style="flex:1 1 47%; min-width:220px; max-width:47%;">
                    <li><b>Objectif</b> : apprendre des motifs visuels (bords, textures, formes).</li>
                    <li><b>Domaine</b> : images, vidéos, signaux en grille.</li>
                    <li><b>Principe</b> : filtres partagés + récepteurs locaux.</li>
                    <li><b>Usages</b> : classification, détection, segmentation.</li>
                    <li><b>Exemples</b> : reconnaissance d'objets, imagerie médicale.</li>
                </ul>
                <figure style="flex:1 1 47%; min-width:220px; max-width:47%; display:flex; justify-content:center;">
                    <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png"
                        style="max-height:260px; width:auto; max-width:100%;"
                        alt="Typical convolutional neural network architecture" />
                </figure>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">46
                    <a class="prev" href="#slide45"></a>
                    <a class="next" href="#slide47"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide47">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
                <div class="flexcontent"
                    style="display:flex; flex-wrap:wrap; gap:1rem; align-items:flex-start; justify-content:space-between;">
                    <ul style="flex:1 1 47%; max-width:47%; min-width:220px;">
                        <li><b>Définition</b> : réseau spécialisé pour données structurées en grille.</li>
                        <li><b>Partage de poids</b> : mêmes filtres appliqués partout dans l'image.</li>
                        <li><b>Récepteurs locaux</b> : chaque neurone voit une petite zone.</li>
                        <li><b>Avantage</b> : moins de paramètres, meilleure généralisation.</li>
                        <li><b>Conséquence</b> : invariance partielle aux translations.</li>
                        <li><b>Exemple</b> : un filtre détecte un bord vertical.</li>
                        <li><b>Application</b> : reconnaissance de chiffres manuscrits.</li>
                    </ul>
                    <div
                        style="flex:1 1 46%; max-width:46%; min-width:210px; background:var(--table-cell-bg); padding:0.7rem; border-radius:0.6rem; border:1px solid var(--card-border); overflow-wrap:anywhere;">
                        <p><b>Exemple math.</b></p>
                        <p>\(y_{i,j}=\sum_{u,v}x_{i+u,j+v}\,w_{u,v}\)</p>
                        <p><b>Exemple commun</b> : image 5×5, noyau 3×3.</p>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">47
                    <a class="prev" href="#slide46"></a>
                    <a class="next" href="#slide48"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide48">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
                <div class="flexcontent"
                    style="display:flex; flex-wrap:wrap; gap:1rem; align-items:flex-start; justify-content:space-between;">
                    <ul style="flex:1 1 47%; max-width:47%; min-width:220px;">
                        <li><b>Convolution</b> : filtres linéaires pour extraire des motifs locaux.</li>
                        <li><b>Stride / padding</b> : contrôlent la taille des cartes de caractéristiques.</li>
                        <li><b>Cartes de traits</b> : plusieurs filtres → plusieurs canaux.</li>
                        <li><b>Intuition</b> : chaque filtre détecte un motif spécifique.</li>
                        <li><b>Calcul</b> : coût proportionnel au nombre de filtres et à la taille des cartes.</li>
                        <li><b>Exemple</b> : padding=1 conserve la taille de l'image.</li>
                        <li><b>Application</b> : détection de bords en vision.</li>
                    </ul>
                    <div
                        style="flex:1 1 47%; max-width:47%; min-width:220px; background:var(--table-cell-bg); padding:0.7rem; border-radius:0.6rem; border:1px solid var(--card-border);">
                        <p><b>Stride</b> : \(H_{out}=\left\lfloor\frac{H+2P-K}{S}\right\rfloor+1\)</p>
                        <p><b>Exemple commun</b> : H=5, K=3, P=1, S=1 ⇒ \(H_{out}=5\).</p>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">48
                    <a class="prev" href="#slide47"></a>
                    <a class="next" href="#slide49"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide49">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
                <div class="flexcontent"
                    style="display:flex; flex-wrap:wrap; gap:1rem; align-items:flex-start; justify-content:space-between;">
                    <ul style="flex:1 1 47%; max-width:47%; min-width:220px;">
                        <li><b>Couches convolutives</b> : extraire des caractéristiques via plusieurs filtres.</li>
                        <li><b>Pooling</b> : réduction spatiale (max/avg) et invariance locale.</li>
                        <li><b>Effet</b> : moins de paramètres, moins de surapprentissage.</li>
                        <li><b>Variante</b> : global average pooling.</li>
                        <li><b>Exemple</b> : max‑pooling 2×2 → 1 valeur.</li>
                    </ul>
                    <div
                        style="flex:1 1 47%; max-width:47%; min-width:220px; background:var(--table-cell-bg); padding:0.6rem; border-radius:0.6rem; border:1px solid var(--card-border); font-size:0.92em;">
                        <p><b>Max-pooling</b></p>
                        <p>\(y_{i,j}=\max\limits_{(u,v)\in\Omega}x_{i+u,j+v}\)</p>
                        <p><b>Exemple</b> : fenêtre 2×2 → 1 valeur.</p>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">49
                    <a class="prev" href="#slide48"></a>
                    <a class="next" href="#slide50"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide50">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Réseaux de neurones convolutionnels: architecture</h3>
                <div class="flexcontent"
                    style="display:flex; flex-wrap:wrap; gap:1rem; align-items:flex-start; justify-content:space-between;">
                    <ul style="flex:1 1 47%; max-width:47%; min-width:220px;">
                        <li><b>Hiérarchie</b> : motifs simples → motifs complexes.</li>
                        <li><b>Structure</b> : entrée → conv → pooling → couches denses → sortie.</li>
                        <li><b>Normalisation</b> : stabilise l'entraînement.</li>
                        <li><b>Lecture finale</b> : softmax / régression selon la tâche.</li>
                        <li><b>Profondeur</b> : plus de couches = plus d'abstraction.</li>
                        <li><b>Exemple</b> : conv(3×3) → pool → dense → softmax.</li>
                        <li><b>Application</b> : tri automatique de photos.</li>
                    </ul>
                    <div
                        style="flex:1 1 47%; max-width:47%; min-width:220px; background:var(--table-cell-bg); padding:0.7rem; border-radius:0.6rem; border:1px solid var(--card-border);">
                        <p><b>Softmax</b></p>
                        <p>\(p_k=\frac{e^{z_k}}{\sum_j e^{z_j}}\)</p>
                        <p><b>Exemple commun</b> : 3 classes → \(\sum p_k=1\).</p>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">50
                    <a class="prev" href="#slide49"></a>
                    <a class="next" href="#slide51"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide51">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Réseaux de neurones convolutionnels: architecture</h3>
                <div class="flexcontent"
                    style="display:flex; flex-wrap:wrap; gap:0.6rem; align-items:flex-start; justify-content:space-between;">
                    <ul style="flex:1 1 46%; max-width:46%; min-width:210px; overflow-wrap:anywhere;">
                        <li><b>Activation (ReLU)</b> : non-linéarité essentielle à l'apprentissage.</li>
                        <li><b>Régularisation</b> : dropout, data augmentation.</li>
                        <li><b>Normalisation</b> : batch norm pour stabilité.</li>
                        <li><b>Convergence</b> : taux d’apprentissage + init.</li>
                        <li><b>Exemple</b> : dropout=0.5.</li>
                    </ul>
                    <div
                        style="flex:1 1 46%; max-width:46%; min-width:210px; background:var(--table-cell-bg); padding:0.55rem; border-radius:0.6rem; border:1px solid var(--card-border); overflow-wrap:anywhere; word-break:break-word; font-size:0.9em;">
                        <p><b>ReLU</b></p>
                        <p>\(f(x)=\max(0,x)\)</p>
                        <p><b>Exemple</b> : x=-2 ⇒ 0, x=3 ⇒ 3.</p>
                    </div>
                </div>
                <p><b>Résumé</b> : caractéristiques locales → représentations globales via couches successives.</p>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">51
                    <a class="prev" href="#slide50"></a>
                    <a class="next" href="#slide52"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide52">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Noyau (traitement d'image)</h3>
                <div class="flexcontent"
                    style="display:flex; flex-wrap:wrap; gap:1rem; align-items:flex-start; justify-content:space-between;">
                    <ul style="flex:1 1 47%; max-width:47%; min-width:220px;">
                        <li><b>Noyau / filtre</b> : petite matrice appliquée par convolution.</li>
                        <li><b>Taille</b> : ex. 3×3, 5×5, 7×7 selon le contexte.</li>
                        <li><b>Canaux</b> : un filtre par canal d'entrée (RGB, etc.).</li>
                        <li><b>Effets</b> : contours, détails, mise en évidence de motifs.</li>
                        <li><b>Paramètres</b> : poids du noyau appris pendant l'entraînement.</li>
                        <li><b>Exemple</b> : noyau de Sobel pour les contours.</li>
                        <li><b>Application</b> : rehaussement de détails en imagerie.</li>
                    </ul>
                    <div
                        style="flex:1 1 47%; max-width:47%; min-width:220px; background:var(--table-cell-bg); padding:0.7rem; border-radius:0.6rem; border:1px solid var(--card-border);">
                        <p><b>Sobel</b></p>
                        <p>\(\begin{bmatrix}-1&0&1\\-2&0&2\\-1&0&1\end{bmatrix}\)</p>
                        <p><b>Exemple commun</b> : applique un gradient horizontal.</p>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">52
                    <a class="prev" href="#slide51"></a>
                    <a class="next" href="#slide53"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide53">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Noyau (traitement d'image)</h3>
                <div class="flexcontent"
                    style="display:flex; flex-wrap:wrap; gap:0.6rem; align-items:flex-start; justify-content:space-between;">
                    <ul style="flex:1 1 47%; max-width:47%; min-width:220px;">
                        <li><b>Apprentissage automatique</b> : les filtres sont appris, pas fixés à la main.</li>
                        <li><b>Optimisation</b> : gradient + rétropropagation.</li>
                        <li><b>Visualisation</b> : inspection des filtres pour interpréter le modèle.</li>
                        <li><b>Stabilité</b> : régularisation pour éviter des filtres bruités.</li>
                        <li><b>Exemple</b> : afficher les filtres de la 1ʳᵉ couche.</li>
                        <li><b>Application</b> : interprétabilité en vision médicale.</li>
                    </ul>
                    <div
                        style="flex:1 1 47%; max-width:47%; min-width:220px; background:var(--table-cell-bg); padding:0.7rem; border-radius:0.6rem; border:1px solid var(--card-border);">
                        <p><b>Update</b></p>
                        <p>\(w \leftarrow w-\eta \nabla_w L\)</p>
                        <p><b>Exemple commun</b> : \(\eta=0{,}01\).</p>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">53
                    <a class="prev" href="#slide52"></a>
                    <a class="next" href="#slide54"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide54">
            <div class="header">
                <h1>3.2. Apprentissage profond</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Noyau (traitement d'image)</h3>
                <div class="flexcontent"
                    style="display:flex; flex-wrap:wrap; gap:1rem; align-items:flex-start; justify-content:space-between;">
                    <ul style="flex:1 1 47%; max-width:47%; min-width:220px;">
                        <li><b>Hiérarchie</b> : filtres simples → filtres complexes.</li>
                        <li><b>Pooling</b> : réduction de dimension sans perdre l'essentiel.</li>
                        <li><b>Invariance</b> : robustesse aux petites translations.</li>
                        <li><b>Résultat</b> : représentations abstraites de l'image.</li>
                        <li><b>Généralisation</b> : meilleure tolérance au bruit visuel.</li>
                        <li><b>Exemple</b> : même objet détecté après un léger décalage.</li>
                        <li><b>Application</b> : surveillance vidéo avec variations de caméra.</li>
                    </ul>
                    <div
                        style="flex:1 1 47%; max-width:47%; min-width:220px; background:var(--table-cell-bg); padding:0.7rem; border-radius:0.6rem; border:1px solid var(--card-border);">
                        <p><b>Invariance</b></p>
                        <p>\(x' = x+\epsilon \Rightarrow f(x')\approx f(x)\)</p>
                        <p><b>Exemple commun</b> : \(\epsilon\) petit décalage.</p>
                    </div>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">54
                    <a class="prev" href="#slide53"></a>
                    <a class="next" href="#slide55"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide55">
            <div class="header">
                <h1>3.3. Apprentissage par renforcement</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Apprentissage par renforcement</h3>
                <div class="flexcontent"
                    style="display:flex; flex-wrap:wrap; gap:1rem; align-items:flex-start; justify-content:space-between;">
                    <ul style="flex:1 1 47%; max-width:47%; min-width:220px;">
                        <li><b>Définition</b> : apprentissage par interaction avec l'environnement.</li>
                        <li><b>Éléments</b> : état, action, récompense, politique.</li>
                        <li><b>Exploration / exploitation</b> : équilibre entre essayer et optimiser.</li>
                        <li><b>Signal</b> : récompenses positives ou négatives.</li>
                        <li><b>Objectif</b> : maximiser la récompense cumulée.</li>
                        <li><b>Exemples</b> : jeux, robotique, optimisation de trafic.</li>
                    </ul>
                    <figure style="flex:1 1 47%; max-width:47%; min-width:220px; display:flex; justify-content:center;">
                        <img src="../../../../../en/teaching/courses/2017/DataMining/images/Reinforcement_learning_diagram.svg"
                            style="max-height:240px; width:auto; max-width:100%;"
                            alt="Reinforcement learning diagram" />
                    </figure>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">55
                    <a class="prev" href="#slide54"></a>
                    <a class="next" href="#slide56"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide56">
            <div class="header">
                <h1>3.4. Licences, Ethiques et la vie privé</h1>
            </div>
            <div class="content" style="display:flex; flex-wrap:wrap; align-items:flex-start; gap:1rem;">
                <h3 class="topicsubheading">Licences, Éthique et la vie privé</h3>
                <ul style="flex:1 1 48%; min-width:260px; max-width:54%;">
                    <li><b>Droits d'utilisation</b> : licences, conditions de réutilisation, attribution.</li>
                    <li><b>Confidentialité</b> : minimisation, anonymisation, gestion des accès.</li>
                    <li><b>Éthique</b> : biais, équité, transparence des modèles.</li>
                    <li><b>Conformité</b> : RGPD, consentement, finalité des traitements.</li>
                    <li><b>Sécurité</b> : protection des données, journalisation, audits.</li>
                    <li><b>Impact écologique</b> : sobriété numérique, choix d'algorithmes, durée d'entraînement.</li>
                    <li><b>Empreinte carbone</b> : mesurer, réduire, compenser quand nécessaire.</li>
                </ul>
                <figure
                    style="flex:1 1 40%; min-width:240px; max-width:42%; display:flex; flex-direction:column; gap:0.6rem; align-items:center;">
                    <img src="../../../../../fr/enseignement/cours/2017/BigData/images/Open_Definition_logo.png"
                        style="max-height:160px; width:auto;" alt="Open Definition logo" />
                    <img src="../../../../../en/teaching/courses/2017/ArchitectureInformationSystems/images/Privacy_written_in_tiles.jpg"
                        style="max-height:220px; width:auto; border-radius:0.4rem;" alt="Privacy written in tiles" />
                </figure>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">56
                    <a class="prev" href="#slide55"></a>
                    <a class="next" href="#slide57"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide57">
            <div class="header">
                <h1>3.4. Licences, Ethiques et la vie privé</h1>
            </div>
            <div class="content" style="display:flex; flex-wrap:wrap; align-items:flex-start; gap:1rem;">
                <h3 class="topicsubheading">Licences ouvertes</h3>
                <ul style="flex:1 1 46%; min-width:260px; max-width:52%;">
                    <li><b>Autorisation</b> : que peut-on faire avec les données ?</li>
                    <li><b>Attribution</b> : citer correctement la source.</li>
                    <li><b>Restrictions</b> : usage commercial, partage à l'identique, dérivés.</li>
                    <li><b>Choix de licence</b> : adapter au contexte et aux objectifs.</li>
                </ul>
                <figure
                    style="flex:1 1 44%; min-width:260px; max-width:48%; display:grid; grid-template-columns:repeat(3, minmax(90px, 1fr)); gap:0.6rem; align-items:center; justify-items:center;">
                    <img src="../../../../../fr/enseignement/cours/2018/BigData/images/CC-BY-NC-ND.svg"
                        style="max-height:120px; width:auto;" alt="Creative Commons BY-NC-ND license" />
                    <img src="../../../../../fr/enseignement/cours/2018/BigData/images/CC-BY-NC-SA.svg"
                        style="max-height:120px; width:auto;" alt="Creative Commons BY-NC-SA license" />
                    <img src="../../../../../fr/enseignement/cours/2018/BigData/images/CC-BY-NC.svg"
                        style="max-height:120px; width:auto;" alt="Creative Commons BY-NC license" />
                    <img src="../../../../../fr/enseignement/cours/2018/BigData/images/CC-BY-ND.svg"
                        style="max-height:120px; width:auto;" alt="Creative Commons BY-ND license" />
                    <img src="../../../../../fr/enseignement/cours/2018/BigData/images/CC-BY-SA.svg"
                        style="max-height:120px; width:auto;" alt="Creative Commons BY-SA license" />
                    <img src="../../../../../fr/enseignement/cours/2018/BigData/images/CC-BY.svg"
                        style="max-height:120px; width:auto;" alt="Creative Commons BY license" />
                    <img src="../../../../../fr/enseignement/cours/2018/BigData/images/Cc-zero.svg"
                        style="max-height:120px; width:auto;" alt="Creative Commons Zero license" />
                    <img src="../../../../../fr/enseignement/cours/2018/BigData/images/Cc-public_domain_mark_white.svg"
                        style="max-height:120px; width:auto;" alt="Public Domain Mark" />
                    <figcaption style="grid-column:1 / -1; margin-top:0.3rem;">Exemples : Creative Commons (CC)
                    </figcaption>
                </figure>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">57
                    <a class="prev" href="#slide56"></a>
                    <a class="next" href="#slide58"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide58">
            <div class="header">
                <h1>3.4. Licences, Ethiques et la vie privé</h1>
            </div>
            <div class="content"
                style="display:flex; flex-wrap:wrap; align-items:flex-start; justify-content:center; gap:1rem;">
                <h3 class="topicsubheading">Spectre des licences CC</h3>
                <ul style="flex:1 1 40%; min-width:240px; max-width:46%;">
                    <li><b>Plus ouvert</b> : davantage d'usages et de réutilisation.</li>
                    <li><b>Plus restrictif</b> : limitations (NC, ND), conditions plus fortes.</li>
                    <li><b>Attribution</b> : BY est la base commune.</li>
                    <li><b>Choisir</b> selon vos objectifs de diffusion et de contrôle.</li>
                </ul>
                <figure
                    style="flex:1 1 55%; min-width:260px; max-width:58%; display:flex; flex-direction:column; align-items:center;">
                    <img src="../../../../../fr/enseignement/cours/2018/BigData/images/Creative_commons_license_spectrum.svg"
                        style="max-height:320px; width:auto; max-width:100%;" alt="Creative Commons license spectrum" />
                    <figcaption>Exemples : Creative Commons (CC)</figcaption>
                </figure>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">58
                    <a class="prev" href="#slide57"></a>
                    <a class="next" href="#slide59"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide59">
            <div class="header">
                <h1>3.4. Licences, Ethiques et la vie privé</h1>
            </div>
            <div class="content"
                style="display:flex; flex-wrap:wrap; align-items:flex-start; justify-content:center; gap:1rem;">
                <h3 class="topicsubheading">Données ouvertes</h3>
                <ul style="flex:1 1 40%; min-width:240px; max-width:46%;">
                    <li><b>Accès libre</b> : données disponibles pour tous.</li>
                    <li><b>Réutilisation</b> : adapter, analyser, redistribuer.</li>
                    <li><b>Transparence</b> : favoriser la science ouverte et la confiance.</li>
                    <li><b>Exemples</b> : Wikimedia, Open Data publics.</li>
                </ul>
                <figure
                    style="flex:1 1 55%; min-width:260px; max-width:58%; display:flex; flex-direction:column; align-items:center;">
                    <img src="../../2018/BigData/images/Wikimedia_logo_family_complete-2013.svg"
                        style="max-height:320px; width:auto; max-width:100%;" alt="Wikimedia logo family" />
                    <figcaption>Données ouvertes</figcaption>
                </figure>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">59
                    <a class="prev" href="#slide58"></a>
                    <a class="next" href="#slide60"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide60">
            <div class="header">
                <h1>3.4. Licences, Ethiques et la vie privé</h1>
            </div>
            <div class="content"
                style="display:flex; flex-wrap:wrap; align-items:flex-start; justify-content:center; gap:1rem;">
                <h3 class="topicsubheading">Linked Open Data (LOD)</h3>
                <ul style="flex:1 1 40%; min-width:240px; max-width:46%;">
                    <li><b>Interopérabilité</b> : données reliées par des URI.</li>
                    <li><b>Réutilisation</b> : croiser des sources ouvertes.</li>
                    <li><b>Enrichissement</b> : liens et contexte supplémentaires.</li>
                    <li><b>Écosystème</b> : nuage LOD comme cartographie des jeux de données.</li>
                </ul>
                <figure
                    style="flex:1 1 55%; min-width:260px; max-width:58%; display:flex; flex-direction:column; align-items:center;">
                    <img src="../../../../../fr/enseignement/cours/2017/BigData/images/LOD_Cloud_2014.svg.png"
                        style="max-height:320px; width:auto; max-width:100%;" alt="LOD Cloud diagram 2014" />
                    <figcaption>Données ouvertes liées (Linked Open Data)</figcaption>
                </figure>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">60
                    <a class="prev" href="#slide59"></a>
                    <a class="next" href="#slide61"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide61">
            <div class="header">
                <h1>3.4. Licences, Ethiques et la vie privé</h1>
            </div>
            <div class="content">
                <figure style="width:42%">
                    <img src="../../../../../fr/enseignement/cours/2017/BigData/images/Internet_Archive_logo_and_wordmark.svg.png"
                        height="400vh" alt="Internet Archive logo" />
                    <figcaption>Données archivées</figcaption>
                </figure>
                <div style="flex:1 1 47%; max-width:47%; min-width:220px;">
                    <ul>
                        <li><b>Bibliothèque numérique</b> : Une organisation à but non lucratif qui vise à fournir un
                            accès universel à toutes les connaissances.</li>
                        <li><b>Wayback Machine</b> : Archive une grande partie du World Wide Web, permettant de
                            consulter des versions historiques de sites web.</li>
                        <li><b>Collections numériques</b> : Héberge une vaste collection de médias numériques, y compris
                            des livres, des films, de la musique et des logiciels.</li>
                    </ul>
                </div>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">61
                    <a class="prev" href="#slide60"></a>
                    <a class="next" href="#slide62"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide62">
            <div class="header">
                <h1>Références</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Ressources en ligne</h3>
                <ul>
                    <ul>
                        <li><a href="https://en.wikipedia.org/wiki/Artificial_neural_network">Artificial Neural
                                Network</a>
                        </li>
                        <li><a href="https://fr.wikipedia.org/wiki/Noyau_(traitement_d%27image)">Noyau (traitement
                                d'image)</a></li>
                        <li><a href="https://fr.wikipedia.org/wiki/R%C3%A9seau_neuronal_convolutif">Réseau neuronal
                                convolutif</a></li>
                        <li><a href="https://en.wikipedia.org/wiki/Perceptron">Perceptron</a></li>
                    </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">62
                    <a class="prev" href="#slide61"></a>
                    <a class="next" href="#slide63"></a>
                </div>
            </div>
        </section>
        <section class="slide" id="slide63">
            <div class="header">
                <h1>Références</h1>
            </div>
            <div class="content">
                <h3 class="topicsubheading">Couleurs</h3>
                <ul>
                    <li><a href="https://material.io/color/">Color Tool - Material Design</a></li>
                </ul>
                <h3 class="topicsubheading">Images</h3>
                <ul>
                    <li><a href="https://commons.wikimedia.org/">Wikimedia Commons</a></li>
                </ul>
            </div>
            <div class="footer">
                <div class="contact">Data Mining | John Samuel</div>
                <div class="navigation">63
                    <a class="prev" href="#slide62"></a>
                </div>
            </div>
        </section>

        <script>
            // Align custom ordered-list counters with the HTML "start" attribute.
            (function syncOrderedListCounters() {
                document.querySelectorAll('ol[start]').forEach(ol => {
                    const start = parseInt(ol.getAttribute('start'), 10);
                    if (!Number.isNaN(start)) {
                        ol.style.counterReset = `item ${start - 1}`;
                    }
                });
            })();

            // Theme Toggle Functionality
            function toggleTheme() {
                const html = document.documentElement;
                const currentTheme = html.getAttribute('data-theme');
                const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
                html.setAttribute('data-theme', newTheme);
                localStorage.setItem('theme', newTheme);
            }

            // Initialize theme from localStorage or system preference
            (function initTheme() {
                const savedTheme = localStorage.getItem('theme');
                if (savedTheme) {
                    document.documentElement.setAttribute('data-theme', savedTheme);
                } else if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                    document.documentElement.setAttribute('data-theme', 'dark');
                }
            })();

            // Listen for system theme changes
            window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', e => {
                if (!localStorage.getItem('theme')) {
                    document.documentElement.setAttribute('data-theme', e.matches ? 'dark' : 'light');
                }
            });

            function changeCurrentURLSlideNumber(isIncrement) {
                url = window.location.href;
                position = url.indexOf("#slide");
                if (position != -1) { // Not on the first page
                    slideIdString = url.substr(position + 6);
                    if (!Number.isNaN(slideIdString)) {
                        slideId = parseInt(slideIdString);
                        if (isIncrement) {
                            if (slideId < 63) {
                                slideId = slideId + 1;
                            }
                        } else {
                            if (slideId > 1) {
                                slideId = slideId - 1;
                            }
                        }
                        /* regexp */
                        url = url.replace(/#slide\d+/g, "#slide" + slideId);
                        window.location.href = url;
                    }
                } else {
                    window.location.href = url + "#slide2";
                }
            }
            document.onkeydown = function (event) {

                event.preventDefault();
                /* This will ensure the default behavior of
                                                                page scroll behaviour (up, down, right, left)*/

                event = event || window.event;
                /*Codes de la touche sur le clavier: 37, 38, 39, 40*/
                if (event.keyCode == '37') {
                    // left
                    changeCurrentURLSlideNumber(false);
                } else if (event.keyCode == '38') {
                    // up
                    changeCurrentURLSlideNumber(false);
                } else if (event.keyCode == '39') {
                    // right
                    changeCurrentURLSlideNumber(true);
                } else if (event.keyCode == '40') {
                    // down
                    changeCurrentURLSlideNumber(true);
                }
            }
            document.body.onmouseup = function (event) {
                event = event || window.event;
                event.preventDefault();
                changeCurrentURLSlideNumber(true);
            }
        </script>
    </body>

</html>
