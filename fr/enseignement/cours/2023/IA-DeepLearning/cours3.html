<html>

<head>
    <meta charset="utf-8" />
    <title>Apprentissage profond (2023-2024): John Samuel</title>
    <link rel="shortcut icon" href="../../../../../images/logo/favicon.png" />
    <style type="text/css">
        body {
            height: 100%;
            width: 100%;
            background-color: white;
            margin: 0;
            overflow: hidden;
            font-family: Arial;
        }

        .slide {
            height: 100%;
            width: 100%;
        }

        .content {
            height: 79%;
            width: 95vw;
            display: flex;
            line-height: 1.7em;
            flex-direction: column;
            align-items: flex-start;
            margin: 0 auto;
            color: #000000;
            text-align: left;
            padding-left: 1.5vmax;
            padding-top: 1.5vmax;
            overflow-x: auto;
            font-size: 2.8vmin;
            flex-wrap: wrap;
        }

        .codeexample {
            background-color: #eeeeee;
        }

        /*
generated by Pygments <https://pygments.org/>
Copyright 2006-2023 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
*/
        pre {
            line-height: 125%;
        }

        td.linenos .normal {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        td.linenos .special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos.special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        body .hll {
            background-color: #ffffcc
        }

        body {
            background: #f8f8f8;
        }

        body .c {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment */
        body .err {
            border: 1px solid #FF0000
        }

        /* Error */
        body .k {
            color: #008000;
            font-weight: bold
        }

        /* Keyword */
        body .o {
            color: #666666
        }

        /* Operator */
        body .ch {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Hashbang */
        body .cm {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Multiline */
        body .cp {
            color: #9C6500
        }

        /* Comment.Preproc */
        body .cpf {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.PreprocFile */
        body .c1 {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Single */
        body .cs {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Special */
        body .gd {
            color: #A00000
        }

        /* Generic.Deleted */
        body .ge {
            font-style: italic
        }

        /* Generic.Emph */
        body .gr {
            color: #E40000
        }

        /* Generic.Error */
        body .gh {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Heading */
        body .gi {
            color: #008400
        }

        /* Generic.Inserted */
        body .go {
            color: #717171
        }

        /* Generic.Output */
        body .gp {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Prompt */
        body .gs {
            font-weight: bold
        }

        /* Generic.Strong */
        body .gu {
            color: #800080;
            font-weight: bold
        }

        /* Generic.Subheading */
        body .gt {
            color: #0044DD
        }

        /* Generic.Traceback */
        body .kc {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Constant */
        body .kd {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Declaration */
        body .kn {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Namespace */
        body .kp {
            color: #008000
        }

        /* Keyword.Pseudo */
        body .kr {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Reserved */
        body .kt {
            color: #B00040
        }

        /* Keyword.Type */
        body .m {
            color: #666666
        }

        /* Literal.Number */
        body .s {
            color: #BA2121
        }

        /* Literal.String */
        body .na {
            color: #687822
        }

        /* Name.Attribute */
        body .nb {
            color: #008000
        }

        /* Name.Builtin */
        body .nc {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Class */
        body .no {
            color: #880000
        }

        /* Name.Constant */
        body .nd {
            color: #AA22FF
        }

        /* Name.Decorator */
        body .ni {
            color: #717171;
            font-weight: bold
        }

        /* Name.Entity */
        body .ne {
            color: #CB3F38;
            font-weight: bold
        }

        /* Name.Exception */
        body .nf {
            color: #0000FF
        }

        /* Name.Function */
        body .nl {
            color: #767600
        }

        /* Name.Label */
        body .nn {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Namespace */
        body .nt {
            color: #008000;
            font-weight: bold
        }

        /* Name.Tag */
        body .nv {
            color: #19177C
        }

        /* Name.Variable */
        body .ow {
            color: #AA22FF;
            font-weight: bold
        }

        /* Operator.Word */
        body .w {
            color: #bbbbbb
        }

        /* Text.Whitespace */
        body .mb {
            color: #666666
        }

        /* Literal.Number.Bin */
        body .mf {
            color: #666666
        }

        /* Literal.Number.Float */
        body .mh {
            color: #666666
        }

        /* Literal.Number.Hex */
        body .mi {
            color: #666666
        }

        /* Literal.Number.Integer */
        body .mo {
            color: #666666
        }

        /* Literal.Number.Oct */
        body .sa {
            color: #BA2121
        }

        /* Literal.String.Affix */
        body .sb {
            color: #BA2121
        }

        /* Literal.String.Backtick */
        body .sc {
            color: #BA2121
        }

        /* Literal.String.Char */
        body .dl {
            color: #BA2121
        }

        /* Literal.String.Delimiter */
        body .sd {
            color: #BA2121;
            font-style: italic
        }

        /* Literal.String.Doc */
        body .s2 {
            color: #BA2121
        }

        /* Literal.String.Double */
        body .se {
            color: #AA5D1F;
            font-weight: bold
        }

        /* Literal.String.Escape */
        body .sh {
            color: #BA2121
        }

        /* Literal.String.Heredoc */
        body .si {
            color: #A45A77;
            font-weight: bold
        }

        /* Literal.String.Interpol */
        body .sx {
            color: #008000
        }

        /* Literal.String.Other */
        body .sr {
            color: #A45A77
        }

        /* Literal.String.Regex */
        body .s1 {
            color: #BA2121
        }

        /* Literal.String.Single */
        body .ss {
            color: #19177C
        }

        /* Literal.String.Symbol */
        body .bp {
            color: #008000
        }

        /* Name.Builtin.Pseudo */
        body .fm {
            color: #0000FF
        }

        /* Name.Function.Magic */
        body .vc {
            color: #19177C
        }

        /* Name.Variable.Class */
        body .vg {
            color: #19177C
        }

        /* Name.Variable.Global */
        body .vi {
            color: #19177C
        }

        /* Name.Variable.Instance */
        body .vm {
            color: #19177C
        }

        /* Name.Variable.Magic */
        body .il {
            color: #666666
        }

        /* Literal.Number.Integer.Long */


        .content h1,
        h2,
        h3,
        h4 {
            color: #1B80CF;
        }

        .content .topichighlight {
            background-color: #78002E;
            color: #FFFFFF;
        }

        .content .topicheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 2vmax 2vmax 0%;
            height: 4vmax;
            line-height: 4vmax;
            padding-left: 1vmax;
            margin: 0.1vmax;
            width: 50%;
            margin-bottom: 1vmax;
        }

        .content .flexcontent {
            display: flex;
            overflow-y: auto;
            font-size: 2.8vmin;
            flex-wrap: wrap;
        }

        .content .gridcontent {
            display: grid;
            grid-template-columns: auto auto auto auto;
            grid-column-gap: 0px;
            grid-row-gap: 0px;
            grid-gap: 0px;
        }

        .content .topicsubheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 1.5vmax 1.5vmax 0%;
            height: 3vmax;
            margin: 0.1vmax;
            font-size: 90%;
            line-height: 3vmax;
            padding-left: 1vmax;
            width: 40%;
            margin-bottom: 1vmax;
        }

        .content table {
            color: #000000;
            font-size: 100%;
            width: 100%;
        }

        .content a:link,
        .content a:visited {
            color: #1B80CF;
            text-decoration: none;
        }

        .content th {
            color: #FFFFFF;
            background-color: #1B80CF;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
            font-size: 120%;
            padding: 15px;
        }

        .content figure {
            max-width: 90%;
            max-height: 90%;
        }

        .content .fullwidth img {
            max-width: 90%;
            max-height: 90%;
        }

        .content figure img {
            max-width: 50vmin;
            max-height: 50vmin;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        .content figure figcaption {
            max-width: 90%;
            max-height: 90%;
            margin: 0.1vmax;
            font-size: 90%;
            text-align: center;
            padding: 0.5vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content td {
            color: #000000;
            width: 8%;
            padding-left: 3vmax;
            padding-top: 1vmax;
            padding-bottom: 1vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content li {
            line-height: 1.7em;
        }

        .header {
            color: #ffffff;
            background-color: #00549d;
            height: 5vmax;
        }

        .header h1 {
            text-align: center;
            vertical-align: middle;
            font-size: 3vmax;
            line-height: 4vmax;
            margin: 0;
        }

        .footer {
            height: 3vmax;
            line-height: 3vmax;
            vertical-align: middle;
            color: #ffffff;
            background-color: #00549d;
            margin: 0;
            padding: .3vmax;
            overflow: hidden;
        }

        .footer .contact {
            float: left;
            color: #ffffff;
            text-align: left;
            font-size: 3.2vmin;
        }

        .footer .navigation {
            float: right;
            text-align: right;
            width: 8vw;
            font-size: 3vmin;
        }

        .footer .navigation .next,
        .prev {
            font-size: 3vmin;
            color: #ffffff;
            text-decoration: none;
        }

        .footer .navigation .next::after {
            content: "| >";
        }

        .footer .navigation .prev::after {
            content: "< ";
        }


        @media (max-width: 640px),
        screen and (orientation: portrait) {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .slide {
                height: 100%;
                width: 100%;
            }

            .content {
                width: 100%;
                height: 92%;
                display: flex;
                flex-direction: row;
                text-align: left;
                padding: 1vw;
                line-height: 3.8vmax;
                font-size: 1.8vmax;
                flex-wrap: wrap;
            }

            .content .topicheading {
                width: 90%;
            }

            .content h1,
            h2,
            h3,
            h4 {
                width: 100%;
            }

            .content figure img {
                max-width: 80vmin;
                max-height: 50vmin;
            }

            .content figure figcaption {
                max-width: 90%;
                max-height: 90%;
            }
        }

        @media print {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .content {
                font-size: 2.8vmin;
            }

            .content .flexcontent {
                font-size: 2.5vmin;
            }
        }
    </style>
    <script src="../../2021/MachineLearning/tex-mml-chtml.js" id="MathJax-script"></script>
</head>

<body>
    <section class="slide" id="slide1">
        <div class="header">
        </div>
        <div class="content">
            <h1 style="font-size:2.5vw">Apprentissage profond</h1>
            <p><b>John Samuel</b><br /> CPE Lyon<br /><br />
                <b>Year</b>: 2023-2024<br />
                <b>Email</b>: john(dot)samuel(at)cpe(dot)fr<br /><br />
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img
                        alt="Creative Commons License" style="border-width:0"
                        src="../../../../../en/teaching/courses/2017/C/88x31.png" /></a>
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">1

                <a class="next" href="#slide2"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide2">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron simple couche</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/ArtificialNeuronModel_english.png"
                    height="380px" />
                <figcaption>Perceptron simple couche</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">2
                <a class="prev" href="#slide1"></a>
                <a class="next" href="#slide3"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide3">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron multicouche</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/XOR_perceptron_net.png"
                    height="380px" />
                <figcaption>Perceptron multicouche</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">3
                <a class="prev" href="#slide2"></a>
                <a class="next" href="#slide4"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide4">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow</h2>
            <div class="demo-highlight">
                <pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>

<span class="c1"># Créer un modèle séquentiel</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>

<span class="c1"># Compilation du modèle</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'mean_squared_error'</span><span class="p">,</span>
   <span class="n">optimizer</span><span class="o">=</span><span class="n">sgd</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
</pre>
            </div>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">4
                <a class="prev" href="#slide3"></a>
                <a class="next" href="#slide5"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide5">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <figure>
                <img src="../../2021/MachineLearning/Screenshot_2020-10-20 Tensorflow — Neural Network Playground.png"
                    height="450px" />
                <figcaption>Source: https://playground.tensorflow.org/</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">5
                <a class="prev" href="#slide4"></a>
                <a class="next" href="#slide6"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide6">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <figure>
                <img src="../../2021/MachineLearning/Screenshot_2020-10-20 Tensorflow 2 — Neural Network Playground.png"
                    height="450px" />
                <figcaption>Source: https://playground.tensorflow.org/</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">6
                <a class="prev" href="#slide5"></a>
                <a class="next" href="#slide7"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide7">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <figure>
                <img src="../../2021/MachineLearning/Deep_Learning.jpg" height="450px" />
                <figcaption>Source: https://en.wikipedia.org/wiki/File:Deep_Learning.jpg</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">7
                <a class="prev" href="#slide6"></a>
                <a class="next" href="#slide8"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide8">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation</h2>
            <ul>
                <li>Les neurones sont généralement organisés en plusieurs couches</li>
                <li>Les neurones d'une couche se connectent uniquement aux neurones des couches immédiatement précédente
                    et immédiatement suivante.</li>
                <li>La couche qui reçoit les données externes est la <b>couche d'entrée</b>. </li>
                <li>La couche qui produit le résultat final est la <b>couche de sortie</b>. </li>
                <li>Entre les deux, il y a zéro ou plusieurs couches cachées.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">8
                <a class="prev" href="#slide7"></a>
                <a class="next" href="#slide9"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide9">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation et connectivité</h2>
            <ul>
                <li>Les couches peuvent être <b>entièrement connectées</b>, chaque neurone d'une couche étant connecté à
                    chaque neurone de la couche suivante. </li>
                <li>Les couches peuvent être mis en commun (pooling), c'est-à-dire qu'un groupe de neurones dans une
                    couche se connecte à un seul neurone dans la couche suivante, réduisant ainsi le nombre de neurones
                    dans cette couche</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">9
                <a class="prev" href="#slide8"></a>
                <a class="next" href="#slide10"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide10">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation et connectivité</h2>
            <ul>
                <li>Les réseaux qui permettent des connexions entre les neurones de la même couche ou des couches
                    précédentes sont connus sous le nom de <b>réseaux récurrents</b>.</li>
                <li> les réseaux qui ne permettent pas de cycles entre les couches sont appelés <b>réseaux de neurones
                        en aval</b> (Feedforward neural network)</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">10
                <a class="prev" href="#slide9"></a>
                <a class="next" href="#slide11"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide11">
        <div class="header">
            <h1>3.1. Apprentissage profond: introduction</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <ul>
                <li>Un hyperparamètre est un paramètre constant dont la valeur est fixée avant le début du processus
                    d'apprentissage.</li>
                <li>Les valeurs des paramètres sont obtenues par apprentissage.</li>
                <li>Exemples
                    <ul>
                        <li>le taux d'apprentissage</li>
                        <li>le nombre de couches cachées</li>
                        <li>la taille des échantillons.</li>
                        <li>...</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">11
                <a class="prev" href="#slide10"></a>
                <a class="next" href="#slide12"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide12">
        <div class="header">
            <h1>3.2. Feedforward neural network</h1>
        </div>
        <div class="content">
            <h1 class="topicheading">Feedforward neural network</h1>
            <ul>
                <li>Les connexions entre les nœuds ne forment pas un cycle</li>
                <li>Les informations se déplacent des nœuds d'entrée vers les nœuds de sortie, en passant par les nœuds
                    cachés (le cas échéant). </li>
                <li>L'information ne circule que dans un seul sens, vers l'avant</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Feed_forward_neural_net.gif"
                    height="280px" />
                <figcaption>Réseau de neurones en aval</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">12
                <a class="prev" href="#slide11"></a>
                <a class="next" href="#slide13"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide13">
        <div class="header">
            <h1>3.2. Feedforward neural network</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Rétropropagation du gradient (Backpropagation)</h1>
            <ul>
                <li>La rétropropagation est une méthode permettant d'ajuster les poids de connexion pour compenser
                    chaque erreur constatée lors de l'apprentissage</li>
                <li>Le montant de l'erreur est effectivement réparti entre les connexions. </li>
                <li>calcule le gradient de la fonction de perte par rapport aux poids du réseau pour un seul exemple
                    d'entrée-sortie.</li>
                <li>fonctionne en calculant le gradient de la fonction de perte par rapport à chaque poids selon la
                    règle de la chaîne</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">13
                <a class="prev" href="#slide12"></a>
                <a class="next" href="#slide14"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide14">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicheading">Réseau de neurones récurrents</h1>
            <ul>
                <li>Un réseau de neurones où les connexions entre les nœuds forment un graphe dirigé le long d'une
                    séquence temporelle, lui permettant de présenter un comportement dynamique temporel. </li>
                <li>Ils peuvent utiliser leur état interne (mémoire) pour traiter des séquences d'entrées de longueur
                    variable</li>
                <li>Applications
                    <ul>
                        <li>la reconnaissance de l'écriture manuscrite</li>
                        <li>la reconnaissance vocale</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">14
                <a class="prev" href="#slide13"></a>
                <a class="next" href="#slide15"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide15">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicheading">Réseau de neurones récurrents</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Recurrent_neural_network_unfold.svg"
                    height="380px" />
                <figcaption>Réseau de neurones récurrents</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">15
                <a class="prev" href="#slide14"></a>
                <a class="next" href="#slide16"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide16">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau récurrent à mémoire court et long terme</h1>
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Long_Short-Term_Memory.svg "
                    height="300px" />
                <figcaption>LSTM</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">16
                <a class="prev" href="#slide15"></a>
                <a class="next" href="#slide17"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide17">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau récurrent à mémoire court et long terme</h1>
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <ul>
                <li>LSTM a des connexions de retour d'information</li>
                <li>Une unité LSTM commune est composée d'une cellule, d'une porte d'entrée, d'une porte de sortie et
                    d'une porte d'oubli.</li>
                <li>La cellule se souvient de valeurs sur des intervalles de temps arbitraires et les trois portes
                    régulent le flux d'informations entrant et sortant de la cellule. </li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Long_Short-Term_Memory.svg "
                    height="200px" />
                <figcaption>LSTM</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">17
                <a class="prev" href="#slide16"></a>
                <a class="next" href="#slide18"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide18">
        <div class="header">
            <h1>3.3. Réseau de neurones récurrents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau récurrent à mémoire court et long terme</h1>
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <ul>
                <li>LSTM a des connexions de retour d'information</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Long_Short-Term_Memory.svg "
                    height="280px" />
                <figcaption>LSTM</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">18
                <a class="prev" href="#slide17"></a>
                <a class="next" href="#slide19"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide19">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h1>Réseaux de neurones convolutionnels</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" height="380px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">19
                <a class="prev" href="#slide18"></a>
                <a class="next" href="#slide20"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide20">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h1>Réseaux de neurones convolutionnels</h1>
            <ul>
                <li>Analyse des images</li>
                <li>Utilise la convolution, une opération mathématique linéaire</li>
                <li>Une couche d'entrée et une couche de sortie</li>
                <li>Plusieurs couches cachées, constituées de couches convolutives</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">20
                <a class="prev" href="#slide19"></a>
                <a class="next" href="#slide21"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide21">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h1>Réseaux de neurones convolutionnels</h1>
            <ul>
                <li>Ils considèrent le modèle hiérarchique des données et assemblent des modèles plus complexes en
                    utilisant des modèles plus petits et plus simples.</li>
                <li>Un réseau neuronal convolutif est constitué d'une couche d'entrée et d'une couche de sortie, ainsi
                    que de plusieurs couches cachées. </li>
                <li>Les couches cachées d'un CNN consistent généralement en une série de couches convolutionnelles qui
                    se convoluent avec une multiplication </li>
                <li> La fonction d'activation est généralement une couche RELU, et est ensuite suivie par des
                    convolutions supplémentaires telles que des couches de regroupement, des couches entièrement
                    connectées et des couches de normalisation</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" height="180px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">21
                <a class="prev" href="#slide20"></a>
                <a class="next" href="#slide22"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide22">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" height="380px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">22
                <a class="prev" href="#slide21"></a>
                <a class="next" href="#slide23"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide23">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
            <ul>
                <li>Analyse des images</li>
                <li>Utilise la convolution, une opération mathématique linéaire</li>
                <li>Une couche d'entrée et une couche de sortie</li>
                <li>Plusieurs couches cachées, constituées de couches convolutives</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">23
                <a class="prev" href="#slide22"></a>
                <a class="next" href="#slide24"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide24">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Réseaux de neurones convolutionnels</h3>
            <ul>
                <li>Ils considèrent le modèle hiérarchique des données et assemblent des modèles plus complexes en
                    utilisant des modèles plus petits et plus simples.</li>
                <li>Un réseau neuronal convolutif est constitué d'une couche d'entrée et d'une couche de sortie, ainsi
                    que de plusieurs couches cachées. </li>
                <li>Les couches cachées d'un CNN consistent généralement en une série de couches convolutionnelles qui
                    se convoluent avec une multiplication </li>
                <li> La fonction d'activation est généralement une couche RELU, et est ensuite suivie par des
                    convolutions supplémentaires telles que des couches de regroupement, des couches entièrement
                    connectées et des couches de normalisation</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" height="180px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">24
                <a class="prev" href="#slide23"></a>
                <a class="next" href="#slide25"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide25">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <h3>Identité</h3>
            <p>
                \( \begin{matrix} \ \ 0 &\ \ 0 &\ \ 0 \\ \ \ 0 &\ \ 1 &\ \ 0 \\ \ \ 0 &\ \ 0 &\ \ 0 \end{matrix} \)
            </p>
            <h3>La détection de contours</h3>
            <p>
                \( \begin{matrix} \ \ 1 & 0 & -1 \\ \ \ 0 & 0 & \ \ 0 \\ -1 & 0 & \ \ 1 \end{matrix} \)
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">25
                <a class="prev" href="#slide24"></a>
                <a class="next" href="#slide26"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide26">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <h3>Box blur</h3>
            <p>
                \( \frac{1}{9} \begin{matrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{matrix} \)
            </p>
            <h3>Flou de Gauss 3 × 3</h3>
            <p>
                \( \frac{1}{16} \begin{matrix} 1 & 2 & 1 \\ 2 & 4 & 2 \\ 1 & 2 & 1 \end{matrix} \)
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">26
                <a class="prev" href="#slide25"></a>
                <a class="next" href="#slide27"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide27">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Convolution matricielle</h2>
            <p>
                \[ \begin{bmatrix} x_{11} & x_{12} & \cdots & x_{1n} \\ x_{21} & x_{22} & \cdots & x_{2n} \\ \vdots &
                \vdots & \ddots & \vdots \\ x_{m1} & x_{m2} & \cdots & x_{mn} \\ \end{bmatrix} * \begin{bmatrix} y_{11}
                & y_{12} & \cdots & y_{1n} \\ y_{21} & y_{22}
                & \cdots & y_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ y_{m1} & y_{m2} & \cdots & y_{mn} \\
                \end{bmatrix} = \sum^{m-1}_{i=0} \sum^{n-1}_{j=0} x_{(m-i)(n-j)} y_{(1+i)(1+j)} \]
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">27
                <a class="prev" href="#slide26"></a>
                <a class="next" href="#slide28"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide28">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Max pooling</h2>
            <figure>
                <img src="../../2021/DataMining/Max_pooling.png" height="400px" />
                <figcaption>Max pooling avec un filtre 2 × 2 et un pas de 2. (Source:
                    https://commons.wikimedia.org/wiki/File:Max_pooling.png)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">28
                <a class="prev" href="#slide27"></a>
                <a class="next" href="#slide29"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide29">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <pre class="codeexample">
            <code>
import tensorflow as tf

from tensorflow.keras import datasets, layers, models

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

# Créer un modèle séquentiel (réseaux de neurones convolutionnels)
model = models.Sequential()
model.add(layers.<span style="color:red">Conv2D</span>(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.<span style="color:red">MaxPooling2D</span>((2, 2)))
model.add(layers.<span style="color:red">Conv2D</span>(64, (3, 3), activation='relu'))
model.add(layers.<span style="color:red">MaxPooling2D</span>((2, 2)))
model.add(layers.<span style="color:red">Conv2D</span>(64, (3, 3), activation='relu'))
            </code>
          </pre>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">29
                <a class="prev" href="#slide28"></a>
                <a class="next" href="#slide30"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide30">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <pre class="codeexample">
            <code>
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10)

#Compilation du modèle
model.compile(optimizer='adam',
   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
   metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=10,
   validation_data=(test_images, test_labels))
            </code>
          </pre>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">30
                <a class="prev" href="#slide29"></a>
                <a class="next" href="#slide31"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide31">
        <div class="header">
            <h1>3.4. Réseaux de neurones convolutionnels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <figure>
                <img src="../../2021/DataMining/convolutionalneuralnetwork.png" height="400vh" />
                <figcaption>Modèle: https://www.tensorflow.org/tutorials/images/cnn</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">31
                <a class="prev" href="#slide30"></a>
                <a class="next" href="#slide32"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide32">
        <div class="header">
            <h1>3.5. Réseaux de neurones récurrents convolutifs (RCNN)</h1>
        </div>
        <div class="content">
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">32
                <a class="prev" href="#slide31"></a>
                <a class="next" href="#slide33"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide33">
        <div class="header">
            <h1>Réseaux de neurones récurrents convolutifs bidirectionnels (Bi-RCNN)</h1>
        </div>
        <div class="content">
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">33
                <a class="prev" href="#slide32"></a>
                <a class="next" href="#slide34"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide34">
        <div class="header">
            <h1>Références</h1>
        </div>
        <div class="content">
            <h1>Articles de recherche</h1>
            <ul>
                <li>[Aly 2005] Aly, Mohamed. Survey on Multiclass Classification Methods. 2005.</li>
                <li>[Jaakkola 2019] Jaakkola, H., et al. “Artificial Intelligence Yesterday, Today and Tomorrow.” 2019
                    42nd International Convention on Information and Communication Technology, Electronics and
                    Microelectronics (MIPRO), 2019, pp. 860–67. IEEE
                    Xplore
                </li>
                <li>[Pan 2016] Pan, Yunhe, “Heading toward Artificial Intelligence 2.0.” Engineering, vol. 2, no. 4,
                    Dec. 2016, pp. 409–13. www.sciencedirect.com,</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">34
                <a class="prev" href="#slide33"></a>
                <a class="next" href="#slide35"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide35">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Web</h1>
            <ul>
                <li><a href="https://en.wikipedia.org/wiki/Perceptron">https://en.wikipedia.org/wiki/Perceptron</a></li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Multiclass_classification">https://en.wikipedia.org/wiki/Multiclass_classification</a>
                </li>
                <li><a href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a></li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Multilayer_perceptron">https://en.wikipedia.org/wiki/Multilayer_perceptron</a>
                </li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
                </li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Recurrent_neural_network">https://en.wikipedia.org/wiki/Recurrent_neural_network</a>
                </li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Long_short-term_memory">https://en.wikipedia.org/wiki/Long_short-term_memory</a>
                </li>
                <li><a
                        href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html</a>
                </li>
                <li><a
                        href="https://en.wikipedia.org/wiki/Activation_function">https://en.wikipedia.org/wiki/Activation_function</a>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">35
                <a class="prev" href="#slide34"></a>
                <a class="next" href="#slide36"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide36">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Couleurs</h1>
            <ul>
                <li><a href="https://material.io/color/">Color Tool - Material Design</a></li>
            </ul>
            <h1>Images</h1>
            <ul>
                <li><a href="https://commons.wikimedia.org/">Wikimedia Commons</a></li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">36
                <a class="prev" href="#slide35"></a>
            </div>
        </div>
    </section>

    <script>
        function changeCurrentURLSlideNumber(isIncrement) {
            url = window.location.href;
            position = url.indexOf("#slide");
            if (position != -1) { // Not on the first page
                slideIdString = url.substr(position + 6);
                if (!Number.isNaN(slideIdString)) {
                    slideId = parseInt(slideIdString);
                    if (isIncrement) {
                        if (slideId < 36) {
                            slideId = slideId + 1;
                        }
                    } else {
                        if (slideId > 1) {
                            slideId = slideId - 1;
                        }
                    }
                    /* regexp */
                    url = url.replace(/#slide\d+/g, "#slide" + slideId);
                    window.location.href = url;
                }
            } else {
                window.location.href = url + "#slide2";
            }
        }
        document.onkeydown = function (event) {

            event.preventDefault();
            /* This will ensure the default behavior of
                                                            page scroll behaviour (up, down, right, left)*/

            event = event || window.event;
            /*Codes de la touche sur le clavier: 37, 38, 39, 40*/
            if (event.keyCode == '37') {
                // left
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '38') {
                // up
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '39') {
                // right
                changeCurrentURLSlideNumber(true);
            } else if (event.keyCode == '40') {
                // down
                changeCurrentURLSlideNumber(true);
            }
        }
        document.body.onmouseup = function (event) {
            event = event || window.event;
            event.preventDefault();
            changeCurrentURLSlideNumber(true);
        }
    </script>
</body>

</html>
