<html>

<head>
    <meta charset="utf-8" />
    <title>Apprentissage machine (2023-2024): Cours: John Samuel</title>
    <link rel="shortcut icon" href="../../../../../images/logo/favicon.png" />
    <style type="text/css">
        body {
            height: 100%;
            width: 100%;
            background-color: white;
            margin: 0;
            overflow: hidden;
            font-family: Arial;
        }

        .slide {
            height: 100%;
            width: 100%;
        }

        .content {
            height: 79%;
            width: 95vw;
            display: flex;
            line-height: 1.7em;
            flex-direction: column;
            align-items: flex-start;
            margin: 0 auto;
            color: #000000;
            text-align: left;
            padding-left: 1.5vmax;
            padding-top: 1.5vmax;
            overflow-x: auto;
            font-size: 2.8vmin;
            flex-wrap: wrap;
        }

        .codeexample {
            background-color: #eeeeee;
        }

        /*
generated by Pygments <https://pygments.org/>
Copyright 2006-2023 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
*/
        pre {
            line-height: 125%;
        }

        td.linenos .normal {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        td.linenos .special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos.special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        body .hll {
            background-color: #ffffcc
        }

        body {
            background: #f8f8f8;
        }

        body .c {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment */
        body .err {
            border: 1px solid #FF0000
        }

        /* Error */
        body .k {
            color: #008000;
            font-weight: bold
        }

        /* Keyword */
        body .o {
            color: #666666
        }

        /* Operator */
        body .ch {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Hashbang */
        body .cm {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Multiline */
        body .cp {
            color: #9C6500
        }

        /* Comment.Preproc */
        body .cpf {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.PreprocFile */
        body .c1 {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Single */
        body .cs {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Special */
        body .gd {
            color: #A00000
        }

        /* Generic.Deleted */
        body .ge {
            font-style: italic
        }

        /* Generic.Emph */
        body .gr {
            color: #E40000
        }

        /* Generic.Error */
        body .gh {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Heading */
        body .gi {
            color: #008400
        }

        /* Generic.Inserted */
        body .go {
            color: #717171
        }

        /* Generic.Output */
        body .gp {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Prompt */
        body .gs {
            font-weight: bold
        }

        /* Generic.Strong */
        body .gu {
            color: #800080;
            font-weight: bold
        }

        /* Generic.Subheading */
        body .gt {
            color: #0044DD
        }

        /* Generic.Traceback */
        body .kc {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Constant */
        body .kd {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Declaration */
        body .kn {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Namespace */
        body .kp {
            color: #008000
        }

        /* Keyword.Pseudo */
        body .kr {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Reserved */
        body .kt {
            color: #B00040
        }

        /* Keyword.Type */
        body .m {
            color: #666666
        }

        /* Literal.Number */
        body .s {
            color: #BA2121
        }

        /* Literal.String */
        body .na {
            color: #687822
        }

        /* Name.Attribute */
        body .nb {
            color: #008000
        }

        /* Name.Builtin */
        body .nc {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Class */
        body .no {
            color: #880000
        }

        /* Name.Constant */
        body .nd {
            color: #AA22FF
        }

        /* Name.Decorator */
        body .ni {
            color: #717171;
            font-weight: bold
        }

        /* Name.Entity */
        body .ne {
            color: #CB3F38;
            font-weight: bold
        }

        /* Name.Exception */
        body .nf {
            color: #0000FF
        }

        /* Name.Function */
        body .nl {
            color: #767600
        }

        /* Name.Label */
        body .nn {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Namespace */
        body .nt {
            color: #008000;
            font-weight: bold
        }

        /* Name.Tag */
        body .nv {
            color: #19177C
        }

        /* Name.Variable */
        body .ow {
            color: #AA22FF;
            font-weight: bold
        }

        /* Operator.Word */
        body .w {
            color: #bbbbbb
        }

        /* Text.Whitespace */
        body .mb {
            color: #666666
        }

        /* Literal.Number.Bin */
        body .mf {
            color: #666666
        }

        /* Literal.Number.Float */
        body .mh {
            color: #666666
        }

        /* Literal.Number.Hex */
        body .mi {
            color: #666666
        }

        /* Literal.Number.Integer */
        body .mo {
            color: #666666
        }

        /* Literal.Number.Oct */
        body .sa {
            color: #BA2121
        }

        /* Literal.String.Affix */
        body .sb {
            color: #BA2121
        }

        /* Literal.String.Backtick */
        body .sc {
            color: #BA2121
        }

        /* Literal.String.Char */
        body .dl {
            color: #BA2121
        }

        /* Literal.String.Delimiter */
        body .sd {
            color: #BA2121;
            font-style: italic
        }

        /* Literal.String.Doc */
        body .s2 {
            color: #BA2121
        }

        /* Literal.String.Double */
        body .se {
            color: #AA5D1F;
            font-weight: bold
        }

        /* Literal.String.Escape */
        body .sh {
            color: #BA2121
        }

        /* Literal.String.Heredoc */
        body .si {
            color: #A45A77;
            font-weight: bold
        }

        /* Literal.String.Interpol */
        body .sx {
            color: #008000
        }

        /* Literal.String.Other */
        body .sr {
            color: #A45A77
        }

        /* Literal.String.Regex */
        body .s1 {
            color: #BA2121
        }

        /* Literal.String.Single */
        body .ss {
            color: #19177C
        }

        /* Literal.String.Symbol */
        body .bp {
            color: #008000
        }

        /* Name.Builtin.Pseudo */
        body .fm {
            color: #0000FF
        }

        /* Name.Function.Magic */
        body .vc {
            color: #19177C
        }

        /* Name.Variable.Class */
        body .vg {
            color: #19177C
        }

        /* Name.Variable.Global */
        body .vi {
            color: #19177C
        }

        /* Name.Variable.Instance */
        body .vm {
            color: #19177C
        }

        /* Name.Variable.Magic */
        body .il {
            color: #666666
        }

        /* Literal.Number.Integer.Long */


        .content h1,
        h2,
        h3,
        h4 {
            color: #1B80CF;
        }

        .content .topichighlight {
            background-color: #78002E;
            color: #FFFFFF;
        }

        .content .topicheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 2vmax 2vmax 0%;
            height: 4vmax;
            line-height: 4vmax;
            padding-left: 1vmax;
            margin: 0.1vmax;
            width: 50%;
            margin-bottom: 1vmax;
        }

        .content .flexcontent {
            display: flex;
            overflow-y: auto;
            font-size: 2.8vmin;
            flex-wrap: wrap;
        }

        .content .gridcontent {
            display: grid;
            grid-template-columns: auto auto auto auto;
            grid-column-gap: 0px;
            grid-row-gap: 0px;
            grid-gap: 0px;
        }

        .content .topicsubheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 1.5vmax 1.5vmax 0%;
            height: 3vmax;
            margin: 0.1vmax;
            font-size: 90%;
            line-height: 3vmax;
            padding-left: 1vmax;
            width: 40%;
            margin-bottom: 1vmax;
        }

        .content table {
            color: #000000;
            font-size: 100%;
            width: 100%;
        }

        .content a:link,
        .content a:visited {
            color: #1B80CF;
            text-decoration: none;
        }

        .content th {
            color: #FFFFFF;
            background-color: #1B80CF;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
            font-size: 120%;
            padding: 15px;
        }

        .content figure {
            max-width: 90%;
            max-height: 90%;
        }

        .content .fullwidth img {
            max-width: 90%;
            max-height: 90%;
        }

        .content figure img {
            max-width: 50vmin;
            max-height: 50vmin;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        .content figure figcaption {
            max-width: 90%;
            max-height: 90%;
            margin: 0.1vmax;
            font-size: 90%;
            text-align: center;
            padding: 0.5vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content td {
            color: #000000;
            width: 8%;
            padding-left: 3vmax;
            padding-top: 1vmax;
            padding-bottom: 1vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content li {
            line-height: 1.7em;
        }

        .header {
            color: #ffffff;
            background-color: #00549d;
            height: 5vmax;
        }

        .header h1 {
            text-align: center;
            vertical-align: middle;
            font-size: 3vmax;
            line-height: 4vmax;
            margin: 0;
        }

        .footer {
            height: 3vmax;
            line-height: 3vmax;
            vertical-align: middle;
            color: #ffffff;
            background-color: #00549d;
            margin: 0;
            padding: .3vmax;
            overflow: hidden;
        }

        .footer .contact {
            float: left;
            color: #ffffff;
            text-align: left;
            font-size: 3.2vmin;
        }

        .footer .navigation {
            float: right;
            text-align: right;
            width: 8vw;
            font-size: 3vmin;
        }

        .footer .navigation .next,
        .prev {
            font-size: 3vmin;
            color: #ffffff;
            text-decoration: none;
        }

        .footer .navigation .next::after {
            content: "| >";
        }

        .footer .navigation .prev::after {
            content: "< ";
        }


        @media (max-width: 640px),
        screen and (orientation: portrait) {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .slide {
                height: 100%;
                width: 100%;
            }

            .content {
                width: 100%;
                height: 92%;
                display: flex;
                flex-direction: row;
                text-align: left;
                padding: 1vw;
                line-height: 3.8vmax;
                font-size: 1.8vmax;
                flex-wrap: wrap;
            }

            .content .topicheading {
                width: 90%;
            }

            .content h1,
            h2,
            h3,
            h4 {
                width: 100%;
            }

            .content figure img {
                max-width: 80vmin;
                max-height: 50vmin;
            }

            .content figure figcaption {
                max-width: 90%;
                max-height: 90%;
            }
        }

        @media print {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .content {
                font-size: 2.8vmin;
            }

            .content .flexcontent {
                font-size: 2.5vmin;
            }
        }
    </style>
    <script src="../../2021/MachineLearning/tex-mml-chtml.js" id="MathJax-script"></script>
</head>

<body>
    <section class="slide" id="slide1">
        <div class="header">
        </div>
        <div class="content">
            <h1 style="font-size:2.5vw">Apprentissage machine</h1>
            <p><b>John Samuel</b><br /> CPE Lyon<br /><br />
                <b>Year</b>: 2023-2024<br />
                <b>Email</b>: john(dot)samuel(at)cpe(dot)fr<br /><br />
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img
                        alt="Creative Commons License" style="border-width:0"
                        src="../../../../../en/teaching/courses/2017/C/88x31.png" /></a>
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">1

                <a class="next" href="#slide2"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide2">
        <div class="header">
            <h1>John SAMUEL</h1>
        </div>
        <div class="content">
            <div class="flexcontent">
                <figure style="width:30vw">
                    <img src="../../../../../images/portrait.jpg" width="300vw" style="background:#ffffff" />
                </figure>
                <ul style="width:40vw">
                    <li> <b>Enseignant-Chercheur</b>, Conception Logicielle et Big Data, CPE Lyon, </li>
                    <li> <b>Intérêts et thèmes de recherche </b>: Représentation de connaissances, le web sémantique,
                        les services web, l'intégration de données, l'entrepôt de données, les systèmes distribués,
                        système d'information géographique</li>
                    <li> <b>Cours </b>: Programmation en C, Algorithmes en C, Data Mining et Machine Learning,
                        Intelligence Artificielle et Deep Learning, Systèmes d'exploitation et Programmation
                        Concurrente, Langages Web</li>
                    <li> <b>Thèse</b> : Intégration des données issues de services web</li>
                </ul>
            </div>
        </div>
        <div class="footer">
            <div class="contact">Programmation en C | John Samuel</div>
            <div class="navigation">2
                <a class="prev" href="#slide1"></a>
                <a class="next" href="#slide3"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide3">
        <div class="header">
            <h1>Intelligence Artificielle - Deep Learning</h1>
        </div>
        <div class="content">
            <h1>Objectifs</h1>
            <ol>
                <li>Introduction à l'Intelligence Artificielle (IA)</li>
                <li>Apprentissage Machine</li>
                <li>Apprentissage Profond</li>
                <li>Applications de l'IA</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">3
                <a class="prev" href="#slide2"></a>
                <a class="next" href="#slide4"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide4">
        <div class="header">
            <h1>Intelligence Artificielle - Deep Learning</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Devoir surveillé (DS): 60%</h1>
            <ul>
                <li><b>Examen</b>: En-ligne sur E-campus</li>
                <li><b>Durée</b>: 2 heures</li>
                <li><b>Total</b>: 10/20 points</li>
                <li><b>Documents</b>: autorisés</li>
                <li><b>Types de documents autorisés</b>: Tous les documents autorisés</li>
                <li><b>Calculatrices</b> : non autorisées</li>
                <li><b>Utilisation de l'internet</b> : non autorisée</li>
                <li><b>Dépôt supplémentaire</b> : disponible pour les fichiers personnels</li>
            </ul>
            <p>Vous recevrez un courrier détaillé avant l'examen</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">4
                <a class="prev" href="#slide3"></a>
                <a class="next" href="#slide5"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide5">
        <div class="header">
            <h1>Intelligence Artificielle - Deep Learning</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Travaux pratiques et Projet: 40%</h1>
            <ul>
                <li> Les 2 travaux pratiques (TP) et le projet seront <b>évalués</b>.</li>
                <li> Deux <b>dates limites</b> de soumission sont précisées sur e-campus.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">5
                <a class="prev" href="#slide4"></a>
                <a class="next" href="#slide6"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide6">
        <div class="header">
            <h1>Intelligence Artificielle - Deep Learning</h1>
        </div>
        <div class="content">
            <table>
                <tr>
                    <th>Cours</th>
                    <th>Nombre d'heures</th>
                </tr>
                <tr>
                    <td>Cours</td>
                    <td>16</td>
                </tr>
                <tr>
                    <td>TP</td>
                    <td>16</td>
                </tr>
                <tr>
                    <td>Projet</td>
                    <td>16</td>
                </tr>
            </table>
            <p><b>Attention</b> : À chaque séance, nous adopterons un format intégrant à la fois des cours et des
                travaux pratiques.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">6
                <a class="prev" href="#slide5"></a>
                <a class="next" href="#slide7"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide7">
        <div class="header">
            <h1>1.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Intelligence Artificielle [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>La méthode d'apprentissage profond</li>
                <li>Les fusions et acquisitions d'entreprises
                    <ul>
                        <li>DNNresearch par Google en 2013 [1] : <b>vision par ordinateur</b>.</li>
                        <li>LinkedIn par Microsoft en 2016 [2] : <b>réseaux sociaux professionnels</b>.</li>
                    </ul>
                </li>
                <li>Les chatbots
                    <ul>
                        <li>Xiaobing par Microsoft: « <b>comprendre</b> » et répondre aux questions des utilisateurs en
                            <b>langage naturel</b>.
                        </li>
                    </ul>
                </li>
                <li>Les programmes de jeux
                    <ul>
                        <li>AlphaGo par Google : victoire historique contre le champion du <b>jeu de go</b> Lee Sedol en
                            2016.</li>
                    </ul>
                </li>
                <li>L'utilisation dans les hôpitaux
                    <ul>
                        <li>Watson par IBM : une plateforme d'IA qui a été utilisée dans le domaine de la santé pour
                            aider les professionnels de la santé à <b>analyser et à interpréter des données
                                médicales</b> complexes.</li>
                    </ul>
                </li>
                <li>La compréhension du langage naturel
                    <ul>
                        <li>Baidu : <b>moteur de recherche</b>.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">7
                <a class="prev" href="#slide6"></a>
                <a class="next" href="#slide8"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide8">
        <div class="header">
            <h1>1.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Intelligence Artificielle [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>1956: la definition d'IA
                    <ul>
                        <li><b>La capacité des machines à comprendre, à penser et à apprendre d'une manière similaire à
                                celle des êtres humains</b></li>
                        <li>Proposée par J. McCarthy, M. L. Minsky, H. Simon, A. Newell, C. E. Shannon, N. Rochester,...
                        </li>
                    </ul>
                </li>
                <li>1970-2000
                    <ul>
                        <li>1983: le rapport par James Lighthill : un rapport critiquant la recherche en IA au
                            Royaume-Uni, ce qui a conduit à un <b>ralentissement temporaire des financements publics</b>
                            pour l'IA, connu sous le nom de « <b>l'effet Lighthill</b> ».</li>
                        <li>1982-1992: l'échec du développement d'un <b>ordinateur intelligent</b> par le Japon</li>
                        <li>1984: la <b>construction manuelle d'une encyclopédie</b> de la connaissance (Cyc) par
                            Douglas Lenat à l'Université Stanford. Cyc est un projet d'IA visant à créer une base de
                            connaissances informatisée capable de raisonner et de répondre à des questions complexes.
                        </li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">8
                <a class="prev" href="#slide7"></a>
                <a class="next" href="#slide9"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide9">
        <div class="header">
            <h1>1.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Intelligence Artificielle 2.0 [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>1990s-présent
                    <ul>
                        <li>Popularité de <b>l'Internet</b></li>
                        <li>l'utilisation des <b>capteurs</b></li>
                        <li><b>Big Data</b></li>
                        <li>l'e-commerce</li>
                    </ul>
                </li>
                <li>Des <b>demandes sociales</b> pour IA
                    <ul>
                        <li>des <b>villes intelligentes</b></li>
                        <li>médecine</li>
                        <li>transport</li>
                        <li>les <b>automobiles sans conducteur</b></li>
                        <li>les smartphones</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">9
                <a class="prev" href="#slide8"></a>
                <a class="next" href="#slide10"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide10">
        <div class="header">
            <h1>1.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Intelligence Artificielle 2.0 [Pan 2016]</h1>
            <ul>
                <li>Les technologies à l'origine de l'IA
                    <ul>
                        <li>L'IA basée sur des <b>données massives (Big Data)</b></li>
                        <li><b>L'intelligence de la foule</b> sur Internet</li>
                        <li>Le savoir médiatique croisé</li>
                        <li>L'intelligence hybride homme-machine</li>
                        <li><b>Systèmes autonomes</b> et intelligents</li>
                    </ul>
                </li>
                <li>L'avenir
                    <ul>
                        <li>L'IA <b>explicative et générique</b></li>
                        <li>la cognition, l'apprentissage et l'inférence trans-médiatiques.</li>
                        <li><b>l'intelligence communautaire</b> à partir de l'intelligence des foules basée sur
                            l'intelligence
                            individuelle</li>
                        <li>des systèmes autonomes et intelligents pour le développement de machines et de produits
                            intelligents.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">10
                <a class="prev" href="#slide9"></a>
                <a class="next" href="#slide11"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide11">
        <div class="header">
            <h1>1.2. Les fondements de l'IA </h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Objectifs</h1>
            <figure>
                <img src="../../../../../images/art/courses/deeplearningposition.svg" height="400px" />
                <figcaption>Intelligence artificielle</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">11
                <a class="prev" href="#slide10"></a>
                <a class="next" href="#slide12"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide12">
        <div class="header">
            <h1>1.2. Les fondements de l'IA </h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">1.2. Les fondements de l'IA </h1>
            <ul>
                <li>1.2.1. Logique et raisonnement</li>
                <li>1.2.2. Représentation des connaissances</li>
                <li>1.2.3. Agents intelligents</li>
                <li>1.2.4. Apprentissage machine</li>
                <li>1.2.5. Apprentissage profond</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">12
                <a class="prev" href="#slide11"></a>
                <a class="next" href="#slide13"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide13">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique et raisonnement</h1>
            <ul>
                <li><b style="color:#1B80CF">Logique propositionnelle</b> : La logique propositionnelle est un système
                    formel qui permet de représenter et d'évaluer des <b>propositions</b> en utilisant des
                    <b>connecteurs logiques (comme ET, OU, NON)</b> pour déterminer leur vérité.
                </li>
                <li><b style="color:#1B80CF">Logique du premier ordre</b> : La logique du premier ordre, également
                    appelée logique des prédicats, est une extension de la logique propositionnelle qui permet de
                    représenter des propositions plus complexes en introduisant des <b>variables, des constantes, des
                        fonctions et des prédicats</b>.</li>
                <li><b style="color:#1B80CF">Logique modale</b> : La logique modale est une extension de la logique qui
                    permet de représenter des notions de <b>possibilité</b>, de <b>nécessité</b>, de <b>croyance</b> et
                    d'autres modalités. </li>
                <li><b style="color:#1B80CF">Raisonnement automatisé</b> : Le raisonnement automatisé fait référence à
                    l'utilisation de systèmes informatiques pour effectuer des <b>inférences logiques</b> et <b>déduire
                        de nouvelles informations</b> à partir de connaissances existantes.</li>
                <li><b style="color:#1B80CF">Problèmes de décision et résolution de problèmes</b> : Les problèmes de
                    décision se réfèrent à des situations où une décision doit être prise parmi <b>plusieurs options
                        possibles</b>, généralement sous contraintes. La résolution de problèmes implique la
                    <b>recherche d'une solution</b> à un problème donné en utilisant des <b>méthodes algorithmiques ou
                        heuristiques</b> pour atteindre un objectif spécifique.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">13
                <a class="prev" href="#slide12"></a>
                <a class="next" href="#slide14"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide14">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique propositionnelle</h1>
            <p>Les propositions dans la logique propositionnelle sont des déclarations qui peuvent être <b>vraies
                    (V)</b> ou <b>fausses (F)</b>. Supposons que nous ayons deux propositions simples : P, Q. Nous
                pouvons utiliser des connecteurs logiques pour créer des propositions plus complexes à partir de ces
                propositions simples.</p>
            <ul>
                <li><b style="color:#1B80CF">NON (¬) </b> : La négation (NON) inverse la valeur de vérité d'une
                    proposition. Si P est vrai, alors NON P est faux, et si P est faux, alors NON P est vrai.</li>
                <li><b style="color:#1B80CF">ET (ET logique, ∧)</b> : L'opérateur ET (ou ET logique) est vrai seulement
                    si toutes les propositions connectées par ET sont vraies. Si P est vrai et Q est vrai, alors P ET Q
                    est vrai. Sinon, P ET Q est faux.</li>
                <li><b style="color:#1B80CF">OU (OU logique, ∨)</b> : L'opérateur OU (ou OU logique) est vrai si au
                    moins l'une des propositions connectées par OU est vraie. Si P est vrai ou Q est vrai (ou les deux),
                    alors P OU Q est vrai. Si les deux sont faux, alors P OU Q est faux.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">14
                <a class="prev" href="#slide13"></a>
                <a class="next" href="#slide15"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide15">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique propositionnelle</h1>
            <ul>
                <li><b style="color:#1B80CF">Implication (=>)</b> : L'implication (=>) exprime une relation où la vérité
                    de la première proposition entraîne la vérité de la seconde. Si P est vrai, alors P => Q est vrai,
                    peu importe la valeur de Q. Si P est faux, alors P => Q est toujours vrai, car il ne dit rien sur Q.
                </li>
                <li><b style="color:#1B80CF">Équivalence (<=>)</b> : L'équivalence (<=>) signifie que deux propositions
                        ont la même valeur de vérité dans toutes les situations. Si P est vrai et Q est vrai, ou si P
                        est faux et Q est faux, alors P <=> Q est vrai. Sinon, c'est faux.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">15
                <a class="prev" href="#slide14"></a>
                <a class="next" href="#slide16"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide16">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique propositionnelle</h1>
            <p>Supposons que nous ayons quatre propositions simples : P, Q, R et S.</p>
            <ul>
                <li><b style="color:#1B80CF">P</b> : Présence de l'eau.</li>
                <li><b style="color:#1B80CF">Q</b> : Présence de sable.</li>
                <li><b style="color:#1B80CF">R</b> : Présence d'oiseaux marins.</li>
                <li><b style="color:#1B80CF">S</b> : Présence de bateaux.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">16
                <a class="prev" href="#slide15"></a>
                <a class="next" href="#slide17"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide17">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique propositionnelle</h1>
            <p> Avec ces propositions, nous pouvons définir des règles pour déterminer si une image représente la mer :
            </p>
            <ul>
                <li> Si l'eau est présente (P), alors il est possible que l'image soit celle de la mer.</li>
                <li> Si en plus il y a du sable (Q), cela renforce la probabilité que l'image soit une plage de mer.
                </li>
                <li> Si des oiseaux marins sont présents (R), cela renforce également la probabilité que la scène soit
                    liée à la mer.</li>
                <li> Si des bateaux sont visibles (S), cela suggère une forte probabilité que la scène soit maritime.
                </li>
            </ul>
            <p>nous pouvons utiliser des opérateurs logiques pour combiner ces propositions et déterminer si l'image est
                celle de la mer :</p>
            <p><b>Image de la mer</b> : (P ET Q) OU (P ET R) OU (P ET S)</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">17
                <a class="prev" href="#slide16"></a>
                <a class="next" href="#slide18"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide18">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <p>Contrairement à la logique propositionnelle, qui traite uniquement de la vérité ou de la fausseté de
                propositions simples, la logique du premier ordre permet de représenter des informations structurées sur
                des objets et leurs relations. Voici quelques concepts clés de la logique du premier ordre :</p>
            <ul>
                <li><b style="color:#1B80CF">Variables</b> : Les variables sont des symboles qui représentent des objets
                    ou des éléments non spécifiés d'un domaine. Elles sont utilisées pour généraliser des expressions et
                    représenter des objets de manière générique.</li>
                <li><b style="color:#1B80CF">Constantes</b> : Les constantes sont des symboles qui représentent des
                    objets spécifiques et immuables d'un domaine.</li>
                <li><b style="color:#1B80CF">Fonctions</b> : Les fonctions sont des opérations qui prennent un ou
                    plusieurs arguments et renvoient un résultat.</li>
            </ul>
            <p>Utilisez des parenthèses pour indiquer la priorité des opérations et la structure de la formule.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">18
                <a class="prev" href="#slide17"></a>
                <a class="next" href="#slide19"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide19">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <ul>
                <li><b style="color:#1B80CF">Prédicats</b> : Les prédicats sont des expressions qui décrivent des
                    relations entre des objets ou des propriétés de ces objets. </li>
                <li><b style="color:#1B80CF">Quantificateurs</b> : Les quantificateurs, tels que "pour tout" (∀) et "il
                    existe" (∃), sont utilisés pour spécifier la portée de variables dans une expression. </li>
                <li><b style="color:#1B80CF">Opérateurs logiques</b> : Les opérateurs logiques tels que "ET" (∧), "OU"
                    (∨), "NON" (¬), "Implication" (=&gt;), et "Équivalence" (&lt;=&gt;) sont utilisés pour combiner des
                    propositions et construire des formules plus complexes. </li>
            </ul>
            <p>Utilisez des parenthèses pour indiquer la priorité des opérations et la structure de la formule.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">19
                <a class="prev" href="#slide18"></a>
                <a class="next" href="#slide20"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide20">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <p>Exemple : </p>
            <ul>
                <li><b style="color:#1B80CF">Variables</b> : une variable pourrait être représentée par "x", où "x" peut
                    représenter n'importe quelle mer.</li>
                <li><b style="color:#1B80CF">Constantes</b> : des constantes pourraient être "Mer Méditerranée", "Mer
                    Noire" et "Mer Rouge" pour représenter des mers spécifiques.</li>
                <li><b style="color:#1B80CF">Fonctions</b> : Nous pourrions utiliser une fonction "Profondeur(x)" pour
                    représenter la profondeur de la mer x. Par exemple, "Profondeur(Mer Méditerranée)" pourrait renvoyer
                    la profondeur de la mer Méditerranée.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">20
                <a class="prev" href="#slide19"></a>
                <a class="next" href="#slide21"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide21">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <p>Exemple : </p>
            <ul>
                <li><b style="color:#1B80CF">Prédicats</b> : Un prédicat tel que "Salée(x)" pourrait toujours être
                    utilisé pour indiquer si une mer donnée (x) est salée ou non. Par exemple, "Salée(Mer Méditerranée)"
                    serait vrai car la mer Méditerranée est salée.. </li>
                <li><b style="color:#1B80CF">Quantificateurs</b> : Les quantificateurs définissent la portée des
                    variables dans une expression logique.
                    <ul>
                        <li>"∀x Salée(x)" signifierait que toutes les mers sont salées.</li>
                        <li>"∃x Superficie(x) > 100 000 km²" signifierait qu'il existe une mer dont la superficie est
                            supérieure à 100 000 kilomètres carrés.</li>
                    </ul>
                </li>
            </ul>
            <p>Les fonctions sont utilisées pour attribuer des valeurs à des objets ou effectuer des opérations, tandis
                que les prédicats sont utilisés pour exprimer des relations ou des propriétés entre des objets et
                renvoient une valeur booléenne indiquant si la relation est vraie ou non.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">21
                <a class="prev" href="#slide20"></a>
                <a class="next" href="#slide22"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide22">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <p>Utilisons l'exemple des règles pour confirmer qu'une image représente effectivement une mer.</p>
            <ul>
                <li><b style="color:#1B80CF">Constantes</b> : Nos constantes pourraient être les noms d'images
                    spécifiques ou d'autres identifiants uniques pour des images particulières.</li>
                <li><b style="color:#1B80CF">Variables</b> : Nous pourrions utiliser une variable, disons "x", pour
                    représenter une image générique.</li>
                <li><b style="color:#1B80CF">Prédicats</b> : Les prédicats sont des expressions qui décrivent des
                    relations entre des objets ou des propriétés de ces objets.
                    <ul>
                        <li> Un prédicat "ContientEau(x)" pourrait être utilisé pour indiquer si l'image x contient de
                            l'eau.</li>
                        <li> Un prédicat "ContientSable(x)" pourrait être utilisé pour indiquer si l'image x contient du
                            sable.</li>
                        <li> Un prédicat "ContientBateaux(x)" pourrait être utilisé pour indiquer si l'image x contient
                            des bateaux.</li>
                        <li> Un prédicat "ContientOiseauxMarins(x)" pourrait être utilisé pour indiquer si l'image x
                            contient des oiseaux marins.</li>
                    </ul>

                </li>
                <li><b style="color:#1B80CF">Quantificateurs</b> : Nous pourrions utiliser des quantificateurs tels que
                    "∃x" (il existe une image) ou "∀x" (pour toutes les images) pour spécifier la portée de nos règles.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">22
                <a class="prev" href="#slide21"></a>
                <a class="next" href="#slide23"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide23">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <p>1. Pour déterminer si une image représente une scène de mer, nous pourrions utiliser une règle du type
            </p>
            <p>
                <code>∀x (ContientEau(x) ∧ ContientSable(x) => EstMer(x))</code>
            </p>
            <p>2. Nous pourrions également ajouter des règles spécifiques pour détecter des éléments spécifiques : </p>
            <p>
                <code>∀x (ContientBateaux(x) => EstPort(x))</code>
            </p>
            <p>
                <code>∀x (ContientOiseauxMarins(x) => EstPlage(x))</code>
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">23
                <a class="prev" href="#slide22"></a>
                <a class="next" href="#slide24"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide24">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <p>3. Il existe au moins une image x telle que l'image contienne de l'eau et du sable.</p>
            <p>
                <code>∃x (ContientEau(x) ∧ ContientSable(x))</code>
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">24
                <a class="prev" href="#slide23"></a>
                <a class="next" href="#slide25"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide25">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique modale</h1>
            <p>La logique modale est une extension de la logique classique qui permet de raisonner sur la notion de
                "modalités", c'est-à-dire des catégories de propositions qui expriment des modalités ou des qualités
                spécifiques, telles que la nécessité, la possibilité, l'obligation, la croyance, etc</p>
            <p><b>Opérateurs modaux</b> : Les opérateurs modaux sont utilisés pour exprimer des modalités. Les deux
                opérateurs modaux les plus courants sont :</p>
            <ul>
                <li><b>◻ (carré)</b> : Il exprime la nécessité, indiquant que quelque chose est nécessairement vrai.
                </li>
                <li><b>◇ (losange)</b> : Il exprime la possibilité, indiquant que quelque chose est possible, mais pas
                    nécessairement vrai.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">25
                <a class="prev" href="#slide24"></a>
                <a class="next" href="#slide26"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide26">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique modale</h1>
            <p>En logique modale, les termes "nécessaire", "contingent", "possible" et "impossible" sont utilisés pour
                décrire les modalités ou les qualités d'une proposition. </p>
            <ul>
                <li><b>Nécessaire</b> : Une proposition est dite "nécessaire" si elle est vraie dans toutes les
                    situations possibles, c'est-à-dire qu'elle ne peut pas être fausse dans aucune situation imaginable.
                    En notation modale, on utilise l'opérateur "◻" (carré) pour représenter la nécessité. Ainsi, "◻(P)"
                    signifie "Il est nécessaire que P soit vrai."</li>
                <li><b>Contingent</b> : Une proposition est dite "contingente" si elle est vraie dans certaines
                    situations possibles et fausse dans d'autres. En d'autres termes, sa vérité dépend du contexte ou
                    des conditions. Les propositions contingentes ne sont ni nécessairement vraies ni nécessairement
                    fausses.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">26
                <a class="prev" href="#slide25"></a>
                <a class="next" href="#slide27"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide27">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique modale</h1>
            <ul>
                <li><b>Possible</b> : Une proposition est dite "possible" si elle est vraie dans au moins une situation
                    possible, même si elle n'est pas nécessairement vraie dans toutes les situations possibles. En
                    notation modale, on utilise l'opérateur "◇" (losange) pour représenter la possibilité. Ainsi, "◇(Q)"
                    signifie "Il est possible que Q soit vrai."</li>
                <li><b>Impossible</b> : Une proposition est dite "impossible" si elle est fausse dans toutes les
                    situations possibles, c'est-à-dire qu'elle ne peut pas être vraie dans aucune situation imaginable.
                    En notation modale, l'opérateur de négation "¬" peut être utilisé en conjonction avec l'opérateur de
                    possibilité "◇" pour représenter l'impossibilité. Ainsi, "¬◇(R)" signifie "Il est impossible que R
                    soit vrai."</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">27
                <a class="prev" href="#slide26"></a>
                <a class="next" href="#slide28"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide28">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique modale</h1>
            <p>Exemple </p>
            <ul>
                <li><b>Nécessaire</b> : "◻(Toute mer est salée)" signifie que dans toutes les situations possibles,
                    toutes les mers sont salées.</li>
                <li><b>Contingent</b> : "◇(Il peut y avoir des mers calmes)" signifie qu'il est possible d'avoir des
                    mers calmes, mais elles ne sont pas nécessairement calmes dans toutes les situations possibles.</li>
                <li><b>Possible</b> : : "◇(Il est possible qu'il y ait des tempêtes en mer)" signifie qu'il est possible
                    qu'il y ait des tempêtes en mer, mais elles ne sont pas nécessaires dans toutes les situations
                    possibles.</li>
                <li><b>Impossible</b> : "¬◇(Toutes les mers sont douces)" signifie qu'il est impossible que toutes les
                    mers soient douces.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">28
                <a class="prev" href="#slide27"></a>
                <a class="next" href="#slide29"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide29">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Raisonnement automatisé</h1>
            <p>Le raisonnement automatisé est un domaine de l'intelligence artificielle (IA) qui concerne la création de
                systèmes informatiques capables de tirer des conclusions logiques et de résoudre des problèmes de
                manière autonome, similaire à la manière dont les humains utilisent leur raisonnement pour résoudre des
                problèmes.</p>
            <ul>
                <li><b>Objectif</b> : L'objectif principal du raisonnement automatisé est de permettre aux machines de
                    prendre des décisions, de résoudre des problèmes et de répondre à des questions en utilisant des
                    règles logiques et des connaissances préalables. </li>
                <li><b>Inférence logique</b> : Les moteurs d'inférence sont des composants logiciels qui appliquent des
                    règles logiques et des axiomes pour déduire de nouvelles informations à partir des connaissances
                    existantes. Cela implique souvent l'utilisation de la logique formelle, telle que la logique
                    propositionnelle, la logique du premier ordre ou la logique modale.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">29
                <a class="prev" href="#slide28"></a>
                <a class="next" href="#slide30"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide30">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Raisonnement automatisé</h1>
            <p>Le raisonnement automatisé peut être expliqué en utilisant différentes logiques, notamment la logique
                propositionnelle, la logique du premier ordre et la logique modale. </p>
            <ul>
                <li><b>Raisonnement automatisé en logique propositionnelle</b> : Les connaissances sont représentées
                    sous forme de propositions atomiques et de règles logiques qui décrivent comment ces propositions
                    sont liées. Les moteurs d'inférence en logique propositionnelle appliquent des règles logiques pour
                    tirer des conclusions à partir des propositions existantes.</li>
                <li><b>Raisonnement automatisé en logique du premier ordre logique</b> : Les connaissances sont
                    représentées de manière plus expressive, ce qui permet de modéliser des relations complexes entre
                    objets et d'exprimer des généralisations.
                    Les moteurs d'inférence en logique du premier ordre utilisent des règles de déduction plus
                    sophistiquées, notamment l'utilisation de quantificateurs tels que "∀" (pour tout) et "∃" (il
                    existe).</li>
                <li><b>Raisonnement automatisé en logique modale :</b> : Les connaissances sont représentées avec des
                    opérateurs modaux pour exprimer des propriétés modales, ce qui permet de traiter l'incertitude et la
                    nécessité.
                    Les moteurs d'inférence en logique modale utilisent des règles modales spécifiques pour tirer des
                    conclusions en tenant compte des modalités.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">30
                <a class="prev" href="#slide29"></a>
                <a class="next" href="#slide31"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide31">
        <div class="header">
            <h1>1.2.2. Représentation des connaissances</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Introduction</h1>
            <p>La représentation des connaissances joue un rôle central dans la manière dont les systèmes informatiques
                comprennent, raisonnent et interagissent avec le monde.
                La représentation des connaissances désigne le processus de capture, de structuration et de stockage des
                informations et des connaissances de manière à les rendre utilisables par des systèmes informatiques.
                Cela implique de transformer des données brutes ou des concepts en une forme que les ordinateurs peuvent
                comprendre et exploiter pour résoudre des problèmes, prendre des décisions ou interagir avec les
                utilisateurs.</p>
            <ul>
                <li><b>Résolution de Problèmes</b> : Une représentation adéquate des connaissances permet aux systèmes
                    informatiques de modéliser des problèmes complexes et de les résoudre de manière efficace. Elle
                    facilite la manipulation et la déduction logique des informations pertinentes.</li>
                <li><b>Prise de Décisions</b> Les machines doivent comprendre le monde qui les entoure pour interagir
                    avec lui de manière significative. Une représentation des connaissances permet de modéliser des
                    concepts tels que les objets, les relations, les événements et les règles.</li>
                <li><b>Communication Homme-Machine</b> Lorsque des systèmes IA interagissent avec des utilisateurs
                    humains, une représentation des connaissances claire et conviviale est essentielle pour rendre ces
                    interactions compréhensibles et productives.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">31
                <a class="prev" href="#slide30"></a>
                <a class="next" href="#slide32"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide32">
        <div class="header">
            <h1>1.2.2. Représentation des connaissances</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Types de connaissances</h1>
            <p>Les types de connaissances peuvent être classés en plusieurs catégories, notamment les connaissances
                déclaratives, les connaissances procédurales, les connaissances explicites et les connaissances tacites.
            </p>
            <ul>
                <li><b>Connaissances déclaratives</b> : Les connaissances déclaratives se rapportent à "ce que nous
                    savons". Elles sont constituées de faits, d'informations et de déclarations qui décrivent le monde
                    ou une partie de celui-ci. Ces connaissances sont souvent exprimées sous forme de propositions ou de
                    déclarations qui peuvent être vraies ou fausses.</li>
                <li><b>Connaissances procédurales</b> Les connaissances procédurales concernent "comment faire quelque
                    chose". Elles sont liées aux compétences, aux savoir-faire et aux procédures nécessaires pour
                    accomplir des tâches ou des activités spécifiques. Ces connaissances sont généralement implicites et
                    liées à l'expérience pratique.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">32
                <a class="prev" href="#slide31"></a>
                <a class="next" href="#slide33"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide33">
        <div class="header">
            <h1>1.2.2. Représentation des connaissances</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Types de connaissances</h1>
            <ul>
                <li><b>Connaissances explicites</b> Les connaissances explicites sont des connaissances qui sont
                    clairement exprimées et documentées. Elles sont généralement formelles et structurées de manière à
                    être transmises et partagées facilement.
                    Ces connaissances sont souvent consignées dans des manuels, des livres, des bases de données, ou
                    d'autres formes de documentation.</li>
                <li><b>Connaissances tacites</b> Les connaissances tacites sont des connaissances qui sont difficiles à
                    exprimer verbalement ou à documenter de manière formelle. Elles résident souvent dans l'expérience
                    personnelle, l'intuition, ou les compétences pratiques. Ces connaissances sont souvent difficiles à
                    transférer d'une personne à une autre et sont souvent acquises par l'expérience.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">33
                <a class="prev" href="#slide32"></a>
                <a class="next" href="#slide34"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide34">
        <div class="header">
            <h1>1.2.2. Représentation des connaissances</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Représentation des connaissances déclaratives</h1>
            <p>Dans la représentation des connaissances déclaratives, les faits, les informations et les connaissances
                sont exprimés sous forme de propositions logiques.</p>
            <ul>
                <li>Logique propositionnelle</li>
                <li>Logique du premier ordre</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">34
                <a class="prev" href="#slide33"></a>
                <a class="next" href="#slide35"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide35">
        <div class="header">
            <h1>1.2.2. Représentation des connaissances</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Représentation des connaissances déclaratives</h1>
            <p>Graphes de Connaissances (Ontologies): Les ontologies sont des structures de données hiérarchiques qui
                organisent et hiérarchisent les connaissances en utilisant des concepts, des classes, des propriétés et
                des relations.</p>
            <ul>
                <li> <b>Concepts</b> : Les ontologies définissent des concepts qui représentent des entités ou des idées
                    du monde réel.</li>
                <li> <b>Classes</b> : Les concepts sont souvent organisés en classes.</li>
                <li> <b>Propriétés</b> : Les ontologies spécifient des propriétés et des relations entre les concepts.
                </li>
                <li> <b>Relations</b> : Les ontologies capturent les relations entre les concepts.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">35
                <a class="prev" href="#slide34"></a>
                <a class="next" href="#slide36"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide36">
        <div class="header">
            <h1>1.2.3. Agents intelligents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Introduction</h1>
            <p>Les agents intelligents sont des entités logicielles ou matérielles capables de percevoir leur
                environnement, de prendre des décisions, et d'agir pour atteindre des objectifs spécifiques.
                Un agent intelligent est un système informatique ou une entité physique qui possède certaines
                caractéristiques clés : </p>
            <ul>
                <li> <b>Perception</b> : Un agent intelligent est capable de percevoir son environnement à travers des
                    capteurs ou d'autres moyens. Il collecte des informations sur l'état du monde qui l'entoure.</li>
                <li> <b>Raisonnement</b> : L'agent intelligent peut traiter les informations perçues, effectuer des
                    calculs, et prendre des décisions basées sur ces données. Il peut utiliser des algorithmes, des
                    méthodes d'apprentissage automatique, ou des règles de raisonnement formelles pour cela.</li>
                <li> <b>Action</b> : En réponse à ses décisions, l'agent intelligent peut agir sur son environnement en
                    utilisant des actionneurs ou en émettant des commandes. Ses actions ont pour objectif d'atteindre
                    des buts ou des objectifs spécifiques.</li>
                <li> <b>Objectifs</b> : Les agents intelligents sont souvent dotés d'objectifs ou de buts à atteindre.
                    Ces objectifs définissent ce que l'agent tente d'accomplir dans son environnement.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">36
                <a class="prev" href="#slide35"></a>
                <a class="next" href="#slide37"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide37">
        <div class="header">
            <h1>1.2.3. Agents intelligents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Types d'agents intelligents</h1>
            <p>Les agents intelligents peuvent être classés en différents types en fonction de leurs caractéristiques et
                de leurs capacités. </p>
            <ul>
                <li> <b>Agents réactifs simples</b> : Les agents réactifs simples sont des agents intelligents qui
                    réagissent
                    directement aux stimuli de leur environnement sans avoir une représentation interne complexe du
                    monde.
                    <ul>
                        <li>Ils prennent des décisions en se basant sur des règles préétablies qui associent des entrées
                            (perceptions) à des sorties (actions).</li>
                        <li>Ces agents sont souvent utilisés pour des tâches spécifiques
                            où la réactivité immédiate est cruciale, comme dans la robotique industrielle. </li>
                        <li>Cependant, ils ont
                            tendance à manquer de capacité à anticiper ou à planifier des actions à long terme en
                            l'absence de
                            modèles internes complexes du monde.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">37
                <a class="prev" href="#slide36"></a>
                <a class="next" href="#slide38"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide38">
        <div class="header">
            <h1>1.2.3. Agents intelligents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Types d'agents intelligents</h1>
            <ul>
                <li> <b>Agents basés sur des modèles</b> : Les agents basés sur des modèles utilisent une représentation
                    interne du monde, généralement sous forme de modèles ou de cartes conceptuelles, pour comprendre
                    leur environnement.
                    <ul>
                        <li>Ils utilisent ces modèles pour anticiper les conséquences de leurs actions,
                            planifier des séquences d'actions et prendre des décisions éclairées.</li>
                        <li>Ces agents sont couramment
                            utilisés dans des domaines tels que la planification automatisée, la simulation, et la
                            modélisation de systèmes complexes.</li>
                        <li>Ils sont plus flexibles que les agents réactifs simples, mais leur
                            performance dépend de la qualité de leurs modèles et de la capacité à anticiper les
                            résultats.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">38
                <a class="prev" href="#slide37"></a>
                <a class="next" href="#slide39"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide39">
        <div class="header">
            <h1>1.2.3. Agents intelligents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Types d'agents intelligents</h1>
            <ul>
                <li> <b>Agents basés sur les buts</b> : Les agents basés sur les buts ont des objectifs ou des buts à
                    atteindre, et leur comportement est guidé par la poursuite de ces buts.
                    <ul>
                        <li>Ils évaluent régulièrement
                            l'état de l'environnement et déterminent les actions à entreprendre pour se rapprocher de
                            leurs objectifs.</li>
                        <li>Ces agents peuvent planifier et ajuster leurs actions en fonction de l'évolution de la
                            situation pour maximiser leurs chances de succès. Ils sont couramment utilisés dans des
                            domaines tels que la planification de parcours, les systèmes de recommandation, et les
                            agents
                            d'assistance personnelle.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">39
                <a class="prev" href="#slide38"></a>
                <a class="next" href="#slide40"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide40">
        <div class="header">
            <h1>1.2.3. Agents intelligents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Types d'agents intelligents</h1>
            <ul>
                <li> <b>Agents hybrides</b> : Certains agents intelligents combinent des caractéristiques de plusieurs
                    types
                    d'agents pour tirer parti des avantages de chacun.
                    <ul>
                        <li>Par exemple, un agent hybride pourrait être
                            réactif dans des situations immédiates, mais basé sur des modèles ou basé sur des buts pour
                            des
                            tâches plus complexes ou à long terme.</li>
                        <li>L'hybridation permet de créer des agents plus polyvalents
                            capables de s'adapter à une variété de scénarios.</li>
                        <ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">40
                <a class="prev" href="#slide39"></a>
                <a class="next" href="#slide41"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide41">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">3 approches</h1>
            <ol>
                <li><b>Apprentissage supervisé</b>:
                    <ul>
                        <li>Un modèle est formé à partir d'un ensemble de données de formation qui sont étiquetées,
                            c'est-à-dire que chaque exemple de données est associé à une étiquette ou une catégorie
                            connue.</li>
                        <li>L'objectif du modèle est d'apprendre à faire des prédictions en utilisant ces étiquettes de
                            manière à pouvoir généraliser et faire des prédictions précises sur de nouvelles données non
                            vues.</li>
                        <li>Par exemple, la classification d'images, la prédiction de prix, et la détection de spam dans
                            les emails.</li>
                    </ul>
                </li>
                <li><b>Apprentissage non supervisé</b>:
                    <ul>
                        <li>Il n'y a pas de données de formation labellisées.</li>
                        <li>Le modèle doit découvrir des structures, des modèles ou des regroupements dans les données
                            par lui-même.</li>
                        <li>Par exemple, la segmentation de clients en groupes, la réduction de la dimensionnalité, ou
                            la détection d'anomalies.</li>
                    </ul>
                </li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">41
                <a class="prev" href="#slide40"></a>
                <a class="next" href="#slide42"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide42">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">3 approches</h1>
            <ol start="3">
                <li><b>Apprentissage semi-supervisé</b>:
                    <ul>
                        <li>Il repose sur un petit ensemble de données de formation étiquetées et une grande quantité de
                            données non étiquetées.</li>
                        <li>Le modèle utilise les données étiquetées pour apprendre à faire des prédictions, mais il
                            peut également tirer parti des données non étiquetées pour améliorer sa performance.</li>
                        <li>Cela peut être particulièrement utile lorsque l'obtention de données étiquetées est coûteuse
                            ou difficile.</li>
                    </ul>
                </li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">42
                <a class="prev" href="#slide41"></a>
                <a class="next" href="#slide43"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide43">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Apprentissage profond</h1>
            <p>Dans l'apprentissage profond, le terme <b>profond</b> fait référence à la présence de multiples couches
                dans le réseau neuronal. Contrairement aux modèles plus simples, tels que les perceptrons monocouche,
                les réseaux profonds ont la capacité d'apprendre des représentations hiérarchiques complexes à partir de
                données brutes.</p>
            <ul>
                <li><b>Perceptron linéaire et XOR</b> : Un perceptron linéaire simple ne peut pas être un classificateur
                    universel. Il est incapable de résoudre des problèmes non linéaires complexes, comme le problème
                    XOR. Cependant, en ajoutant des couches et des non-linéarités (fonctions d'activation) aux
                    perceptrons, on peut construire des réseaux neuronaux capables de résoudre des problèmes plus
                    complexes.</li>
                <li><b>Extraction progressive de caractéristiques</b> : Une caractéristique clé de l'apprentissage
                    profond est la capacité à extraire progressivement des caractéristiques complexes à partir de
                    données brutes. Chaque couche du réseau peut apprendre des représentations de plus en plus
                    abstraites, permettant au modèle de comprendre des niveaux de complexité croissants dans les
                    données. </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">43
                <a class="prev" href="#slide42"></a>
                <a class="next" href="#slide44"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide44">
        <div class="header">
            <h1>2.1. Introduction à l'apprentissage machine</h1>
        </div>
        <div class="content">
            <p><b>L'apprentissage machine</b>, également connu sous le nom de machine learning (ML), est un domaine de
                l'intelligence artificielle (IA) qui se concentre sur le développement de techniques permettant aux
                ordinateurs d'apprendre à partir de données. L'objectif principal de l'apprentissage machine est de
                permettre aux systèmes informatiques de prendre des décisions ou de réaliser des tâches sans être
                explicitement programmés, en s'appuyant sur des <b>modèles</b> et des <b>motifs appris à partir des
                    données</b>.</p>
            <h4>Principes fondamentaux de l'apprentissage machine</h4>
            <ul>
                <li><b>Données d'entraînement</b> : L'apprentissage machine commence par des données. Ces données,
                    appelées données d'entraînement, sont utilisées pour enseigner au modèle les modèles et les
                    relations dans lesquels il doit identifier.</li>
                <li><b>Modèles</b> : Les modèles en apprentissage machine sont des représentations mathématiques qui
                    capturent les relations entre les différentes caractéristiques des données. Ces modèles sont
                    entraînés à partir des données d'entraînement et sont capables de généraliser pour faire des
                    prédictions sur de nouvelles données non vues.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">44
                <a class="prev" href="#slide43"></a>
                <a class="next" href="#slide45"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide45">
        <div class="header">
            <h1>2.1. Introduction à l'apprentissage machine </h1>
        </div>
        <div class="content">
            <h4>Principes fondamentaux de l'apprentissage machine</h4>
            <ul>
                <li><b>Entraînement et apprentissage</b> : L'entraînement d'un modèle implique de l'exposer aux données
                    d'entraînement, lui permettant d'ajuster ses paramètres pour minimiser les erreurs de prédiction.
                    L'apprentissage se produit lorsque le modèle améliore sa capacité à faire des prédictions précises.
                </li>
                <li><b>Validation et test</b> : Après l'entraînement, le modèle est évalué sur des données de validation
                    et de test pour s'assurer qu'il généralise bien aux données non vues. Cela aide à éviter le
                    surajustement, où le modèle apprend trop spécifiquement les données d'entraînement et ne peut pas
                    généraliser correctement.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">45
                <a class="prev" href="#slide44"></a>
                <a class="next" href="#slide46"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide46">
        <div class="header">
            <h1>2.1.1. Positionnement de l'apprentissage machine</h1>
        </div>
        <div class="content">
            <p>L'apprentissage machine occupe une place centrale dans le paysage technologique actuel et a un impact
                significatif dans divers domaines. </p>
            <ul>
                <li><b>Intelligence Artificielle (IA)</b> : L'apprentissage machine est une composante essentielle de
                    l'intelligence artificielle. Il permet aux systèmes informatiques de tirer des conclusions,
                    d'apprendre à partir d'expériences passées et d'améliorer leur performance sans être explicitement
                    programmés.</li>
                <li><b>Informatique et Technologie</b> : L'apprentissage machine est largement utilisé dans les
                    applications technologiques, y compris la vision par ordinateur, la reconnaissance vocale, la
                    traduction automatique, les chatbots, et diverses autres applications qui exploitent la capacité des
                    modèles à apprendre des données.</li>
                <li><b>Santé</b> : Dans le domaine de la santé, l'apprentissage machine est utilisé pour la prédiction
                    de maladies, l'analyse d'images médicales, la personnalisation des traitements, la découverte de
                    médicaments, et la gestion des dossiers médicaux électroniques.</li>
                <li><b>Finance</b> : Les institutions financières utilisent l'apprentissage machine pour la détection de
                    fraudes, la prévision de tendances du marché, l'analyse de crédit, et l'optimisation des
                    portefeuilles d'investissement.</li>
                <li><b>Industrie</b> : Dans le secteur industriel, l'apprentissage machine est appliqué à la maintenance
                    prédictive, à l'optimisation de la chaîne d'approvisionnement, à la qualité de production, et à la
                    robotique.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">46
                <a class="prev" href="#slide45"></a>
                <a class="next" href="#slide47"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide47">
        <div class="header">
            <h1>2.1.2. Approches de l'apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Approches</h3>
            <ul>
                <li><b>Apprentissage supervisé</b> : Le modèle est entraîné sur un ensemble de données étiquetées où les
                    exemples d'entrée sont associés à des sorties désirées. Le modèle apprend à faire des prédictions
                    sur de nouvelles données en se basant sur ces associations.</li>
                <li><b>Apprentissage non supervisé</b> : Le modèle est exposé à des données non étiquetées et cherche à
                    découvrir des modèles, des structures ou des relations intrinsèques dans les données.</li>
                <li><b>Apprentissage semi-supervisé</b> : Une combinaison des deux précédents, utilisant à la fois des
                    données étiquetées et non étiquetées pour l'entraînement.</li>
                <li><b>Apprentissage par renforcement</b> : Le modèle apprend à prendre des décisions en interagissant
                    avec son environnement. Il reçoit des récompenses ou des pénalités en fonction de ses actions, ce
                    qui guide son apprentissage.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">47
                <a class="prev" href="#slide46"></a>
                <a class="next" href="#slide48"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide48">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation</h3>
            <ul>
                <li><b>Vecteur euclidien</b>:
                    <ul>
                        <li>Un vecteur euclidien est un objet géométrique caractérisé par sa magnitude (longueur) et sa
                            direction. </li>
                        <li>Les vecteurs euclidiens sont couramment utilisés pour représenter des données sous forme de
                            points dans un espace multidimensionnel, où chaque dimension correspond à une
                            caractéristique ou une variable.</li>
                    </ul>
                </li>
                <li><b>Espace vectoriel</b>:
                    <ul>
                        <li>Un espace vectoriel est une collection de vecteurs qui peuvent être additionnés entre eux et
                            multipliés par des nombres (scalaires).</li>
                    </ul>
                </li>
                <li><b>Vecteur de caractéristiques (features)</b>:
                    <ul>
                        <li>Un vecteur de caractéristiques est un vecteur n-dimensionnel qui représente les
                            caractéristiques ou les attributs d'une entité. </li>
                    </ul>
                </li>
                <li><b>Espace de caractéristiques</b>:
                    <ul>
                        <li>L'espace de caractéristiques est l'espace vectoriel associé aux vecteurs de
                            caractéristiques.</li>
                        <li>Chaque dimension de cet espace représente une caractéristique particulière, et les vecteurs
                            sont utilisés pour positionner les données dans cet espace en fonction de leurs
                            caractéristiques.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">48
                <a class="prev" href="#slide47"></a>
                <a class="next" href="#slide49"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide49">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Exemples de caractéristiques</h3>
            <ul>
                <li><b>Images</b>: Dans le contexte des images, les vecteurs de caractéristiques peuvent être construits
                    à partir des valeurs des pixels. Chaque pixel peut être considéré comme une dimension, et un vecteur
                    de caractéristiques contiendra les valeurs de tous les pixels, permettant ainsi de représenter une
                    image sous forme de vecteur.</li>
                <li><b>Textes</b>: Pour les textes, les vecteurs de caractéristiques sont souvent construits à partir de
                    la fréquence d'apparition des mots, des phrases, ou des tokens dans un document. Cela permet de
                    représenter le contenu textuel en utilisant des valeurs numériques, ce qui est essentiel pour
                    l'analyse de texte et la recherche d'informations.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">49
                <a class="prev" href="#slide48"></a>
                <a class="next" href="#slide50"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide50">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation</h1>
            <ul>
                <li><b>Construction de caractéristiques<sup>1</sup></b>:
                    <ul>
                        <li>La construction de caractéristiques consiste à créer de nouvelles variables ou attributs à
                            partir de celles déjà présentes dans les données.</li>
                        <li>Cette étape peut être cruciale pour améliorer les performances des modèles d'apprentissage
                            machine en introduisant des informations pertinentes et en éliminant du bruit.</li>
                    </ul>
                </li>
                <li><b>Opérateurs de construction pour les caractéristiques</b>
                    <ul>
                        <li>Les opérateurs de construction sont des fonctions ou des opérations mathématiques qui
                            permettent de créer de nouvelles caractéristiques à partir de celles existantes. </li>
                        <li>Parmi les opérateurs couramment utilisés, on trouve les opérateurs d'égalité (comparaisons),
                            les opérateurs arithmétiques (addition, soustraction, multiplication, division), les
                            opérateurs de tableau (min, max, moyenne, médiane, etc.), les fonctions de transformation,
                            etc.</li>
                    </ul>
                </li>
            </ul>
            <ol style="font-size:2vh">
                <li>https://en.wikipedia.org/wiki/Feature_vector</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">50
                <a class="prev" href="#slide49"></a>
                <a class="next" href="#slide51"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide51">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Exemple</h3>
            <ul>
                <li>Soit <b>Année de naissance</b> et <b>Année de décès</b> deux caractéristiques existantes.</li>
                <li>Une nouvelle caractéristique appelée <b>âge</b> est créée. <b>âge</b> = <b>Année de décès</b> -
                    <b>Année de naissance</b>
                </li>
            </ul>
            <p>La construction de caractéristiques est une étape essentielle dans le pipeline de prétraitement des
                données en apprentissage machine, car elle peut aider à rendre les données plus informatives pour les
                algorithmes d'apprentissage.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">51
                <a class="prev" href="#slide50"></a>
                <a class="next" href="#slide52"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide52">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <ul>
                    <li><b>Le nombre d'exemples d'entraînement (N)</b> : Cela représente la quantité d'exemples de
                        données que vous avez pour entraîner un modèle supervisé. Chaque exemple d'entraînement se
                        compose d'un vecteur de caractéristiques (x) et de son label (y).</li>
                    <li><b>L'espace de saisie des caractéristiques (X)</b> : C'est l'ensemble de toutes les combinaisons
                        possibles de vecteurs de caractéristiques qui peuvent être utilisées comme entrée pour le
                        modèle. Cet espace est défini par les caractéristiques que vous avez extraites des données.</li>
                    <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble de toutes les
                        valeurs possibles que peuvent prendre les étiquettes ou les labels. </li>
                    <li><b>Exemples d'entraînement (D)</b> : C'est votre ensemble de données d'entraînement, composé de
                        paires (x, y) où x est le vecteur de caractéristiques et y est le label correspondant.</li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">52
                <a class="prev" href="#slide51"></a>
                <a class="next" href="#slide53"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide53">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <ul>
                    <li><b>Objectif de l'algorithme d'apprentissage supervisé</b> : Il s'agit de trouver une fonction
                        (g) qui associe un vecteur de caractéristiques (x) à un label (y). L'ensemble des fonctions
                        possibles est appelé espace des hypothèses (G). L'objectif est de choisir la fonction (g) qui
                        minimise l'erreur de prédiction sur les exemples d'entraînement et généralise bien sur de
                        nouvelles données.</li>
                    <li><b>Fonction d'évaluation (F)</b> : Elle indique l'espace des fonctions d'évaluation utilisées
                        pour évaluer la performance des fonctions hypothétiques. L'objectif est de trouver la fonction
                        (g) qui renvoie la fonction d'évaluation (f) la plus élevée, c'est-à-dire celle qui donne les
                        prédictions les plus précises.</li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">53
                <a class="prev" href="#slide52"></a>
                <a class="next" href="#slide54"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide54">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <p>Cette formalisation est au cœur de l'apprentissage supervisé, où l'objectif est d'apprendre à partir
                    d'exemples étiquetés et de trouver une fonction qui puisse prédire de manière précise les étiquettes
                    pour de nouvelles données non vues.</p>
                <ul>
                    <li>Soit \(N\) le nombre d'exemples d'entraînement</li>
                    <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                    <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                    <li>Soit \({(x_1, y_1),...,(x_N, y_N)}\) les \(N\) exemples d'entraînement, où
                        <ul>
                            <li>\(x_i\) est le vecteur de caractéristiques de <i>i<sup>ème</sup></i> exemple
                                d'entraînement.
                            </li>
                            <li>\(y_i\) est son label.</li>
                        </ul>
                    </li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">54
                <a class="prev" href="#slide53"></a>
                <a class="next" href="#slide55"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide55">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <ul>
                    <li>L'objectif de l'algorithme d'apprentissage supervisé est de trouver \(g: X &#8594; Y\), où
                        <ul>
                            <li><i>g</i> est l'une des fonctions de l'ensemble des fonctions possibles <i>G</i> (espace
                                des
                                hypothèses)</li>
                        </ul>
                    </li>
                    <li><b>Fonction d'évaluation <i>F</i></b> indiquent l'espace des fonctions d'évaluation, où
                        <ul>
                            <li>\(f: X &#215; Y &#8594; R\) telle que <i>g</i> renvoie la fonction d'évaluation la plus
                                élevée.</li>
                        </ul>
                    </li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">55
                <a class="prev" href="#slide54"></a>
                <a class="next" href="#slide56"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide56">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage non supervisé</h1>
            <ul>
                <li><b>L'espace de saisie des caractéristiques (X)</b> : C'est l'ensemble de toutes les combinaisons
                    possibles de vecteurs de caractéristiques qui peuvent être utilisées comme entrée pour le modèle en
                    apprentissage non supervisé. Cet espace est défini par les caractéristiques que vous avez extraites
                    des données.</li>
                <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble des caractéristiques
                    de sortie potentielles. Contrairement à l'apprentissage supervisé, en apprentissage non supervisé, Y
                    ne consiste pas en des étiquettes ou des labels prédéfinis, mais plutôt en des transformations, des
                    représentations, ou des caractéristiques extraites des données d'entrée.</li>
                <li><b>Objectif de l'algorithme d'apprentissage non supervisé</b> : L'objectif est de trouver une
                    correspondance entre l'espace de saisie des caractéristiques (X) et l'espace des caractéristiques de
                    sortie (Y). Cela peut impliquer diverses tâches, telles que la réduction de la dimensionnalité, la
                    classification automatique de données non étiquetées, la détection d'anomalies, la segmentation, ou
                    la représentation latente des données.</li>
                <li><b>Mise en correspondance X → Y</b> : Cette mise en correspondance peut être réalisée de différentes
                    manières, selon la tâche d'apprentissage non supervisé spécifique. Par exemple, dans la réduction de
                    la dimensionnalité, X peut être une représentation à haute dimension des données, tandis que Y
                    représente la version réduite de ces données, souvent avec moins de dimensions.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">56
                <a class="prev" href="#slide55"></a>
                <a class="next" href="#slide57"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide57">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage non supervisé</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>L'objectif de l'algorithme d'apprentissage non supervisé est
                    <ul>
                        <li>trouver la mise en correspondance \(X &#8594; Y\)</li>
                    </ul>
                </li>
            </ul>
            <p>L'apprentissage non supervisé est utilisé pour explorer et découvrir des modèles, des structures ou des
                caractéristiques inhérentes aux données, sans l'utilisation d'étiquettes ou de labels préalables. Il est
                couramment utilisé dans des domaines tels que la clustering, l'analyse de composantes principales (PCA),
                l'analyse en composantes indépendantes (ICA), et bien d'autres.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">57
                <a class="prev" href="#slide56"></a>
                <a class="next" href="#slide58"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide58">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li><b>L'espace de saisie des caractéristiques (X)</b> : Il s'agit de l'ensemble de toutes les
                    combinaisons possibles de vecteurs de caractéristiques qui peuvent être utilisés comme entrée pour
                    le modèle en apprentissage semi-supervisé.</li>
                <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble des caractéristiques
                    de sortie potentielles, mais contrairement à l'apprentissage supervisé, il n'est pas nécessairement
                    constitué d'étiquettes ou de labels prédéfinis.</li>
                <li><b>Ensemble d'exemples d'exercices étiquetés (l)</b> : Cela correspond à un sous-ensemble d'exemples
                    qui ont été annotés ou étiquetés avec des valeurs de sortie connues.</li>
                <li><b>Ensembles des vecteurs de caractéristiques non étiquetées (u)</b> : Il s'agit des exemples non
                    étiquetés, où les valeurs de sortie ne sont pas connues.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">58
                <a class="prev" href="#slide57"></a>
                <a class="next" href="#slide59"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide59">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li><b>Objectif de l'algorithme d'apprentissage semi-supervisé</b> : L'objectif principal est de trouver
                    des étiquettes correctes pour les exemples non étiquetés (apprentissage transductif), ainsi que de
                    trouver la bonne mise en correspondance entre les caractéristiques d'entrée et les caractéristiques
                    de sortie (apprentissage inductif).
                    <ul>
                        <li><b>Apprentissage transductif</b> : Il s'agit de trouver des étiquettes correctes pour les
                            exemples non étiquetés. Cela revient à prédire les valeurs de sortie pour les exemples non
                            étiquetés sans nécessairement chercher à généraliser à de nouvelles données.</li>
                        <li><b>Apprentissage inductif</b> : Cela concerne la recherche de la bonne mise en
                            correspondance entre les vecteurs de caractéristiques d'entrée et les caractéristiques de
                            sortie. Cela peut inclure la généralisation à de nouvelles données en utilisant le modèle
                            appris.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">59
                <a class="prev" href="#slide58"></a>
                <a class="next" href="#slide60"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide60">
        <div class="header">
            <h1>2.1.3. Formalisation des problèmes d'apprentissage</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>Soit \({(x_1, y_1),...,(x_l, y_l)}\) l'ensemble d'exemples d'exercices étiquetés</li>
                <li>Soit \({x_{l+1},...,x_{l+u}}\) sont les \(u\) ensembles des vecteurs de caractéristiques non
                    étiquetées de \(X\).</li>
                <li>L'objectif de l'algorithme d'apprentissage semi-supervisé est de faire
                    <ul>
                        <li><b>l'apprentissage transductif</b>, c'est-à-dire trouver des étiquettes correctes pour
                            \({x_{l+1},...,x_{l+u}}\).</li>
                        <li><b>l'apprentissage inductif</b>, c'est-à-dire trouver la bonne mise en correspondance \(X
                            &#8594; Y\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">60
                <a class="prev" href="#slide59"></a>
                <a class="next" href="#slide61"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide61">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Classification: Définition formelle</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>L'objectif de l'algorithme de classification (ou classificateur) est de trouver \({(x_1,
                    y_1),...,(x_l, y_k)}\), c'est-à-dire l'attribution d'une étiquette connue à chaque vecteur de
                    caractéristique d'entrée, où
                    <ul>
                        <li>\(x_i &#8712; X \)</li>
                        <li>\(y_i &#8712; Y \)</li>
                        <li>\(|X| = l \)</li>
                        <li>\(|Y| = k \)</li>
                        <li>\(l &gt;= k\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">61
                <a class="prev" href="#slide60"></a>
                <a class="next" href="#slide62"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide62">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classificateurs</h3>
            <ul>
                <li>Algorithme de classification</li>
                <li>Deux types de classificateurs:
                    <ul>
                        <li><b>Classificateurs binaires</b> attribue un objet à l'une des deux classes</li>
                        <li><b>Classificateurs multiclasses</b> attribue un objet à une ou plusieurs classes</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">62
                <a class="prev" href="#slide61"></a>
                <a class="next" href="#slide63"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide63">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Classification binaire</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/binaryclassifier.svg"
                    height="400px" />
                <figcaption>Classification binaire</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">63
                <a class="prev" href="#slide62"></a>
                <a class="next" href="#slide64"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide64">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Linear Classificateurs</h3>
            <ul>
                <li>Fonction linéaire attribuant un score à chaque catégorie possible en combinant le vecteur de
                    caractéristiques d'une instance avec un vecteur de poids, en utilisant un produit de points.</li>
                <li>Formalisation :
                    <ul>
                        <li>Soit <i><b>X</b></i> être l'espace de saisie des caractéristiques et <i><b>x</b><sub>i</sub>
                                &#8712; <b>X</b></i></li>
                        <li>Soit <i><b>&#946;</b><sub>k</sub></i> un vecteur de poids pour la catégorie <i>k</i></li>
                        <li><i>score(<b>x</b><sub>i</sub>, k) = <b>x</b><sub>i</sub>.<b>&#946;</b><sub>k</sub></i>,
                            score pour l'attribution de la catégorie <i>k</i> à l'instance <i><b>x</b><sub>i</sub></i>.
                            La catégorie qui donne le score le plus élevé est
                            attribuée à la catégorie de l'instance.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">64
                <a class="prev" href="#slide63"></a>
                <a class="next" href="#slide65"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide65">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>Dans le contexte de la classification en apprentissage machine, l'évaluation des performances d'un modèle
                implique la compréhension de différents types de prédictions qu'il peut faire par rapport à la réalité.
                Les vrais positifs (VP) et les vrais négatifs (VN) sont deux de ces éléments.</p>
            <ul>
                <li><b>Vrais Positifs (VP/TP)</b> : Les vrais positifs représentent les cas où le modèle prédit
                    correctement la classe positive. En d'autres termes, il a correctement identifié les exemples qui
                    appartiennent réellement à la classe que le modèle essaie de prédire.</li>
                <li><b>Vrais Négatifs (VN/FN)</b> : Les vrais négatifs représentent les cas où le modèle prédit
                    correctement la classe négative. Cela signifie qu'il a correctement identifié les exemples qui
                    n'appartiennent pas à la classe que le modèle essaie de prédire.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">65
                <a class="prev" href="#slide64"></a>
                <a class="next" href="#slide66"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide66">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/positivenegative.svg" width="400vw" />
                <figcaption>Les vrais positifs et les vrais négatifs</figcaption>
            </figure>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" width="400vw" />
                <figcaption>Précision et rappel</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">66
                <a class="prev" href="#slide65"></a>
                <a class="next" href="#slide67"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide67">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>Soit</p>
            <ul>
                <li><i>tp</i>: nombre de vrais postifs</li>
                <li><i>fp</i>: nombre de faux positifs</li>
                <li><i>fn</i>: nombre de faux négatifs</li>
            </ul>
            <figure class="gridcontent">
                <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" height="400px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">67
                <a class="prev" href="#slide66"></a>
                <a class="next" href="#slide68"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide68">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>La <b>précision</b> mesure la proportion de prédictions positives faites par le modèle qui étaient
                <b>effectivement correctes</b>, tandis que le <b>rappel</b> mesure la proportion d'exemples positifs
                réels qui ont été correctement identifiés par le modèle. Alors</p>
            <ul>
                <li>Précision \[p = \frac{tp}{(tp + fp)}\]</li>
                <li>Rappel (Recall) \[r = \frac{tp}{(tp + fn)}\]</i>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">68
                <a class="prev" href="#slide67"></a>
                <a class="next" href="#slide69"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide69">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <p>Le F1-score est la moyenne harmonique de la précision et du rappel. Il fournit une mesure globale de la
                performance d'un modèle de classification, tenant compte à la fois de la précision et du rappel. Il est
                particulièrement utile lorsque les classes sont déséquilibrées.</p>
            <ul>
                <li>F1-score \[f1 = 2 * \frac{(p * r)}{(p + r)}\]</li>
                <li>F1-score: meilleure valeur à 1 (précision et rappel parfaits) et pire à 0.</li>
            </ul>
            <p>Le F1-score tient compte à la fois des <b>erreurs de type I (faux positifs)</b> et des <b>erreurs de type
                    II (faux négatifs)</b>, fournissant ainsi une mesure équilibrée de la performance du modèle.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">69
                <a class="prev" href="#slide68"></a>
                <a class="next" href="#slide70"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide70">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation</h3>
            <ul>
                <li>\(F_\beta\)-score utilise un facteur réel positif β, où β est choisi de telle sorte que le rappel
                    est considéré comme β fois plus important que la précision, est : </li>
                <li>\(F_\beta\)-score \[F_\beta = (1 + \beta^2) \cdot \frac{\mathrm{p} \cdot \mathrm{r}}{(\beta^2 \cdot
                    \mathrm{p}) + \mathrm{r}}\]</li>
                <li>Exemple: <b>\(F_2\) score</b>: Cette métrique est souvent utilisée dans des situations où le rappel
                    est jugé plus critique que la précision, par exemple, dans des tâches où la détection des exemples
                    positifs est particulièrement importante, même si cela entraîne un nombre plus élevé de faux
                    positifs.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">70
                <a class="prev" href="#slide69"></a>
                <a class="next" href="#slide71"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide71">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <p>Le \(F_2\)-score est souvent utilisé dans des domaines où le rappel est considéré comme plus critique que
                la précision. </p>
            <ul>
                <li><b>Détection de Maladies</b> : Dans le domaine médical, en particulier pour la détection de maladies
                    graves, le F2-score peut être utilisé pour évaluer la performance des modèles. Il est crucial
                    d'identifier correctement autant de cas positifs que possible, même si cela conduit à quelques faux
                    positifs.</li>
                <li><b>Sécurité et Détection d'Intrusion</b> : Lors de la détection d'intrusions dans les systèmes
                    informatiques, il est souvent plus important de minimiser les faux négatifs (intrusions manquées) au
                    profit de quelques faux positifs, d'où l'utilisation du F2-score.</li>
                <li><b>Recherche Biomédicale</b> : Dans des domaines de recherche biomédicale où la découverte de
                    certaines caractéristiques ou protéines spécifiques est critique, le F2-score peut être privilégié
                    pour s'assurer que ces éléments sont correctement identifiés.</li>
                <li><b>Prévision de Catastrophes Naturelles</b> : Lors de la prévision de catastrophes naturelles comme
                    les tremblements de terre ou les tsunamis, il est essentiel de minimiser les faux négatifs pour
                    garantir que le maximum d'avertissements est donné, même au prix de quelques alertes erronées.</li>
                <li><b>Recherche en Astronomie</b> : Dans la recherche astronomique, la découverte de nouveaux objets
                    célestes ou de phénomènes rares peut être cruciale. Le F2-score peut être utilisé pour évaluer les
                    performances des algorithmes de détection.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">71
                <a class="prev" href="#slide70"></a>
                <a class="next" href="#slide72"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide72">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Évaluation: matrice de confusion</h2>
            <p>La matrice de confusion est un outil essentiel dans l'évaluation des performances d'un système de
                classification. Elle fournit une vue détaillée des prédictions faites par le modèle par rapport aux
                classes réelles.</p>
            <ul>
                <li>Chaque ligne de la matrice représente les instances d'une classe prédite.</li>
                <li>Chaque colonne représente les instances d'une classe réelle.</li>
                <li>Toutes les prédictions correctes sont situées dans la diagonale du tableau.</li>
                <li>Les erreurs de prédiction sont représentées par des valeurs situées en dehors de la diagonale
                    principale.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">72
                <a class="prev" href="#slide71"></a>
                <a class="next" href="#slide73"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide73">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation: matrice de confusion</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix.png" height="400px" />
                <figcaption>Matrice de confusion pour un classificateur SVM pour les chiffres manuscrits (MNIST)
                </figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">73
                <a class="prev" href="#slide72"></a>
                <a class="next" href="#slide74"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide74">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Évaluation: matrice de confusion</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix1.png" height="400px" />
                <figcaption>Matrice de confusion pour un perceptron pour les chiffres manuscrits (MNIST)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">74
                <a class="prev" href="#slide73"></a>
                <a class="next" href="#slide75"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide75">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg"
                    height="400px" />
                <figcaption>Classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">75
                <a class="prev" href="#slide74"></a>
                <a class="next" href="#slide76"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide76">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse [Aly 2005]</h3>
            <ul>
                <li>Transformation en classification binaire
                    <ul>
                        <li>L'approche un contre le reste (Un contre tous)</li>
                        <li>L'approche un-contre-un</li>
                    </ul>
                </li>
                <li>Extension de la classification binaire
                    <ul>
                        <li>Réseaux de neurones</li>
                        <li>k-voisins les plus proches</li>
                    </ul>
                </li>
                <li>la classification hiérarchique.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">76
                <a class="prev" href="#slide75"></a>
                <a class="next" href="#slide77"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide77">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg"
                    height="400px" />
                <figcaption>Classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">77
                <a class="prev" href="#slide76"></a>
                <a class="next" href="#slide78"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide78">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest (One-vs.-all) strategy</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsall.svg" height="350px" />
                <figcaption>La strategie un-contre le rest pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">78
                <a class="prev" href="#slide77"></a>
                <a class="next" href="#slide79"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide79">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <ul>
                <li>Entraîner un seul classificateur par classe, avec les échantillons de cette classe comme
                    échantillons positifs et tous les autres comme négatifs. </li>
                <li>Chaque classificateur produit un score de confiance réel pour sa décision</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsall.svg" height="200px" />
                <figcaption>La strategie un-contre le rest pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">79
                <a class="prev" href="#slide78"></a>
                <a class="next" href="#slide80"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide80">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <ul>
                <li>Entrées :
                    <ul>
                        <li>\(L\), un apprenant (algorithme d'entraînement pour les classificateurs binaires)</li>
                        <li>échantillons \(X\)</li>
                        <li>étiquettes \(y\), où \(y_i ∈ \{1,..,K \} \) est l'étiquette de l'échantillon \(X_i\)
                    </ul>
                </li>
                <li>Sortie :
                    <ul>
                        <li>une liste de classificateurs \(f_k\), où \(k ∈ \{1,..,K \} \)
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">80
                <a class="prev" href="#slide79"></a>
                <a class="next" href="#slide81"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide81">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <p>Prendre des décisions signifie appliquer tous les classificateurs à un échantillon invisible x et prédire
                l'étiquette k pour laquelle le classificateur correspondant rapporte le score de confiance le plus élevé
                : \[\hat{y} = \underset{k \in
                \{1 \ldots K\}}{\arg\!\max}\; f_k(x)\]</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">81
                <a class="prev" href="#slide80"></a>
                <a class="next" href="#slide82"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide82">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-one strategy</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsone.svg" height="300px" />
                <figcaption>La strategie un-contre-un pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">82
                <a class="prev" href="#slide81"></a>
                <a class="next" href="#slide83"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide83">
        <div class="header">
            <h1>2.2. Méthodes de classification</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse</h3>
            <h3 class="topicsubheading">One-vs.-one strategy</h3>
            <li>nécessite l'entraînement des \(\frac{K (K - 1)}{2}\) classificateurs binaires</li>
            <li>chaque classificateur reçoit les échantillons d'une paire de classes du jeu de formation original, et
                doit apprendre à distinguer ces deux classes.</li>
            <li>Au moment de la prédiction, un système de vote est appliqué : tous les \(\frac{K (K - 1)}{2}\)
                classificateurs sont appliqués à un échantillon non vu et la classe qui a obtenu le plus grand nombre de
                prédictions est prédite par le classificateur
                combiné.
            </li>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsone.svg" width="200vw" />
                <figcaption>La strategie un-contre-un pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">83
                <a class="prev" href="#slide82"></a>
                <a class="next" href="#slide84"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide84">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Neurones biologiques</h2>
            <figure>
                <img src="../../2021/MachineLearning/Neuron3.png" height="350px" />
                <figcaption>Neurone biologique<sup>1</sup></figcaption>
            </figure>
            <ol style="font-size:2vh">
                <li>https://en.wikipedia.org/wiki/File:Neuron3.png</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">84
                <a class="prev" href="#slide83"></a>
                <a class="next" href="#slide85"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide85">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Introduction</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Colored_neural_network.svg" />
                <figcaption>Réseaux de neurones artificiels</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">85
                <a class="prev" href="#slide84"></a>
                <a class="next" href="#slide86"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide86">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseau de neurones</h2>
            <p>Les réseaux de neurones sont couramment utilisés dans le domaine de l'apprentissage machine, en
                particulier dans des tâches telles que la classification, la régression, la reconnaissance d'images, le
                traitement du langage naturel, et bien d'autres. Un réseau de neurones artificiels est une collection
                d'unités interconnectées appelées neurones artificiels. Ces réseaux sont inspirés de la structure du
                cerveau biologique</p>
            <ul>
                <li><b>Connexions</b> : Chaque connexion entre les neurones, similaire aux synapses dans le cerveau
                    biologique, peut transmettre un signal aux autres neurones.</li>
                <li><b>Transmission de signal</b> : Un neurone artificiel reçoit un signal, le traite à l'aide d'une
                    fonction non linéaire, et peut ensuite transmettre un signal aux neurones qui lui sont connectés.
                </li>
                <li><b>Fonction d'activation</b> : La sortie de chaque neurone est calculée par une fonction non
                    linéaire appliquée à la somme pondérée de ses entrées. Cette fonction d'activation introduit une
                    non-linéarité dans le réseau, permettant de modéliser des relations complexes.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">86
                <a class="prev" href="#slide85"></a>
                <a class="next" href="#slide87"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide87">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseau de neurones</h2>
            <ul>
                <li><b>Poids ajustables</b> : Les neurones et les connexions ont généralement des poids qui sont ajustés
                    au fur et à mesure de l'apprentissage. Ces poids déterminent l'importance relative des différentes
                    entrées pour chaque neurone.</li>
                <li><b>Ajustement des poids</b> : Les poids peuvent être ajustés pour augmenter ou diminuer la force du
                    signal au niveau d'une connexion, influençant ainsi la contribution de cette connexion aux calculs
                    du réseau.</li>
                <li><b>Seuil</b> : Les neurones peuvent avoir un seuil, de sorte qu'un signal n'est envoyé que si la
                    somme pondérée de ses entrées dépasse ce seuil. Cela permet au réseau de moduler sa sensibilité aux
                    entrées.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">87
                <a class="prev" href="#slide86"></a>
                <a class="next" href="#slide88"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide88">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Les couches</h2>
            <p>Les neurones sont organisés en couches. Il existe généralement trois types de couches dans un réseau de
                neurones :</p>
            <ul>
                <li><b>Couche d'Entrée (Input Layer)</b> : Cette couche reçoit les signaux initiaux ou les données en
                    entrée. Chaque neurone dans cette couche représente une caractéristique ou une variable d'entrée.
                </li>
                <li><b>Couches Cachées (Hidden Layers)</b> : Ces couches effectuent des transformations non linéaires
                    sur les entrées. Elles sont responsables de l'extraction et de la représentation des
                    caractéristiques importantes des données. Un réseau de neurones peut avoir une ou plusieurs couches
                    cachées.</li>
                <li><b>Couche de Sortie (Output Layer)</b> : Cette couche génère la sortie du réseau. Le nombre de
                    neurones dans cette couche dépend de la nature de la tâche, par exemple, une classification binaire
                    aurait un neurone de sortie, tandis qu'une classification multi-classes en aurait plusieurs.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">88
                <a class="prev" href="#slide87"></a>
                <a class="next" href="#slide89"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide89">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Les couches</h2>
            <ul>
                <li><b>Transformations</b> : Chaque couche, y compris la couche d'entrée, effectue des transformations
                    sur les signaux qu'elle reçoit. Ces transformations sont déterminées par les poids des connexions
                    entre les neurones.</li>
                <li><b>Propagation des signaux</b> : Les signaux passent de la première couche (l'entrée) à la dernière
                    couche (la sortie) à travers les connexions pondérées entre les neurones. Ce processus est souvent
                    appelé la propagation avant (forward propagation). Pendant l'apprentissage, la rétropropagation
                    (backpropagation) est utilisée pour ajuster les poids afin de minimiser l'erreur de prédiction.</li>
                <li><b>Architecture</b> : La manière dont les couches sont organisées et connectées dans le réseau
                    constitue son architecture. Les réseaux de neurones peuvent avoir des architectures diverses, y
                    compris des réseaux profonds (avec de nombreuses couches cachées) ou des architectures plus simples.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">89
                <a class="prev" href="#slide88"></a>
                <a class="next" href="#slide90"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide90">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">L'entraînement</h2>
            <p>L'objectif global de l'entraînement est d'ajuster les poids du réseau de manière à ce qu'il puisse
                généraliser à de nouvelles données, produisant des résultats précis pour des exemples qu'il n'a pas vu
                pendant l'entraînement.</p>
            <ul>
                <li><b>Données d'entraînement</b> : Les réseaux neuronaux apprennent à partir d'exemples. Chaque exemple
                    se compose d'une "entrée" (les caractéristiques) et d'un "résultat" connu (l'étiquette ou la sortie
                    attendue).</li>
                <li><b>Calcul de l'erreur</b> : Lorsque le réseau produit une sortie pour une entrée donnée, l'erreur
                    est calculée en comparant cette sortie à la sortie cible (le résultat connu). Il existe différentes
                    mesures d'erreur, mais la somme des carrés des différences (Mean Squared Error, MSE) est couramment
                    utilisée.</li>
                <li><b>Rétropropagation (Backpropagation)</b> : Le réseau ajuste ses poids en utilisant la
                    rétropropagation. Cette technique minimise l'erreur en modifiant les poids à partir de la couche de
                    sortie jusqu'à la couche d'entrée. La règle de la chaîne du calcul différentiel est appliquée pour
                    propager l'erreur à travers le réseau.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">90
                <a class="prev" href="#slide89"></a>
                <a class="next" href="#slide91"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide91">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">L'entraînement</h2>
            <ul>
                <li><b>Descente de gradient</b> : La règle d'apprentissage souvent utilisée pour ajuster les poids est
                    la descente de gradient. Elle utilise le gradient de l'erreur par rapport aux poids pour mettre à
                    jour les poids dans la direction qui minimise l'erreur.</li>
                <li><b>Itérations</b> : Le processus d'ajustement des poids en fonction de l'erreur est répété pour de
                    nombreux exemples du jeu de données d'entraînement. Chaque itération est appelée une "époque".
                    Plusieurs époques peuvent être nécessaires pour que le réseau converge vers un état où l'erreur est
                    suffisamment basse.</li>
                <li><b>Optimisation</b> : Différentes techniques d'optimisation peuvent être utilisées pour améliorer la
                    convergence du réseau, telles que l'ajustement adaptatif du taux d'apprentissage.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">91
                <a class="prev" href="#slide90"></a>
                <a class="next" href="#slide92"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide92">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <ul>
                <li><b>Neurones</b> : Les neurones artificiels sont les unités de base d'un réseau de neurones. Chaque
                    neurone reçoit des signaux d'entrée, effectue un calcul sur ces signaux à l'aide d'une fonction
                    d'activation, et produit une sortie. Les neurones sont organisés en couches, à savoir la couche
                    d'entrée, les couches cachées, et la couche de sortie.</li>
                <li><b>Connexions et Poids</b> : Les connexions entre les neurones sont représentées par des poids.
                    Chaque connexion a un poids associé, qui détermine l'importance relative de cette connexion dans le
                    calcul du neurone de sortie. Pendant l'entraînement, ces poids sont ajustés pour minimiser l'erreur
                    de prédiction du réseau.</li>
                <li><b>Fonction de Propagation (Propagation avant)</b> : La fonction de propagation, également appelée
                    propagation avant, décrit le processus par lequel les signaux se propagent à travers le réseau
                    depuis la couche d'entrée jusqu'à la couche de sortie. Chaque neurone effectue une transformation
                    sur les signaux qu'il reçoit, et ces signaux modifiés sont transmis aux neurones de la couche
                    suivante.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">92
                <a class="prev" href="#slide91"></a>
                <a class="next" href="#slide93"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide93">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Neurones</h2>
            <p>Chaque neurone artificiel a des entrées, qui peuvent être les valeurs caractéristiques d'un échantillon
                de données externe, et produit une seule sortie. Cette sortie peut être envoyée à plusieurs autres
                neurones, formant ainsi la structure interconnectée du réseau neuronal. La <b>fonction d'activation</b>
                joue un rôle crucial dans le calcul de la sortie d'un neurone. Le processus comprend les étapes
                suivantes :</p>
            <ul>
                <li><b>Somme pondérée</b> : Pour trouver la sortie du neurone, on prend la somme pondérée de tous les
                    intrants (entrées). Chaque entrée est multipliée par le poids correspondant à la connexion.</li>
                <li><b>Ajout d'un terme de biais</b> : Un terme de biais est ajouté à la somme pondérée. Le terme de
                    biais est un paramètre supplémentaire qui permet au modèle d'apprendre un décalage ou une
                    translation.</li>
                <li><b>Activation</b> : La somme pondérée, parfois appelée activation, est ensuite passée par une
                    fonction d'activation. Cette fonction est généralement non linéaire et introduit de la complexité
                    dans le modèle, permettant au réseau de capturer des relations non linéaires dans les données</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">93
                <a class="prev" href="#slide92"></a>
                <a class="next" href="#slide94"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide94">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Connexions et poids</h2>
            <p>Le réseau de neurones est constitué de connexions, où chaque connexion transmet la sortie d'un neurone
                comme entrée à un autre neurone. Chaque connexion possède un poids qui représente son importance
                relative dans la transmission du signal.</p>
            <ul>
                <li>Un neurone donné peut avoir <b>plusieurs connexions d'entrée</b>, recevant des signaux de différents
                    neurones, et plusieurs connexions de sortie, transmettant des signaux à d'autres neurones. Les poids
                    associés à ces connexions permettent au réseau de moduler l'influence de chaque neurone sur les
                    autres, ajustant ainsi la force et la direction des signaux transmis à travers le réseau.</li>
                <li>Cette structure de connexion et de pondération est fondamentale dans le fonctionnement des réseaux
                    de neurones, car elle permet au réseau d'apprendre des représentations complexes des données et
                    d'ajuster ses paramètres pendant l'entraînement pour accomplir des tâches spécifiques.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">94
                <a class="prev" href="#slide93"></a>
                <a class="next" href="#slide95"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide95">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Fonction de propagation</h2>
            <p><b>Calcul de l'entrée d'un neurone</b> : La fonction de propagation calcule l'entrée d'un neurone en
                prenant la somme pondérée des sorties de ses prédécesseurs, où chaque sortie est multipliée par le poids
                de la connexion correspondante. Cela peut être représenté mathématiquement comme suit :</p>
            <p>\[ \text{Entrée du Neurone} = \sum_{i=1}^{n} (\text{Sortie du Prédécesseur}_i \times \text{Poids}_i) \]
                où \(n\) est le nombre de connexions d'entrée.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">95
                <a class="prev" href="#slide94"></a>
                <a class="next" href="#slide96"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide96">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Fonction de propagation</h2>
            <p><b>Ajout d'un terme de biais</b> : Un terme de biais peut être ajouté au résultat de la propagation. Le
                terme de biais est un paramètre supplémentaire, souvent représenté par \(b\) dans les équations, qui
                permet au modèle d'apprendre un décalage ou une translation. Cela donne la forme finale de l'entrée du
                neurone :</p>

            <p>\[ \text{Entrée du Neurone} = \sum_{i=1}^{n} (\text{Sortie du Prédécesseur}_i \times \text{Poids}_i) +
                \text{Biais} \]</p>

        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">96
                <a class="prev" href="#slide95"></a>
                <a class="next" href="#slide97"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide97">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Fonction de propagation</h2>
            <p><b>Fonction d'Activation</b> : Après avoir calculé l'entrée du neurone, celle-ci est passée à travers une
                fonction d'activation. Cette fonction introduit une non-linéarité dans le modèle, permettant au réseau
                de neurones de capturer des relations complexes et d'apprendre des modèles non linéaires. Certaines des
                fonctions d'activation couramment utilisées comprennent :</p>
            <ul>
                <li><b>Sigmoïde</b> : \( \sigma(x) = \frac{1}{1 + e^{-x}} \)</li>
                <li><b>Tangente hyperbolique (tanh)</b> : \( \text{tanh}(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} \)
                </li>
                <li><b>ReLU (Rectified Linear Unit)</b> : \( \text{ReLU}(x) = \max(0, x) \)</li>
                <li><b>Softmax</b> (pour la couche de sortie dans la classification) : \( \text{Softmax}(x)_i =
                    \frac{e^{x_i}}{\sum_{j} e^{x_j}} \)</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">97
                <a class="prev" href="#slide96"></a>
                <a class="next" href="#slide98"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide98">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Perceptron</h3>
            <p>Le perceptron est un <b>algorithme d'apprentissage supervisé</b> utilisé pour la <b>classification
                    binaire</b>. Il est conçu pour résoudre des problèmes où l'objectif est de déterminer si une entrée
                donnée appartient ou non à une classe particulière.</p>
            <ul>
                <li>Le perceptron a été inventé par <b>Frank Rosenblatt</b> en 1958. L'idée était de créer un modèle
                    simple de neurone artificiel inspiré du fonctionnement des neurones biologiques. Rosenblatt a
                    formulé un algorithme d'apprentissage qui permet au perceptron d'ajuster ses poids en fonction des
                    erreurs de classification, améliorant ainsi ses performances au fil du temps.</li>
                <li><b>Fonctionnement</b> : Le perceptron prend plusieurs entrées pondérées et les combine en une somme.
                    Ensuite, cette somme est soumise à une fonction d'activation, généralement une fonction échelon
                    (step function), qui produit la sortie binaire du perceptron.</li>
                <li><b>Limitations</b> : Le perceptron a des limitations, notamment sa capacité à résoudre des problèmes
                    non linéaires et son incapacité à apprendre des modèles complexes. Cependant, il a jeté les bases
                    pour le développement de réseaux de neurones plus avancés, en particulier les réseaux multicouches
                    qui peuvent apprendre des représentations hiérarchiques.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">98
                <a class="prev" href="#slide97"></a>
                <a class="next" href="#slide99"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide99">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron</h1>
            <figure>
                <img src="../../2021/MachineLearning/Perceptron_example.svg" height="350px" />
                <figcaption>Perceptron en mettant à jour sa limite linéaire à mesure que d'autres exemples de formation
                    sont ajoutés.<sup>1</sup></figcaption>
            </figure>
            <ol style="font-size:2vh">
                <li>Source: https://en.wikipedia.org/wiki/File:Perceptron_example.svg</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">99
                <a class="prev" href="#slide98"></a>
                <a class="next" href="#slide100"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide100">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Perceptron.svg" height="400px" />
                <figcaption>Perceptron</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">100
                <a class="prev" href="#slide99"></a>
                <a class="next" href="#slide101"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide101">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron: Définition formelle</h1>
            <ul>
                <li>Soit \(y = f(z)\) la sortie du perceptron pour un vecteur d'entrée <i>z</i></li>
                <li>Soit \(N\) le nombre d'exemples d'entraînement</li>
                <li>Soit <i><b>X</b></i> l'espace de saisie des caractéristiques</li>
                <li>Soit \({(x_{1}, d_{1}),...,(x_{N}, d_{N})}\) be the <i><b>N</b></i> training examples, where
                    <ul>
                        <li>\(x_i\) est le vecteur caractéristique de <i>i<sup>ème</sup></i> exemple d'entraînement.
                        </li>
                        <li>\(d_i\) est la valeur de sortie souhaitée</li>
                        <li>\(x_{j,i}\) est la <i>i<sup>ème</sup></i> caractéristique de <i>j<sup>ème</sup></i> exemple
                            d'entraînement.</li>
                        <li>\(x_{j,0} = 1\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">101
                <a class="prev" href="#slide100"></a>
                <a class="next" href="#slide102"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide102">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1>Perceptron: Définition formelle</h1>
            <ul>
                <li>Les poids sont représentés de la manière suivante:
                    <ul>
                        <li>\(w_i\) est la <i>i<sup>ème</sup></i> valeur du vecteur de poids.</li>
                        <li>\(w_i(t)\) est la <i>i<sup>ème</sup></i> valeur du vecteur de poids à un moment donné t.
                        </li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">102
                <a class="prev" href="#slide101"></a>
                <a class="next" href="#slide103"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide103">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1>Perceptron : Étapes</h1>
            <ol>
                <li>Initialiser les poids et les seuils</li>
                <li>Pour chaque exemple, \((x_j, d_j)\) dans l'ensemble d'entraînement<i></i>
                    <ul>
                        <li>Calculer la sortie actuelle : \[y_j(t)= f[w(t).x_j]\] \[= f[w_0(t)x_{j,0} + w_1(t)x_{j,1} +
                            w_2(t)x_{j,2} + \dotsb + w_n(t)x_{j,n}]\]</li>
                        <li>Calculer le poids: \[w_i(t + 1) = w_i(t) + r. (d_j-y_j(t))x_{j,i}\]</li>
                    </ul> \(r\) est le taux d'apprentissage.
                </li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">103
                <a class="prev" href="#slide102"></a>
                <a class="next" href="#slide104"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide104">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1>Perceptron : Étapes</h1>
            <ol start="3">
                <li>Répétez l'étape 2 jusqu'à l'erreur d'itération \[\frac{1}{s} (&#931; |d_j - y_j(t)|)\] est inférieur
                    au seuil spécifié par l'utilisateur \(\gamma\), ou un nombre prédéterminé d'itérations ont été
                    effectuées, où \(s\) est à nouveau la taille
                    de l'ensemble de l'échantillon.</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">104
                <a class="prev" href="#slide103"></a>
                <a class="next" href="#slide105"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide105">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'Échelon (Step Function)</h2>
            <p>Le perceptron utilise généralement une fonction d'activation simple, et la fonction d'échelon (step
                function) est fréquemment choisie pour cette tâche. </p>
            <h4>Définition</h4>
            <p>La fonction d'échelon attribue une sortie de 1 si la somme pondérée des entrées dépasse un certain seuil,
                et 0 sinon.</p>
            <p>\( f(x) = \begin{cases} 1 & \text{si } x \geq \text{seuil} \\ 0 & \text{sinon} \end{cases} \)</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">105
                <a class="prev" href="#slide104"></a>
                <a class="next" href="#slide106"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide106">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: fonction d'identité</h2>
            <h4>Équation</h4>
            <p>\[f(x)=x\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=1\]</p>
            <h3></h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_identity.svg"
                    height="380px" />
                <figcaption>Fonction d'identité</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">106
                <a class="prev" href="#slide105"></a>
                <a class="next" href="#slide107"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide107">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Fonction d'activation: pas binaire</h2>
                <h4>Équation</h4>
                <p>\[f(x) = \begin{cases} 0 & \text{for } x
                    < 0\\ 1 & \text{for } x \ge 0 \end{cases} \]</p>
                        <h4>Dérivée</h4>
                        <p>\[f'(x) = \begin{cases} 0 & \text{for } x \ne 0\\ ? & \text{for } x = 0\end{cases}\]</p>
                        <figure>
                            <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_binary_step.svg"
                                height="380px" />
                            <figcaption>Pas binaire</figcaption>
                        </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">107
                <a class="prev" href="#slide106"></a>
                <a class="next" href="#slide108"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide108">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: fonction sigmoïde</h2>
            <h4>Équation</h4>
            <p>\[f(x)=\sigma(x)=\frac{1}{1+e^{-x}}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=f(x)(1-f(x))\]</p>
            <figure>
                <img src="../../2021/MachineLearning/Logistic-curve.svg" height="380px" />
                <figcaption>La fonction sigmoïde</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">108
                <a class="prev" href="#slide107"></a>
                <a class="next" href="#slide109"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide109">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: TanH</h2>
            <h4>Équation</h4>
            <p>\[f(x)=\tanh(x)=\frac{(e^{x} - e^{-x})}{(e^{x} + e^{-x})}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=1-f(x)^2\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_tanh.svg" height="380px" />
                <figcaption>TanH</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">109
                <a class="prev" href="#slide108"></a>
                <a class="next" href="#slide110"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide110">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: Rectified linear unit: ReLU</h2>
            <h4>Équation</h4>
            <p>\[f(x) = \begin{cases} 0 & \text{for } x \le 0\\ x & \text{for } x > 0\end{cases} = \max\{0,x\}= x
                \textbf{1}_{x>0}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x) = \begin{cases} 0 & \text{for } x \le 0\\ 1 & \text{for } x > 0\end{cases}\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_rectified_linear.svg"
                    height="380px" />
                <figcaption>Unité linéaire rectifiée (ReLU)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">110
                <a class="prev" href="#slide109"></a>
                <a class="next" href="#slide111"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide111">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: Gaussien</h2>
            <h4>Équation</h4>
            <p>\[f(x)=e^{-x^2}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=-2xe^{-x^2}\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_gaussian.svg"
                    height="380px" />
                <figcaption>Gaussien</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">111
                <a class="prev" href="#slide110"></a>
                <a class="next" href="#slide112"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide112">
        <div class="header">
            <h1>2.3. Réseaux de neurones artificiels</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Perceptron multiclasse</h2>
            <ul>
                <li>Perceptron peut être généralisé à la classification multiclasse. </li>
                <li>Une fonction de représentation d'élément \(f( x , y )\) fait correspondre chaque paire
                    d'entrée/sortie possible à un vecteur d'élément à valeur réelle en dimension finie.</li>
                <li>le vecteur de caractéristique est multiplié par un vecteur de poids \(w\), mais le score obtenu est
                    maintenant utilisé pour choisir parmi de nombreux résultats possibles : \[\hat y =
                    \operatorname{argmax}_y f(x,y) \cdot w.\]</li>
                <li>La réapprentissage se fait par itération sur les exemples, en prédisant un résultat pour chacun, en
                    laissant les poids inchangés lorsque le résultat prédit correspond à l'objectif, et en les modifiant
                    lorsqu'il ne correspond pas. La mise
                    à jour devient : \[w_{t+1} = w_t + f(x, y) - f(x,\hat y)\].</li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">112
                <a class="prev" href="#slide111"></a>
                <a class="next" href="#slide113"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide113">
        <div class="header">
            <h1>2.4. Réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <p>Un <b>réseau de neurones profond</b>, également connu sous le nom de réseau de neurones profondément
                hiérarchisé ou réseau neuronal profond (DNN pour Deep Neural Network en anglais), est un type de réseau
                de neurones artificiels qui comprend plusieurs couches de traitement, généralement plus de deux. Ces
                réseaux sont appelés "profonds" en raison de leur architecture empilée de couches, permettant la
                création de représentations hiérarchiques complexes des données.</p>
            <p><b>Architecture en couches</b> : Les réseaux de neurones profonds sont composés de multiples couches,
                généralement divisées en trois types principaux :</p>
            <ul>
                <li><b>Couche d'Entrée</b> : Reçoit les données brutes ou caractéristiques en entrée.</li>
                <li><b>Couches Cachées</b> : Effectuent des transformations non linéaires et apprennent des
                    représentations hiérarchiques des données.</li>
                <li><b>Couche de Sortie</b> : Produit la sortie du réseau, adaptée à la tâche spécifique
                    (classification, régression, etc.).</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">113
                <a class="prev" href="#slide112"></a>
                <a class="next" href="#slide114"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide114">
        <div class="header">
            <h1>2.4. Réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <ul>
                <li><b>Apprentissage Hiérarchique</b> : Les couches cachées d'un réseau de neurones profond apprennent
                    des caractéristiques de plus en plus abstraites et complexes à mesure que l'on progresse en
                    profondeur. Chaque couche représente une abstraction des caractéristiques extraites par les couches
                    précédentes.</li>
                <li><b>Fonctions d'Activation</b> : Des fonctions d'activation non linéaires, telles que ReLU (Rectified
                    Linear Unit) ou ses variantes, sont couramment utilisées dans les couches cachées pour permettre au
                    réseau d'apprendre des relations non linéaires.</li>
                <li><b>Apprentissage Profond</b> : L'apprentissage profond implique l'ajustement simultané des poids de
                    toutes les couches du réseau pour minimiser l'erreur de prédiction. Cela est généralement réalisé en
                    utilisant des techniques de rétropropagation et de descente de gradient.</li>
                <li><b>Utilisations</b> : Les réseaux de neurones profonds sont utilisés dans une variété de tâches,
                    notamment la vision par ordinateur, la reconnaissance vocale, le traitement du langage naturel, la
                    traduction automatique, la recommandation de contenu, et bien d'autres. Leur capacité à apprendre
                    des représentations complexes a conduit à des avancées significatives dans de nombreux domaines de
                    l'intelligence artificielle.</li>
            </ul>
            <p>L'entraînement de réseaux de neurones profonds peut nécessiter des volumes importants de données et de
                puissance de calcul. </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">114
                <a class="prev" href="#slide113"></a>
                <a class="next" href="#slide115"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide115">
        <div class="header">
            <h1>2.4. Réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <p>Il existe plusieurs types de réseaux de neurones profonds.</p>
            <ul>
                <li><b style="color:#1B80CF">Réseaux de Neurones Convolutionnels (CNN)</b> :
                    <ul>
                        <li><b>Utilisation Principale</b> : Vision par ordinateur, reconnaissance d'images.</li>
                        <li><b>Caractéristiques</b> : Les CNN sont efficaces pour extraire des motifs spatiaux à partir
                            d'images en utilisant des opérations de convolution. Ils sont largement utilisés dans des
                            applications telles que la classification d'images, la détection d'objets et la segmentation
                            d'images.</li>
                    </ul>
                </li>
                <li><b style="color:#1B80CF">Réseaux de Neurones Récurrents (RNN)</b> :
                    <ul>
                        <li><b>Utilisation Principale</b> : Traitement de séquences, traitement du langage naturel.</li>
                        <li><b> Caractéristiques</b> : Les RNN sont conçus pour traiter des données séquentielles en
                            utilisant des connexions récurrentes qui leur permettent de conserver une mémoire à long
                            terme. Ils sont utilisés pour des tâches telles que la traduction automatique, la génération
                            de texte et l'analyse de séquences temporelles.</li>
                    </ul>
                </li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">115
                <a class="prev" href="#slide114"></a>
                <a class="next" href="#slide116"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide116">
        <div class="header">
            <h1>2.4. Réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <ul>
                <li><b style="color:#1B80CF">Réseaux de Neurones Générateurs Adverses (GAN)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Génération d'images réalistes.</li>
                        <li><b> Caractéristiques</b> : Les GAN sont composés de deux réseaux, un générateur et un
                            discriminateur, qui s'entraînent de manière adversaire. Les GAN sont utilisés pour générer
                            des données réalistes, y compris des images, des vidéos et du son.</li>
                    </ul>
                </li>
                <li><b style="color:#1B80CF">Réseaux de Neurones Résiduels (ResNet)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Classification d'images profondes.</li>
                        <li><b> Caractéristiques</b> : Les architectures ResNet utilisent des connexions résiduelles
                            pour faciliter l'apprentissage profond en surmontant le problème du "vanishing gradient".
                            Ils sont fréquemment utilisés dans des compétitions de classification d'images.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">116
                <a class="prev" href="#slide115"></a>
                <a class="next" href="#slide117"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide117">
        <div class="header">
            <h1>2.4. Réseaux de neurones profonds</h1>
        </div>
        <div class="content">
            <ul>

                <li><b style="color:#1B80CF">Autoencodeurs et Variational Autoencoders (VAE)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Compression et génération de données.
                        <li><b> Caractéristiques</b> : Les autoencodeurs sont utilisés pour apprendre des
                            représentations compactes de données en comprimant et en reconstruisant les informations.
                            Les VAE introduisent des composants probabilistes, permettant de générer de nouvelles
                            données similaires aux données d'entraînement.
                    </ul>
                </li>

                <li><b style="color:#1B80CF">Réseaux de Neurones de Mémoire à Long Terme (LSTM)</b> :
                    <ul>
                        <li><b> Utilisation Principale</b> : Traitement du langage naturel, séquences temporelles.</li>
                        <li><b> Caractéristiques</b> : Les LSTMs sont une variation des RNN qui intègrent des mécanismes
                            de portes pour mieux gérer le problème du gradient qui s'estompe sur de longues séquences.
                            Ils sont couramment utilisés dans la génération de texte et d'autres tâches basées sur des
                            séquences.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">117
                <a class="prev" href="#slide116"></a>
                <a class="next" href="#slide118"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide118">
        <div class="header">
            <h1>Références</h1>
        </div>
        <div class="content">
            <h1>Articles de recherche</h1>
            <ul>
                <li>[Aly 2005] Aly, Mohamed. Survey on Multiclass Classification Methods. 2005.</li>
                <li>[Jaakkola 2019] Jaakkola, H., et al. “Artificial Intelligence Yesterday, Today and Tomorrow.” 2019
                    42nd International Convention on Information and Communication Technology, Electronics and
                    Microelectronics (MIPRO), 2019, pp. 860–67. IEEE
                    Xplore
                </li>
                <li>[Pan 2016] Pan, Yunhe, “Heading toward Artificial Intelligence 2.0.” Engineering, vol. 2, no. 4,
                    Dec. 2016, pp. 409–13. www.sciencedirect.com,</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">118
                <a class="prev" href="#slide117"></a>
                <a class="next" href="#slide119"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide119">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Web</h1>
            <ol>
                <li>Google acquiert DNNresearch, spécialisé dans les réseaux de neurones profonds: <a
                        href="https://www.lemondeinformatique.fr/actualites/lire-google-acquiert-dnnresearch-specialise-dans-les-reseaux-de-neurones-profonds-52829.html">https://www.lemondeinformatique.fr/actualites/lire-google-acquiert-dnnresearch-specialise-dans-les-reseaux-de-neurones-profonds-52829.html</a>
                </li>
                <li>Pourquoi Microsoft rachète Linkedin: <a
                        href="https://www.lemondeinformatique.fr/actualites/lire-pourquoi-microsoft-rachete-linkedin-65136.html">https://www.lemondeinformatique.fr/actualites/lire-pourquoi-microsoft-rachete-linkedin-65136.html</a>
                </li>
                <li>Scikit-learn: <a href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a></li>
                <li>Perceptron: <a
                        href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html</a>
                </li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">119
                <a class="prev" href="#slide118"></a>
                <a class="next" href="#slide120"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide120">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Wikipédia</h1>
            <ul>
                <li>Perceptron: <a
                        href="https://en.wikipedia.org/wiki/Perceptron">https://en.wikipedia.org/wiki/Perceptron</a>
                </li>
                <li>Multiclass Classification: <a
                        href="https://en.wikipedia.org/wiki/Multiclass_classification">https://en.wikipedia.org/wiki/Multiclass_classification</a>
                </li>
                <li>Multilayer Perceptron: <a
                        href="https://en.wikipedia.org/wiki/Multilayer_perceptron">https://en.wikipedia.org/wiki/Multilayer_perceptron</a>
                </li>
                <li>Feedforward Neural Network: <a
                        href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
                </li>
                <li>Recurrent Neural Network: <a
                        href="https://en.wikipedia.org/wiki/Recurrent_neural_network">https://en.wikipedia.org/wiki/Recurrent_neural_network</a>
                </li>
                <li>Long Short-Term Memory: <a
                        href="https://en.wikipedia.org/wiki/Long_short-term_memory">https://en.wikipedia.org/wiki/Long_short-term_memory</a>
                </li>
                <li>Activation Function: <a
                        href="https://en.wikipedia.org/wiki/Activation_function">https://en.wikipedia.org/wiki/Activation_function</a>
                </li>
                <li>Logique et Raisonnement Mathématique: <a
                        href="https://fr.wikipedia.org/wiki/Logique_et_raisonnement_math%C3%A9matique">https://fr.wikipedia.org/wiki/Logique_et_raisonnement_math%C3%A9matique</a>
                </li>
                <li>Représentation des Connaissances: <a
                        href="https://fr.wikipedia.org/wiki/Repr%C3%A9sentation_des_connaissances">https://fr.wikipedia.org/wiki/Repr%C3%A9sentation_des_connaissances</a>
                </li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">120
                <a class="prev" href="#slide119"></a>
                <a class="next" href="#slide121"></a>
            </div>
        </div>
    </section>

    <section class="slide" id="slide121">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Wikipédia</h1>
            <ul>
                <li>Agent Intelligent: <a
                        href="https://fr.wikipedia.org/wiki/Agent_intelligent">https://fr.wikipedia.org/wiki/Agent_intelligent</a>
                </li>
                <li>Calcul des Propositions: <a
                        href="https://fr.wikipedia.org/wiki/Calcul_des_propositions">https://fr.wikipedia.org/wiki/Calcul_des_propositions</a>
                </li>
                <li>Calcul des Prédicats: <a
                        href="https://fr.wikipedia.org/wiki/Calcul_des_pr%C3%A9dicats">https://fr.wikipedia.org/wiki/Calcul_des_pr%C3%A9dicats</a>
                </li>
                <li>Logique Modale: <a
                        href="https://fr.wikipedia.org/wiki/Logique_modale">https://fr.wikipedia.org/wiki/Logique_modale</a>
                </li>
                <li>Raisonnement Automatisé: <a
                        href="https://fr.wikipedia.org/wiki/Raisonnement_automatis%C3%A9">https://fr.wikipedia.org/wiki/Raisonnement_automatis%C3%A9</a>
                </li>
                <li>Connaissance: <a
                        href="https://fr.wikipedia.org/wiki/Connaissance">https://fr.wikipedia.org/wiki/Connaissance</a>
                </li>
                <li>Gestion des connaissances: <a
                        href="https://fr.wikipedia.org/wiki/Gestion_des_connaissances">https://fr.wikipedia.org/wiki/Gestion_des_connaissances</a>
                </li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">121
                <a class="prev" href="#slide120"></a>
                <a class="next" href="#slide122"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide122">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Couleurs</h1>
            <ul>
                <li><a href="https://material.io/color/">Color Tool - Material Design</a></li>
            </ul>
            <h1>Images</h1>
            <ul>
                <li><a href="https://commons.wikimedia.org/">Wikimedia Commons</a></li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">122
                <a class="prev" href="#slide121"></a>
            </div>
        </div>
    </section>

    <script>
        function changeCurrentURLSlideNumber(isIncrement) {
            url = window.location.href;
            position = url.indexOf("#slide");
            if (position != -1) { // Not on the first page
                slideIdString = url.substr(position + 6);
                if (!Number.isNaN(slideIdString)) {
                    slideId = parseInt(slideIdString);
                    if (isIncrement) {
                        if (slideId < 122) {
                            slideId = slideId + 1;
                        }
                    } else {
                        if (slideId > 1) {
                            slideId = slideId - 1;
                        }
                    }
                    /* regexp */
                    url = url.replace(/#slide\d+/g, "#slide" + slideId);
                    window.location.href = url;
                }
            } else {
                window.location.href = url + "#slide2";
            }
        }
        document.onkeydown = function (event) {

            event.preventDefault();
            /* This will ensure the default behavior of
                                                            page scroll behaviour (up, down, right, left)*/

            event = event || window.event;
            /*Codes de la touche sur le clavier: 37, 38, 39, 40*/
            if (event.keyCode == '37') {
                // left
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '38') {
                // up
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '39') {
                // right
                changeCurrentURLSlideNumber(true);
            } else if (event.keyCode == '40') {
                // down
                changeCurrentURLSlideNumber(true);
            }
        }
        document.body.onmouseup = function (event) {
            event = event || window.event;
            event.preventDefault();
            changeCurrentURLSlideNumber(true);
        }
    </script>
</body>

</html>
