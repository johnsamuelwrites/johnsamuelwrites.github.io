<html>

<head>
    <meta charset="utf-8" />
    <title>Apprentissage machine (2023-2024): Cours: John Samuel</title>
    <link rel="shortcut icon" href="../../../../../images/logo/favicon.png" />
    <style type="text/css">
        body {
            height: 100%;
            width: 100%;
            background-color: white;
            margin: 0;
            overflow: hidden;
            font-family: Arial;
        }

        .slide {
            height: 100%;
            width: 100%;
        }

        .content {
            height: 79%;
            width: 95vw;
            display: flex;
            flex-direction: column;
            color: #000000;
            text-align: left;
            padding-left: 1.5vmax;
            padding-top: 1.5vmax;
            overflow-x: auto;
            font-size: 3vmin;
            flex-wrap: wrap;
        }

        .content h1,
        h2,
        h3,
        h4 {
            color: #1B80CF;
        }

        .content .topichighlight {
            background-color: #78002E;
            color: #FFFFFF;
        }

        .content .topicheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 2vmax 2vmax 0%;
            height: 4vmax;
            line-height: 4vmax;
            padding-left: 1vmax;
            margin: 0.1vmax;
            width: 50%;
        }

        .content .flexcontent {
            display: flex;
            overflow-y: auto;
            font-size: 3vmin;
            flex-wrap: wrap;
        }

        .content .gridcontent {
            display: grid;
            grid-template-columns: auto auto auto auto;
            grid-column-gap: 0px;
            grid-row-gap: 0px;
            grid-gap: 0px;
        }

        .content .topicsubheading {
            background-color: #1B80CF;
            color: #FFFFFF;
            vertical-align: middle;
            border-radius: 0 1.5vmax 1.5vmax 0%;
            height: 3vmax;
            margin: 0.1vmax;
            font-size: 90%;
            line-height: 3vmax;
            padding-left: 1vmax;
            width: 40%;
        }

        .content table {
            color: #000000;
            font-size: 100%;
            width: 100%;
        }

        .content a:link,
        .content a:visited {
            color: #1B80CF;
            text-decoration: none;
        }

        .content th {
            color: #FFFFFF;
            background-color: #1B80CF;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
            font-size: 120%;
            padding: 15px;
        }

        .content figure {
            max-width: 100%;
            max-height: 100%;
        }

        .content figure img {
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        .content figure figcaption {
            max-width: 90%;
            max-height: 90%;
            margin: 0.1vmax;
            font-size: 90%;
            text-align: center;
            padding: 0.5vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content td {
            color: #000000;
            width: 8%;
            padding-left: 3vmax;
            padding-top: 1vmax;
            padding-bottom: 1vmax;
            background-color: #E1F5FE;
            border-radius: 2vmax 2vmax 2vmax 2vmax;
        }

        .content li {
            line-height: 4vh;
        }

        .header {
            color: #ffffff;
            background-color: #00549d;
            height: 5vmax;
        }

        .header h1 {
            text-align: center;
            vertical-align: middle;
            font-size: 3vmax;
            line-height: 4vmax;
            margin: 0;
        }

        .footer {
            height: 3vmax;
            line-height: 3vmax;
            vertical-align: middle;
            color: #ffffff;
            background-color: #00549d;
            margin: 0;
            padding: .3vmax;
            overflow: hidden;
        }

        .footer .contact {
            float: left;
            color: #ffffff;
            text-align: left;
            font-size: 3.2vmin;
        }

        .footer .navigation {
            float: right;
            text-align: right;
            width: 8vw;
            font-size: 3vmin;
        }

        .footer .navigation .next,
        .prev {
            font-size: 3vmin;
            color: #ffffff;
            text-decoration: none;
        }

        .footer .navigation .next::after {
            content: "| >";
        }

        .footer .navigation .prev::after {
            content: "< ";
        }

        /*Use Pygment CSS*/
        pre {
            line-height: 125%;
        }

        td.linenos .normal {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos {
            color: inherit;
            background-color: transparent;
            padding-left: 5px;
            padding-right: 5px;
        }

        td.linenos .special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        span.linenos.special {
            color: #000000;
            background-color: #ffffc0;
            padding-left: 5px;
            padding-right: 5px;
        }

        .demo-highlight .hll {
            background-color: #ffffcc
        }

        .demo-highlight {
            background: #f8f8f8;
        }

        .demo-highlight .c {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment */
        .demo-highlight .err {
            border: 1px solid #FF0000
        }

        /* Error */
        .demo-highlight .k {
            color: #008000;
            font-weight: bold
        }

        /* Keyword */
        .demo-highlight .o {
            color: #666666
        }

        /* Operator */
        .demo-highlight .ch {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Hashbang */
        .demo-highlight .cm {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Multiline */
        .demo-highlight .cp {
            color: #9C6500
        }

        /* Comment.Preproc */
        .demo-highlight .cpf {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.PreprocFile */
        .demo-highlight .c1 {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Single */
        .demo-highlight .cs {
            color: #3D7B7B;
            font-style: italic
        }

        /* Comment.Special */
        .demo-highlight .gd {
            color: #A00000
        }

        /* Generic.Deleted */
        .demo-highlight .ge {
            font-style: italic
        }

        /* Generic.Emph */
        .demo-highlight .gr {
            color: #E40000
        }

        /* Generic.Error */
        .demo-highlight .gh {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Heading */
        .demo-highlight .gi {
            color: #008400
        }

        /* Generic.Inserted */
        .demo-highlight .go {
            color: #717171
        }

        /* Generic.Output */
        .demo-highlight .gp {
            color: #000080;
            font-weight: bold
        }

        /* Generic.Prompt */
        .demo-highlight .gs {
            font-weight: bold
        }

        /* Generic.Strong */
        .demo-highlight .gu {
            color: #800080;
            font-weight: bold
        }

        /* Generic.Subheading */
        .demo-highlight .gt {
            color: #0044DD
        }

        /* Generic.Traceback */
        .demo-highlight .kc {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Constant */
        .demo-highlight .kd {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Declaration */
        .demo-highlight .kn {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Namespace */
        .demo-highlight .kp {
            color: #008000
        }

        /* Keyword.Pseudo */
        .demo-highlight .kr {
            color: #008000;
            font-weight: bold
        }

        /* Keyword.Reserved */
        .demo-highlight .kt {
            color: #B00040
        }

        /* Keyword.Type */
        .demo-highlight .m {
            color: #666666
        }

        /* Literal.Number */
        .demo-highlight .s {
            color: #BA2121
        }

        /* Literal.String */
        .demo-highlight .na {
            color: #687822
        }

        /* Name.Attribute */
        .demo-highlight .nb {
            color: #008000
        }

        /* Name.Builtin */
        .demo-highlight .nc {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Class */
        .demo-highlight .no {
            color: #880000
        }

        /* Name.Constant */
        .demo-highlight .nd {
            color: #AA22FF
        }

        /* Name.Decorator */
        .demo-highlight .ni {
            color: #717171;
            font-weight: bold
        }

        /* Name.Entity */
        .demo-highlight .ne {
            color: #CB3F38;
            font-weight: bold
        }

        /* Name.Exception */
        .demo-highlight .nf {
            color: #0000FF
        }

        /* Name.Function */
        .demo-highlight .nl {
            color: #767600
        }

        /* Name.Label */
        .demo-highlight .nn {
            color: #0000FF;
            font-weight: bold
        }

        /* Name.Namespace */
        .demo-highlight .nt {
            color: #008000;
            font-weight: bold
        }

        /* Name.Tag */
        .demo-highlight .nv {
            color: #19177C
        }

        /* Name.Variable */
        .demo-highlight .ow {
            color: #AA22FF;
            font-weight: bold
        }

        /* Operator.Word */
        .demo-highlight .w {
            color: #bbbbbb
        }

        /* Text.Whitespace */
        .demo-highlight .mb {
            color: #666666
        }

        /* Literal.Number.Bin */
        .demo-highlight .mf {
            color: #666666
        }

        /* Literal.Number.Float */
        .demo-highlight .mh {
            color: #666666
        }

        /* Literal.Number.Hex */
        .demo-highlight .mi {
            color: #666666
        }

        /* Literal.Number.Integer */
        .demo-highlight .mo {
            color: #666666
        }

        /* Literal.Number.Oct */
        .demo-highlight .sa {
            color: #BA2121
        }

        /* Literal.String.Affix */
        .demo-highlight .sb {
            color: #BA2121
        }

        /* Literal.String.Backtick */
        .demo-highlight .sc {
            color: #BA2121
        }

        /* Literal.String.Char */
        .demo-highlight .dl {
            color: #BA2121
        }

        /* Literal.String.Delimiter */
        .demo-highlight .sd {
            color: #BA2121;
            font-style: italic
        }

        /* Literal.String.Doc */
        .demo-highlight .s2 {
            color: #BA2121
        }

        /* Literal.String.Double */
        .demo-highlight .se {
            color: #AA5D1F;
            font-weight: bold
        }

        /* Literal.String.Escape */
        .demo-highlight .sh {
            color: #BA2121
        }

        /* Literal.String.Heredoc */
        .demo-highlight .si {
            color: #A45A77;
            font-weight: bold
        }

        /* Literal.String.Interpol */
        .demo-highlight .sx {
            color: #008000
        }

        /* Literal.String.Other */
        .demo-highlight .sr {
            color: #A45A77
        }

        /* Literal.String.Regex */
        .demo-highlight .s1 {
            color: #BA2121
        }

        /* Literal.String.Single */
        .demo-highlight .ss {
            color: #19177C
        }

        /* Literal.String.Symbol */
        .demo-highlight .bp {
            color: #008000
        }

        /* Name.Builtin.Pseudo */
        .demo-highlight .fm {
            color: #0000FF
        }

        /* Name.Function.Magic */
        .demo-highlight .vc {
            color: #19177C
        }

        /* Name.Variable.Class */
        .demo-highlight .vg {
            color: #19177C
        }

        /* Name.Variable.Global */
        .demo-highlight .vi {
            color: #19177C
        }

        /* Name.Variable.Instance */
        .demo-highlight .vm {
            color: #19177C
        }

        /* Name.Variable.Magic */
        .demo-highlight .il {
            color: #666666
        }

        /* Literal.Number.Integer.Long */

        @media (max-width: 640px),
        screen and (orientation: portrait) {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .slide {
                height: 100%;
                width: 100%;
            }

            .content {
                width: 100%;
                height: 92%;
                display: flex;
                flex-direction: row;
                text-align: left;
                padding: 1vw;
                line-height: 3.8vmax;
                font-size: 1.8vmax;
                flex-wrap: wrap;
            }

            .content .topicheading {
                width: 90%;
            }

            .content h1,
            h2,
            h3,
            h4 {
                width: 100%;
            }

            .content figure img {
                max-width: 80vmin;
                max-height: 50vmin;
            }

            .content figure figcaption {
                max-width: 90%;
                max-height: 90%;
            }
        }

        @media print {
            body {
                max-width: 100%;
                max-height: 100%;
            }

            .content {
                height: 76%;
                width: 90vw;
                display: flex;
                color: #000000;
                text-align: left;
                padding: 5vw;
                font-size: 3vmin;
                flex-wrap: wrap;
            }

            .content figure img {
                max-width: 80%;
                max-height: 80%;
            }

            .content figcaption {
                max-width: 80%;
                max-height: 80%;
            }
        }
    </style>
    <script src="../../2021/MachineLearning/tex-mml-chtml.js" id="MathJax-script"></script>
</head>

<body>
    <section class="slide" id="slide1">
        <div class="header">
        </div>
        <div class="content">
            <h1 style="font-size:2.5vw">Apprentissage machine</h1>
            <p><b>John Samuel</b><br /> CPE Lyon<br /><br />
                <b>Year</b>: 2023-2024<br />
                <b>Email</b>: john(dot)samuel(at)cpe(dot)fr<br /><br />
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img
                        alt="Creative Commons License" style="border-width:0"
                        src="../../../../../en/teaching/courses/2017/C/88x31.png" /></a>
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">1

                <a class="next" href="#slide2"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide2">
        <div class="header">
            <h1>John SAMUEL</h1>
        </div>
        <div class="content">
            <div class="flexcontent">
                <figure style="width:30vw">
                    <img src="../../../../../images/portrait.jpg" width="300vw" style="background:#ffffff" />
                </figure>
                <ul style="width:40vw">
                    <li> <b>Enseignant-Chercheur</b>, Conception Logicielle et Big Data, CPE Lyon, </li>
                    <li> <b>Intérêts et thèmes de recherche </b>: Représentation de connaissances, le web sémantique,
                        les services web, l'intégration de données, l'entrepôt de données, les systèmes distribués,
                        système d'information géographique</li>
                    <li> <b>Cours </b>: Programmation en C, Algorithmes en C, Data Mining et Machine Learning,
                        Intelligence Artificielle et Deep Learning, Systèmes d'exploitation et Programmation
                        Concurrente, Langages Web</li>
                    <li> <b>Thèse</b> : Intégration des données issues de services web</li>
                </ul>
            </div>
        </div>
        <div class="footer">
            <div class="contact">Programmation en C | John Samuel</div>
            <div class="navigation">2
                <a class="prev" href="#slide1"></a>
                <a class="next" href="#slide3"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide3">
        <div class="header">
            <h1>Intelligence Artificielle - Deep Learning</h1>
        </div>
        <div class="content">
            <h1>Objectifs</h1>
            <ol>
                <li>Introduction à l'Intelligence Artificielle (IA)</li>
                <li>Apprentissage Machine</li>
                <li>Apprentissage Profond</li>
                <li>Applications de l'IA</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">3
                <a class="prev" href="#slide2"></a>
                <a class="next" href="#slide4"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide4">
        <div class="header">
            <h1>Intelligence Artificielle - Deep Learning</h1>
        </div>
        <div class="content">
            <h1 class="topicheading">Devoir surveillé (DS): 60%</h1>
            <ul>
                <li><b>Examen</b>: En-ligne sur E-campus</li>
                <li><b>Durée</b>: 2 heures</li>
                <li><b>Total</b>: 10/20 points</li>
                <li><b>Documents</b>: autorisés</li>
                <li><b>Types de documents autorisés</b>: Tous les documents autorisés</li>
                <li><b>Calculatrices</b> : non autorisées</li>
                <li><b>Utilisation de l'internet</b> : non autorisée</li>
                <li><b>Dépôt supplémentaire</b> : disponible pour les fichiers personnels</li>
            </ul>
            <p>Vous recevrez un courrier détaillé avant l'examen</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">4
                <a class="prev" href="#slide3"></a>
                <a class="next" href="#slide5"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide5">
        <div class="header">
            <h1>Intelligence Artificielle - Deep Learning</h1>
        </div>
        <div class="content">
            <h1 class="topicheading">Travaux pratiques et Projet: 40%</h1>
            <ul>
                <li> Les 2 travaux pratiques (TP) et le projet seront <b>évalués</b>.</li>
                <li> Deux <b>dates limites</b> de soumission sont précisées sur e-campus.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">5
                <a class="prev" href="#slide4"></a>
                <a class="next" href="#slide6"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide6">
        <div class="header">
            <h1>Intelligence Artificielle - Deep Learning</h1>
        </div>
        <div class="content">
            <table>
                <tr>
                    <th>Cours</th>
                    <th>Nombre d'heures</th>
                </tr>
                <tr>
                    <td>Cours</td>
                    <td>16</td>
                </tr>
                <tr>
                    <td>TP</td>
                    <td>16</td>
                </tr>
                <tr>
                    <td>Projet</td>
                    <td>16</td>
                </tr>
            </table>
            <p><b>Attention</b> : À chaque séance, nous adopterons un format intégrant à la fois des cours et des
                travaux pratiques.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">6
                <a class="prev" href="#slide5"></a>
                <a class="next" href="#slide7"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide7">
        <div class="header">
            <h1>1.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1>Intelligence Artificielle [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>La méthode d'apprentissage profond</li>
                <li>Les fusions et acquisitions d'entreprises
                    <ul>
                        <li>DNNresearch par Google en 2013 [1] : <b>vision par ordinateur</b>.</li>
                        <li>LinkedIn par Microsoft en 2016 [2] : <b>réseaux sociaux professionnels</b>.</li>
                    </ul>
                </li>
                <li>Les chatbots
                    <ul>
                        <li>Xiaobing par Microsoft: « <b>comprendre</b> » et répondre aux questions des utilisateurs en
                            <b>langage naturel</b>.
                        </li>
                    </ul>
                </li>
                <li>Les programmes de jeux
                    <ul>
                        <li>AlphaGo par Google : victoire historique contre le champion du <b>jeu de go</b> Lee Sedol en
                            2016.</li>
                    </ul>
                </li>
                <li>L'utilisation dans les hôpitaux
                    <ul>
                        <li>Watson par IBM : une plateforme d'IA qui a été utilisée dans le domaine de la santé pour
                            aider les professionnels de la santé à <b>analyser et à interpréter des données
                                médicales</b> complexes.</li>
                    </ul>
                </li>
                <li>La compréhension du langage naturel
                    <ul>
                        <li>Baidu : <b>moteur de recherche</b>.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">7
                <a class="prev" href="#slide6"></a>
                <a class="next" href="#slide8"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide8">
        <div class="header">
            <h1>1.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1>Intelligence Artificielle [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>1956: la definition d'IA
                    <ul>
                        <li><b>La capacité des machines à comprendre, à penser et à apprendre d'une manière similaire à
                                celle des êtres humains</b></li>
                        <li>Proposée par J. McCarthy, M. L. Minsky, H. Simon, A. Newell, C. E. Shannon, N. Rochester,...
                        </li>
                    </ul>
                </li>
                <li>1970-2000
                    <ul>
                        <li>1983: le rapport par James Lighthill : un rapport critiquant la recherche en IA au
                            Royaume-Uni, ce qui a conduit à un <b>ralentissement temporaire des financements publics</b>
                            pour l'IA, connu sous le nom de « <b>l'effet Lighthill</b> ».</li>
                        <li>1982-1992: l'échec du développement d'un <b>ordinateur intelligent</b> par le Japon</li>
                        <li>1984: la <b>construction manuelle d'une encyclopédie</b> de la connaissance (Cyc) par
                            Douglas Lenat à l'Université Stanford. Cyc est un projet d'IA visant à créer une base de
                            connaissances informatisée capable de raisonner et de répondre à des questions complexes.
                        </li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">8
                <a class="prev" href="#slide7"></a>
                <a class="next" href="#slide9"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide9">
        <div class="header">
            <h1>1.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1>Intelligence Artificielle 2.0 [Pan 2016, Jaakkola 2019]</h1>
            <ul>
                <li>1990s-présent
                    <ul>
                        <li>Popularité de <b>l'Internet</b></li>
                        <li>l'utilisation des <b>capteurs</b></li>
                        <li><b>Big Data</b></li>
                        <li>l'e-commerce</li>
                    </ul>
                </li>
                <li>Des <b>demandes sociales</b> pour IA
                    <ul>
                        <li>des <b>villes intelligentes</b></li>
                        <li>médecine</li>
                        <li>transport</li>
                        <li>les <b>automobiles sans conducteur</b></li>
                        <li>les smartphones</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">9
                <a class="prev" href="#slide8"></a>
                <a class="next" href="#slide10"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide10">
        <div class="header">
            <h1>1.1. Histoire scientifique: Intelligence Artificielle</h1>
        </div>
        <div class="content">
            <h1>Intelligence Artificielle 2.0 [Pan 2016]</h1>
            <ul>
                <li>Les technologies à l'origine de l'IA
                    <ul>
                        <li>L'IA basée sur des <b>données massives (Big Data)</b></li>
                        <li><b>L'intelligence de la foule</b> sur Internet</li>
                        <li>Le savoir médiatique croisé</li>
                        <li>L'intelligence hybride homme-machine</li>
                        <li><b>Systèmes autonomes</b> et intelligents</li>
                    </ul>
                </li>
                <li>L'avenir
                    <ul>
                        <li>L'IA <b>explicative et générique</b></li>
                        <li>la cognition, l'apprentissage et l'inférence trans-médiatiques.</li>
                        <li><b>l'intelligence communautaire</b> à partir de l'intelligence des foules basée sur
                            l'intelligence
                            individuelle</li>
                        <li>des systèmes autonomes et intelligents pour le développement de machines et de produits
                            intelligents.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">10
                <a class="prev" href="#slide9"></a>
                <a class="next" href="#slide11"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide11">
        <div class="header">
            <h1>1.2. Les fondements de l'IA </h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Objectifs</h1>
            <figure>
                <img src="../../../../../images/art/courses/deeplearningposition.svg" height="400px" />
                <figcaption>Intelligence artificielle</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">11
                <a class="prev" href="#slide10"></a>
                <a class="next" href="#slide12"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide12">
        <div class="header">
            <h1>1.2. Les fondements de l'IA </h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">1.2. Les fondements de l'IA </h1>
            <ul>
                <li>1.2.1. Logique et raisonnement</li>
                <li>1.2.2. Représentation des connaissances</li>
                <li>1.2.3. Agents intelligents</li>
                <li>1.2.4. Apprentissage machine</li>
                <li>1.2.5. Apprentissage profond</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">12
                <a class="prev" href="#slide11"></a>
                <a class="next" href="#slide13"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide13">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique et raisonnement</h1>
            <ul>
                <li><b style="color:#1B80CF">Logique propositionnelle</b> : La logique propositionnelle est un système
                    formel qui permet de représenter et d'évaluer des <b>propositions</b> en utilisant des
                    <b>connecteurs logiques (comme ET, OU, NON)</b> pour déterminer leur vérité.
                </li>
                <li><b style="color:#1B80CF">Logique du premier ordre</b> : La logique du premier ordre, également
                    appelée logique des prédicats, est une extension de la logique propositionnelle qui permet de
                    représenter des propositions plus complexes en introduisant des <b>variables, des constantes, des
                        fonctions et des prédicats</b>.</li>
                <li><b style="color:#1B80CF">Logique modale</b> : La logique modale est une extension de la logique qui
                    permet de représenter des notions de <b>possibilité</b>, de <b>nécessité</b>, de <b>croyance</b> et
                    d'autres modalités. </li>
                <li><b style="color:#1B80CF">Raisonnement automatisé</b> : Le raisonnement automatisé fait référence à
                    l'utilisation de systèmes informatiques pour effectuer des <b>inférences logiques</b> et <b>déduire
                        de nouvelles informations</b> à partir de connaissances existantes.</li>
                <li><b style="color:#1B80CF">Problèmes de décision et résolution de problèmes</b> : Les problèmes de
                    décision se réfèrent à des situations où une décision doit être prise parmi <b>plusieurs options
                        possibles</b>, généralement sous contraintes. La résolution de problèmes implique la
                    <b>recherche d'une solution</b> à un problème donné en utilisant des <b>méthodes algorithmiques ou
                        heuristiques</b> pour atteindre un objectif spécifique.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">13
                <a class="prev" href="#slide12"></a>
                <a class="next" href="#slide14"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide14">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique propositionnelle</h1>
            <p>Les propositions dans la logique propositionnelle sont des déclarations qui peuvent être <b>vraies
                    (V)</b> ou <b>fausses (F)</b>. Supposons que nous ayons deux propositions simples : P, Q. Nous
                pouvons utiliser des connecteurs logiques pour créer des propositions plus complexes à partir de ces
                propositions simples.</p>
            <ul>
                <li><b style="color:#1B80CF">NON (¬) </b> : La négation (NON) inverse la valeur de vérité d'une
                    proposition. Si P est vrai, alors NON P est faux, et si P est faux, alors NON P est vrai.</li>
                <li><b style="color:#1B80CF">ET (ET logique, ∧)</b> : L'opérateur ET (ou ET logique) est vrai seulement
                    si toutes les propositions connectées par ET sont vraies. Si P est vrai et Q est vrai, alors P ET Q
                    est vrai. Sinon, P ET Q est faux.</li>
                <li><b style="color:#1B80CF">OU (OU logique, ∨)</b> : L'opérateur OU (ou OU logique) est vrai si au
                    moins l'une des propositions connectées par OU est vraie. Si P est vrai ou Q est vrai (ou les deux),
                    alors P OU Q est vrai. Si les deux sont faux, alors P OU Q est faux.</li>
                <li><b style="color:#1B80CF">Implication (=>)</b> : L'implication (=>) exprime une relation où la vérité
                    de la première proposition entraîne la vérité de la seconde. Si P est vrai, alors P => Q est vrai,
                    peu importe la valeur de Q. Si P est faux, alors P => Q est toujours vrai, car il ne dit rien sur Q.
                </li>
                <li><b style="color:#1B80CF">Équivalence (<=>)</b> : L'équivalence (<=>) signifie que deux propositions
                        ont la même valeur de vérité dans toutes les situations. Si P est vrai et Q est vrai, ou si P
                        est faux et Q est faux, alors P <=> Q est vrai. Sinon, c'est faux.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">14
                <a class="prev" href="#slide13"></a>
                <a class="next" href="#slide15"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide15">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique propositionnelle</h1>
            <p>Supposons que nous ayons quatre propositions simples : P, Q, R et S.</p>
            <ul>
                <li><b style="color:#1B80CF">P</b> : Présence de l'eau.</li>
                <li><b style="color:#1B80CF">Q</b> : Présence de sable.</li>
                <li><b style="color:#1B80CF">R</b> : Présence d'oiseaux marins.</li>
                <li><b style="color:#1B80CF">S</b> : Présence de bateaux.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">15
                <a class="prev" href="#slide14"></a>
                <a class="next" href="#slide16"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide16">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique propositionnelle</h1>
            <p> Avec ces propositions, nous pouvons définir des règles pour déterminer si une image représente la mer :
            </p>
            <ul>
                <li> Si l'eau est présente (P), alors il est possible que l'image soit celle de la mer.</li>
                <li> Si en plus il y a du sable (Q), cela renforce la probabilité que l'image soit une plage de mer.
                </li>
                <li> Si des oiseaux marins sont présents (R), cela renforce également la probabilité que la scène soit
                    liée à la mer.</li>
                <li> Si des bateaux sont visibles (S), cela suggère une forte probabilité que la scène soit maritime.
                </li>
            </ul>
            <p>nous pouvons utiliser des opérateurs logiques pour combiner ces propositions et déterminer si l'image est
                celle de la mer :</p>
            <p><b>Image de la mer</b> : (P ET Q) OU (P ET R) OU (P ET S)</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">16
                <a class="prev" href="#slide15"></a>
                <a class="next" href="#slide17"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide17">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <p>Contrairement à la logique propositionnelle, qui traite uniquement de la vérité ou de la fausseté de
                propositions simples, la logique du premier ordre permet de représenter des informations structurées sur
                des objets et leurs relations. Voici quelques concepts clés de la logique du premier ordre :</p>
            <ul>
                <li><b style="color:#1B80CF">Variables</b> : Les variables sont des symboles qui représentent des objets
                    ou des éléments non spécifiés d'un domaine. Elles sont utilisées pour généraliser des expressions et
                    représenter des objets de manière générique.</li>
                <li><b style="color:#1B80CF">Constantes</b> : Les constantes sont des symboles qui représentent des
                    objets spécifiques et immuables d'un domaine.</li>
                <li><b style="color:#1B80CF">Fonctions</b> : Les fonctions sont des opérations qui prennent un ou
                    plusieurs arguments et renvoient un résultat.</li>
                <li><b style="color:#1B80CF">Prédicats</b> : Les prédicats sont des expressions qui décrivent des
                    relations entre des objets ou des propriétés de ces objets. </li>
                <li><b style="color:#1B80CF">Quantificateurs</b> : Les quantificateurs, tels que "pour tout" (∀) et "il
                    existe" (∃), sont utilisés pour spécifier la portée de variables dans une expression. </li>
                <li><b style="color:#1B80CF">Opérateurs logiques</b> : Les opérateurs logiques tels que "ET" (∧), "OU"
                    (∨), "NON" (¬), "Implication" (=&gt;), et "Équivalence" (&lt;=&gt;) sont utilisés pour combiner des
                    propositions et construire des formules plus complexes. </li>
            </ul>
            <p>Utilisez des parenthèses pour indiquer la priorité des opérations et la structure de la formule.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">17
                <a class="prev" href="#slide16"></a>
                <a class="next" href="#slide18"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide18">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <p>Exemple : </p>
            <ul>
                <li><b style="color:#1B80CF">Variables</b> : une variable pourrait être représentée par "x", où "x" peut
                    représenter n'importe quelle mer.</li>
                <li><b style="color:#1B80CF">Constantes</b> : des constantes pourraient être "Mer Méditerranée", "Mer
                    Noire" et "Mer Rouge" pour représenter des mers spécifiques.</li>
                <li><b style="color:#1B80CF">Fonctions</b> : Nous pourrions utiliser une fonction "Profondeur(x)" pour
                    représenter la profondeur de la mer x. Par exemple, "Profondeur(Mer Méditerranée)" pourrait renvoyer
                    la profondeur de la mer Méditerranée.</li>
                <li><b style="color:#1B80CF">Prédicats</b> : Un prédicat tel que "Salée(x)" pourrait toujours être
                    utilisé pour indiquer si une mer donnée (x) est salée ou non. Par exemple, "Salée(Mer Méditerranée)"
                    serait vrai car la mer Méditerranée est salée.. </li>
                <li><b style="color:#1B80CF">Quantificateurs</b> : Les quantificateurs définissent la portée des
                    variables dans une expression logique.
                    <ul>
                        <li>"∀x Salée(x)" signifierait que toutes les mers sont salées.</li>
                        <li>"∃x Superficie(x) > 100 000 km²" signifierait qu'il existe une mer dont la superficie est
                            supérieure à 100 000 kilomètres carrés.</li>
                    </ul>
                </li>
            </ul>
            <p>Les fonctions sont utilisées pour attribuer des valeurs à des objets ou effectuer des opérations, tandis
                que les prédicats sont utilisés pour exprimer des relations ou des propriétés entre des objets et
                renvoient une valeur booléenne indiquant si la relation est vraie ou non.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">18
                <a class="prev" href="#slide17"></a>
                <a class="next" href="#slide19"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide19">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <p>Utilisons l'exemple des règles pour confirmer qu'une image représente effectivement une mer.</p>
            <ul>
                <li><b style="color:#1B80CF">Constantes</b> : Nos constantes pourraient être les noms d'images
                    spécifiques ou d'autres identifiants uniques pour des images particulières.</li>
                <li><b style="color:#1B80CF">Variables</b> : Nous pourrions utiliser une variable, disons "x", pour
                    représenter une image générique.</li>
                <li><b style="color:#1B80CF">Prédicats</b> : Les prédicats sont des expressions qui décrivent des
                    relations entre des objets ou des propriétés de ces objets.
                    <ul>
                        <li> Un prédicat "ContientEau(x)" pourrait être utilisé pour indiquer si l'image x contient de
                            l'eau.</li>
                        <li> Un prédicat "ContientSable(x)" pourrait être utilisé pour indiquer si l'image x contient du
                            sable.</li>
                        <li> Un prédicat "ContientBateaux(x)" pourrait être utilisé pour indiquer si l'image x contient
                            des bateaux.</li>
                        <li> Un prédicat "ContientOiseauxMarins(x)" pourrait être utilisé pour indiquer si l'image x
                            contient des oiseaux marins.</li>
                    </ul>

                </li>
                <li><b style="color:#1B80CF">Quantificateurs</b> : Nous pourrions utiliser des quantificateurs tels que
                    "∃x" (il existe une image) ou "∀x" (pour toutes les images) pour spécifier la portée de nos règles.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">19
                <a class="prev" href="#slide18"></a>
                <a class="next" href="#slide20"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide20">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <p>1. Pour déterminer si une image représente une scène de mer, nous pourrions utiliser une règle du type
            </p>
            <p>
                <code>∀x (ContientEau(x) ∧ ContientSable(x) => EstMer(x))</code>
            </p>
            <p>2. Nous pourrions également ajouter des règles spécifiques pour détecter des éléments spécifiques : </p>
            <p>
                <code>∀x (ContientBateaux(x) => EstPort(x))</code>
            </p>
            <p>
                <code>∀x (ContientOiseauxMarins(x) => EstPlage(x))</code>
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">20
                <a class="prev" href="#slide19"></a>
                <a class="next" href="#slide21"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide21">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading"> Logique du premier ordre</h1>
            <p>3. Il existe au moins une image x telle que l'image contienne de l'eau et du sable.</p>
            <p>
                <code>∃x (ContientEau(x) ∧ ContientSable(x))</code>
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">21
                <a class="prev" href="#slide20"></a>
                <a class="next" href="#slide22"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide22">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique modale</h1>
            <p>La logique modale est une extension de la logique classique qui permet de raisonner sur la notion de
                "modalités", c'est-à-dire des catégories de propositions qui expriment des modalités ou des qualités
                spécifiques, telles que la nécessité, la possibilité, l'obligation, la croyance, etc</p>
            <p><b>Opérateurs modaux</b> : Les opérateurs modaux sont utilisés pour exprimer des modalités. Les deux
                opérateurs modaux les plus courants sont :</p>
            <ul>
                <li><b>◻ (carré)</b> : Il exprime la nécessité, indiquant que quelque chose est nécessairement vrai.
                </li>
                <li><b>◇ (losange)</b> : Il exprime la possibilité, indiquant que quelque chose est possible, mais pas
                    nécessairement vrai.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">22
                <a class="prev" href="#slide21"></a>
                <a class="next" href="#slide23"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide23">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique modale</h1>
            <p>En logique modale, les termes "nécessaire", "contingent", "possible" et "impossible" sont utilisés pour
                décrire les modalités ou les qualités d'une proposition. </p>
            <ul>
                <li><b>Nécessaire</b> : Une proposition est dite "nécessaire" si elle est vraie dans toutes les
                    situations possibles, c'est-à-dire qu'elle ne peut pas être fausse dans aucune situation imaginable.
                    En notation modale, on utilise l'opérateur "◻" (carré) pour représenter la nécessité. Ainsi, "◻(P)"
                    signifie "Il est nécessaire que P soit vrai."</li>
                <li><b>Contingent</b> : Une proposition est dite "contingente" si elle est vraie dans certaines
                    situations possibles et fausse dans d'autres. En d'autres termes, sa vérité dépend du contexte ou
                    des conditions. Les propositions contingentes ne sont ni nécessairement vraies ni nécessairement
                    fausses.</li>
                <li><b>Possible</b> : Une proposition est dite "possible" si elle est vraie dans au moins une situation
                    possible, même si elle n'est pas nécessairement vraie dans toutes les situations possibles. En
                    notation modale, on utilise l'opérateur "◇" (losange) pour représenter la possibilité. Ainsi, "◇(Q)"
                    signifie "Il est possible que Q soit vrai."</li>
                <li><b>Impossible</b> : Une proposition est dite "impossible" si elle est fausse dans toutes les
                    situations possibles, c'est-à-dire qu'elle ne peut pas être vraie dans aucune situation imaginable.
                    En notation modale, l'opérateur de négation "¬" peut être utilisé en conjonction avec l'opérateur de
                    possibilité "◇" pour représenter l'impossibilité. Ainsi, "¬◇(R)" signifie "Il est impossible que R
                    soit vrai."</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">23
                <a class="prev" href="#slide22"></a>
                <a class="next" href="#slide24"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide24">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Logique modale</h1>
            <p>Exemple </p>
            <ul>
                <li><b>Nécessaire</b> : "◻(Toute mer est salée)" signifie que dans toutes les situations possibles,
                    toutes les mers sont salées.</li>
                <li><b>Contingent</b> : "◇(Il peut y avoir des mers calmes)" signifie qu'il est possible d'avoir des
                    mers calmes, mais elles ne sont pas nécessairement calmes dans toutes les situations possibles.</li>
                <li><b>Possible</b> : : "◇(Il est possible qu'il y ait des tempêtes en mer)" signifie qu'il est possible
                    qu'il y ait des tempêtes en mer, mais elles ne sont pas nécessaires dans toutes les situations
                    possibles.</li>
                <li><b>Impossible</b> : "¬◇(Toutes les mers sont douces)" signifie qu'il est impossible que toutes les
                    mers soient douces.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">24
                <a class="prev" href="#slide23"></a>
                <a class="next" href="#slide25"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide25">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Raisonnement automatisé</h1>
            <p>Le raisonnement automatisé est un domaine de l'intelligence artificielle (IA) qui concerne la création de
                systèmes informatiques capables de tirer des conclusions logiques et de résoudre des problèmes de
                manière autonome, similaire à la manière dont les humains utilisent leur raisonnement pour résoudre des
                problèmes.</p>
            <ul>
                <li><b>Objectif</b> : L'objectif principal du raisonnement automatisé est de permettre aux machines de
                    prendre des décisions, de résoudre des problèmes et de répondre à des questions en utilisant des
                    règles logiques et des connaissances préalables. </li>
                <li><b>Inférence logique</b> : Les moteurs d'inférence sont des composants logiciels qui appliquent des
                    règles logiques et des axiomes pour déduire de nouvelles informations à partir des connaissances
                    existantes. Cela implique souvent l'utilisation de la logique formelle, telle que la logique
                    propositionnelle, la logique du premier ordre ou la logique modale.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">25
                <a class="prev" href="#slide24"></a>
                <a class="next" href="#slide26"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide26">
        <div class="header">
            <h1>1.2.1. Logique et raisonnement</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Raisonnement automatisé</h1>
            <p>Le raisonnement automatisé peut être expliqué en utilisant différentes logiques, notamment la logique
                propositionnelle, la logique du premier ordre et la logique modale. </p>
            <ul>
                <li><b>Raisonnement automatisé en logique propositionnelle</b> : Les connaissances sont représentées
                    sous forme de propositions atomiques et de règles logiques qui décrivent comment ces propositions
                    sont liées. Les moteurs d'inférence en logique propositionnelle appliquent des règles logiques pour
                    tirer des conclusions à partir des propositions existantes.</li>
                <li><b>Raisonnement automatisé en logique du premier ordre logique</b> : Les connaissances sont
                    représentées de manière plus expressive, ce qui permet de modéliser des relations complexes entre
                    objets et d'exprimer des généralisations.
                    Les moteurs d'inférence en logique du premier ordre utilisent des règles de déduction plus
                    sophistiquées, notamment l'utilisation de quantificateurs tels que "∀" (pour tout) et "∃" (il
                    existe).</li>
                <li><b>Raisonnement automatisé en logique modale :</b> : Les connaissances sont représentées avec des
                    opérateurs modaux pour exprimer des propriétés modales, ce qui permet de traiter l'incertitude et la
                    nécessité.
                    Les moteurs d'inférence en logique modale utilisent des règles modales spécifiques pour tirer des
                    conclusions en tenant compte des modalités.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">26
                <a class="prev" href="#slide25"></a>
                <a class="next" href="#slide27"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide27">
        <div class="header">
            <h1>1.2.2. Représentation des connaissances</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Introduction</h1>
            <p>La représentation des connaissances joue un rôle central dans la manière dont les systèmes informatiques
                comprennent, raisonnent et interagissent avec le monde.
                La représentation des connaissances désigne le processus de capture, de structuration et de stockage des
                informations et des connaissances de manière à les rendre utilisables par des systèmes informatiques.
                Cela implique de transformer des données brutes ou des concepts en une forme que les ordinateurs peuvent
                comprendre et exploiter pour résoudre des problèmes, prendre des décisions ou interagir avec les
                utilisateurs.</p>
            <ul>
                <li><b>Résolution de Problèmes</b> : Une représentation adéquate des connaissances permet aux systèmes
                    informatiques de modéliser des problèmes complexes et de les résoudre de manière efficace. Elle
                    facilite la manipulation et la déduction logique des informations pertinentes.</li>
                <li><b>Prise de Décisions</b> Les machines doivent comprendre le monde qui les entoure pour interagir
                    avec lui de manière significative. Une représentation des connaissances permet de modéliser des
                    concepts tels que les objets, les relations, les événements et les règles.</li>
                <li><b>Communication Homme-Machine</b> Lorsque des systèmes IA interagissent avec des utilisateurs
                    humains, une représentation des connaissances claire et conviviale est essentielle pour rendre ces
                    interactions compréhensibles et productives.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">27
                <a class="prev" href="#slide26"></a>
                <a class="next" href="#slide28"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide28">
        <div class="header">
            <h1>1.2.2. Représentation des connaissances</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Types de connaissances</h1>
            <p>Les types de connaissances peuvent être classés en plusieurs catégories, notamment les connaissances
                déclaratives, les connaissances procédurales, les connaissances explicites et les connaissances tacites.
            </p>
            <ul>
                <li><b>Connaissances déclaratives</b> : Les connaissances déclaratives se rapportent à "ce que nous
                    savons". Elles sont constituées de faits, d'informations et de déclarations qui décrivent le monde
                    ou une partie de celui-ci. Ces connaissances sont souvent exprimées sous forme de propositions ou de
                    déclarations qui peuvent être vraies ou fausses.</li>
                <li><b>Connaissances procédurales</b> Les connaissances procédurales concernent "comment faire quelque
                    chose". Elles sont liées aux compétences, aux savoir-faire et aux procédures nécessaires pour
                    accomplir des tâches ou des activités spécifiques. Ces connaissances sont généralement implicites et
                    liées à l'expérience pratique.</li>
                <li><b>Connaissances explicites</b> Les connaissances explicites sont des connaissances qui sont
                    clairement exprimées et documentées. Elles sont généralement formelles et structurées de manière à
                    être transmises et partagées facilement.
                    Ces connaissances sont souvent consignées dans des manuels, des livres, des bases de données, ou
                    d'autres formes de documentation.</li>
                <li><b>Connaissances tacites</b> Les connaissances tacites sont des connaissances qui sont difficiles à
                    exprimer verbalement ou à documenter de manière formelle. Elles résident souvent dans l'expérience
                    personnelle, l'intuition, ou les compétences pratiques. Ces connaissances sont souvent difficiles à
                    transférer d'une personne à une autre et sont souvent acquises par l'expérience.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">28
                <a class="prev" href="#slide27"></a>
                <a class="next" href="#slide29"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide29">
        <div class="header">
            <h1>1.2.2. Représentation des connaissances</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Représentation des connaissances déclaratives</h1>
            <p>Dans la représentation des connaissances déclaratives, les faits, les informations et les connaissances
                sont exprimés sous forme de propositions logiques.</p>
            <ul>
                <li>Logique propositionnelle</li>
                <li>Logique du premier ordre</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">29
                <a class="prev" href="#slide28"></a>
                <a class="next" href="#slide30"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide30">
        <div class="header">
            <h1>1.2.2. Représentation des connaissances</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Représentation des connaissances déclaratives</h1>
            <p>Graphes de Connaissances (Ontologies): Les ontologies sont des structures de données hiérarchiques qui
                organisent et hiérarchisent les connaissances en utilisant des concepts, des classes, des propriétés et
                des relations.</p>
            <ul>
                <li> <b>Concepts</b> : Les ontologies définissent des concepts qui représentent des entités ou des idées
                    du monde réel.</li>
                <li> <b>Classes</b> : Les concepts sont souvent organisés en classes.</li>
                <li> <b>Propriétés</b> : Les ontologies spécifient des propriétés et des relations entre les concepts.
                </li>
                <li> <b>Relations</b> : Les ontologies capturent les relations entre les concepts.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">30
                <a class="prev" href="#slide29"></a>
                <a class="next" href="#slide31"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide31">
        <div class="header">
            <h1>1.2.3. Agents intelligents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Introduction</h1>
            <p>Les agents intelligents sont des entités logicielles ou matérielles capables de percevoir leur
                environnement, de prendre des décisions, et d'agir pour atteindre des objectifs spécifiques.</p>
            <p>Un agent intelligent est un système informatique ou une entité physique qui possède certaines
                caractéristiques clés : </p>
            <ul>
                <li> <b>Perception</b> : Un agent intelligent est capable de percevoir son environnement à travers des
                    capteurs ou d'autres moyens. Il collecte des informations sur l'état du monde qui l'entoure.</li>
                <li> <b>Raisonnement</b> : L'agent intelligent peut traiter les informations perçues, effectuer des
                    calculs, et prendre des décisions basées sur ces données. Il peut utiliser des algorithmes, des
                    méthodes d'apprentissage automatique, ou des règles de raisonnement formelles pour cela.</li>
                <li> <b>Action</b> : En réponse à ses décisions, l'agent intelligent peut agir sur son environnement en
                    utilisant des actionneurs ou en émettant des commandes. Ses actions ont pour objectif d'atteindre
                    des buts ou des objectifs spécifiques.</li>
                <li> <b>Objectifs</b> : Les agents intelligents sont souvent dotés d'objectifs ou de buts à atteindre.
                    Ces objectifs définissent ce que l'agent tente d'accomplir dans son environnement.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">31
                <a class="prev" href="#slide30"></a>
                <a class="next" href="#slide32"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide32">
        <div class="header">
            <h1>1.2.3. Agents intelligents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Types d'agents intelligents</h1>
            <p>Les agents intelligents peuvent être classés en différents types en fonction de leurs caractéristiques et
                de leurs capacités. </p>
            <ul>
                <li> <b>Agents réactifs simples</b> : Les agents réactifs simples sont des agents intelligents qui
                    réagissent
                    directement aux stimuli de leur environnement sans avoir une représentation interne complexe du
                    monde.
                    <ul>
                        <li>Ils prennent des décisions en se basant sur des règles préétablies qui associent des entrées
                            (perceptions) à des sorties (actions).</li>
                        <li>Ces agents sont souvent utilisés pour des tâches spécifiques
                            où la réactivité immédiate est cruciale, comme dans la robotique industrielle. </li>
                        <li>Cependant, ils ont
                            tendance à manquer de capacité à anticiper ou à planifier des actions à long terme en
                            l'absence de
                            modèles internes complexes du monde.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">32
                <a class="prev" href="#slide31"></a>
                <a class="next" href="#slide33"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide33">
        <div class="header">
            <h1>1.2.3. Agents intelligents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Types d'agents intelligents</h1>
            <ul>
                <li> <b>Agents basés sur des modèles</b> : Les agents basés sur des modèles utilisent une représentation
                    interne du monde, généralement sous forme de modèles ou de cartes conceptuelles, pour comprendre
                    leur environnement.
                    <ul>
                        <li>Ils utilisent ces modèles pour anticiper les conséquences de leurs actions,
                            planifier des séquences d'actions et prendre des décisions éclairées.</li>
                        <li>Ces agents sont couramment
                            utilisés dans des domaines tels que la planification automatisée, la simulation, et la
                            modélisation
                            de systèmes complexes.</li>
                        <li>Ils sont plus flexibles que les agents réactifs simples, mais leur
                            performance dépend de la qualité de leurs modèles et de la capacité à anticiper les
                            résultats.</li>
                    </ul>
                </li>
                <li> <b>Agents basés sur les buts</b> : Les agents basés sur les buts ont des objectifs ou des buts à
                    atteindre, et leur comportement est guidé par la poursuite de ces buts.
                    <ul>
                        <li>Ils évaluent régulièrement
                            l'état de l'environnement et déterminent les actions à entreprendre pour se rapprocher de
                            leurs
                            objectifs.</li>
                        <li>Ces agents peuvent planifier et ajuster leurs actions en fonction de l'évolution de la
                            situation pour maximiser leurs chances de succès. Ils sont couramment utilisés dans des
                            domaines
                            tels que la planification de parcours, les systèmes de recommandation, et les agents
                            d'assistance
                            personnelle.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">33
                <a class="prev" href="#slide32"></a>
                <a class="next" href="#slide34"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide34">
        <div class="header">
            <h1>1.2.3. Agents intelligents</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Types d'agents intelligents</h1>
            <ul>
                <li> <b>Agents hybrides</b> : Certains agents intelligents combinent des caractéristiques de plusieurs
                    types
                    d'agents pour tirer parti des avantages de chacun.
                    <ul>
                        <li>Par exemple, un agent hybride pourrait être
                            réactif dans des situations immédiates, mais basé sur des modèles ou basé sur des buts pour
                            des
                            tâches plus complexes ou à long terme.</li>
                        <li>L'hybridation permet de créer des agents plus polyvalents
                            capables de s'adapter à une variété de scénarios.</li>
                        <ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">34
                <a class="prev" href="#slide33"></a>
                <a class="next" href="#slide35"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide35">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">3 approches</h1>
            <ol>
                <li><b>Apprentissage supervisé</b>:
                    <ul>
                        <li>Un modèle est formé à partir d'un ensemble de données de formation qui sont étiquetées,
                            c'est-à-dire que chaque exemple de données est associé à une étiquette ou une catégorie
                            connue.</li>
                        <li>L'objectif du modèle est d'apprendre à faire des prédictions en utilisant ces étiquettes de
                            manière à pouvoir généraliser et faire des prédictions précises sur de nouvelles données non
                            vues.</li>
                        <li>Par exemple, la classification d'images, la prédiction de prix, et la détection de spam dans
                            les emails.</li>
                    </ul>
                </li>
                <li><b>Apprentissage non supervisé</b>:
                    <ul>
                        <li>Il n'y a pas de données de formation labellisées.</li>
                        <li>Le modèle doit découvrir des structures, des modèles ou des regroupements dans les données
                            par lui-même.</li>
                        <li>Par exemple, la segmentation de clients en groupes, la réduction de la dimensionnalité, ou
                            la détection d'anomalies.</li>
                    </ul>
                </li>
                <li><b>Apprentissage semi-supervisé</b>:
                    <ul>
                        <li>Il repose sur un petit ensemble de données de formation étiquetées et une grande quantité de
                            données non étiquetées.</li>
                        <li>Le modèle utilise les données étiquetées pour apprendre à faire des prédictions, mais il
                            peut également tirer parti des données non étiquetées pour améliorer sa performance.</li>
                        <li>Cela peut être particulièrement utile lorsque l'obtention de données étiquetées est coûteuse
                            ou difficile.</li>
                    </ul>
                </li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">35
                <a class="prev" href="#slide34"></a>
                <a class="next" href="#slide36"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide36">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Formalisation</h1>
            <ul>
                <li><b>Vecteur euclidien</b>:
                    <ul>
                        <li>Un vecteur euclidien est un objet géométrique caractérisé par sa magnitude (longueur) et sa
                            direction. </li>
                        <li>Les vecteurs euclidiens sont couramment utilisés pour représenter des données sous forme de
                            points dans un espace multidimensionnel, où chaque dimension correspond à une
                            caractéristique ou une variable.</li>
                    </ul>
                </li>
                <li><b>Espace vectoriel</b>:
                    <ul>
                        <li>Un espace vectoriel est une collection de vecteurs qui peuvent être additionnés entre eux et
                            multipliés par des nombres (scalaires).</li>
                    </ul>
                </li>
                <li><b>Vecteur de caractéristiques (features)</b>:
                    <ul>
                        <li>Un vecteur de caractéristiques est un vecteur n-dimensionnel qui représente les
                            caractéristiques ou les attributs d'une entité. </li>
                    </ul>
                </li>
                <li><b>Espace de caractéristiques</b>:
                    <ul>
                        <li>L'espace de caractéristiques est l'espace vectoriel associé aux vecteurs de
                            caractéristiques.</li>
                        <li>Chaque dimension de cet espace représente une caractéristique particulière, et les vecteurs
                            sont utilisés pour positionner les données dans cet espace en fonction de leurs
                            caractéristiques.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">36
                <a class="prev" href="#slide35"></a>
                <a class="next" href="#slide37"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide37">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3>Exemples de caractéristiques</h3>
            <ul>
                <li><b>Images</b>: Dans le contexte des images, les vecteurs de caractéristiques peuvent être construits
                    à partir des valeurs des pixels. Chaque pixel peut être considéré comme une dimension, et un vecteur
                    de caractéristiques contiendra les valeurs de tous les pixels, permettant ainsi de représenter une
                    image sous forme de vecteur.</li>
                <li><b>Textes</b>: Pour les textes, les vecteurs de caractéristiques sont souvent construits à partir de
                    la fréquence d'apparition des mots, des phrases, ou des tokens dans un document. Cela permet de
                    représenter le contenu textuel en utilisant des valeurs numériques, ce qui est essentiel pour
                    l'analyse de texte et la recherche d'informations.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">37
                <a class="prev" href="#slide36"></a>
                <a class="next" href="#slide38"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide38">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Formalisation</h1>
            <ul>
                <li><b>Construction de caractéristiques<sup>1</sup></b>:
                    <ul>
                        <li>La construction de caractéristiques consiste à créer de nouvelles variables ou attributs à
                            partir de celles déjà présentes dans les données.</li>
                        <li>Cette étape peut être cruciale pour améliorer les performances des modèles d'apprentissage
                            machine en introduisant des informations pertinentes et en éliminant du bruit.</li>
                    </ul>
                </li>
                <li><b>Opérateurs de construction pour les caractéristiques</b>
                    <ul>
                        <li>Les opérateurs de construction sont des fonctions ou des opérations mathématiques qui
                            permettent de créer de nouvelles caractéristiques à partir de celles existantes. </li>
                        <li>Parmi les opérateurs couramment utilisés, on trouve les opérateurs d'égalité (comparaisons),
                            les opérateurs arithmétiques (addition, soustraction, multiplication, division), les
                            opérateurs de tableau (min, max, moyenne, médiane, etc.), les fonctions de transformation,
                            etc.</li>
                    </ul>
                </li>
            </ul>
            <ol style="font-size:2vh">
                <li>https://en.wikipedia.org/wiki/Feature_vector</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">38
                <a class="prev" href="#slide37"></a>
                <a class="next" href="#slide39"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide39">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3>Exemple</h3>
            <ul>
                <li>Soit <b>Année de naissance</b> et <b>Année de décès</b> deux caractéristiques existantes.</li>
                <li>Une nouvelle caractéristique appelée <b>âge</b> est créée. <b>âge</b> = <b>Année de décès</b> -
                    <b>Année de naissance</b>
                </li>
            </ul>
            <p>La construction de caractéristiques est une étape essentielle dans le pipeline de prétraitement des
                données en apprentissage machine, car elle peut aider à rendre les données plus informatives pour les
                algorithmes d'apprentissage.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">39
                <a class="prev" href="#slide38"></a>
                <a class="next" href="#slide40"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide40">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <ul>
                    <li><b>Le nombre d'exemples d'entraînement (N)</b> : Cela représente la quantité d'exemples de
                        données que vous avez pour entraîner un modèle supervisé. Chaque exemple d'entraînement se
                        compose d'un vecteur de caractéristiques (x) et de son label (y).</li>
                    <li><b>L'espace de saisie des caractéristiques (X)</b> : C'est l'ensemble de toutes les combinaisons
                        possibles de vecteurs de caractéristiques qui peuvent être utilisées comme entrée pour le
                        modèle. Cet espace est défini par les caractéristiques que vous avez extraites des données.</li>
                    <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble de toutes les
                        valeurs possibles que peuvent prendre les étiquettes ou les labels. </li>
                    <li><b>Exemples d'entraînement (D)</b> : C'est votre ensemble de données d'entraînement, composé de
                        paires (x, y) où x est le vecteur de caractéristiques et y est le label correspondant.</li>
                    <li><b>Objectif de l'algorithme d'apprentissage supervisé</b> : Il s'agit de trouver une fonction
                        (g) qui associe un vecteur de caractéristiques (x) à un label (y). L'ensemble des fonctions
                        possibles est appelé espace des hypothèses (G). L'objectif est de choisir la fonction (g) qui
                        minimise l'erreur de prédiction sur les exemples d'entraînement et généralise bien sur de
                        nouvelles données.</li>
                    <li><b>Fonction d'évaluation (F)</b> : Elle indique l'espace des fonctions d'évaluation utilisées
                        pour évaluer la performance des fonctions hypothétiques. L'objectif est de trouver la fonction
                        (g) qui renvoie la fonction d'évaluation (f) la plus élevée, c'est-à-dire celle qui donne les
                        prédictions les plus précises.</li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">40
                <a class="prev" href="#slide39"></a>
                <a class="next" href="#slide41"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide41">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Formalisation: Apprentissage supervisé</h1>
                <p>Cette formalisation est au cœur de l'apprentissage supervisé, où l'objectif est d'apprendre à partir
                    d'exemples étiquetés et de trouver une fonction qui puisse prédire de manière précise les étiquettes
                    pour de nouvelles données non vues.</p>
                <ul>
                    <li>Soit \(N\) le nombre d'exemples d'entraînement</li>
                    <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                    <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                    <li>Soit \({(x_1, y_1),...,(x_N, y_N)}\) les \(N\) exemples d'entraînement, où
                        <ul>
                            <li>\(x_i\) est le vecteur de caractéristiques de <i>i<sup>ème</sup></i> exemple
                                d'entraînement.
                            </li>
                            <li>\(y_i\) est son label.</li>
                        </ul>
                    </li>
                    <li>L'objectif de l'algorithme d'apprentissage supervisé est de trouver \(g: X &#8594; Y\), où
                        <ul>
                            <li><i>g</i> est l'une des fonctions de l'ensemble des fonctions possibles <i>G</i> (espace
                                des
                                hypothèses)</li>
                        </ul>
                    </li>
                    <li><b>Fonction d'évaluation <i>F</i></b> indiquent l'espace des fonctions d'évaluation, où
                        <ul>
                            <li>\(f: X &#215; Y &#8594; R\) telle que <i>g</i> renvoie la fonction d'évaluation la plus
                                élevée.</li>
                        </ul>
                    </li>
                </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">41
                <a class="prev" href="#slide40"></a>
                <a class="next" href="#slide42"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide42">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage non supervisé</h1>
            <ul>
                <li><b>L'espace de saisie des caractéristiques (X)</b> : C'est l'ensemble de toutes les combinaisons
                    possibles de vecteurs de caractéristiques qui peuvent être utilisées comme entrée pour le modèle en
                    apprentissage non supervisé. Cet espace est défini par les caractéristiques que vous avez extraites
                    des données.</li>
                <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble des caractéristiques
                    de sortie potentielles. Contrairement à l'apprentissage supervisé, en apprentissage non supervisé, Y
                    ne consiste pas en des étiquettes ou des labels prédéfinis, mais plutôt en des transformations, des
                    représentations, ou des caractéristiques extraites des données d'entrée.</li>
                <li><b>Objectif de l'algorithme d'apprentissage non supervisé</b> : L'objectif est de trouver une
                    correspondance entre l'espace de saisie des caractéristiques (X) et l'espace des caractéristiques de
                    sortie (Y). Cela peut impliquer diverses tâches, telles que la réduction de la dimensionnalité, la
                    classification automatique de données non étiquetées, la détection d'anomalies, la segmentation, ou
                    la représentation latente des données.</li>
                <li><b>Mise en correspondance X → Y</b> : Cette mise en correspondance peut être réalisée de différentes
                    manières, selon la tâche d'apprentissage non supervisé spécifique. Par exemple, dans la réduction de
                    la dimensionnalité, X peut être une représentation à haute dimension des données, tandis que Y
                    représente la version réduite de ces données, souvent avec moins de dimensions.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">42
                <a class="prev" href="#slide41"></a>
                <a class="next" href="#slide43"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide43">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage non supervisé</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>L'objectif de l'algorithme d'apprentissage non supervisé est
                    <ul>
                        <li>trouver la mise en correspondance \(X &#8594; Y\)</li>
                    </ul>
                </li>
            </ul>
            <p>L'apprentissage non supervisé est utilisé pour explorer et découvrir des modèles, des structures ou des
                caractéristiques inhérentes aux données, sans l'utilisation d'étiquettes ou de labels préalables. Il est
                couramment utilisé dans des domaines tels que la clustering, l'analyse de composantes principales (PCA),
                l'analyse en composantes indépendantes (ICA), et bien d'autres.</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">43
                <a class="prev" href="#slide42"></a>
                <a class="next" href="#slide44"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide44">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li><b>L'espace de saisie des caractéristiques (X)</b> : Il s'agit de l'ensemble de toutes les
                    combinaisons possibles de vecteurs de caractéristiques qui peuvent être utilisés comme entrée pour
                    le modèle en apprentissage semi-supervisé.</li>
                <li><b>L'espace des caractéristiques de sortie (Y)</b> : Il représente l'ensemble des caractéristiques
                    de sortie potentielles, mais contrairement à l'apprentissage supervisé, il n'est pas nécessairement
                    constitué d'étiquettes ou de labels prédéfinis.</li>
                <li><b>Ensemble d'exemples d'exercices étiquetés (l)</b> : Cela correspond à un sous-ensemble d'exemples
                    qui ont été annotés ou étiquetés avec des valeurs de sortie connues.</li>
                <li><b>Ensembles des vecteurs de caractéristiques non étiquetées (u)</b> : Il s'agit des exemples non
                    étiquetés, où les valeurs de sortie ne sont pas connues.</li>
                <li><b>Objectif de l'algorithme d'apprentissage semi-supervisé</b> : L'objectif principal est de trouver
                    des étiquettes correctes pour les exemples non étiquetés (apprentissage transductif), ainsi que de
                    trouver la bonne mise en correspondance entre les caractéristiques d'entrée et les caractéristiques
                    de sortie (apprentissage inductif).
                    <ul>
                        <li><b>Apprentissage transductif</b> : Il s'agit de trouver des étiquettes correctes pour les
                            exemples non étiquetés. Cela revient à prédire les valeurs de sortie pour les exemples non
                            étiquetés sans nécessairement chercher à généraliser à de nouvelles données.</li>
                        <li><b>Apprentissage inductif</b> : Cela concerne la recherche de la bonne mise en
                            correspondance entre les vecteurs de caractéristiques d'entrée et les caractéristiques de
                            sortie. Cela peut inclure la généralisation à de nouvelles données en utilisant le modèle
                            appris.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">44
                <a class="prev" href="#slide43"></a>
                <a class="next" href="#slide45"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide45">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Formalisation: Apprentissage semi-supervisé</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>Soit \({(x_1, y_1),...,(x_l, y_l)}\) l'ensemble d'exemples d'exercices étiquetés</li>
                <li>Soit \({x_{l+1},...,x_{l+u}}\) sont les \(u\) ensembles des vecteurs de caractéristiques non
                    étiquetées de \(X\).</li>
                <li>L'objectif de l'algorithme d'apprentissage semi-supervisé est de faire
                    <ul>
                        <li><b>l'apprentissage transductif</b>, c'est-à-dire trouver des étiquettes correctes pour
                            \({x_{l+1},...,x_{l+u}}\).</li>
                        <li><b>l'apprentissage inductif</b>, c'est-à-dire trouver la bonne mise en correspondance \(X
                            &#8594; Y\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">45
                <a class="prev" href="#slide44"></a>
                <a class="next" href="#slide46"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide46">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Classification: Définition formelle</h1>
            <ul>
                <li>Soit \(X\) l'espace de saisie des caractéristiques</li>
                <li>Soit \(Y\) l'espace des caractéristiques de sortie (des étiquettes)</li>
                <li>L'objectif de l'algorithme de classification (ou classificateur) est de trouver \({(x_1,
                    y_1),...,(x_l, y_k)}\), c'est-à-dire l'attribution d'une étiquette connue à chaque vecteur de
                    caractéristique d'entrée, où
                    <ul>
                        <li>\(x_i &#8712; X \)</li>
                        <li>\(y_i &#8712; Y \)</li>
                        <li>\(|X| = l \)</li>
                        <li>\(|Y| = k \)</li>
                        <li>\(l &gt;= k\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">46
                <a class="prev" href="#slide45"></a>
                <a class="next" href="#slide47"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide47">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classificateurs</h3>
            <ul>
                <li>Algorithme de classification</li>
                <li>Deux types de classificateurs:
                    <ul>
                        <li><b>Classificateurs binaires</b> attribue un objet à l'une des deux classes</li>
                        <li><b>Classificateurs multiclasses</b> attribue un objet à une ou plusieurs classes</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">47
                <a class="prev" href="#slide46"></a>
                <a class="next" href="#slide48"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide48">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification binaire</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/binaryclassifier.svg"
                    height="400px" />
                <figcaption>Classification binaire</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">48
                <a class="prev" href="#slide47"></a>
                <a class="next" href="#slide49"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide49">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Linear Classificateurs</h3>
            <ul>
                <li>Fonction linéaire attribuant un score à chaque catégorie possible en combinant le vecteur de
                    caractéristiques d'une instance avec un vecteur de poids, en utilisant un produit de points.</li>
                <li>Formalisation :
                    <ul>
                        <li>Soit <i><b>X</b></i> être l'espace de saisie des caractéristiques et <i><b>x</b><sub>i</sub>
                                &#8712; <b>X</b></i></li>
                        <li>Soit <i><b>&#946;</b><sub>k</sub></i> un vecteur de poids pour la catégorie <i>k</i></li>
                        <li><i>score(<b>x</b><sub>i</sub>, k) = <b>x</b><sub>i</sub>.<b>&#946;</b><sub>k</sub></i>,
                            score pour l'attribution de la catégorie <i>k</i> à l'instance <i><b>x</b><sub>i</sub></i>.
                            La catégorie qui donne le score le plus élevé est
                            attribuée à la catégorie de l'instance.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">49
                <a class="prev" href="#slide48"></a>
                <a class="next" href="#slide50"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide50">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Évaluation</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/positivenegative.svg" height="400px" />
                <figcaption>Les vrais positifs et les vrais négatifs</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">50
                <a class="prev" href="#slide49"></a>
                <a class="next" href="#slide51"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide51">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Évaluation</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" height="400px" />
                <figcaption>Précision et rappel</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">51
                <a class="prev" href="#slide50"></a>
                <a class="next" href="#slide52"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide52">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Évaluation</h2>
            <p>Soit</p>
            <ul>
                <li><i>tp</i>: nombre de vrais postifs</li>
                <li><i>fp</i>: nombre de faux positifs</li>
                <li><i>fn</i>: nombre de faux négatifs</li>
            </ul>
            <figure class="gridcontent">
                <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" height="400px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">52
                <a class="prev" href="#slide51"></a>
                <a class="next" href="#slide53"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide53">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Évaluation</h2>
            <p>Alors</p>
            <ul>
                <li>Précision \[p = \frac{tp}{(tp + fp)}\]</li>
                <li>Rappel (Recall) \[r = \frac{tp}{(tp + fn)}\]</i>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">53
                <a class="prev" href="#slide52"></a>
                <a class="next" href="#slide54"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide54">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Évaluation</h2>
            <ul>
                <li>score F1 est la moyenne harmonique de la précision et du rappel : </li>
                <li>F1-score \[f1 = 2 * \frac{(p * r)}{(p + r)}\]</li>
                <li>F1-score: meilleure valeur à 1 (précision et rappel parfaits) et pire à 0.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">54
                <a class="prev" href="#slide53"></a>
                <a class="next" href="#slide55"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide55">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Évaluation</h2>
            <ul>
                <li>\(F_\beta\)-score utilise un facteur réel positif β, où β est choisi de telle sorte que le rappel
                    est considéré comme β fois plus important que la précision, est : </li>
                <li>\(F_\beta\)-score \[F_\beta = (1 + \beta^2) \cdot \frac{\mathrm{p} \cdot \mathrm{r}}{(\beta^2 \cdot
                    \mathrm{p}) + \mathrm{r}}\]</li>
                <li>Exemple: \(F_2\) score</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">55
                <a class="prev" href="#slide54"></a>
                <a class="next" href="#slide56"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide56">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Évaluation: matrice de confusion</h2>
            <ul>
                <li>une matrice qui mesure la qualité d'un système de classification</li>
                <li>chaque ligne de la matrice représente les instances d'une classe prédite</li>
                <li>chaque colonne représente les instances d'une classe réelle</li>
                <li>Toutes les prédictions correctes sont situées dans la diagonale du tableau</li>
                <li>Les erreurs de prédiction seront représentées par des valeurs situées en dehors de la diagonale.
                </li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2018/DataMining/positivenegative.svg" height="200px" />
                <figcaption>Les vrais positifs et les vrais négatifs</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">56
                <a class="prev" href="#slide55"></a>
                <a class="next" href="#slide57"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide57">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Évaluation: matrice de confusion</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix.png" height="400px" />
                <figcaption>Matrice de confusion pour un classificateur SVM pour les chiffres manuscrits (MNIST)
                </figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">57
                <a class="prev" href="#slide56"></a>
                <a class="next" href="#slide58"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide58">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Évaluation: matrice de confusion</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix1.png" height="400px" />
                <figcaption>Matrice de confusion pour un perceptron pour les chiffres manuscrits (MNIST)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">58
                <a class="prev" href="#slide57"></a>
                <a class="next" href="#slide59"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide59">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification multiclasse</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg"
                    height="400px" />
                <figcaption>Classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">59
                <a class="prev" href="#slide58"></a>
                <a class="next" href="#slide60"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide60">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h3 class="topicsubheading">Classification multiclasse [Aly 2005]</h3>
            <ul>
                <li>Transformation en classification binaire
                    <ul>
                        <li>L'approche un contre le reste (Un contre tous)</li>
                        <li>L'approche un-contre-un</li>
                    </ul>
                </li>
                <li>Extension de la classification binaire
                    <ul>
                        <li>Réseaux de neurones</li>
                        <li>k-voisins les plus proches</li>
                    </ul>
                </li>
                <li>la classification hiérarchique.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">60
                <a class="prev" href="#slide59"></a>
                <a class="next" href="#slide61"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide61">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification multiclasse</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg"
                    height="400px" />
                <figcaption>Classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">61
                <a class="prev" href="#slide60"></a>
                <a class="next" href="#slide62"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide62">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification multiclasse</h2>
            <h3 class="topicsubheading">One-vs.-rest (One-vs.-all) strategy</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsall.svg" height="350px" />
                <figcaption>La strategie un-contre le rest pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">62
                <a class="prev" href="#slide61"></a>
                <a class="next" href="#slide63"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide63">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification multiclasse</h2>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <ul>
                <li>Entraîner un seul classificateur par classe, avec les échantillons de cette classe comme
                    échantillons positifs et tous les autres comme négatifs. </li>
                <li>Chaque classificateur produit un score de confiance réel pour sa décision</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsall.svg" height="200px" />
                <figcaption>La strategie un-contre le rest pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">63
                <a class="prev" href="#slide62"></a>
                <a class="next" href="#slide64"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide64">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification multiclasse</h2>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <ul>
                <li>Entrées :
                    <ul>
                        <li>\(L\), un apprenant (algorithme d'entraînement pour les classificateurs binaires)</li>
                        <li>échantillons \(X\)</li>
                        <li>étiquettes \(y\), où \(y_i ∈ \{1,..,K \} \) est l'étiquette de l'échantillon \(X_i\)
                    </ul>
                </li>
                <li>Sortie :
                    <ul>
                        <li>une liste de classificateurs \(f_k\), où \(k ∈ \{1,..,K \} \)
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">64
                <a class="prev" href="#slide63"></a>
                <a class="next" href="#slide65"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide65">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification multiclasse</h2>
            <h3 class="topicsubheading">One-vs.-rest or One-vs.-all (OvR, OvA) strategy</h3>
            <p>Prendre des décisions signifie appliquer tous les classificateurs à un échantillon invisible x et prédire
                l'étiquette k pour laquelle le classificateur correspondant rapporte le score de confiance le plus élevé
                : \[\hat{y} = \underset{k \in
                \{1 \ldots K\}}{\arg\!\max}\; f_k(x)\]</p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">65
                <a class="prev" href="#slide64"></a>
                <a class="next" href="#slide66"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide66">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification multiclasse</h2>
            <h3 class="topicsubheading">One-vs.-one strategy</h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsone.svg" height="300px" />
                <figcaption>La strategie un-contre-un pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">66
                <a class="prev" href="#slide65"></a>
                <a class="next" href="#slide67"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide67">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Classification multiclasse</h2>
            <h3 class="topicsubheading">One-vs.-one strategy</h3>
            <li>nécessite l'entraînement des \(\frac{K (K - 1)}{2}\) classificateurs binaires</li>
            <li>chaque classificateur reçoit les échantillons d'une paire de classes du jeu de formation original, et
                doit apprendre à distinguer ces deux classes.</li>
            <li>Au moment de la prédiction, un système de vote est appliqué : tous les \(\frac{K (K - 1)}{2}\)
                classificateurs sont appliqués à un échantillon non vu et la classe qui a obtenu le plus grand nombre de
                prédictions est prédite par le classificateur
                combiné.
            </li>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsone.svg" height="200px" />
                <figcaption>La strategie un-contre-un pour la classification multiclasse</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">67
                <a class="prev" href="#slide66"></a>
                <a class="next" href="#slide68"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide68">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Introduction</h2>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Colored_neural_network.svg" />
                <figcaption>Réseaux de neurones artificiels</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">68
                <a class="prev" href="#slide67"></a>
                <a class="next" href="#slide69"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide69">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicheading">Perceptron</h2>
            <ul>
                <li>Algorithme pour l'apprentissage supervisé des classificateurs binaires</li>
                <li>Le classificateur binaire est un classificateur qui décide si une entrée donnée appartient ou non à
                    une classe particulière</li>
                <li>Inventé en 1958 par Frank Rosenblatt</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">69
                <a class="prev" href="#slide68"></a>
                <a class="next" href="#slide70"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide70">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron</h1>
            <figure>
                <img src="../../2021/MachineLearning/Perceptron_example.svg" height="350px" />
                <figcaption>Perceptron en mettant à jour sa limite linéaire à mesure que d'autres exemples de formation
                    sont ajoutés.<sup>1</sup></figcaption>
            </figure>
            <ol style="font-size:2vh">
                <li>Source: https://en.wikipedia.org/wiki/File:Perceptron_example.svg</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">70
                <a class="prev" href="#slide69"></a>
                <a class="next" href="#slide71"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide71">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Perceptron.svg" height="400px" />
                <figcaption>Perceptron</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">71
                <a class="prev" href="#slide70"></a>
                <a class="next" href="#slide72"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide72">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Perceptron: Définition formelle</h1>
            <ul>
                <li>Soit \(y = f(z)\) la sortie du perceptron pour un vecteur d'entrée <i>z</i></li>
                <li>Soit \(N\) le nombre d'exemples d'entraînement</li>
                <li>Soit <i><b>X</b></i> l'espace de saisie des caractéristiques</li>
                <li>Soit \({(x_{1}, d_{1}),...,(x_{N}, d_{N})}\) be the <i><b>N</b></i> training examples, where
                    <ul>
                        <li>\(x_i\) est le vecteur caractéristique de <i>i<sup>ème</sup></i> exemple d'entraînement.
                        </li>
                        <li>\(d_i\) est la valeur de sortie souhaitée</li>
                        <li>\(x_{j,i}\) est la <i>i<sup>ème</sup></i> caractéristique de <i>j<sup>ème</sup></i> exemple
                            d'entraînement.</li>
                        <li>\(x_{j,0} = 1\)</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">72
                <a class="prev" href="#slide71"></a>
                <a class="next" href="#slide73"></a>est le taux d'apprentissage.
            </div>
        </div>
    </section>
    <section class="slide" id="slide73">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Perceptron: Définition formelle</h1>
            <ul>
                <li>Les poids sont représentés de la manière suivante:
                    <ul>
                        <li>\(w_i\) est la <i>i<sup>ème</sup></i> valeur du vecteur de poids.</li>
                        <li>\(w_i(t)\) est la <i>i<sup>ème</sup></i> valeur du vecteur de poids à un moment donné t.
                        </li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">73
                <a class="prev" href="#slide72"></a>
                <a class="next" href="#slide74"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide74">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Perceptron : Étapes</h1>
            <ol>
                <li>Initialiser les poids et les seuils</li>
                <li>Pour chaque exemple, \((x_j, d_j)\) dans l'ensemble d'entraînement<i></i>
                    <ul>
                        <li>Calculer la sortie actuelle : \[y_j(t)= f[w(t).x_j]\] \[= f[w_0(t)x_{j,0} + w_1(t)x_{j,1} +
                            w_2(t)x_{j,2} + \dotsb + w_n(t)x_{j,n}]\]</li>
                        <li>Calculer le poids: \[w_i(t + 1) = w_i(t) + r. (d_j-y_j(t))x_{j,i}\]</li>
                    </ul> \(r\) est le taux d'apprentissage.
                </li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">74
                <a class="prev" href="#slide73"></a>
                <a class="next" href="#slide75"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide75">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1>Perceptron : Étapes</h1>
            <ol start="3">
                <li>Répétez l'étape 2 jusqu'à l'erreur d'itération \[\frac{1}{s} (&#931; |d_j - y_j(t)|)\] est inférieur
                    au seuil spécifié par l'utilisateur \(\gamma\), ou un nombre prédéterminé d'itérations ont été
                    effectuées, où \(s\) est à nouveau la taille
                    de l'ensemble de l'échantillon.</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">75
                <a class="prev" href="#slide74"></a>
                <a class="next" href="#slide76"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide76">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: fonction d'identité</h2>
            <h4>Équation</h4>
            <p>\[f(x)=x\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=1\]</p>
            <h3></h3>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_identity.svg"
                    height="380px" />
                <figcaption>Fonction d'identité</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">76
                <a class="prev" href="#slide75"></a>
                <a class="next" href="#slide77"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide77">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Fonction d'activation: pas binaire</h2>
                <h4>Équation</h4>
                <p>\[f(x) = \begin{cases} 0 & \text{for } x
                    < 0\\ 1 & \text{for } x \ge 0 \end{cases} \]</p>
                        <h4>Dérivée</h4>
                        <p>\[f'(x) = \begin{cases} 0 & \text{for } x \ne 0\\ ? & \text{for } x = 0\end{cases}\]</p>
                        <figure>
                            <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_binary_step.svg"
                                height="380px" />
                            <figcaption>Pas binaire</figcaption>
                        </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">77
                <a class="prev" href="#slide76"></a>
                <a class="next" href="#slide78"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide78">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: fonction sigmoïde</h2>
            <h4>Équation</h4>
            <p>\[f(x)=\sigma(x)=\frac{1}{1+e^{-x}}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=f(x)(1-f(x))\]</p>
            <figure>
                <img src="../../2021/MachineLearning/Logistic-curve.svg" height="380px" />
                <figcaption>La fonction sigmoïde</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">78
                <a class="prev" href="#slide77"></a>
                <a class="next" href="#slide79"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide79">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: TanH</h2>
            <h4>Équation</h4>
            <p>\[f(x)=\tanh(x)=\frac{(e^{x} - e^{-x})}{(e^{x} + e^{-x})}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=1-f(x)^2\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_tanh.svg" height="380px" />
                <figcaption>TanH</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">79
                <a class="prev" href="#slide78"></a>
                <a class="next" href="#slide80"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide80">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: Rectified linear unit: ReLU</h2>
            <h4>Équation</h4>
            <p>\[f(x) = \begin{cases} 0 & \text{for } x \le 0\\ x & \text{for } x > 0\end{cases} = \max\{0,x\}= x
                \textbf{1}_{x>0}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x) = \begin{cases} 0 & \text{for } x \le 0\\ 1 & \text{for } x > 0\end{cases}\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_rectified_linear.svg"
                    height="380px" />
                <figcaption>Unité linéaire rectifiée (ReLU)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">80
                <a class="prev" href="#slide79"></a>
                <a class="next" href="#slide81"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide81">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Fonction d'activation: Gaussien</h2>
            <h4>Équation</h4>
            <p>\[f(x)=e^{-x^2}\]</p>
            <h4>Dérivée</h4>
            <p>\[f'(x)=-2xe^{-x^2}\]</p>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_gaussian.svg"
                    height="380px" />
                <figcaption>Gaussien</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">81
                <a class="prev" href="#slide80"></a>
                <a class="next" href="#slide82"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide82">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Perceptron multiclasse</h2>
            <ul>
                <li>Perceptron peut être généralisé à la classification multiclasse. </li>
                <li>Une fonction de représentation d'élément \(f( x , y )\) fait correspondre chaque paire
                    d'entrée/sortie possible à un vecteur d'élément à valeur réelle en dimension finie.</li>
                <li>le vecteur de caractéristique est multiplié par un vecteur de poids \(w\), mais le score obtenu est
                    maintenant utilisé pour choisir parmi de nombreux résultats possibles : \[\hat y =
                    \operatorname{argmax}_y f(x,y) \cdot w.\]</li>
                <li>La réapprentissage se fait par itération sur les exemples, en prédisant un résultat pour chacun, en
                    laissant les poids inchangés lorsque le résultat prédit correspond à l'objectif, et en les modifiant
                    lorsqu'il ne correspond pas. La mise
                    à jour devient : \[w_{t+1} = w_t + f(x, y) - f(x,\hat y)\].</li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">82
                <a class="prev" href="#slide81"></a>
                <a class="next" href="#slide83"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide83">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Neurones biologiques</h2>
            <figure>
                <img src="../../2021/MachineLearning/Neuron3.png" height="350px" />
                <figcaption>Neurone biologique<sup>1</sup></figcaption>
            </figure>
            <ol style="font-size:2vh">
                <li>https://en.wikipedia.org/wiki/File:Neuron3.png</li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">83
                <a class="prev" href="#slide82"></a>
                <a class="next" href="#slide84"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide84">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseau de neurones</h2>
            <ul>
                <li>collection d'unités ou de nœuds connectés, appelés neurones artificiels, qui modèlent vaguement les
                    neurones d'un cerveau biologique.</li>
                <li>Chaque connexion, comme les synapses dans un cerveau biologique, peut transmettre un signal aux
                    autres neurones. </li>
                <li>Un neurone artificiel qui reçoit un signal le traite ensuite et peut signaler les neurones qui lui
                    sont connectés. </li>
                <li> Le "signal" à une connexion est un nombre réel, et la sortie de chaque neurone est calculée par une
                    fonction non linéaire de la somme de ses entrées. </li>
                <li>Les neurones et les arêtes (connexions) ont généralement un poids qui s'ajuste au fur et à mesure de
                    l'apprentissage. </li>
                <li>Le poids augmente ou diminue la force du signal au niveau d'une connexion.</li>
                <li> Les neurones peuvent avoir un seuil tel qu'un signal n'est envoyé que si le signal global franchit
                    ce seuil. </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">84
                <a class="prev" href="#slide83"></a>
                <a class="next" href="#slide85"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide85">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseau de neurones artificiels: les couches</h2>
            <ul>
                <li>Les neurones sont agrégés en couches.</li>
                <li>Différentes couches peuvent effectuer des transformations différentes sur leurs entrées.</li>
                <li>Les signaux passent de la première couche (la couche d'entrée) à la dernière couche (la couche de
                    sortie), éventuellement après avoir traversé les couches plusieurs fois.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">85
                <a class="prev" href="#slide84"></a>
                <a class="next" href="#slide86"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide86">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseau de neurones artificiels: l'entraînement</h2>
            <ul>
                <li>Les réseaux neuronaux apprennent (ou sont entraînés) en traitant des exemples.</li>
                <li>chaque exemple contient une "entrée" et un "résultat" connus.</li>
                <li><b>Erreur</b>: L'entraînement d'un réseau de neurones à partir d'un exemple donné est généralement
                    effectué en déterminant la différence entre la sortie traitée du réseau (souvent une prédiction) et
                    une sortie cible</li>
                <li> Le réseau ajuste ensuite ses associations pondérées en fonction d'une règle d'apprentissage et en
                    utilisant cette valeur d'erreur. </li>
                <li> Des ajustements successifs amèneront le réseau de neurones à produire un résultat de plus en plus
                    similaire au résultat cible.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">86
                <a class="prev" href="#slide85"></a>
                <a class="next" href="#slide87"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide87">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <ul>
                <li>Neurones</li>
                <li>Connexions et poids</li>
                <li>Fonction de propagation</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">87
                <a class="prev" href="#slide86"></a>
                <a class="next" href="#slide88"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide88">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Neurones</h2>
            <ul>
                <li>Chaque neurone artificiel a des entrées et produit une seule sortie qui peut être envoyée à
                    plusieurs autres neurones. </li>
                <li>Les entrées peuvent être les valeurs caractéristiques d'un échantillon de données externes</li>
                <li>Les sorties des neurones de sortie finale du réseau neuronal accomplissent la tâche</li>
                <li><b>Fonction d'activation</b>
                    <ul>
                        <li>Pour trouver la sortie du neurone, nous prenons d'abord la somme pondérée de tous les
                            intrants</li>
                        <li>Nous ajoutons un terme de biais à cette somme. Cette somme pondérée est parfois appelée
                            l'activation.</li>
                        <li>Cette somme est ensuite passée par une fonction d'activation (généralement non linéaire)
                            pour produire le résultat.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">88
                <a class="prev" href="#slide87"></a>
                <a class="next" href="#slide89"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide89">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Connexions et poids</h2>
            <ul>
                <li>Le réseau est constitué de connexions, chaque connexion fournissant la sortie d'un neurone comme
                    entrée à un autre neurone. </li>
                <li>Chaque connexion se voit attribuer un poids qui représente son importance relative</li>
                <li>Un neurone donné peut avoir plusieurs connexions d'entrée et de sortie.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">89
                <a class="prev" href="#slide88"></a>
                <a class="next" href="#slide90"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide90">
        <div class="header">
            <h1>1.2.4. Apprentissage machine</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Fonction de propagation</h2>
            <ul>
                <li>La fonction de propagation calcule l'entrée d'un neurone à partir des sorties de ses prédécesseurs
                    et de leurs connexions comme une somme pondérée.</li>
                <li>Un terme de biais peut être ajouté au résultat de la propagation</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">90
                <a class="prev" href="#slide89"></a>
                <a class="next" href="#slide91"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide91">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1>Apprentissage profond</h1>
            <ul>
                <li>Le mot "profond" dans l'apprentissage profond vient de l'utilisation de multiples couches dans le
                    réseau neuronal.</li>
                <li>Un perceptron linéaire ne peut pas être un classificateur universel. Un perceptron "monocouche" ne
                    peut pas mettre en œuvre le XOR</li>
                <li>Les réseaux d'apprentissage en profondeur permettent un nombre illimité de couches de taille limitée
                </li>
                <li>Il utilise plusieurs couches pour extraire progressivement des caractéristiques de l'entrée brute.
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">91
                <a class="prev" href="#slide90"></a>
                <a class="next" href="#slide92"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide92">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <figure>
                <img src="../../2021/MachineLearning/Deep_Learning.jpg" height="450px" />
                <figcaption>Source: https://en.wikipedia.org/wiki/File:Deep_Learning.jpg</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">92
                <a class="prev" href="#slide91"></a>
                <a class="next" href="#slide93"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide93">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation</h2>
            <ul>
                <li>Les neurones sont généralement organisés en plusieurs couches</li>
                <li>Les neurones d'une couche se connectent uniquement aux neurones des couches immédiatement précédente
                    et immédiatement suivante.</li>
                <li>La couche qui reçoit les données externes est la <b>couche d'entrée</b>. </li>
                <li>La couche qui produit le résultat final est la <b>couche de sortie</b>. </li>
                <li>Entre les deux, il y a zéro ou plusieurs couches cachées.</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">93
                <a class="prev" href="#slide92"></a>
                <a class="next" href="#slide94"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide94">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation et connectivité</h2>
            <ul>
                <li>Les couches peuvent être <b>entièrement connectées</b>, chaque neurone d'une couche étant connecté à
                    chaque neurone de la couche suivante. </li>
                <li>Les couches peuvent être mis en commun (pooling), c'est-à-dire qu'un groupe de neurones dans une
                    couche se connecte à un seul neurone dans la couche suivante, réduisant ainsi le nombre de neurones
                    dans cette couche</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">94
                <a class="prev" href="#slide93"></a>
                <a class="next" href="#slide95"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide95">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Composants des réseaux de neurones artificiels</h2>
            <h2 class="topicsubheading">Organisation et connectivité</h2>
            <ul>
                <li>Les réseaux qui permettent des connexions entre les neurones de la même couche ou des couches
                    précédentes sont connus sous le nom de <b>réseaux récurrents</b>.</li>
                <li> les réseaux qui ne permettent pas de cycles entre les couches sont appelés <b>réseaux de neurones
                        en aval</b> (Feedforward neural network)</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">95
                <a class="prev" href="#slide94"></a>
                <a class="next" href="#slide96"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide96">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Réseaux de neurones artificiels: Hyperparamètres</h2>
            <ul>
                <li>Un hyperparamètre est un paramètre constant dont la valeur est fixée avant le début du processus
                    d'apprentissage.</li>
                <li>Les valeurs des paramètres sont obtenues par apprentissage.</li>
                <li>Exemples
                    <ul>
                        <li>le taux d'apprentissage</li>
                        <li>le nombre de couches cachées</li>
                        <li>la taille des échantillons.</li>
                        <li>...</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">96
                <a class="prev" href="#slide95"></a>
                <a class="next" href="#slide97"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide97">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <figure>
                <img src="../../2021/MachineLearning/Screenshot_2020-10-20 Tensorflow — Neural Network Playground.png"
                    height="450px" />
                <figcaption>Source: https://playground.tensorflow.org/</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">97
                <a class="prev" href="#slide96"></a>
                <a class="next" href="#slide98"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide98">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow</h2>
            <div class="demo-highlight">
                <pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>

<span class="c1"># Créer un modèle séquentiel</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>

<span class="c1"># Compilation du modèle</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'mean_squared_error'</span><span class="p">,</span>
   <span class="n">optimizer</span><span class="o">=</span><span class="n">sgd</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
</pre>
            </div>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">98
                <a class="prev" href="#slide97"></a>
                <a class="next" href="#slide99"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide99">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <figure>
                <img src="../../2021/MachineLearning/Screenshot_2020-10-20 Tensorflow 2 — Neural Network Playground.png"
                    height="450px" />
                <figcaption>Source: https://playground.tensorflow.org/</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">99
                <a class="prev" href="#slide98"></a>
                <a class="next" href="#slide100"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide100">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau de neurones en aval (Feedforward neural networks) </h1>
            <ul>
                <li>Les connexions entre les nœuds ne forment pas un cycle</li>
                <li>Les informations se déplacent des nœuds d'entrée vers les nœuds de sortie, en passant par les nœuds
                    cachés (le cas échéant). </li>
                <li>L'information ne circule que dans un seul sens, vers l'avant</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Feed_forward_neural_net.gif"
                    height="280px" />
                <figcaption>Réseau de neurones en aval</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">100
                <a class="prev" href="#slide99"></a>
                <a class="next" href="#slide101"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide101">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron simple couche</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/ArtificialNeuronModel_english.png"
                    height="380px" />
                <figcaption>Perceptron simple couche</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">101
                <a class="prev" href="#slide100"></a>
                <a class="next" href="#slide102"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide102">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Perceptron multicouche</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/XOR_perceptron_net.png"
                    height="380px" />
                <figcaption>Perceptron multicouche</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">102
                <a class="prev" href="#slide101"></a>
                <a class="next" href="#slide103"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide103">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Rétropropagation du gradient (Backpropagation)</h1>
            <ul>
                <li>La rétropropagation est une méthode permettant d'ajuster les poids de connexion pour compenser
                    chaque erreur constatée lors de l'apprentissage</li>
                <li>Le montant de l'erreur est effectivement réparti entre les connexions. </li>
                <li>calcule le gradient de la fonction de perte par rapport aux poids du réseau pour un seul exemple
                    d'entrée-sortie.</li>
                <li>fonctionne en calculant le gradient de la fonction de perte par rapport à chaque poids selon la
                    règle de la chaîne</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">103
                <a class="prev" href="#slide102"></a>
                <a class="next" href="#slide104"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide104">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicheading">Réseau de neurones récurrents</h1>
            <ul>
                <li>Un réseau de neurones où les connexions entre les nœuds forment un graphe dirigé le long d'une
                    séquence temporelle, lui permettant de présenter un comportement dynamique temporel. </li>
                <li>Ils peuvent utiliser leur état interne (mémoire) pour traiter des séquences d'entrées de longueur
                    variable</li>
                <li>Applications
                    <ul>
                        <li>la reconnaissance de l'écriture manuscrite</li>
                        <li>la reconnaissance vocale</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">104
                <a class="prev" href="#slide103"></a>
                <a class="next" href="#slide105"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide105">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicheading">Réseau de neurones récurrents</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Recurrent_neural_network_unfold.svg"
                    height="380px" />
                <figcaption>Réseau de neurones récurrents</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">105
                <a class="prev" href="#slide104"></a>
                <a class="next" href="#slide106"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide106">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau récurrent à mémoire court et long terme</h1>
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Long_Short-Term_Memory.svg "
                    height="300px" />
                <figcaption>LSTM</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">106
                <a class="prev" href="#slide105"></a>
                <a class="next" href="#slide107"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide107">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau récurrent à mémoire court et long terme</h1>
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <ul>
                <li>LSTM a des connexions de retour d'information</li>
                <li>Une unité LSTM commune est composée d'une cellule, d'une porte d'entrée, d'une porte de sortie et
                    d'une porte d'oubli.</li>
                <li>La cellule se souvient de valeurs sur des intervalles de temps arbitraires et les trois portes
                    régulent le flux d'informations entrant et sortant de la cellule. </li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Long_Short-Term_Memory.svg "
                    height="200px" />
                <figcaption>LSTM</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">107
                <a class="prev" href="#slide106"></a>
                <a class="next" href="#slide108"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide108">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1 class="topicsubheading">Réseau récurrent à mémoire court et long terme</h1>
            <h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
            <ul>
                <li>LSTM a des connexions de retour d'information</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2019/MachineLearning/Long_Short-Term_Memory.svg "
                    height="280px" />
                <figcaption>LSTM</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">108
                <a class="prev" href="#slide107"></a>
                <a class="next" href="#slide109"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide109">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1>Réseaux de neurones convolutionnels</h1>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" height="380px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">109
                <a class="prev" href="#slide108"></a>
                <a class="next" href="#slide110"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide110">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1>Réseaux de neurones convolutionnels</h1>
            <ul>
                <li>Analyse des images</li>
                <li>Utilise la convolution, une opération mathématique linéaire</li>
                <li>Une couche d'entrée et une couche de sortie</li>
                <li>Plusieurs couches cachées, constituées de couches convolutives</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">110
                <a class="prev" href="#slide109"></a>
                <a class="next" href="#slide111"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide111">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h1>Réseaux de neurones convolutionnels</h1>
            <ul>
                <li>Ils considèrent le modèle hiérarchique des données et assemblent des modèles plus complexes en
                    utilisant des modèles plus petits et plus simples.</li>
                <li>Un réseau neuronal convolutif est constitué d'une couche d'entrée et d'une couche de sortie, ainsi
                    que de plusieurs couches cachées. </li>
                <li>Les couches cachées d'un CNN consistent généralement en une série de couches convolutionnelles qui
                    se convoluent avec une multiplication </li>
                <li> La fonction d'activation est généralement une couche RELU, et est ensuite suivie par des
                    convolutions supplémentaires telles que des couches de regroupement, des couches entièrement
                    connectées et des couches de normalisation</li>
            </ul>
            <figure>
                <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" height="180px" />
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">111
                <a class="prev" href="#slide110"></a>
                <a class="next" href="#slide112"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide112">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <h3>Identité</h3>
            <p>
                \( \begin{matrix} \ \ 0 &\ \ 0 &\ \ 0 \\ \ \ 0 &\ \ 1 &\ \ 0 \\ \ \ 0 &\ \ 0 &\ \ 0 \end{matrix} \)
            </p>
            <h3>La détection de contours</h3>
            <p>
                \( \begin{matrix} \ \ 1 & 0 & -1 \\ \ \ 0 & 0 & \ \ 0 \\ -1 & 0 & \ \ 1 \end{matrix} \)
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">112
                <a class="prev" href="#slide111"></a>
                <a class="next" href="#slide113"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide113">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Noyau (traitement d'image)</h2>
            <h3>Box blur</h3>
            <p>
                \( \frac{1}{9} \begin{matrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{matrix} \)
            </p>
            <h3>Flou de Gauss 3 × 3</h3>
            <p>
                \( \frac{1}{16} \begin{matrix} 1 & 2 & 1 \\ 2 & 4 & 2 \\ 1 & 2 & 1 \end{matrix} \)
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">113
                <a class="prev" href="#slide112"></a>
                <a class="next" href="#slide114"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide114">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Convolution matricielle</h2>
            <p>
                \[ \begin{bmatrix} x_{11} & x_{12} & \cdots & x_{1n} \\ x_{21} & x_{22} & \cdots & x_{2n} \\ \vdots &
                \vdots & \ddots & \vdots \\ x_{m1} & x_{m2} & \cdots & x_{mn} \\ \end{bmatrix} * \begin{bmatrix} y_{11}
                & y_{12} & \cdots & y_{1n} \\ y_{21} & y_{22}
                & \cdots & y_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ y_{m1} & y_{m2} & \cdots & y_{mn} \\
                \end{bmatrix} = \sum^{m-1}_{i=0} \sum^{n-1}_{j=0} x_{(m-i)(n-j)} y_{(1+i)(1+j)} \]
            </p>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">114
                <a class="prev" href="#slide113"></a>
                <a class="next" href="#slide115"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide115">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Max pooling</h2>
            <figure>
                <img src="../../2021/DataMining/Max_pooling.png" height="400px" />
                <figcaption>Max pooling avec un filtre 2 × 2 et un pas de 2. (Source:
                    https://commons.wikimedia.org/wiki/File:Max_pooling.png)</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">115
                <a class="prev" href="#slide114"></a>
                <a class="next" href="#slide116"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide116">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <pre class="codeexample">
            <code>
import tensorflow as tf

from tensorflow.keras import datasets, layers, models

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

# Créer un modèle séquentiel (réseaux de neurones convolutionnels)
model = models.Sequential()
model.add(layers.<span style="color:red">Conv2D</span>(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.<span style="color:red">MaxPooling2D</span>((2, 2)))
model.add(layers.<span style="color:red">Conv2D</span>(64, (3, 3), activation='relu'))
model.add(layers.<span style="color:red">MaxPooling2D</span>((2, 2)))
model.add(layers.<span style="color:red">Conv2D</span>(64, (3, 3), activation='relu'))
            </code>
          </pre>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">116
                <a class="prev" href="#slide115"></a>
                <a class="next" href="#slide117"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide117">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <pre class="codeexample">
            <code>
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10)

#Compilation du modèle
model.compile(optimizer='adam',
   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
   metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=10,
   validation_data=(test_images, test_labels))
            </code>
          </pre>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">117
                <a class="prev" href="#slide116"></a>
                <a class="next" href="#slide118"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide118">
        <div class="header">
            <h1>1.2.5. Apprentissage profond</h1>
        </div>
        <div class="content">
            <h2 class="topicsubheading">Exemple: Tensorflow (réseaux de neurones convolutionnels)</h2>
            <figure>
                <img src="../../2021/DataMining/convolutionalneuralnetwork.png" height="400vh" />
                <figcaption>Modèle: https://www.tensorflow.org/tutorials/images/cnn</figcaption>
            </figure>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">118
                <a class="prev" href="#slide117"></a>
                <a class="next" href="#slide119"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide119">
        <div class="header">
            <h1>Références</h1>
        </div>
        <div class="content">
            <h1>Articles de recherche</h1>
            <ul>
                <li>[Aly 2005] Aly, Mohamed. Survey on Multiclass Classification Methods. 2005.</li>
                <li>[Jaakkola 2019] Jaakkola, H., et al. “Artificial Intelligence Yesterday, Today and Tomorrow.” 2019
                    42nd International Convention on Information and Communication Technology, Electronics and
                    Microelectronics (MIPRO), 2019, pp. 860–67. IEEE
                    Xplore
                </li>
                <li>[Pan 2016] Pan, Yunhe, “Heading toward Artificial Intelligence 2.0.” Engineering, vol. 2, no. 4,
                    Dec. 2016, pp. 409–13. www.sciencedirect.com,</li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">119
                <a class="prev" href="#slide118"></a>
                <a class="next" href="#slide120"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide120">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Web</h1>
            <ol>
                <li>Google acquiert DNNresearch, spécialisé dans les réseaux de neurones profonds: <a
                        href="https://www.lemondeinformatique.fr/actualites/lire-google-acquiert-dnnresearch-specialise-dans-les-reseaux-de-neurones-profonds-52829.html">https://www.lemondeinformatique.fr/actualites/lire-google-acquiert-dnnresearch-specialise-dans-les-reseaux-de-neurones-profonds-52829.html</a>
                </li>
                <li>Pourquoi Microsoft rachète Linkedin: <a
                        href="https://www.lemondeinformatique.fr/actualites/lire-pourquoi-microsoft-rachete-linkedin-65136.html">https://www.lemondeinformatique.fr/actualites/lire-pourquoi-microsoft-rachete-linkedin-65136.html</a>
                </li>
                <li>Scikit-learn: <a href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a></li>
                <li>Perceptron: <a
                        href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html</a>
                </li>
            </ol>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">120
                <a class="prev" href="#slide119"></a>
                <a class="next" href="#slide121"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide121">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Wikipédia</h1>
            <ul>
                <li>Perceptron: <a
                        href="https://en.wikipedia.org/wiki/Perceptron">https://en.wikipedia.org/wiki/Perceptron</a>
                </li>
                <li>Multiclass Classification: <a
                        href="https://en.wikipedia.org/wiki/Multiclass_classification">https://en.wikipedia.org/wiki/Multiclass_classification</a>
                </li>
                <li>Multilayer Perceptron: <a
                        href="https://en.wikipedia.org/wiki/Multilayer_perceptron">https://en.wikipedia.org/wiki/Multilayer_perceptron</a>
                </li>
                <li>Feedforward Neural Network: <a
                        href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
                </li>
                <li>Recurrent Neural Network: <a
                        href="https://en.wikipedia.org/wiki/Recurrent_neural_network">https://en.wikipedia.org/wiki/Recurrent_neural_network</a>
                </li>
                <li>Long Short-Term Memory: <a
                        href="https://en.wikipedia.org/wiki/Long_short-term_memory">https://en.wikipedia.org/wiki/Long_short-term_memory</a>
                </li>
                <li>Activation Function: <a
                        href="https://en.wikipedia.org/wiki/Activation_function">https://en.wikipedia.org/wiki/Activation_function</a>
                </li>
                <li>Logique et Raisonnement Mathématique: <a
                        href="https://fr.wikipedia.org/wiki/Logique_et_raisonnement_math%C3%A9matique">https://fr.wikipedia.org/wiki/Logique_et_raisonnement_math%C3%A9matique</a>
                </li>
                <li>Représentation des Connaissances: <a
                        href="https://fr.wikipedia.org/wiki/Repr%C3%A9sentation_des_connaissances">https://fr.wikipedia.org/wiki/Repr%C3%A9sentation_des_connaissances</a>
                </li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">121
                <a class="prev" href="#slide120"></a>
                <a class="next" href="#slide122"></a>
            </div>
        </div>
    </section>

    <section class="slide" id="slide122">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Wikipédia</h1>
            <ul>
                <li>Agent Intelligent: <a
                        href="https://fr.wikipedia.org/wiki/Agent_intelligent">https://fr.wikipedia.org/wiki/Agent_intelligent</a>
                </li>
                <li>Calcul des Propositions: <a
                        href="https://fr.wikipedia.org/wiki/Calcul_des_propositions">https://fr.wikipedia.org/wiki/Calcul_des_propositions</a>
                </li>
                <li>Calcul des Prédicats: <a
                        href="https://fr.wikipedia.org/wiki/Calcul_des_pr%C3%A9dicats">https://fr.wikipedia.org/wiki/Calcul_des_pr%C3%A9dicats</a>
                </li>
                <li>Logique Modale: <a
                        href="https://fr.wikipedia.org/wiki/Logique_modale">https://fr.wikipedia.org/wiki/Logique_modale</a>
                </li>
                <li>Raisonnement Automatisé: <a
                        href="https://fr.wikipedia.org/wiki/Raisonnement_automatis%C3%A9">https://fr.wikipedia.org/wiki/Raisonnement_automatis%C3%A9</a>
                </li>
                <li>Connaissance: <a
                        href="https://fr.wikipedia.org/wiki/Connaissance">https://fr.wikipedia.org/wiki/Connaissance</a>
                </li>
                <li>Gestion des connaissances: <a
                        href="https://fr.wikipedia.org/wiki/Gestion_des_connaissances">https://fr.wikipedia.org/wiki/Gestion_des_connaissances</a>
                </li>

            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">122
                <a class="prev" href="#slide121"></a>
                <a class="next" href="#slide123"></a>
            </div>
        </div>
    </section>
    <section class="slide" id="slide123">
        <div class="header">
            <h1>Références:</h1>
        </div>
        <div class="content">
            <h1>Couleurs</h1>
            <ul>
                <li><a href="https://material.io/color/">Color Tool - Material Design</a></li>
            </ul>
            <h1>Images</h1>
            <ul>
                <li><a href="https://commons.wikimedia.org/">Wikimedia Commons</a></li>
            </ul>
        </div>
        <div class="footer">
            <div class="contact">Apprentissage machine | John Samuel</div>
            <div class="navigation">123
                <a class="prev" href="#slide122"></a>
            </div>
        </div>
    </section>

    <script>
        function changeCurrentURLSlideNumber(isIncrement) {
            url = window.location.href;
            position = url.indexOf("#slide");
            if (position != -1) { // Not on the first page
                slideIdString = url.substr(position + 6);
                if (!Number.isNaN(slideIdString)) {
                    slideId = parseInt(slideIdString);
                    if (isIncrement) {
                        if (slideId < 123) {
                            slideId = slideId + 1;
                        }
                    } else {
                        if (slideId > 1) {
                            slideId = slideId - 1;
                        }
                    }
                    /* regexp */
                    url = url.replace(/#slide\d+/g, "#slide" + slideId);
                    window.location.href = url;
                }
            } else {
                window.location.href = url + "#slide2";
            }
        }
        document.onkeydown = function (event) {

            event.preventDefault();
            /* This will ensure the default behavior of
                                                            page scroll behaviour (up, down, right, left)*/

            event = event || window.event;
            /*Codes de la touche sur le clavier: 37, 38, 39, 40*/
            if (event.keyCode == '37') {
                // left
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '38') {
                // up
                changeCurrentURLSlideNumber(false);
            } else if (event.keyCode == '39') {
                // right
                changeCurrentURLSlideNumber(true);
            } else if (event.keyCode == '40') {
                // down
                changeCurrentURLSlideNumber(true);
            }
        }
        document.body.onmouseup = function (event) {
            event = event || window.event;
            event.preventDefault();
            changeCurrentURLSlideNumber(true);
        }
    </script>
</body>

</html>
