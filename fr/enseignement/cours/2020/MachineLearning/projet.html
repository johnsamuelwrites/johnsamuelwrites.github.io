<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <meta http-equiv="Content-Language" content="en"/>
    <link rel="shortcut icon" href="../.../../2017/DataMining/images/logo/favicon.png"/>
    <title>Deep Learning: John Samuel</title>
    <style type="text/css">
    body{
      background-color: #FFFFFF;
    }
    #sidebar {
      position: fixed;
      background-color: #00363a;
      top: 0;
      left: 0;
      bottom: 0;
      width:25vw;
    }
    #sidebar .title {
      position:relative;
      text-align: center;
      line-height: 5vmax;
      font-size: 1.4vmax;
      font-family: 'Arial';
      margin-top: 30vh;
    }
    #sidebar .title a:link,
    #sidebar .title a:visited{
     color: #FFFFFF;
     text-decoration:none;
    }
    .subtitle {
      top: 50vh;
      text-align: center;
      line-height: 1.3vmax;
      font-family: 'Arial';
      font-size: 1.5vmax;
      color: #FFFFFF;
    }
    a:link, a:visited {
     color:#00363a;
    }
    .subtitle a:link,
    .subtitle a:visited{
     color: #FFFFFF;
     text-decoration:none;
    }
    .licence {
      position:fixed;
      text-align: right;
      bottom:0;
      right:0;
    }
    .home {
     position:fixed;
     text-align: left;
     font-family: 'Arial';
     color: #D3D3D3;
     z-index:100;
     width:100%;
     background-color:#FFFFFF;
     top:0px;
     margin-bottom:10px;
     padding-bottom:10px;
    }
    .codeexample {
      background-color:#eeeeee;
    }
    .home ul{
      margin: 0;
      padding: 0;
      text-align: left;
      list-style:none;
    }
    .home li{
     position: relative;
     float: left;
     padding-top:15px;
     margin-right: 1em;
     font-family: 'Arial';
    }
    .home li:hover {
      display:block;
    }
    .home a:link,
    .home a:visited{
     color: #D3D3D3;
    }
    .home li:hover a:link,
    .home li:hover a:visited{
      text-decoration:none;
      padding:15px;
      color:#FFFFFF;
      background-color: #00363a;
    }
    .content {
     line-height: 1.8vmax;
     font-size: 1.2vmax;
     font-family: 'Arial';
     margin-top: 15vh;
     width:90%;
    }
    .content h2, h3, h4{
     color:#00363a;
    }
    .content a:link,
    .content a:visited{
     color: #00363a;
    }
    .content h2::before,
    .content h3::before{
       display: block;
       content : " ";
       visibility:hidden;
       height:50px;
       margin-top:-50px;
       pointer-events: none;
       background-color:#FFFFFF;
    }
    .content a:link,
    .content a:visited{
     color:#00363a;
    }
    .content li {
      margin:5px;
    }
    .exercise {
     margin-left:2vw;
    }
    .exercise p{
     margin-left:1vw;
    }
    .exercise img{
     width:100%;
    }
    .content a:link,
    .content a:visited{
     color:#00363a;
    }
    .home a:link,
    .home a:visited{
     color: #D3D3D3;
    }
    .page {
      width:65vw;
      height:100%;
      margin-left:25vw;
      overflow: auto;
      padding: 0 1em;
    }
    table td,tr {
      text-align:center;
    }
    img {
     max-width:100%;
     max-height:100%;
    }
    /* Using same Jupyter CSS
     */
    .highlight  { background: #f8f8f8; }
    .highlight .c { color: #408080; font-style: italic } /* Comment */
    .highlight .err { border: 1px solid #FF0000 } /* Error */
    .highlight .k { color: #008000; font-weight: bold } /* Keyword */
    .highlight .o { color: #666666 } /* Operator */
    .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
    .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
    .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
    .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
    .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
    .highlight .k { color: #008000; font-weight: bold } /* Keyword */
    .highlight .s2 { color: #BA2121 } /* Literal.String.Double */
    .highlight .s1 { color: #BA2121 } /* Literal.String.Single */
    .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
    .highlight .nb { color: #008000 } /* Name.Builtin */
    .highlight .mb { color: #666666 } /* Literal.Number.Bin */
    .highlight .mf { color: #666666 } /* Literal.Number.Float */
    .highlight .mh { color: #666666 } /* Literal.Number.Hex */
    .highlight .mi { color: #666666 } /* Literal.Number.Integer */
    .highlight .mo { color: #666666 } /* Literal.Number.Oct */
    @media (max-width: 640px), screen and (orientation: portrait) {
      body {
        max-width:100%;
        max-height:100%;
      }
      #sidebar {
        position: fixed;
        background-color: #00363a;
        top: 0;
        left: 0;
        bottom: 80vh;
        width:100vw;
      }
      #sidebar .title {
        text-align: center;
        position: fixed;
        margin-top: 6vh;
        left:0px;
        right:0px;
        line-height: 3.5vmax;
        font-size: 1.5vmax;
        font-family: 'Arial';
      }
      #sidebar .subtitle {
        text-align:center;
        top: 5vh;
        left:0px;
        right:0px;
        position: fixed;
        margin-top: 10vh;
        font-size: 1.5vmax;
      }
      #sidebar .title a:link,
      #sidebar .title a:visited{
        text-align:center;
        color:#FFFFFF;
      }
      #sidebar .subtitle a:link,
      #sidebar .subtitle a:visited{
        text-align:center;
        color:#FFFFFF;
      }
      .home{
        z-index:100;
        width:100%;
        background-color:#00363a;
        font-size:1.5vmax;
      }
      .home a:link,
      .home a:visited{
        text-decoration:none;
        color:#FFFFFF;
      }
      .content {
        line-height: 3.8vmax;
        font-size: 1.8vmax;
        font-family: 'Arial';
        margin-top:22vh;
      }
      .content a:link,
      .content a:visited{
        color:#00363a;
      }
      .page {
        top: 40vh;
        width:99%;
        margin-left:0vw;
      }
      .page img {
        max-width:100%;
        max-height:100%;
        border:0;
      }
    }
    @media print {
      #sidebar {
        width:100%;
        top:0;
        position:relative;
        padding-bottom:3vh; 
      }
      #sidebar .title {
        margin-top:0;
      }
      .home {
        display:none;
      }
      .page {
        margin-left:5vw;
        width:90%;
      }
    }

    </style>
  </head>
  <body vocab="http://schema.org/">
    <div id="sidebar">
     <div class="title">
      <h1><a href="./index.html">Practicals: Deep Learning</a></h1>
     </div>
     <div class="subtitle">
      <h3><a href="../../../../about.html">John Samuel</a></h3>
     </div>
    </div>
    <div class="licence"><a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="../../../../../images/license.png"/></a>
    </div>
    <div class="page">
      <div class="home">
       <ul typeof="BreadcrumbList">
        <li property="itemListElement" typeof="ListItem">
          <a property="item" typeof="WebPage" href="../../../../index.html">
            <span property="name">Home</span>
          </a>
        </li>
        <li property="itemListElement" typeof="ListItem">
         <a property="item" typeof="WebPage" href="index.html">
          <span property="name">Deep Learning</span>
         </a>
        </li>
        <li property="itemListElement" typeof="ListItem">
         <a property="item" typeof="WebPage" href="../../../index.html">
          <span property="name">Teaching</span>
         </a>
        </li>
       </ul>
      </div>
      <div class="content">
        <h3>Goals</h3>
        <ul>
          <li>Understanding the translation pattern</li>
        </ul>
        <h4>Exercise 1.1</h4>
        <div class="exercise">
          <h5>Download</h5>
          <p>Download the data from <a href="https://zenodo.org/record/3271358">https://zenodo.org/record/3271358</a>.</p>
          <p>View the data contents. As you can see in the output, there are four columns: timestamp, property, language and type.</p>
          <p>Taking an example line from this dataset,</p>
          <p class="codeexample">
            <code>
             2013-09-10T22:43:54Z,P856,en,label
            </code>
          </p>
          <p>corresponds to the action that an English label of Property P856 was added for the first time at 2013-09-10T22:43:54Z.</p>
          <p>Following is a description of each column.</p>
          <ol>
           <li>timestamp: the time at which an action was made. For example, 2013-09-10T22:43:54Z</li>
           <li>property: Wikidata property identifier. It uses the P-number, For example, P856</li> 
           <li>language: the language in which a label/description/alias was first translated</li> 
           <li>type: It could be one of the following values: label, description and alias</li>
          </ol>
          <h5>Creation of dataframe</h5>
          <p class="codeexample">
            <code>
              import pandas as pd</br>
</br>
              dataframe = pd.read_csv("multilingual_wikidata_translation_flow.csv")</br>
              # remove duplicates</br>
              dataframe = dataframe.drop_duplicates()</br>
              </br>
              # remove rows with missing values</br>
              dataframe = dataframe.dropna()</br>
              print(dataframe)</br>
            </code>
          </p>
          <p>Get a detailed information of the given dataframe.</p>
          <p class="codeexample">
            <code>
             dataframe.describe()
            </code>
          </p>
          <p>Let us now take a look at the translation of labels in different languages for a given property.</p>
          <p class="codeexample">
            <code>
              dataframe.loc[(dataframe["property"]=="P856") & (dataframe["type"]=="label")]
            </code>
          </p>
          <p>We will check the data available for a property like P856.</p>
          <p class="codeexample">
            <code>
            ptranslation = dataframe.loc[(dataframe["property"]=="P856")]</br>
            print(ptranslation)</br>
            </code>
          </p>
          <p>You can also add additional conditions to filter out any information. The code below filters out the translation of labels of property P856. Please copy the code below and create new cells for testing with different properties and see the results for translation of descriptions and aliases. What are your first observations? Please note them as comments in your notebook.</p>
          <p class="codeexample">
            <code>
            ptranslation = dataframe.loc[(dataframe["property"]=="P856") & (dataframe["type"]=="label")]</br>
            print(ptranslation)</br>
            </code>
          </p>
          <h5>Visualization of translation</h5>
          <p>Our next goal is to plot the translation of a property and see whether we can observe any translation pattern. Please copy the code below and create new cells for testing with different properties and plot the results. In this plot, we plot the time on the x-axis and translation type on the y-axis.</p>
          <p class="codeexample">
            <code>
import matplotlib
import&nbsp;&nbsp;matplotlib.pyplot as plot</br>
from&nbsp;&nbsp;dateutil import parser</br>
import&nbsp;&nbsp;numpy as np</br>
</br>
ptranslation&nbsp;&nbsp;= dataframe.loc[(dataframe["property"]=="P856")]</br>
</br>
x&nbsp;&nbsp;= []</br>
y&nbsp;&nbsp;= []</br>
z&nbsp;&nbsp;= []</br>
for&nbsp;&nbsp;i in range(0, len(ptranslation['timestamp'])):</br>
&nbsp;&nbsp; #parsing the date in string and converting it to datetime</br>
&nbsp;&nbsp; try:</br>
&nbsp;&nbsp;&nbsp;&nbsp;   value = parser.parse(ptranslation['timestamp'].iloc[i])</br>
&nbsp;&nbsp;&nbsp;&nbsp;   x.append(value)</br>
&nbsp;&nbsp; except Exception:</br>
&nbsp;&nbsp;&nbsp;&nbsp;   continue</br>
&nbsp;&nbsp; y.append(ptranslation['type'].iloc[i])</br>
&nbsp;&nbsp; z.append(ptranslation['language'].iloc[i])</br>
</br>
#creating&nbsp;&nbsp;a plot</br>
plot.rcParams["figure.figsize"]&nbsp;&nbsp;= (25, 9) </br>
</br>
colors&nbsp;&nbsp;= matplotlib.cm.rainbow(np.linspace(0, 1, 3))</br>
tcolors&nbsp;&nbsp;= {'label': colors[0],</br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'description':colors[1],</br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'alias':colors[2]</br>
&nbsp;&nbsp;&nbsp;&nbsp;}</br>
cs&nbsp;&nbsp;= [tcolors[i] for i in y] </br>
fig,&nbsp;&nbsp;ax = plot.subplots()</br>
ax.scatter(x, y, s=30, color=cs)</br>
</br>
plot.xlabel("Time")</br>
plot.ylabel("Translation type")</br>
</br>
#annotating&nbsp;&nbsp;the points</br>
for i, txt in enumerate(z):</br>
&nbsp;&nbsp;ax.annotate(txt, (x[i], y[i]))</br>
</br>
fig.show()</br>
            </code>
          </p>
          <p>Now, we plot another graph, this time, language on the y-axis and time on the x-axis.</p>
          <p class="codeexample">
            <code>
import matplotlib</br>
import matplotlib.pyplot as plot</br>
from dateutil import parser</br>
import numpy as np</br>
</br>
ptranslation = dataframe.loc[(dataframe["property"]=="P279")]</br>
</br>
x = []</br>
y = []</br>
z = []</br>
for i in range(0, len(ptranslation['timestamp'])):</br>
&nbsp;&nbsp; try:</br>
&nbsp;&nbsp;   #parsing the date in string and converting it to datetime</br>
&nbsp;&nbsp;&nbsp;&nbsp;value = parser.parse(ptranslation['timestamp'].iloc[i])</br>
&nbsp;&nbsp;&nbsp;&nbsp;x.append(value)</br>
&nbsp;&nbsp; except Exception:</br>
&nbsp;&nbsp;&nbsp;&nbsp;   continue</br>
&nbsp;&nbsp; y.append(ptranslation['type'].iloc[i])</br>
&nbsp;&nbsp; z.append(ptranslation['language'].iloc[i])</br>
</br>
#creating a plot</br>
colors = matplotlib.cm.rainbow(np.linspace(0, 1, 3))</br>
tcolors = {'label': colors[0],</br>
&nbsp;&nbsp;&nbsp;&nbsp;          'description':colors[1],</br>
&nbsp;&nbsp;&nbsp;&nbsp;          'alias':colors[2]</br>
           }</br>
cs = [tcolors[i] for i in y] </br>
</br>
plot.rcParams["figure.figsize"] = (25, 25) </br>
fig, ax = plot.subplots()</br>
ax.scatter(x, z, s=50, color=cs)</br>
</br>
</br>
plot.xlabel("Time")</br>
plot.ylabel("Language")</br>
</br>
# saving the plot in a file</br>
plot.savefig('translation.png')</br>
fig.show()</br>
            </code>
          </p>
          <p>Following are three plots concerning properties: P31, P279 and P856 respectively. What are your observations on the values on the y-axis? Please note them as comments on the notebook. You can also see that some translations can be even made in a single edit. Please check a column of red lines in the first figure (P31).</p>
          <p>
            <figure>
             <img src="../../../../../en/teaching/courses/2019/MachineLearning/p31.png"></img>
             <figcaption>Translation plot of property P31</figcaption>
            </figure>
            <figure>
             <img src="../../../../../en/teaching/courses/2019/MachineLearning/p279.png"></img>
             <figcaption>Translation plot of property P279</figcaption>
            </figure>
            <figure>
             <img src="../../../../../en/teaching/courses/2019/MachineLearning/p856.png"></img>
             <figcaption>Translation plot of property P856</figcaption>
            </figure>
          </p>
          <p>In the code given below, we select some languages and see the order of translation. Copy the code below and plot the graphs for different properties. Please note your observations as comments on the notebook.</p>
          <p class="codeexample">
            <code>
import matplotlib</br>
import matplotlib.pyplot as plot</br>
from dateutil import parser</br>
import numpy as np</br>
</br>
#list of languages under consideration</br>
langlist&nbsp;&nbsp;= ["fr", "es", "en", "de", "it", "pt", "ja"]</br>
ptranslation&nbsp;&nbsp;= dataframe.loc[(dataframe["property"]=="P18") & (dataframe["language"].isin (langlist))]</br>
print(ptranslation)</br>
</br>
x= []</br>
y= []</br>
z= []</br>
for i in range(0, len(ptranslation['timestamp'])):</br>
&nbsp;&nbsp; try:</br>
&nbsp;&nbsp;&nbsp;&nbsp;   #parsing the date in string and converting it to datetime</br>
&nbsp;&nbsp;&nbsp;&nbsp;  value = parser.parse(ptranslation['timestamp'].iloc[i])</br>
&nbsp;&nbsp;&nbsp;&nbsp;x.append(value)</br>
&nbsp;&nbsp; except Exception:</br>
&nbsp;&nbsp;&nbsp;&nbsp;   continue</br>
&nbsp;&nbsp; y.append(ptranslation['type'].iloc[i])</br>
&nbsp;&nbsp; z.append(ptranslation['language'].iloc[i])</br>
</br>
#creating&nbsp;&nbsp;a plot</br>
colors&nbsp;&nbsp;= matplotlib.cm.rainbow(np.linspace(0, 1, 3))</br>
tcolors&nbsp;&nbsp;= {'label': colors[0],</br>
&nbsp;&nbsp;&nbsp;&nbsp;          'description':colors[1],</br>
&nbsp;&nbsp;&nbsp;&nbsp;          'alias':colors[2]</br>
&nbsp;&nbsp;          }</br>
cs&nbsp;&nbsp;= [tcolors[i] for i in y] </br>
</br>
plot.rcParams["figure.figsize"]&nbsp;&nbsp;= (10, 5) </br>
fig,&nbsp;&nbsp;ax = plot.subplots()</br>
ax.scatter(x,&nbsp;&nbsp;z, s=50, color=cs)</br>
</br>
plot.savefig('translation.png')</br>
fig.show()</br>
            </code>
          </p>
        </div>
        <h4>Exercise 1.2</h4>
        <div class="exercise">
          <p>We used plotting techniques to manually detect some patterns of translation. Now we use other algorithms to see whether groups of languages are always present together</p>
          <p>Before continuing, we need to install the library <i>mlxtend</i>.</p>
          <p class="codeexample">
            <code>
            !pip install mlxtend  
            </code>
          </p>
          <p>Next we prepare the language dataset. We will focus on the translation of property labels. We create a list of list of available translations of labels of all the properties from our dataset</p>
          <p class="codeexample">
            <code>
#prepare dataset of languages</br>
languageorder = []</br>
labeldataframe = dataframe.loc[(dataframe["type"] == "label")]</br>
groups = labeldataframe.groupby(["property"])</br>
for k, group in groups:</br>
&nbsp;&nbsp;languageorder.append(list(groups.get_group((k))["language"]))</br>
print(languageorder);</br>

            </code>
          </p>
          <p>This will give us the following output.</p>
          <p class="codeexample">
            <code>
              [['en', 'it', 'fi', 'fr', 'de', 'zh-hans', 'ru', 'hu', 'he', 'nl', 'pt', 'pl', 'ca', 'cs', 'ilo', 'zh', 'nb', 'ko',..
            </code>
          </p>
          <p>Now we calculate the frequent itemsets using <i>apriori</i> algorithm. Please uncomment the print statement to see the intermediate dataframe.</p>
          <p class="codeexample">
            <code>
from mlxtend.preprocessing import TransactionEncoder </br>
from mlxtend.frequent_patterns import apriori</br>
</br>
te = TransactionEncoder()</br>
</br>
te_ary = te.fit(languageorder).transform(languageorder)</br>
</br>
# preparation of data frame</br>
df = pd.DataFrame(te_ary, columns=te.columns_)</br>
#print(df)</br>
</br>
#use of apriori algorithm</br>
frequent_itemsets = apriori(df, min_support=0.75, use_colnames=True)</br>
</br>
print (frequent_itemsets)</br>
            </code>
          </p>
          <p>The program uses a minimum support of 0.75. We see that English labels are present for all the properties, whereas French labels are only available for 93% of the properties. On considering pairs of languages, we see that English and Arabic are present in 93% of the translations. As we go further below, we see combinations of 3, 4, 5 languages etc.</p>
          <p> Please change this value between 0 and 1 and see the output.</p>
          <table>
<thead>
<tr><th>S.No.</th><th></th><th> support</th><th> itemsets</th></tr>
</thead>
<tbody>
<tr><td>0</td><td>  0.998424 </td><td>              (ar)</td></tr>
<tr><td>1</td><td>  0.759414 </td><td>              (ca)</td></tr>
<tr><td>2</td><td>  1.000000 </td><td>              (en)</td></tr>
<tr><td>3</td><td>  0.932409 </td><td>              (fr)</td></tr>
<tr><td>4</td><td>  0.993540 </td><td>              (nl)</td></tr>
<tr><td>5</td><td>  0.985978 </td><td>              (uk)</td></tr>
<tr><td>6</td><td>  0.758626 </td><td>          (ar, ca)</td></tr>
<tr><td>7</td><td>  0.998424 </td><td>          (en, ar)</td></tr>
<tr><td>8</td><td>  0.931621 </td><td>          (ar, fr)</td></tr>
<tr><td>9</td><td>  0.992752 </td><td>          (nl, ar)</td></tr>
<tr><td>10</td><td> 0.985663 </td><td>          (ar, uk)</td></tr>
<tr><td>11</td><td> 0.759414 </td><td>          (en, ca)</td></tr>
<tr><td>12</td><td> 0.759256 </td><td>          (nl, ca)</td></tr>
<tr><td>13</td><td> 0.754215 </td><td>          (uk, ca)</td></tr>
<tr><td>14</td><td> 0.932409 </td><td>          (en, fr)</td></tr>
<tr><td>15</td><td> 0.993540 </td><td>          (nl, en)</td></tr>
<tr><td>16</td><td> 0.985978 </td><td>          (en, uk)</td></tr>
<tr><td>17</td><td> 0.931779 </td><td>          (nl, fr)</td></tr>
<tr><td>18</td><td> 0.928155 </td><td>          (uk, fr)</td></tr>
<tr><td>19</td><td> 0.985663 </td><td>          (nl, uk)</td></tr>
<tr><td>20</td><td> 0.758626 </td><td>      (en, ar, ca)</td></tr>
<tr><td>21</td><td> 0.758469 </td><td>      (nl, ar, ca)</td></tr>
<tr><td>22</td><td> 0.753899 </td><td>      (ar, uk, ca)</td></tr>
<tr><td>23</td><td> 0.931621 </td><td>      (en, ar, fr)</td></tr>
<tr><td>24</td><td> 0.992752 </td><td>      (nl, en, ar)</td></tr>
<tr><td>25</td><td> 0.985663 </td><td>      (en, ar, uk)</td></tr>
<tr><td>26</td><td> 0.931149 </td><td>      (nl, ar, fr)</td></tr>
<tr><td>27</td><td> 0.927997 </td><td>      (ar, uk, fr)</td></tr>
<tr><td>28</td><td> 0.985347 </td><td>      (nl, ar, uk)</td></tr>
<tr><td>29</td><td> 0.759256 </td><td>      (nl, en, ca)</td></tr>
<tr><td>30</td><td> 0.754215 </td><td>      (en, uk, ca)</td></tr>
<tr><td>31</td><td> 0.754057 </td><td>      (nl, uk, ca)</td></tr>
<tr><td>32</td><td> 0.931779 </td><td>      (nl, en, fr)</td></tr>
<tr><td>33</td><td> 0.928155 </td><td>      (en, uk, fr)</td></tr>
<tr><td>34</td><td> 0.985663 </td><td>      (nl, en, uk)</td></tr>
<tr><td>35</td><td> 0.927840 </td><td>      (nl, uk, fr)</td></tr>
<tr><td>36</td><td> 0.758469 </td><td>  (nl, en, ar, ca)</td></tr>
<tr><td>37</td><td> 0.753899 </td><td>  (en, ar, uk, ca)</td></tr>
<tr><td>38</td><td> 0.753742 </td><td>  (nl, ar, uk, ca)</td></tr>
<tr><td>39</td><td> 0.931149 </td><td>  (nl, en, ar, fr)</td></tr>
<tr><td>40</td><td> 0.927997 </td><td>  (en, ar, uk, fr)</td></tr>
<tr><td>41</td><td> 0.985347 </td><td>  (nl, en, ar, uk)</td></tr>
<tr><td>42</td><td> 0.927682 </td><td>  (nl, ar, uk, fr)</td></tr>
<tr><td>43</td><td> 0.754057 </td><td>  (nl, en, uk, ca)</td></tr>
<tr><td>44</td><td> 0.927840 </td><td>  (nl, en, uk, fr)</td></tr>
<tr><td>45</td><td> 0.753742 </td><td>  (ar, en, ca, nl, uk)</td></tr>
<tr><td>46</td><td> 0.927682 </td><td>  (ar, en, fr, nl, uk)</td></tr>
</tbody>
          </table>
          <p>Repeat the above experiment for descriptions and aliases. What are your observations. Please note them in the notebook as comments.</p>
        </div>
        <h4>Exercise 1.3</h4>
        <div class="exercise">
          <p>
            Our next goal is to generate the association rules, i.e, rules of the form.
<i>A -> C</i>, where A is the antecedent and C is the consequent.
          </p>
          <p class="codeexample">
            <code>
from mlxtend.frequent_patterns import association_rules</br>
</br>
association_rules(frequent_itemsets, metric="confidence", min_threshold=0.95)</br>
            </code>
          </p>
          <p>It will give us the following output.</p>
<table>
<tr><th>S.No. </th><th>antecedents </th><th>consequents </th><th>antecedent support </th><th>consequent support </th><th>support </th><th>confidence </th><th>lift </th><th>leverage </th><th>conviction</th></tr>
<tr><td>0 </td><td>(de) </td><td>(en) </td><td>0.479193 </td><td>0.988966 </td><td>0.477932 </td><td>0.997368 </td><td>1.008496 </td><td>0.004026 </td><td>4.192938</td></tr>
<tr><td>1 </td><td>(de) </td><td>(uk) </td><td>0.479193 </td><td>0.960277 </td><td>0.468789 </td><td>0.978289 </td><td>1.018757 </td><td>0.008631 </td><td>1.829646</td></tr>
<tr><td>2 </td><td>(es) </td><td>(en) </td><td>0.389975 </td><td>0.988966 </td><td>0.388556 </td><td>0.996362 </td><td>1.007479 </td><td>0.002884 </td><td>3.033137</td></tr>
<tr><td>3 </td><td>(fr) </td><td>(en) </td><td>0.713272 </td><td>0.988966 </td><td>0.708859 </td><td>0.993812 </td><td>1.004900 </td><td>0.003457 </td><td>1.783181</td></tr>
<tr><td>4 </td><td>(it) </td><td>(en) </td><td>0.413934 </td><td>0.988966 </td><td>0.413146 </td><td>0.998096 </td><td>1.009232 </td><td>0.003779 </td><td>5.795082</td></tr>
<tr><td>5 </td><td>(ru) </td><td>(en) </td><td>0.301387 </td><td>0.988966 </td><td>0.300441 </td><td>0.996862 </td><td>1.007984 </td><td>0.002380 </td><td>3.516183</td></tr>
<tr><td>6 </td><td>(en) </td><td>(uk) </td><td>0.988966 </td><td>0.960277 </td><td>0.950189 </td><td>0.960791 </td><td>1.000534 </td><td>0.000507 </td><td>1.013087</td></tr>
<tr><td>7 </td><td>(uk) </td><td>(en) </td><td>0.960277 </td><td>0.988966 </td><td>0.950189 </td><td>0.989494 </td><td>1.000534 </td><td>0.000507 </td><td>1.050303</td></tr>
<tr><td>8 </td><td>(es) </td><td>(uk) </td><td>0.389975 </td><td>0.960277 </td><td>0.383039 </td><td>0.982215 </td><td>1.022845 </td><td>0.008555 </td><td>2.233492</td></tr>
<tr><td>9 </td><td>(fr) </td><td>(uk) </td><td>0.713272 </td><td>0.960277 </td><td>0.689470 </td><td>0.966630 </td><td>1.006615 </td><td>0.004531 </td><td>1.190362</td></tr>
<tr><td>10 </td><td>(it) </td><td>(uk) </td><td>0.413934 </td><td>0.960277 </td><td>0.405738 </td><td>0.980198 </td><td>1.020745 </td><td>0.008246 </td><td>2.005990</td></tr>
<tr><td>11 </td><td>(ru) </td><td>(uk) </td><td>0.301387 </td><td>0.960277 </td><td>0.300126 </td><td>0.995816 </td><td>1.037009 </td><td>0.010711 </td><td>9.493695</td></tr>
<tr><td>12 </td><td>(de, fr) </td><td>(en) </td><td>0.391393 </td><td>0.988966 </td><td>0.391078 </td><td>0.999195 </td><td>1.010343 </td><td>0.004003 </td><td>13.698770</td></tr>
<tr><td>13 </td><td>(de, uk) </td><td>(en) </td><td>0.468789 </td><td>0.988966 </td><td>0.467686 </td><td>0.997646 </td><td>1.008777 </td><td>0.004069 </td><td>4.687894</td></tr>
</table>
        <p>Let's take a look at one of the association rule <i>(de, fr)->(en)</i>. The confidence score is 0.999195. But this rule states that when we have French and German translations available, we will also have the English translation. </p>
        <p>You can change the metric to 'lift' and test.</p>
        <p>We will now add two columns that will contain the length of antecedents and consequents. As you may have noticed, association rules are dataframes. So we can easily write filter conditions to get antecedents and consequents of length more than 1.</p>
          <p class="codeexample">
            <code>
from mlxtend.frequent_patterns import association_rules</br>
</br>
arules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.95)</br>
arules["antecedent_len"] = arules["antecedents"].apply(lambda x: len(x))</br>
arules["consequent_len"] = arules["consequents"].apply(lambda x: len(x))</br>
</br>
arules.loc[(arules["antecedent_len"]>1) &</br>
                 (arules["consequent_len"]>1)]</br>
            </code>
            <table>
<tr><th>S.No. </th><th>antecedents </th><th>consequents </th><th>antecedent support </th><th>consequent support </th><th>support </th><th>confidence </th><th>lift </th><th>leverage </th><th>conviction </th><th>antecedent_len </th><th>consequent_len</th></tr>
<tr><td>32 </td><td>(de, fr) </td><td>(en, uk) </td><td>0.391393 </td><td>0.950189 </td><td>0.383670 </td><td>0.980266 </td><td>1.031653 </td><td>0.011772 </td><td>2.524088 </td><td>2 </td><td>2</td></tr>
<tr><td>35 </td><td>(fr, es) </td><td>(en, uk) </td><td>0.332755 </td><td>0.950189 </td><td>0.326765 </td><td>0.981999 </td><td>1.033477 </td><td>0.010585 </td><td>2.767124 </td><td>2 </td><td>2</td></tr>
<tr><td>38 </td><td>(fr, it) </td><td>(en, uk) </td><td>0.345523 </td><td>0.950189 </td><td>0.338430 </td><td>0.979471 </td><td>1.030817 </td><td>0.010117 </td><td>2.426342 </td><td>2 </td><td>2</td></tr>
            </table>
          </p>
        <p>Repeat the above experiment for translation of descriptions and aliases. Please note down your observations as comments in your notebook.</p>
        </div>
        <h4>Exercise 1.4</h4>
        <div class="exercise">
          <p>Our next goal is to visualize the flow of translation. For this purpose, we install holoviews and bokeh.</p>
          <p class="codeexample">
            <code>
!pip install holoviews bokeh --upgrade
            </code>
          </p>
          <p>First, we create groups for different translations.</p>
          <p class="codeexample">
            <code>
languageorder = []</br>
labeldataframe = dataframe.loc[(dataframe["type"] == "label")]</br>
groups = labeldataframe.groupby(["property"])</br>
for k, group in groups:</br>
&nbsp;&nbsp;  languageorder.append(list(groups.get_group((k))["language"]))</br>
</br>
languagepairs = []</br>
for lo in languageorder:</br>
&nbsp;&nbsp;  for i in range(0, len(lo)-1):</br>
&nbsp;&nbsp;&nbsp;    languagepairs.append([lo[i], lo[i+1], 1])</br>
</br>
lpdataframe = pd.DataFrame(languagepairs)</br>
lpdataframe.columns = ['source', 'target', 'count']</br>
</br>
groups = lpdataframe.groupby(["source","target"]).count().reset_index()</br>
print(groups)</br>
            </code>
          </p>
          <p>Next we visualize them using circular layout. Note the code below, we have only taken 500 combinations of language pairs.</p>
          <p class="codeexample">
            <code>
import networkx as nx</br>
import matplotlib.pyplot as plot</br>
</br>
G = nx.from_pandas_edgelist(groups[:500], 'source', 'target')</br>
</br>
plot.rcParams["figure.figsize"] = (15,15) </br>
pos = nx.circular_layout(G)</br>
nx.draw(G, pos, with_labels=True)</br>
            </code>
          </p>
          <p>Copy the above code and check the flow of translations for any languages of your choice (number of languages &gt; 20).</p>
          <p>Use Bokeh/Holoviews chord layout for visualizing the weights as well.</p>
        </div>
        <h4>Exercise 1.5</h4>
        <div class="exercise">
          <h5>Prediction</h5>
          <p>Our final goal is to predict the next language(s) that will be translated, given a sequence of available translations.</p>
          Take for example, let's assume we have seen the following sequences of translation.
          <p class="codeexample">
            <code>
             [['en', 'it', 'fi', 'fr', 'de', 'nl', 'pt', 'pl', 'ca', 'cs']</br>
              &nbsp;['en', 'it', 'fi', 'fr', 'de', 'ilo', 'zh', 'nb']</br>
              &nbsp;['ru', 'hu', 'he', 'nl', 'pt', 'pl', 'ca', 'cs'],</br>
              &nbsp;...</br>
             ]
            </code>
          </p>
          <p>Once your model has been trained using this data, it may be able to predict the next possible translation(s).</p>
          <p><b>Example 1</b>: If the user enters the following sequence,</p>
          <p class="codeexample">
            <code>
             ['pt']
            </code>
          </p>
          <p>your model may return the following language</p>
          <p class="codeexample">
            <code>
             ['pl']
            </code>
          </p>
          <p><b>Example 2</b>: If the user enters the following sequence,</p>
          <p class="codeexample">
            <code>
             ['it', 'fi']
            </code>
          </p>
          <p>your model may return the following language</p>
          <p class="codeexample">
            <code>
             ['fr']
            </code>
          </p>
          <p><b>Example 3</b>: If the user enters the following sequence,</p>
          <p class="codeexample">
            <code>
             ['nl', 'pt', 'pl']
            </code>
          </p>
          <p>your model may return the following languages</p>
          <p class="codeexample">
            <code>
             ['ca', 'cs']
            </code>
          </p>
          <p>Your goal in this exercise is to train a neural network model that can predict the next probable translation(s) of labels (or descriptions or aliases).</p>
          <p>For creating this model, you must use the translation sequence of Wikidata properties seen above. You must split the translation sequences into training and test sequences. Please show the accuracy metrics of your model.</p>
          <p>It is important that you distinguish among the translation sequences of labels, descriptions and aliases, i.e., the user may ask the next probable language(s) for any of the three.</p>
          <p>Please comment your code and write down your observations. For example, what's the maximum length of input sequence and output sequence? What's the accuracy metrics? Why did you choose a given neural network model? ...</p>
          <p><b>Hint: </b> You may use recurrent neural network with LSTM (Long short-term memory).</p>
        </div>
        <h4>Submission</h4>
        <ul>
          <li>Rename your notebook as Name1_Name2_[Name3].ipynb, where Name1, Name2 are your names.</li>
          <li>Submit your notebook online.</li>
          <li>Please <b>don't</b> submit your JSON, TSV and CSV files.</li>
        </ul>
        <h4>References</h4>
        <p><a href="./references.html">Link</a></p>
      </div>
  </body>
</html>
