<html>
<head>
<meta charset="utf-8"/>
<title>Apprentissage machine</title>
<style type="text/css">
    body {
      height: 100%;
      width: 100%;
      background-color: white;
      margin: 0;
      overflow: hidden;
      font-family: Arial;
    }
    .slide {
      height: 100%;
      width: 100%;
    }
    .content {
      height: 79%;
      width: 95vw;
      display: flex;
      flex-direction: column;
      color: #000000;
      text-align: left;
      padding-left: 1.5vmax;
      padding-top: 1.5vmax;
      overflow-x: auto;
      font-size: 3vmin;
      flex-wrap: wrap;
    }
    .content h1, h2, h3, h4 {
      color: #1B80CF;
    }
    .content .topichighlight {
      background-color: #78002E;
      color: #FFFFFF;
    }
    .content .topicheading{
      background-color: #1B80CF;
      color: #FFFFFF;
      vertical-align:middle;
      border-radius:0 2vmax 2vmax 0%;
      height:4vmax;
      line-height:4vmax;
      padding-left:1vmax;
      margin:0.1vmax;
      width:50%;
    }
    .content .flexcontent{
      display: flex;
      overflow-y: auto;
      font-size: 3vmin;
      flex-wrap: wrap;
    }
    .content .gridcontent{
      display:grid;
      grid-template-columns: auto auto auto auto;
      grid-column-gap:0px;
      grid-row-gap:0px;
      grid-gap:0px;
    }
    .content .topicsubheading{
      background-color: #1B80CF;
      color: #FFFFFF;
      vertical-align:middle;
      border-radius:0 1.5vmax 1.5vmax 0%;
      height:3vmax;
      margin:0.1vmax;
      font-size:90%;
      line-height:3vmax;
      padding-left:1vmax;
      width:40%;
    }
    .content table {
      color: #000000;
      font-size: 100%;
      width: 100%;
    }
    .content a:link,
    .content a:visited{
      color: #1B80CF;
      text-decoration:none;
    }
    .content th {
      color: #FFFFFF;
      background-color: #1B80CF;
      border-radius:2vmax 2vmax 2vmax 2vmax;
      font-size: 120%;
      padding: 15px;
    }
    .content figure {
      max-width:100%;
      max-height:100%;
    }
    .content figure img{
      vertical-align:center;
      display:block;
      margin-left:auto;
      margin-right:auto;
    }
    .content figure figcaption {
      max-width:90%;
      max-height:90%;
      margin:0.1vmax;
      font-size:90%;
      text-align:center;
      padding:0.5vmax;
      background-color: #E1F5FE;
      border-radius:2vmax 2vmax 2vmax 2vmax;
    }
    .content td {
      color: #000000;
      width: 8%;
      padding-left: 3vmax;
      padding-top: 1vmax;
      padding-bottom: 1vmax;
      background-color: #E1F5FE;
      border-radius:2vmax 2vmax 2vmax 2vmax;
    }
    .content li {
      line-height: 4vh;
    }
    .header {
      color: #ffffff;
      background-color: #00549d;
      height: 5vmax;
    }
    .header h1 {
      text-align: center;
      vertical-align: middle;
      font-size: 3vmax;
      line-height: 4vmax;
      margin: 0;
    }
    .footer {
      height: 3vmax;
      line-height: 3vmax;
      vertical-align: middle;
      color: #ffffff;
      background-color: #00549d;
      margin: 0;
      padding: .3vmax;
      overflow: hidden;
    }
    .footer .contact {
      float: left;
      color: #ffffff;
      text-align: left;
      font-size: 3.2vmin;
    }
    .footer .navigation {
      float: right;
      text-align: right;
      width: 8vw;
      font-size: 3vmin;
    }

    .footer .navigation .next,.prev {
      font-size: 3vmin;
      color: #ffffff;
      text-decoration: none;
    }

    .footer .navigation .next::after {
      content: "| >";
    }

    .footer .navigation .prev::after {
      content: "< ";
    }
    /* Using same Jupyter CSS
     */
    .highlight  { background: #f8f8f8; }
    .highlight .c { color: #408080; font-style: italic } /* Comment */
    .highlight .err { border: 1px solid #FF0000 } /* Error */
    .highlight .k { color: #008000; font-weight: bold } /* Keyword */
    .highlight .o { color: #666666 } /* Operator */
    .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
    .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
    .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
    .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
    .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
    .highlight .k { color: #008000; font-weight: bold } /* Keyword */
    .highlight .s2 { color: #BA2121 } /* Literal.String.Double */
    .highlight .s1 { color: #BA2121 } /* Literal.String.Single */
    .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
    .highlight .nb { color: #008000 } /* Name.Builtin */
    .highlight .mb { color: #666666 } /* Literal.Number.Bin */
    .highlight .mf { color: #666666 } /* Literal.Number.Float */
    .highlight .mh { color: #666666 } /* Literal.Number.Hex */
    .highlight .mi { color: #666666 } /* Literal.Number.Integer */
    .highlight .mo { color: #666666 } /* Literal.Number.Oct */
    @media (max-width: 640px), screen and (orientation: portrait) {
       body {
         max-width:100%;
         max-height:100%;
       }
       .slide {
          height: 100%;
          width: 100%;
       }
       .content {
          width: 100%;
          height:92%;
          display: flex;
          flex-direction: row;
          text-align: left;
          padding: 1vw;
          line-height: 3.8vmax;
          font-size: 1.8vmax;
          flex-wrap: wrap;
       }
       .content .topicheading{
         width:90%;
       }
       .content h1, h2, h3, h4 {
          width:100%;
       }
       .content figure img{
          max-width:80vmin;
          max-height:50vmin;
       }
       .content figure figcaption {
           max-width:90%;
           max-height:90%;
       }
    }

    @media print {
      body {
        max-width:100%;
        max-height:100%;
      }
      .content {
        height: 76%;
        width: 90vw;
        display: flex;
        color: #000000;
        text-align: left;
        padding: 5vw;
        font-size: 3vmin;
        flex-wrap: wrap;
      }
      .content figure img{
        max-width:80%;
        max-height:80%;
      }
      .content figcaption {
        max-width:80%;
        max-height:80%;
      }
    }
    </style>
    <script src="tex-mml-chtml.js" id="MathJax-script"></script>
</head>
<body>
	<section class="slide" id="slide1">
		<div class="header">
		</div>
		<div class="content">
			<h1 style="font-size:2.5vw">Apprentissage machine</h1>
                        <p><b>John Samuel</b><br/>
                          CPE Lyon<br/><br/>
                        <b>Year</b>: 2020-2021<br/>
                        <b>Email</b>: john(dot)samuel(at)cpe(dot)fr<br/><br/>
                        <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="../../../../../en/teaching/courses/2017/C/88x31.png" /></a></p>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">1

                                <a class="next" href="#slide2"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide2">
		<div class="header">
			<h1>1. Histoire scientifique: Intelligence Artificielle</h1>
		</div>
		<div class="content">
			<h1>Intelligence Artificielle [Pan 2016, Jaakkola 2019]</h1>
			<ul>
			  <li>La méthode d'apprentissage profond</li>
			  <li>les fusions et acquisitions d'entreprises
			    <ul>
			      <li>DNNresearch par Google</li>
			      <li>LinkedIn par Microsoft</li>
			    </ul>
			  </li>
			  <li>Les chatbots
			    <ul>
			      <li>Xiaobing par Microsoft</li>
			    </ul>
			  </li>
			  <li>Les programmes de jeux
			    <ul>
			      <li>AlphaGo par Google</li>
			    </ul>
			  </li>
			  <li>L'utilisation dans les hôpitaux
			    <ul>
			      <li>Watson par IBM</li>
			    </ul>
			  </li>
			  <li>La compréhension du langage naturel
			    <ul>
			      <li>Baidu</li>
			    </ul>
			  </li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">2
				<a class="prev" href="#slide1"></a>
                                <a class="next" href="#slide3"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide3">
		<div class="header">
			<h1>1. Histoire scientifique: Intelligence Artificielle</h1>
		</div>
		<div class="content">
			<h1>Intelligence Artificielle [Pan 2016, Jaakkola 2019]</h1>
			<ul>
			  <li>1956: la definition d'IA
			    <ul>
			      <li>Proposée par J. McCarthy, M. L. Minsky, H. Simon, A. Newell, C. E. Shannon, N. Rochester,...</li>
			      <li>La capacité des machines à comprendre, à penser et à apprendre d'une manière similaire à celle des êtres humains, </li>
			    </ul>
			  </li>
			  <li>1970-2000
			    <ul>
			      <li>1983: le rapport par James Lighthill</li>
			      <li>1982-1992: l'échec du développement d'un ordinateur intelligent par le Japon</li>
			      <li>1984: la construction manuelle d'une encyclopédie de la connaissance (Cyc) par Stanford</li>
			    </ul>
			  </li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">3
				<a class="prev" href="#slide2"></a>
                                <a class="next" href="#slide4"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide4">
		<div class="header">
			<h1>1. Histoire scientifique: Intelligence Artificielle</h1>
		</div>
		<div class="content">
			<h1>Intelligence Artificielle 2.0 [Pan 2016, Jaakkola 2019]</h1>
			<ul>
			  <li>1990s-présent
			    <ul>
				    <li>Popularité de l'Internet</li>
                                    <li>l'utilisation des capteurs
				    <li>Big Data</li>
				    <li>l'e-commerce</li>
			    </ul>
			  </li>
			  <li>Des demandes sociales pour AI
			    <ul>
			      <li>des villes intelligentes</li>
			      <li>médecine</li>
			      <li>transport</li>
			      <li>les automobiles sans conducteur</li>
			      <li>les smartphones</li>
			    </ul>
			  </li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">4
				<a class="prev" href="#slide3"></a>
                                <a class="next" href="#slide5"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide5">
		<div class="header">
			<h1>1. Histoire scientifique: Intelligence Artificielle</h1>
		</div>
		<div class="content">
			<h1>Intelligence Artificielle 2.0 [Pan 2016]</h1>
			<ul>
			  <li>les technologies à l'origine de l'IA
			    <ul>
				    <li>L'IA basée sur des données massives (Big Data)</li>
				    <li>L'intelligence de la foule sur Internet</li>
				    <li>Le savoir médiatique croisé</li>
				    <li>L'intelligence hybride homme-machine</li>
				    <li>Systèmes autonomes et intelligents</li>
			    </ul>
			  </li>
			  <li>L'avenir
			    <ul>
			      <li>L'AI explicative et générique</li>
			      <li>la cognition, l'apprentissage et l'inférence trans-médiatiques.</li>
			      <li>l'intelligence communautaire à partir de l'intelligence des foules basée sur l'intelligence individuelle</li>
			      <li>des systèmes autonomes et intelligents pour le développement de machines et de produits intelligents.</li>
			    </ul>
			  </li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">5
				<a class="prev" href="#slide4"></a>
                                <a class="next" href="#slide6"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide6">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1 class="topicsubheading">Objectifs</h1>
                       <figure>
                         <img src="../../../../../images/art/courses/deeplearningposition.svg" height="400px"/>
                         <figcaption>Intelligence artificielle</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">6
				<a class="prev" href="#slide5"></a>
                                <a class="next" href="#slide7"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide7">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1 class="topicsubheading">Objectifs</h1>
                        <ol>
                          <li>Apprentissage machine</li>
                          <li>Apprentissage profond</li>
                          <li>Intelligence artificielle</li>
                        </ol>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">7
				<a class="prev" href="#slide6"></a>
                                <a class="next" href="#slide8"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide8">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1 class="topicsubheading">3 approches</h1>
                        <ol>
                         <li><b>Apprentissage supervisé</b>: disponibilité des données de formation labellisées</li>
                         <li><b>Apprentissage non supervisé</b>: aucune donnée de formation labellisée n'est disponible</li>
                         <li><b>Apprentissage semi-supervisé</b>: un petit ensemble de données de formation étiquetées et une grande quantité de données non étiquetées</li>
                        </ol>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">8
				<a class="prev" href="#slide7"></a>
                                <a class="next" href="#slide9"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide9">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1>Formalisation</h1>
			<ul>
                           <li><b>Vecteur euclidien</b>: objet géométrique avec magnitude et direction</li>
                           <li><b>Espace vectoriel</b>: collection de vecteurs qui peuvent être additionnés et multipliés par des nombres</li>
                           <li><b>Vecteur de caractéristiques</b>: vecteur n-dimensionnel</li>
                           <li><b>Espace de caractéristiques</b>: Espace vectoriel associé aux vecteurs</li>
			</ul>
			<h3>Exemples de caractéristiques</h3>
			<ul>
                           <li><b>Images</b>: les valeurs des pixels.</li>
                           <li><b>Textes</b>: Fréquence d'apparition des phrases textuelles.</li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">9
				<a class="prev" href="#slide8"></a>
                                <a class="next" href="#slide10"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide10">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1>Formalisation</h1>
			<ul>
                           <li><b>Construction de caractéristiques<sup>1</sup></b>: construction of new features from already available features</li>
                           <li><b>Opérateurs de construction pour les caractéristiques</b>
                             <ul>
                               <li>Opérateurs d'égalité, opérateurs arithmétiques, opérateurs de tableau (min, max, moyenne, etc.)...</li>
                             </ul>
                           </li>
			</ul>
			<h3>Example</h3>
			<ul>
                           <li>Soit <b>Année de naissance</b> et <b>Année de décès</b> deux caractéristiques existantes.</li>
			   <li>Une nouvelle caractéristique appelée  <b>âge</b> est créée. <b>âge</b> =  <b>Année de décès</b> - <b>Année de naissance</b></li>
			</ul>
                        <ol style="font-size:2vh">
                           <li>https://en.wikipedia.org/wiki/Feature_vector</li>
                        </ol>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">10
				<a class="prev" href="#slide9"></a>
                                <a class="next" href="#slide11"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide11">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1>Formalisation: Supervised learning</h1>
			<ul>
                           <li>Soit <i><b>N</b></i> le nombre d'exemples d'entraînement</li>
                           <li>Soit <i><b>X</b></i> l'espace de saisie des caractéristiques</li>
                           <li>Soit <i><b>Y</b></i> l'espace des caractéristiques de sortie (des étiquettes)</li>
                           <li>Soit {<i>(x<sub>1</sub>, y<sub>1</sub>),...,(x<sub><b>N</b></sub>, y<sub><b>N</b></sub>)</i>} les <i><b>N</b></i> exemples d'entraînement, où
                            <ul>
                             <li><i>x<sub>i</sub></i>  est le vecteur de caractéristiques de <i>i<sup>ème</sup></i> exemple d'entraînement.</li>
                             <li><i>y<sub>i</sub></i> est son label.</li>
                            </ul>
                           </li>
                           <li>L'objectif de l'algorithme d'apprentissage supervisé est de trouver  <i>g: <b>X</b> &#8594; <b>Y</b></i>, où
                            <ul>
                              <li><i>g</i> est l'une des fonctions de l'ensemble des fonctions possibles <i>G</i> (espace des hypothèses)</li>
                            </ul>
                           </li>
                           <li><b>Fonction d'évaluation<i>F</i></b> indiquent l'espace des fonctions d'évaluation, où
                            <ul>
                              <li><i>f: <b>X</b> &#215; <b>Y</b> &#8594; <b>R</b></i> telle que <i>g</i> renvoie la fonction d'évaluation la plus élevée.</li>
                            </ul>
                           </li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">11
				<a class="prev" href="#slide10"></a>
                                <a class="next" href="#slide12"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide12">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1>Formalisation: Apprentissage non supervisé</h1>
			<ul>
                           <li>Soit <i><b>X</b></i> l'espace de saisie des caractéristiques</li>
                           <li>Soit <i><b>Y</b></i> l'espace des caractéristiques de sortie (des étiquettes)</li>
                           <li>L'objectif de l'algorithme d'apprentissage non supervisé est
                            <ul>
                              <li>trouver la mise en correspondance <i><b>X</b> &#8594; <b>Y</b></i></li>
                            </ul>
                           </li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">12
				<a class="prev" href="#slide11"></a>
                                <a class="next" href="#slide13"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide13">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1>Formalisation: Apprentissage semi-supervisé</h1>
			<ul>
                           <li>Soit <i><b>X</b></i> l'espace de saisie des caractéristiques</li>
                           <li>Soit <i><b>Y</b></i> l'espace des caractéristiques de sortie (des étiquettes)</li>
                           <li>Soit {<i>(x<sub>1</sub>, y<sub>1</sub>),...,(x<sub>l</sub>, y<sub>l</sub>)</i>} l'ensemble d'exemples d'exercices étiquetés</li>
                           <li>Soit {<i>x<sub>l+1</sub>,...,x<sub>l+u</sub></i>} be the <i><b>u</b></i> l'ensemble des vecteurs de caractéristiques non étiquetées de <i><b>X</b></i>.</li>
                           <li>L'objectif de l'algorithme d'apprentissage semi-supervisé est de faire
                            <ul>
                              <li><b>l'apprentissage transductif</b>, c'est-à-dire trouver des étiquettes correctes pour  {<i>x<sub>l+1</sub>,...,x<sub>l+u</sub></i>}.</li>
                              <li><b>l'apprentissage inductif</b>, c'est-à-dire trouver la bonne mise en correspondance <i><b>X</b> &#8594; <b>Y</b></i></li>
                            </ul>
                           </li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">13
				<a class="prev" href="#slide12"></a>
                                <a class="next" href="#slide14"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide14">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1 class="topicheading">Classification</h1>
			<h1 class="topicsubheading">Définition formelle</h1>
			<ul>
                           <li>Soit <i><b>X</b></i> l'espace de saisie des caractéristiques</li>
                           <li>Soit <i><b>Y</b></i> l'espace des caractéristiques de sortie (des étiquettes)</li>
                           <li>L'objectif de l'algorithme de classification (ou classificateur) est de trouver
                             {<i>(x<sub>1</sub>, y<sub>1</sub>),...,(x<sub>l</sub>, y<sub>k</sub>)</i>}, c'est-à-dire l'attribution d'une étiquette connue à chaque vecteur de caractéristique d'entrée, où
                            <ul>
                             <li><i>x<sub>i</sub> &#8712; <b>X</b></i> </li>
                             <li><i>y<sub>i</sub> &#8712; <b>Y</b></i></li>
                             <li>|<i><b>X</b> </i>| <i>= l</i></li>
                             <li>|<i><b>Y</b> </i>| <i>= k</i></li>
                             <li>l &gt;= k</li>
                            </ul>
                           </li>
                         </ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">14
				<a class="prev" href="#slide13"></a>
                                <a class="next" href="#slide15"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide15">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Classification</h2>
			<h3 class="topicsubheading">Classificateurs</h3>
			<ul>
                           <li>Algorithme de classification</li>
                           <li>Deux types de classificateurs:
                            <ul>
                             <li><b>Classificateurs binaires</b> attribue un objet à l'une des deux classes</li>
                             <li><b>Classificateurs multiclasses</b> attribue un objet à une ou plusieurs classes</li>
                            </ul>
                           </li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">15
				<a class="prev" href="#slide14"></a>
                                <a class="next" href="#slide16"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide16">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Classification binaire</h2>
                  <figure>
                    <img src="../../../../../en/teaching/courses/2019/MachineLearning/binaryclassifier.svg" height="400px"/>
                    <figcaption>Classification binaire</figcaption>
                  </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">16
				<a class="prev" href="#slide15"></a>
                                <a class="next" href="#slide17"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide17">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Classification</h2>
			<h3 class="topicsubheading">Linear Classificateurs</h3>
			<ul>
                           <li>Fonction linéaire attribuant un score à chaque catégorie possible en combinant le vecteur de caractéristiques d'une instance avec un vecteur de poids, en utilisant un produit de points.</li>
                           <li>Formalisation :
			   <ul>
                             <li>Soit <i><b>X</b></i> être l'espace de saisie des caractéristiques et <i><b>x</b><sub>i</sub> &#8712; <b>X</b></i></li>
                             <li>Soit <i><b>&#946;</b><sub>k</sub></i>  un vecteur de poids pour la catégorie <i>k</i></li>
                             <li><i>score(<b>x</b><sub>i</sub>, k) = <b>x</b><sub>i</sub>.<b>&#946;</b><sub>k</sub></i>, score pour l'attribution de la catégorie <i>k</i> à l'instance <i><b>x</b><sub>i</sub></i>. La catégorie qui donne le score le plus élevé est attribuée à la catégorie de l'instance.</li>
                            </ul>
                           </li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">17
				<a class="prev" href="#slide16"></a>
                                <a class="next" href="#slide18"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide18">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Classification</h2>
                  <figure>
                    <img src="../../../../../en/teaching/courses/2018/DataMining/positivenegative.svg" height="400px"/>
                    <figcaption>Les vrais positifs et les vrais négatifs</figcaption>
                  </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">18
				<a class="prev" href="#slide17"></a>
                                <a class="next" href="#slide19"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide19">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Classification</h2>
                  <figure>
                    <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" height="400px"/>
                    <figcaption>Précision et rappel</figcaption>
                  </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">19
				<a class="prev" href="#slide18"></a>
                                <a class="next" href="#slide20"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide20">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Classification</h2>
                   <p>Soit</p>
                   <ul>
                    <li><i>tp</i>: nombre de vrais postifs</li>
                    <li><i>fp</i>: nombre de faux positifs</li>
                    <li><i>fn</i>: nombre de faux négatifs</li>
                   </ul>
                   <p>Alors</p>
                   <ul>
                    <li>Précision <i>p  = tp / (tp + fp)</i></li>
                    <li>Rappel (Recall) <i>r  = tp / (tp + fn)</i></li>
                    <li>F1-score <i>f1  = 2 * ((p * r) / (p + r))</i></li>
                    <li>F1-score: meilleure valeur à 1 (précision et rappel parfaits) et pire à 0.</li>
                   </ul>
                  <figure class="gridcontent">
                    <img src="../../../../../en/teaching/courses/2018/DataMining/Precisionrecall.svg" height="400px"/>
                  </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">20
				<a class="prev" href="#slide19"></a>
                                <a class="next" href="#slide21"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide21">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Matrice de confusion</h2>
                  <figure>
                    <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix.png" height="400px"/>
                    <figcaption>Matrice de confusion pour un classificateur SVM pour les chiffres manuscrits (MNIST)</figcaption>
                  </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">21
				<a class="prev" href="#slide20"></a>
                                <a class="next" href="#slide22"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide22">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Matrice de confusion</h2>
                  <figure>
                    <img src="../../../../../en/teaching/courses/2019/DataMining/confusionmatrix1.png" height="400px"/>
                    <figcaption>Matrice de confusion pour un perceptron pour les chiffres manuscrits (MNIST)</figcaption>
                  </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">22
				<a class="prev" href="#slide21"></a>
                                <a class="next" href="#slide23"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide23">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Classification multiclasse</h2>
                  <figure>
                    <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg" height="400px"/>
                    <figcaption>Classification multiclasse</figcaption>
                  </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">23
				<a class="prev" href="#slide22"></a>
                                <a class="next" href="#slide24"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide24">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Classification</h2>
			<h3 class="topicsubheading">Classification multiclasse</h3>
                        <ul>
                          <li>Transformation en classification binaire
                           <ul>
                              <li>L'approche un contre le reste (Un contre tous)</li>
                              <li>L'approche un-contre-un</li>
                           </ul>
                          </li>
                          <li>Extension de la classification binaire
                           <ul>
                              <li>Réseaux de neurones</li>
                              <li>k-voisins les plus proches</li>
                           </ul>
                          </li>
                        </ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">24
				<a class="prev" href="#slide23"></a>
                                <a class="next" href="#slide25"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide25">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Classification multiclasse</h2>
                  <figure>
                    <img src="../../../../../en/teaching/courses/2019/MachineLearning/multiclassclassifier.svg" height="400px"/>
                    <figcaption>Classification multiclasse</figcaption>
                  </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">25
				<a class="prev" href="#slide24"></a>
                                <a class="next" href="#slide26"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide26">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h3 class="topicsubheading">One-vs.-rest (One-vs.-all) strategy</h3>
                  <figure>
                    <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsall.svg" height="400px"/>
                    <figcaption>La strategie un-contre le rest pour la classification multiclasse</figcaption>
                  </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">26
				<a class="prev" href="#slide25"></a>
                                <a class="next" href="#slide27"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide27">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h3 class="topicsubheading">One-vs.-one strategy</h3>
                  <figure>
                    <img src="../../../../../en/teaching/courses/2019/MachineLearning/onevsone.svg" height="400px"/>
                    <figcaption>La strategie un-contre-un pour la classification multiclasse</figcaption>
                  </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">27
				<a class="prev" href="#slide26"></a>
                                <a class="next" href="#slide28"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide28">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Réseaux de neurones artificiels</h2>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2017/DataMining/images/Colored_neural_network.svg"/>
                         <figcaption>Réseaux de neurones artificiels</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">28
				<a class="prev" href="#slide27"></a>
                                <a class="next" href="#slide29"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide29">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicheading">Perceptron</h2>
			<ul>
                           <li>Algorithme pour l'apprentissage supervisé des classificateurs binaires</li>
                           <li>Le classificateur binaire est un classificateur qui décide si une entrée donnée appartient ou non à une classe particulière</li>
                           <li>Inventé en 1958 par Frank Rosenblatt</li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">29
				<a class="prev" href="#slide28"></a>
                                <a class="next" href="#slide30"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide30">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1 class="topicsubheading">Perceptron</h1>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2017/DataMining/images/Perceptron.svg" height="400px"/>
                         <figcaption>Perceptron</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">30
				<a class="prev" href="#slide29"></a>
                                <a class="next" href="#slide31"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide31">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1>Perceptron: Définition formelle</h1>
			<ul>
                           <li>Soit \(y = f(z)\) la sortie du perceptron pour un vecteur d'entrée <i>z</i></li>
                           <li>Soit \(N\) le nombre d'exemples d'entraînement</li>
                           <li>Soit <i><b>X</b></i> l'espace de saisie des caractéristiques</li>
			   <li>Soit \({(x_{1}, d_{1}),...,(x_{N}, d_{N})}\) be the <i><b>N</b></i> training examples, where
                            <ul>
                             <li><i>x<sub>i</sub></i> est le vecteur caractéristique de <i>i<sup>ème</sup></i> exemple d'entraînement.</li>
                             <li><i>d<sub>i</sub></i> est la valeur de sortie souhaitée</li>
                             <li><i>x<sub>j,i</sub></i> est la <i>i<sup>ème</sup></i> caractéristique de <i>j<sup>ème</sup></i> exemple d'entraînement.</li>
                             <li><i>x<sub>j,0</sub></i> = 1</li>
                            </ul>
                           </li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">31
				<a class="prev" href="#slide30"></a>
                                <a class="next" href="#slide32"></a>est le taux d'apprentissage.
			</div>
		</div>
	</section>
	<section class="slide" id="slide32">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1>Perceptron: Définition formelle</h1>
			<ul>
                           <li>Les poids sont représentés de la manière suivante:
                            <ul>
                             <li><i>w<sub>i</sub></i> est la <i>i<sup>ème</sup></i> value of weight vector.</li>
                             <li><i>w<sub>i</sub>(t)</i> est la <i>i<sup>ème</sup></i> valeur du vecteur de poids à un moment donné t.</li>
                            </ul>
                           </li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">32
				<a class="prev" href="#slide31"></a>
                                <a class="next" href="#slide33"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide33">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1>Perceptron : Étapes</h1>
			<ol>
                           <li>Initialiser les poids et les seuils</li>
                           <li>Pour chaque exemple, <i>(x<sub>j</sub>, d<sub>j</sub>)</i> dans l'ensemble d'entraînement<i></i>
                            <ul>
                             <li>Calculate the weight: <i>y<sub>j</sub>(t)=f[w(t).x<sub>j</sub>]</i></li>
                             <li>Calculer le poids: <i>w<sub>i</sub>(t + 1) = w<sub>i</sub>(t) + r. (d<sub>j</sub>-y<sub>j</sub>(t))x<sub>j,i</sub></i></li>
                            </ul>
                           </li>
                           <li>Répétez l'étape 2 jusqu'à l'erreur d'itération <i>1/s (&#931; |d<sub>j</sub> - y<sub>j</sub>(t)|)</i> est inférieur au seuil spécifié par l'utilisateur.</li>
                           <li><i>s</i> est la taille de l'échantillon et <i>r</i> est le taux d'apprentissage.</li>
			</ol>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">33
				<a class="prev" href="#slide32"></a>
                                <a class="next" href="#slide34"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide34">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicsubheading">Fonction d'activation: fonction d'identité</h2>
			<h4>Équation</h4>
			<p>\[f(x)=x\]</p>
			<h4>Dérivée</h4>
			<p>\[f'(x)=1\]</p>
			<h3></h3>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_identity.svg" height="380px"/>
                         <figcaption>Fonction d'identité</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">34
				<a class="prev" href="#slide33"></a>
                                <a class="next" href="#slide35"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide35">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h1 class="topicsubheading">Fonction d'activation: pas binaire</h2>
			<h4>Équation</h4>
			<p>\[f(x) = \begin{cases}
	0 & \text{for } x < 0\\
	1 & \text{for } x \ge 0 \end{cases}
	 \]</p>
			<h4>Dérivée</h4>
			<p>\[f'(x) = \begin{cases}
	0 & \text{for } x \ne 0\\
	? & \text{for } x = 0\end{cases}\]</p>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_binary_step.svg" height="380px"/>
                         <figcaption>Pas binaire</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">35
				<a class="prev" href="#slide34"></a>
                                <a class="next" href="#slide36"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide36">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicsubheading">Fonction d'activation: fonction sigmoïde</h2>
			<h4>Équation</h4>
			<p>\[f(x)=\sigma(x)=\frac{1}{1+e^{-x}}\]</p>
			<h4>Dérivée</h4>
			<p>\[f'(x)=f(x)(1-f(x))\]</p>
                       <figure>
                         <img src="Logistic-curve.svg" height="380px"/>
                         <figcaption>La fonction sigmoïde</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">36
				<a class="prev" href="#slide35"></a>
                                <a class="next" href="#slide37"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide37">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicsubheading">Fonction d'activation: TanH</h2>
			<h4>Équation</h4>
			<p>\[f(x)=\tanh(x)=\frac{(e^{x} - e^{-x})}{(e^{x} + e^{-x})}\]</p>
			<h4>Dérivée</h4>
			<p>\[f'(x)=1-f(x)^2\]</p>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_tanh.svg" height="380px"/>
                         <figcaption>TanH</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">37
				<a class="prev" href="#slide36"></a>
                                <a class="next" href="#slide38"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide38">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicsubheading">Fonction d'activation: Rectified linear unit: ReLU</h2>
			<h4>Équation</h4>
			<p>\[f(x) = \begin{cases}
	0 & \text{for } x \le 0\\
	x & \text{for } x > 0\end{cases} = \max\{0,x\}= x \textbf{1}_{x>0}\]</p>
			<h4>Dérivée</h4>
			<p>\[f'(x) = \begin{cases}
	0 & \text{for } x \le 0\\
	1 & \text{for } x > 0\end{cases}\]</p>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_rectified_linear.svg" height="380px"/>
                         <figcaption>Unité linéaire rectifiée (ReLU)</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">38
				<a class="prev" href="#slide37"></a>
                                <a class="next" href="#slide39"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide39">
		<div class="header">
			<h1>2. Apprentissage machine</h1>
		</div>
		<div class="content">
			<h2 class="topicsubheading">Fonction d'activation: Gaussien</h2>
			<h4>Équation</h4>
			<p>\[f(x)=e^{-x^2}\]</p>
			<h4>Dérivée</h4>
			<p>\[f'(x)=-2xe^{-x^2}\]</p>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2019/MachineLearning/Activation_gaussian.svg" height="380px"/>
                         <figcaption>Gaussien</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">39
				<a class="prev" href="#slide38"></a>
                                <a class="next" href="#slide40"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide40">
		<div class="header">
			<h1>3. Apprentissage profond</h1>
		</div>
		<div class="content">
			<h1>Apprentissage profond</h1>
                        <ul>
			  <li>Le mot "profond" dans l'apprentissage profond vient de l'utilisation de multiples couches dans le réseau neuronal.</li>
			  <li>Un perceptron linéaire ne peut pas être un classificateur universel. Un perceptron "monocouche" ne peut pas mettre en œuvre le XOR</li>
			  <li>Les réseaux d'apprentissage en profondeur permettent un nombre illimité de couches de taille limitée</li>
                          <li>Il utilise plusieurs couches pour extraire progressivement des caractéristiques de l'entrée brute.</li>
                        </ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">40
				<a class="prev" href="#slide39"></a>
                                <a class="next" href="#slide41"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide41">
		<div class="header">
			<h1>3. Apprentissage profond</h1>
		</div>
		<div class="content">
                       <figure>
                         <img src="Deep_Learning.jpg" height="450px"/>
                         <figcaption>Source: https://en.wikipedia.org/wiki/File:Deep_Learning.jpg</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">41
				<a class="prev" href="#slide40"></a>
                                <a class="next" href="#slide42"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide42">
		<div class="header">
			<h1>3. Apprentissage profond</h1>
		</div>
		<div class="content">
                       <figure>
                         <img src="Screenshot_2020-10-20 Tensorflow — Neural Network Playground.png" height="450px"/>
                         <figcaption>Source: https://playground.tensorflow.org/</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">42
				<a class="prev" href="#slide41"></a>
                                <a class="next" href="#slide43"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide43">
		<div class="header">
			<h1>3. Apprentissage profond</h1>
		</div>
		<div class="content">
                       <figure>
                         <img src="Screenshot_2020-10-20 Tensorflow 2 — Neural Network Playground.png" height="450px"/>
                         <figcaption>Source: https://playground.tensorflow.org/</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">43
				<a class="prev" href="#slide42"></a>
                                <a class="next" href="#slide44"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide44">
		<div class="header">
			<h1>3. Apprentissage profond</h1>
		</div>
		<div class="content">
			<h1 class="topicheading">Feedforward neural network</h1>
			<ul>
                           <li>Les connexions entre les nœuds ne forment pas un cycle</li>
                           <li>Les informations se déplacent des nœuds d'entrée vers les nœuds de sortie, en passant par les nœuds cachés (le cas échéant). </li>
                           <li>L'information ne circule que dans un seul sens, vers l'avant</li>
			</ul>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2019/MachineLearning/Feed_forward_neural_net.gif" height="280px"/>
                         <figcaption>Réseau de neurones en aval</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">44
				<a class="prev" href="#slide43"></a>
                                <a class="next" href="#slide45"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide45">
		<div class="header">
			<h1>3. Apprentissage profond</h1>
		</div>
		<div class="content">
			<h1 class="topicsubheading">Réseau de neurones en aval (Feedforward neural networks)</h1>
			<h1 class="topicsubheading">Perceptron simple couche</h1>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2019/MachineLearning/ArtificialNeuronModel_english.png" height="380px"/>
                         <figcaption>Perceptron simple couche</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">45
				<a class="prev" href="#slide44"></a>
                                <a class="next" href="#slide46"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide46">
		<div class="header">
			<h1>3. Apprentissage profond</h1>
		</div>
		<div class="content">
			<h1 class="topicsubheading">Réseau de neurones en aval (Feedforward neural networks)</h1>
			<h1 class="topicsubheading">Perceptron multicouche</h1>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2019/MachineLearning/XOR_perceptron_net.png" height="380px"/>
                         <figcaption>Perceptron multicouche</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">46
				<a class="prev" href="#slide45"></a>
                                <a class="next" href="#slide47"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide47">
		<div class="header">
			<h1>3. Apprentissage profond</h1>
		</div>
		<div class="content">
			<h1 class="topicsubheading">Réseau de neurones en aval (Feedforward neural networks) </h1>
			<h1 class="topicsubheading">Rétropropagation du gradient (Backpropagation)</h1>
			<ul>
                           <li>calcule le gradient de la fonction de perte par rapport aux poids du réseau pour un seul exemple d'entrée-sortie.</li>
                           <li>fonctionne en calculant le gradient de la fonction de perte par rapport à chaque poids selon la règle de la chaîne</li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">47
				<a class="prev" href="#slide46"></a>
                                <a class="next" href="#slide48"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide48">
		<div class="header">
			<h1>2. Apprentissage profond</h1>
		</div>
		<div class="content">
			<h1 class="topicheading">Réseau de neurones récurrents</h1>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2019/MachineLearning/Recurrent_neural_network_unfold.svg" height="380px"/>
                         <figcaption>Réseau de neurones récurrents</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">48
				<a class="prev" href="#slide47"></a>
                                <a class="next" href="#slide49"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide49">
		<div class="header">
			<h1>2. Apprentissage profond</h1>
		</div>
		<div class="content">
			<h1 class="topicsubheading">Réseau récurrent à mémoire court et long terme</h1>
			<h1 class="topicsubheading">Long short-term memory (LSTM) network</h1>
                       <figure>
                         <img src="../../../../../en/teaching/courses/2019/MachineLearning/Long_Short-Term_Memory.svg " height="380px"/>
                         <figcaption>LSTM</figcaption>
                       </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">49
				<a class="prev" href="#slide48"></a>
                                <a class="next" href="#slide50"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide50">
		<div class="header">
			<h1>2. Apprentissage profond</h1>
		</div>
		<div class="content">
			<h1>Réseaux de neurones convolutionnels</h1>
                        <figure>
                           <img src="../../../../../en/teaching/courses/2017/DataMining/images/Typical_cnn.png" height="380px"/>
                        </figure>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">50
				<a class="prev" href="#slide49"></a>
                                <a class="next" href="#slide51"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide51">
		<div class="header">
			<h1>2. Apprentissage profond</h1>
		</div>
		<div class="content">
			<h1>Réseaux de neurones convolutionnels</h1>
			<ul>
                           <li>Analyse des images</li>
                           <li>Utilise la convolution, une opération mathématique linéaire</li>
                           <li>Une couche d'entrée et une couche de sortie</li>
                           <li>Plusieurs couches cachées, constituées de couches convolutives</li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">51
				<a class="prev" href="#slide50"></a>
                                <a class="next" href="#slide52"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide52">
		<div class="header">
			<h1>Références</h1>
		</div>
		<div class="content">
			<h1>Articles de recherche</h1>
			<ul>
				<li>[Jaakkola 2019] Jaakkola, H., et al. “Artificial Intelligence Yesterday, Today and Tomorrow.” 2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO), 2019, pp. 860–67. IEEE Xplore</li>
				<li>[Pan 2016] Pan, Yunhe, “Heading toward Artificial Intelligence 2.0.” Engineering, vol. 2, no. 4, Dec. 2016, pp. 409–13. www.sciencedirect.com,</li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">52
				<a class="prev" href="#slide51"></a>
                                <a class="next" href="#slide53"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide53">
		<div class="header">
			<h1>Références:</h1>
		</div>
		<div class="content">
			<h1>Web</h1>
			<ul>
				<li><a href="https://en.wikipedia.org/wiki/Perceptron">https://en.wikipedia.org/wiki/Perceptron</a></li>
				<li><a href="https://en.wikipedia.org/wiki/Multiclass_classification">https://en.wikipedia.org/wiki/Multiclass_classification</a></li>
				<li><a href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a></li>
				<li><a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">https://en.wikipedia.org/wiki/Multilayer_perceptron</a></li>
				<li><a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a></li>
				<li><a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">https://en.wikipedia.org/wiki/Recurrent_neural_network</a></li>
				<li><a href="https://en.wikipedia.org/wiki/Long_short-term_memory">https://en.wikipedia.org/wiki/Long_short-term_memory</a></li>
				<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html</a></li>
				<li><a href="https://en.wikipedia.org/wiki/Activation_function">https://en.wikipedia.org/wiki/Activation_function</a></li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">53
				<a class="prev" href="#slide52"></a>
                                <a class="next" href="#slide54"></a>
			</div>
		</div>
	</section>
	<section class="slide" id="slide54">
		<div class="header">
			<h1>Références:</h1>
		</div>
		<div class="content">
			<h1>Couleurs</h1>
			<ul>
				<li><a href="https://material.io/color/">Color Tool - Material Design</a></li>
			</ul>
			<h1>Images</h1>
			<ul>
				<li><a href="https://commons.wikimedia.org/">Wikimedia Commons</a></li>
			</ul>
		</div>
		<div class="footer">
			<div class="contact">Apprentissage machine | John Samuel</div>
			<div class="navigation">54
				<a class="prev" href="#slide53"></a>
			</div>
		</div>
	</section>

	<script>
		function changeCurrentURLSlideNumber(isIncrement) {
			url = window.location.href;
			position = url.indexOf("#slide");
			if (position != -1) { // Not on the first page
				slideIdString = url.substr(position + 6);
				if (!Number.isNaN(slideIdString)) {
					slideId = parseInt(slideIdString);
					if (isIncrement) {
                                               if (slideId  < 60) {
						slideId = slideId + 1;
                                               }
					} else {
						if (slideId > 1) {
							slideId = slideId - 1;
						}
					}
                                        /* regexp */
					url = url.replace(/#slide\d+/g, "#slide" + slideId);
					window.location.href = url;
				}
			} else {
				window.location.href = url + "#slide2";
			}
		}
		document.onkeydown = function(event) {

			event.preventDefault(); /* This will ensure the default behavior of
													        page scroll behaviour (up, down, right, left)*/

			event = event || window.event;
                        /*Codes de la touche sur le clavier: 37, 38, 39, 40*/
			if (event.keyCode == '37') {
				// left
				changeCurrentURLSlideNumber(false);
			} else if (event.keyCode == '38') {
				// up
				changeCurrentURLSlideNumber(false);
			} else if (event.keyCode == '39') {
				// right
				changeCurrentURLSlideNumber(true);
			} else if (event.keyCode == '40') {
				// down
				changeCurrentURLSlideNumber(true);
			}
		}
		document.body.onmouseup = function(event) {
			event = event || window.event;
			event.preventDefault();
			changeCurrentURLSlideNumber(true);
		}
       </script>
</body>
</html>

