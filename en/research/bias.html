<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <meta http-equiv="Content-Language" content="en"/>
    <link rel="shortcut icon" href="../../images/logo/favicon.png"/>
    <title>Bias in Data Science: John Samuel</title>
    <style type="text/css">
    body{
      background-color: #FFFFFF;
    }
    #sidebar {
      position: fixed;
      background-color: #1B80CF;
      top: 0;
      left: 0;
      bottom: 0;
      width:30vw;
    }
    #sidebar .title {
      position:relative;
      text-align: center;
      line-height: 4vmax;
      font-size: 1.4vmax;
      font-family: 'Arial';
      margin-top: 25vh;
    }
    #sidebar .title a:link,
    #sidebar .title a:visited{
     color: #FFFFFF;
     text-decoration:none;
    }
    .subtitle {
      top: 50vh;
      text-align: center;
      line-height: 1.3vmax;
      font-family: 'Arial';
      font-size: 1.5vmax;
      color: #FFFFFF;
    }
    .subtitle a:link,
    .subtitle a:visited{
     color: #FFFFFF;
     text-decoration:none;
    }
    .licence {
      position:fixed;
      text-align: right;
      bottom:0;
      right:0;
    }
    .home {
     position:fixed;
     text-align: left;
     font-family: 'Arial';
     color: #D3D3D3;
     z-index:100;
     width:100%;
     background-color:#FFFFFF;
     top:0px;
     margin-bottom:10px;
     padding-bottom:10px;
    }
    .home a:link,
    .home a:visited{
     text-decoration:none;
     color: #D3D3D3;
    }
    .home ul{
      margin: 0;
      padding: 0;
      text-align: left;
      list-style:none;
    }
    .home li{
     position: relative;
     float: left;
     padding-top:15px;
     margin-right: 1em;
     font-family: 'Arial';
    }
    .home li:hover {
      display:block;
    }
    .home a:link,
    .home a:visited{
     color: #D3D3D3;
    }
    .home li:hover a:link,
    .home li:hover a:visited{
      text-decoration:none;
      padding:15px;
      color:#FFFFFF;
      background-color: #1B80CF;
    }
    .content {
     line-height: 1.8vmax;
     font-size: 1.2vmax;
     font-family: 'Arial';
     margin-top: 15vh;
     width:90%;
    }
    .content h2, h3, h4{
     color:#1B80CF;
    }
    .content a:link,
    .content a:visited{
     color: #1B80CF;
    }
    .content h3 {
     color: #1B80CF;
    }
    .content h2::before,
    .content h3::before{
       display: block;
       content : " ";
       visibility:hidden;
       height:50px;
       margin-top:-50px;
       pointer-events: none;
       background-color:#FFFFFF;
    }
    .content a:link,
    .content a:visited{
     color:#1B80CF;
    }
    .content li {
      margin:5px;
    }
    .page {
      width:65vw;
      height:100%;
      margin-left:30vw;
      overflow: hidden;
      padding: 0 1em;
      font-family: 'Arial';
    }
   .page img {
     max-width:100%;
     max-height:100%;
   }
    @media (max-width: 640px), screen and (orientation: portrait) {
      body {
        max-width:100%;
        max-height:100%;
      }
      #sidebar {
        position: fixed;
        background-color: #1B80CF;
        top: 0;
        left: 0;
        bottom: 80vh;
        width:100vw;
      }
      #sidebar .title {
        text-align: center;
        position: fixed;
        margin-top: 6vh;
        left:0px;
        right:0px;
        line-height: 3.5vmax;
        font-size: 1.5vmax;
        font-family: 'Arial';
      }
      #sidebar .subtitle {
        text-align:center;
        top: 5vh;
        left:0px;
        right:0px;
        position: fixed;
        margin-top: 10vh;
        font-size: 1.5vmax;
      }
      #sidebar .title a:link,
      #sidebar .title a:visited{
        text-align:center;
        color:#FFFFFF;
      }
      #sidebar .subtitle a:link,
      #sidebar .subtitle a:visited{
        text-align:center;
        color:#FFFFFF;
      }
      .home{
        z-index:100;
        width:100%;
        background-color:#1B80CF;
        font-size:1.5vmax;
      }
      .home a:link,
      .home a:visited{
        text-decoration:none;
        color:#FFFFFF;
      }
      .content {
        line-height: 3.8vmax;
        font-size: 1.8vmax;
        font-family: 'Arial';
        margin-top:22vh;
      }
      .content a:link,
      .content a:visited{
        color:#1B80CF;
      }
      .page {
        top: 40vh;
        width:95%;
        margin-left:0vw;
      }
      .page img {
        max-width:100%;
        max-height:100%;
        border:0;
      }
    }

    </style>
  </head>
  <body vocab="http://schema.org/">
    <div class="page">
      <div class="home">
       <ul typeof="BreadcrumbList">
        <li property="itemListElement" typeof="ListItem">
            <a property="item" typeof="WebPage" href="../index.html">
              <span property="name">Home</span>
            </a>
        </li>
        <li property="itemListElement" typeof="ListItem">
            <a property="item" typeof="WebPage" href="../research/research.html">
              <span property="name">Research</span>
            </a>
        </li>
       </ul>

      </div>
      <div id="sidebar">
      <div class="title">
        <h1><a href="template.html">Bias in Data Science</a></h1>
      </div>
      <div class="subtitle">
        <h3><a href="../about.html">John Samuel</a></h3>
      </div>
      </div>
      
      <div class="content">
        <p style="color:red;text-align:center">NOTE: Article in Progress</p>
        <p>
         One of the goals of machine learning algorithms is to detect patterns from the available data and then predict similar possible patterns. 
        </p>
        <p>
         Human bias and prejudices are well known.
         Laws and regulations have been created around the world to tackle such bias.
         Anti-discrimination laws ensure fair treatment of every individual.
         However, what will happen if our biases and prejudices also appear in the technologies that we create.
         But impacts of such prediction technologies<sup><a href="#bias-technology">1</a></sup> are numerous on the society
        </p>
        <p>disadvantaged</p>
        <p>
        Current generation of algorithms are trained to build models from the data that is fed unto them and the results may not help.
        Results may confirm our human biases and prejudices<sup><a href="#racism-software">2</a></sup>, but won't help to build technology that serves a diverse community.
        </p>
        <p>data diversity: is the amount of data for each group enough? data quantity as well?</p>
        <p>Human beings have evolved all these years. Our assumption that our past can predict our future<sup><a href="#bias-technology">1</a></sup> will not help the progress of humanity.</p>
        <p>Sample data used for analysis must cover a wide range</p>
        <p>correlation does not mean causation</p>
        <p>'discrimination-aware' data mining</p>
        <p>principles and steps to take ensure fairness<sup><a href="#principles-accountability">5</a></sup> especially in matters of race, nationality, sex, gender identity etc.
        </p>
        <h3>References</h3>
        <ol>
         <li id="bias-technology"><a href="https://fivethirtyeight.com/features/technology-is-biased-too-how-do-we-fix-it/">Technology Is Biased Too. How Do We Fix It?</a></li>
         <li id="racism-software"><a href="https://www.politico.com/agenda/story/2018/02/07/algorithmic-bias-software-recommendations-000631">Is your software racist?</a></li>
         <li id="confirmation-bias"><a href="https://en.wikipedia.org/wiki/Confirmation_bias">Confirmation bias</a></li>
         <li id="digital-decisions"><a href="https://cdt.org/issue/privacy-data/digital-decisions/">Digital Decisions</a></li>
          <li id="principles-accountability"><a href="https://www.fatml.org/resources/principles-for-accountable-algorithms">Principles for Accountable Algorithms and a Social Impact Statement for Algorithms</a></li>
        </ol>
      </div>
      
      <br/>
      
    </div>
  </body>
</html>
