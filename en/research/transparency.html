<!DOCTYPE html>
<html lang="en">

    <head>
        <meta charset="utf-8" />
        <meta http-equiv="Content-Language" content="en" />
        <link rel="shortcut icon" href="../../images/logo/favicon.png" />
        <title>Data Science and Transparency: John Samuel</title>
        <style type="text/css">
            body {
                background-color: #FFFFFF;
            }

            #sidebar {
                position: fixed;
                background-color: #1B80CF;
                top: 0;
                left: 0;
                bottom: 0;
                width: 30vw;
            }

            #sidebar .title {
                position: relative;
                text-align: center;
                line-height: 4vmax;
                font-size: 1.4vmax;
                font-family: 'Arial';
                margin-top: 25vh;
            }

            #sidebar .title a:link,
            #sidebar .title a:visited {
                color: #FFFFFF;
                text-decoration: none;
            }

            .subtitle {
                top: 50vh;
                text-align: center;
                line-height: 1.3vmax;
                font-family: 'Arial';
                font-size: 1.5vmax;
                color: #FFFFFF;
            }

            .subtitle a:link,
            .subtitle a:visited {
                color: #FFFFFF;
                text-decoration: none;
            }

            .licence {
                position: fixed;
                text-align: right;
                bottom: 0;
                right: 0;
            }

            .home {
                position: fixed;
                text-align: left;
                font-family: 'Arial';
                color: #D3D3D3;
                z-index: 100;
                width: 100%;
                background-color: #FFFFFF;
                top: 0px;
                margin-bottom: 10px;
                padding-bottom: 10px;
            }

            .home a:link,
            .home a:visited {
                text-decoration: none;
                color: #D3D3D3;
            }

            .home ul {
                margin: 0;
                padding: 0;
                text-align: left;
                list-style: none;
            }

            .home li {
                position: relative;
                float: left;
                padding-top: 15px;
                margin-right: 1em;
                font-family: 'Arial';
            }

            .home li:hover {
                display: block;
            }

            .home a:link,
            .home a:visited {
                color: #D3D3D3;
            }

            .home li:hover a:link,
            .home li:hover a:visited {
                text-decoration: none;
                padding: 15px;
                color: #FFFFFF;
                background-color: #1B80CF;
            }

            .content {
                line-height: 1.8vmax;
                font-size: 1.2vmax;
                font-family: 'Arial';
                margin-top: 15vh;
                width: 90%;
            }

            .content h2,
            h3,
            h4 {
                color: #1B80CF;
            }

            .content a:link,
            .content a:visited {
                color: #1B80CF;
            }

            .content h3 {
                color: #1B80CF;
            }

            .content h2::before,
            .content h3::before {
                display: block;
                content: " ";
                visibility: hidden;
                height: 50px;
                margin-top: -50px;
                pointer-events: none;
                background-color: #FFFFFF;
            }

            .content a:link,
            .content a:visited {
                color: #1B80CF;
            }

            .content li {
                margin: 5px;
            }

            .page {
                width: 65vw;
                height: 100%;
                margin-left: 30vw;
                overflow: hidden;
                padding: 0 1em;
                font-family: 'Arial';
            }

            .page img {
                max-width: 100%;
                max-height: 100%;
            }

            @media (max-width: 640px),
            screen and (orientation: portrait) {
                body {
                    max-width: 100%;
                    max-height: 100%;
                }

                #sidebar {
                    position: fixed;
                    background-color: #1B80CF;
                    top: 0;
                    left: 0;
                    bottom: 80vh;
                    width: 100vw;
                }

                #sidebar .title {
                    text-align: center;
                    position: fixed;
                    margin-top: 6vh;
                    left: 0px;
                    right: 0px;
                    line-height: 3.5vmax;
                    font-size: 1.5vmax;
                    font-family: 'Arial';
                }

                #sidebar .subtitle {
                    text-align: center;
                    top: 5vh;
                    left: 0px;
                    right: 0px;
                    position: fixed;
                    margin-top: 10vh;
                    font-size: 1.5vmax;
                }

                #sidebar .title a:link,
                #sidebar .title a:visited {
                    text-align: center;
                    color: #FFFFFF;
                }

                #sidebar .subtitle a:link,
                #sidebar .subtitle a:visited {
                    text-align: center;
                    color: #FFFFFF;
                }

                .home {
                    z-index: 100;
                    width: 100%;
                    background-color: #1B80CF;
                    font-size: 1.5vmax;
                }

                .home a:link,
                .home a:visited {
                    text-decoration: none;
                    color: #FFFFFF;
                }

                .content {
                    line-height: 3.8vmax;
                    font-size: 1.8vmax;
                    font-family: 'Arial';
                    margin-top: 22vh;
                }

                .content a:link,
                .content a:visited {
                    color: #1B80CF;
                }

                .page {
                    top: 40vh;
                    width: 95%;
                    margin-left: 0vw;
                }

                .page img {
                    max-width: 100%;
                    max-height: 100%;
                    border: 0;
                }
            }
        </style>
    </head>

    <body vocab="http://schema.org/">
        <div class="page">
            <div class="home">
                <ul typeof="BreadcrumbList">
                    <li property="itemListElement" typeof="ListItem">
                        <a property="item" typeof="WebPage" href="../index.html">
                            <span property="name">Home</span>
                        </a>
                    </li>
                    <li property="itemListElement" typeof="ListItem">
                        <a property="item" typeof="WebPage" href="../research/research.html">
                            <span property="name">Research</span>
                        </a>
                    </li>
                </ul>

            </div>
            <div id="sidebar">
                <div class="title">
                    <h1><a href="./transparency.html">Data Science and Transparency</a></h1>
                </div>
                <div class="subtitle">
                    <h3><a href="../about.html">John Samuel</a></h3>
                </div>
            </div>

            <div class="content">
                <header>
                    <h2>Transparency in Data Science</h2>
                    <div
                        style="background-color: #f0f8ff; border-left: 4px solid #1e90ff; padding: 1em; margin-bottom: 1.5em;">
                        <strong>This article is part of a series on <a href="./data-science.html">Data
                                Science</a>.</strong>
                    </div>
                    <p>Understanding the importance of openness, reproducibility, and accountability in
                        data-driven decision-making.</p>
                </header>

                <main>
                    <section>
                        <h3>What Is Transparency in Data Science?</h3>
                        <p>
                            Transparency in data science refers to the clear and open communication of all
                            stages of a research or analytics process, from data collection to interpretation of
                            results. It involves documenting where data comes from, how it's processed, what
                            methods are used for analysis, and how conclusions are drawn. This approach helps
                            other researchers, stakeholders, and the public understand, trust, and potentially
                            replicate the work.
                        </p>
                        <p>
                            Transparency is essential because data science affects many parts of everyday
                            life—from healthcare to finance to public policy. Making the decision-making process
                            behind data-driven systems visible not only fosters public trust but also guards
                            against hidden biases, errors, and misinterpretation of results.
                        </p>
                    </section>

                    <section>
                        <h3>Core Elements of Transparent Practice</h3>
                        <p>
                            A foundational aspect of transparency is disclosing the sources of data used in a
                            study. Researchers must specify whether the datasets originate from public
                            repositories, government portals, private institutions, or scraped from the web.
                            They should also provide details about dataset size, variables involved, time of
                            collection, and any preprocessing done (such as anonymization, cleaning, or
                            formatting). This level of documentation allows others to assess the validity and
                            reliability of the data itself.
                        </p>
                        <p>
                            Equally important is disclosing funding sources and potential conflicts of interest.
                            Knowing who sponsored the research—be it governments, corporations, or academic
                            institutions—helps readers understand whether the results might have been
                            unintentionally biased. Even non-financial affiliations can influence outcomes, so
                            transparency here supports integrity and accountability.
                        </p>
                        <p>
                            Researchers should also describe their data collection methods in detail. This
                            includes explaining sampling strategies, the design of surveys or experiments,
                            technologies used (such as sensors or web scrapers), and how subjects were selected
                            or excluded. These methodological details help reveal possible limitations, biases,
                            or errors introduced during the early stages of a project.
                        </p>
                        <p>
                            Lastly, the analytical methods used—whether statistical models, machine learning
                            algorithms, or qualitative techniques—must be transparently reported. This includes
                            justification for choosing specific techniques, how parameters were tuned, and what
                            alternative approaches were considered. Sharing this information ensures the work
                            can be independently verified and possibly improved upon.
                        </p>
                    </section>

                    <section>
                        <h3>Why Transparency Matters</h3>
                        <p>
                            One of the most significant reasons for transparency is reproducibility. In science
                            and data analytics, if others cannot replicate your findings using your methods and
                            data, the credibility of those results is weakened. Transparent documentation
                            ensures that results can be reproduced, which is a cornerstone of scientific
                            inquiry.
                        </p>
                        <p>
                            Transparency also plays a key role in building public trust. In an age where
                            algorithms influence credit scores, medical diagnostics, and social media feeds, the
                            public deserves to know how decisions are being made. Openly explaining the
                            assumptions, methods, and data behind those decisions helps reduce misinformation
                            and skepticism.
                        </p>
                        <p>
                            Moreover, transparency allows stakeholders to spot and address potential biases.
                            Data-driven models often reflect societal inequalities, especially when trained on
                            historical data. By openly sharing model logic and training data characteristics,
                            researchers make it easier to identify and correct unfair or discriminatory
                            patterns.
                        </p>
                        <p>
                            Legal and ethical standards also demand transparency. For instance, the General Data
                            Protection Regulation (GDPR) in Europe requires that individuals understand how
                            decisions affecting them are made. As AI regulation grows globally, transparency
                            will become a compliance issue, not just a best practice.
                        </p>
                    </section>

                    <section>
                        <h3>Best Practices for Transparent Reporting</h3>
                        <p>
                            A well-documented dataset should include its origin, metadata, access methods, and
                            any modifications made during preprocessing. Platforms like Kaggle, DataHub, and
                            Zenodo encourage good documentation practices by requiring data descriptions and
                            licenses.
                        </p>
                        <p>
                            Declaring funding sources and affiliations prevents conflicts of interest from going
                            unnoticed. For example, studies evaluating the safety of a drug should disclose any
                            ties to pharmaceutical sponsors. Journals, conferences, and research institutions
                            now require conflict-of-interest statements in most submissions.
                        </p>
                        <p>
                            Transparent projects often publish their analysis pipelines, including the code and
                            tools used. Tools like Jupyter Notebooks, R Markdown, and GitHub repositories enable
                            researchers to share their workflows and enable others to run them end-to-end.
                            Platforms such as MLflow and Data Version Control (DVC) also help manage versions of
                            data and models.
                        </p>
                        <p>
                            Conclusions should never overstate the certainty of results. Honest reporting
                            includes discussing limitations, acknowledging uncertainty, and identifying areas
                            for future work. For example, a correlation found in the data may not imply
                            causation, and readers should be made aware of such nuances.
                        </p>
                    </section>

                    <section>
                        <h3>Next-Generation Transparency: Explainability and Openness</h3>
                        <p>
                            In recent years, the need for transparency has evolved to include the inner workings
                            of algorithms themselves. This field, known as <strong>Explainable AI
                                (XAI)</strong>, seeks to make complex machine learning models interpretable to
                            humans. Tools such as SHAP (SHapley Additive exPlanations) and LIME (Local
                            Interpretable Model-Agnostic Explanations) help reveal which inputs influence a
                            model’s decision, and by how much.
                        </p>
                        <p>
                            In addition, open access to code and data has become a hallmark of transparent
                            research. Interactive dashboards, data visualizations, and dynamic notebooks allow
                            wider audiences to explore findings in intuitive ways. These tools not only improve
                            accessibility but also increase public engagement in scientific
                            discourse.
                        </p>
                    </section>

                    <section>
                        <h3>Multiverse Analysis: Exploring All Reasonable Alternatives</h3>
                        <p>
                            One of the most innovative techniques for increasing transparency is
                            <strong>multiverse analysis</strong>. Rather than conducting a single analysis,
                            researchers perform multiple plausible analyses using different but defensible
                            choices in data cleaning, model selection, and variable definitions. This creates a
                            "multiverse" of analytical paths, helping to identify how robust the results are to
                            these choices.
                        </p>
                        <p>
                            For example, a researcher studying the impact of education on income might try
                            different ways of defining education levels, handling missing data, or including
                            covariates. Multiverse analysis reveals whether findings are consistent across these
                            choices or highly sensitive to them. This helps prevent the selective reporting of
                            only the most favorable results.
                        </p>
                        <p>
                            Tools such as the <em>multiverse</em> R package automate the process of generating
                            and testing these multiple analytic decisions. This innovation is particularly
                            useful in fields like psychology and neuroscience, where methodological flexibility
                            can easily lead to misleading conclusions.
                        </p>
                    </section>

                    <footer>
                        <h3>References</h3>
                        <ol>
                            <li><a href="https://doi.org/10.1177/1745691616658637">Steegen, S., et
                                    al. (2016). <em>Increasing transparency through a multiverse analysis</em>.</a>
                                Perspectives on Psychological Science, 11(5), 702–712.</li>
                            <li><a href="https://doi.org/10.1371/journal.pbio.2006930">Stodden, V.,
                                    et al. (2018). <em>Computational transparency in science</em>.</a> PLOS Biology.
                            </li>
                            <li><a href="https://doi.org/10.1016/j.cub.2013.11.014">Vines, T. H., et
                                    al. (2014). <em>The availability of research data declines rapidly with article
                                        age</em>.</a> Current Biology.</li>
                            <li><a href="https://doi.org/10.1145/3236009">Guidotti, R., et al.
                                    (2018). <em>A survey of methods for explaining black box models</em>.</a> ACM
                                Computing Surveys.</li>
                            <li><a href="https://www.science.org/doi/10.1126/science.1213847">Peng,
                                    R. D. (2011). <em>Reproducible research in computational science</em>.</a>
                                Science.</li>
                            <li><a href="https://doi.org/10.1371/journal.pmed.0020124">Ioannidis, J.
                                    P. A. (2005). <em>Why most published research findings are false</em>.</a> PLOS
                                Medicine.</li>
                            <li><a href="https://cran.r-project.org/package=multiverse">Sarma, A.,
                                    et al. (2021). <em>multiverse: Multiplexing Alternative Data Analyses in R
                                        Notebooks</em>.</a> CRAN Project.</li>
                            <li><a href="https://www.nature.com/articles/d41586-018-01023-3">Munafò,
                                    M. R., & Chambers, C. D. (2021). <em>Robust research needs many lines of
                                        evidence</em>.</a> Nature.</li>
                            <li><a
                                    href="https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai">European
                                    Commission. (2019). <em>Ethics guidelines for
                                        trustworthy AI</em>.</a></li>
                            <li><a href="https://en.wikipedia.org/wiki/Transparency_(behavior)">
                                    <em>Transparency (behavior)</em>.</a>
                                Wikipedia.</li>
                            <li><a href="https://christophm.github.io/interpretable-ml-book/">Molnar, C. (2020).
                                    <em>Interpretable Machine Learning</em>.</a>
                                Lulu Press.</li>
                            <li><a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">Wikipedia
                                    contributors. <em>Explainable artificial
                                        intelligence</em>.</a> Wikipedia.</li>
                            <li><a href="https://doi.org/10.1371/journal.pone.0021101">Tenopir, C.,
                                    et al. (2011). <em>Data sharing by scientists: practices and
                                        perceptions</em>.</a> PLOS ONE.</li>
                            <li><a href="https://en.wikipedia.org/wiki/Conflict_of_interest">
                                    <em>Conflict of interest</em>.</a>
                                Wikipedia.</li>
                            <li><a href="https://shap.readthedocs.io/en/latest/index.html">SHAP</a></li>
                            <li><a href="https://en.wikipedia.org/wiki/Multiverse_analysis">
                                    <em>Multiverse analysis</em>.</a>
                                Wikipedia.</li>
                            <li><a href="https://artificialintelligenceact.eu">European Parliament.
                                    (2023). <em>Proposal for a Regulation on Artificial Intelligence (AI
                                        Act)</em>.</a></li>
                            <li><a href="https://fairmlbook.org">Barocas, S., Hardt, M., &
                                    Narayanan, A. (2019). <em>Fairness and Machine Learning</em>.</a></li>
                            <li><a href="https://opendatahandbook.org/guide/en/what-is-open-data/">Open Data Handbook.
                                    (2024). <em>What is open data?</em></a></li>
                            <li><a href="https://mlflow.org">MLflow Documentation. (2025).</a></li>
                            <li><a href="https://dvc.org">Data Version Control (DVC). (2025).</a>
                            </li>
                            <li><a href="https://doi.org/10.1177/1745691616658637">Steegen, S., et
                                    al. (2016). Increasing Transparency Through a Multiverse Analysis.</a></li>
                        </ol>
                    </footer>
                </main>
            </div>
        </div>
    </body>

</html>