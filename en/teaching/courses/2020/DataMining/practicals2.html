<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta http-equiv="Content-Language" content="en" />
  <link rel="shortcut icon" href="../.../../2017/DataMining/images/logo/favicon.png" />
  <title>Data Mining: John Samuel</title>
  <style type="text/css">
    body {
      background-color: #FFFFFF;
    }

    #sidebar {
      position: fixed;
      background-color: #00363a;
      top: 0;
      left: 0;
      bottom: 0;
      width: 25vw;
    }

    #sidebar .title {
      position: relative;
      text-align: center;
      line-height: 5vmax;
      font-size: 1.4vmax;
      font-family: 'Arial';
      margin-top: 30vh;
    }

    #sidebar .title a:link,
    #sidebar .title a:visited {
      color: #FFFFFF;
      text-decoration: none;
    }

    .subtitle {
      top: 50vh;
      text-align: center;
      line-height: 1.3vmax;
      font-family: 'Arial';
      font-size: 1.5vmax;
      color: #FFFFFF;
    }

    a:link,
    a:visited {
      color: #00363a;
    }

    .subtitle a:link,
    .subtitle a:visited {
      color: #FFFFFF;
      text-decoration: none;
    }

    .licence {
      position: fixed;
      text-align: right;
      bottom: 0;
      right: 0;
    }

    .home {
      position: fixed;
      text-align: left;
      font-family: 'Arial';
      color: #D3D3D3;
      z-index: 100;
      width: 100%;
      background-color: #FFFFFF;
      top: 0px;
      margin-bottom: 10px;
      padding-bottom: 10px;
    }

    .codeexample {
      background-color: #eeeeee;
    }

    .home ul {
      margin: 0;
      padding: 0;
      text-align: left;
      list-style: none;
    }

    .home li {
      position: relative;
      float: left;
      padding-top: 15px;
      margin-right: 1em;
      font-family: 'Arial';
    }

    .home li:hover {
      display: block;
    }

    .home a:link,
    .home a:visited {
      color: #D3D3D3;
    }

    .home li:hover a:link,
    .home li:hover a:visited {
      text-decoration: none;
      padding: 15px;
      color: #FFFFFF;
      background-color: #00363a;
    }

    .content {
      line-height: 1.8vmax;
      font-size: 1.2vmax;
      font-family: 'Arial';
      margin-top: 15vh;
      width: 90%;
    }

    .content h2,
    h3,
    h4 {
      color: #00363a;
    }

    .content a:link,
    .content a:visited {
      color: #00363a;
    }

    .content h2::before,
    .content h3::before {
      display: block;
      content: " ";
      visibility: hidden;
      height: 50px;
      margin-top: -50px;
      pointer-events: none;
      background-color: #FFFFFF;
    }

    .content a:link,
    .content a:visited {
      color: #00363a;
    }

    .content li {
      margin: 5px;
    }

    .exercise {
      margin-left: 2vw;
    }

    .exercise p {
      margin-left: 1vw;
    }

    .exercise img {
      width: 100%;
    }

    .content a:link,
    .content a:visited {
      color: #00363a;
    }

    .home a:link,
    .home a:visited {
      color: #D3D3D3;
    }

    .page {
      width: 65vw;
      height: 100%;
      margin-left: 25vw;
      overflow: auto;
      padding: 0 1em;
    }

    img {
      max-width: 100%;
      max-height: 100%;
    }

    /* Using same Jupyter CSS
     */
    .highlight {
      background: #f8f8f8;
    }

    .highlight .c {
      color: #408080;
      font-style: italic
    }

    /* Comment */
    .highlight .err {
      border: 1px solid #FF0000
    }

    /* Error */
    .highlight .k {
      color: #008000;
      font-weight: bold
    }

    /* Keyword */
    .highlight .o {
      color: #666666
    }

    /* Operator */
    .highlight .ch {
      color: #408080;
      font-style: italic
    }

    /* Comment.Hashbang */
    .highlight .c1 {
      color: #408080;
      font-style: italic
    }

    /* Comment.Single */
    .highlight .cs {
      color: #408080;
      font-style: italic
    }

    /* Comment.Special */
    .highlight .cm {
      color: #408080;
      font-style: italic
    }

    /* Comment.Multiline */
    .highlight .nn {
      color: #0000FF;
      font-weight: bold
    }

    /* Name.Namespace */
    .highlight .k {
      color: #008000;
      font-weight: bold
    }

    /* Keyword */
    .highlight .s2 {
      color: #BA2121
    }

    /* Literal.String.Double */
    .highlight .s1 {
      color: #BA2121
    }

    /* Literal.String.Single */
    .highlight .kn {
      color: #008000;
      font-weight: bold
    }

    /* Keyword.Namespace */
    .highlight .nb {
      color: #008000
    }

    /* Name.Builtin */
    .highlight .mb {
      color: #666666
    }

    /* Literal.Number.Bin */
    .highlight .mf {
      color: #666666
    }

    /* Literal.Number.Float */
    .highlight .mh {
      color: #666666
    }

    /* Literal.Number.Hex */
    .highlight .mi {
      color: #666666
    }

    /* Literal.Number.Integer */
    .highlight .mo {
      color: #666666
    }

    /* Literal.Number.Oct */
    @media (max-width: 640px),
    screen and (orientation: portrait) {
      body {
        max-width: 100%;
        max-height: 100%;
      }
    }

    @media print {
      #sidebar {
        width: 100%;
        top: 0;
        position: relative;
        padding-bottom: 3vh;
      }

      #sidebar .title {
        margin-top: 0;
      }

      .home {
        display: none;
      }

      .page {
        margin-left: 5vw;
        width: 90%;
      }
    }
  </style>
</head>

<body vocab="http://schema.org/">
  <div id="sidebar">
    <div class="title">
      <h1><a href="./index.html">Practicals: Data Mining</a></h1>
    </div>
    <div class="subtitle">
      <h3><a href="../../../../about.html">John Samuel</a></h3>
    </div>
  </div>
  <div class="licence"><a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img
        alt="Creative Commons License" style="border-width:0" src="../../../../../images/license.png" /></a>
  </div>
  <div class="page">
    <div class="home">
      <ul typeof="BreadcrumbList">
        <li property="itemListElement" typeof="ListItem">
          <a property="item" typeof="WebPage" href="../../../../index.html">
            <span property="name">Home</span>
          </a>
        </li>
        <li property="itemListElement" typeof="ListItem">
          <a property="item" typeof="WebPage" href="index.html">
            <span property="name">Data Mining</span>
          </a>
        </li>
        <li property="itemListElement" typeof="ListItem">
          <a property="item" typeof="WebPage" href="../../../index.html">
            <span property="name">Teaching</span>
          </a>
        </li>
      </ul>
    </div>
    <div class="content">
      <h3>Goals</h3>
      <ol>
        <li>Plotting graphs using <a href="https://matplotlib.org/api/pyplot_api.html">matplotlib</a></li>
        <li>Reading and plotting image histograms.</li>
        <li>Working with <a href="http://scikit-learn.org/stable/modules/clustering.html">clustering</a> and <a
            href="http://scikit-learn.org/stable/modules/svm.html">classification</a> algorithms</li>
        <li>Start building a <a href="https://en.wikipedia.org/wiki/Recommender_system">recommender system</a></li>
      </ol>
      <h3>Scoring</h3>
      <p>Every exercise has an associated difficulty level. Easy and medium-difficult exercises help you understand the
        fundamentals and give you ideas to work on difficult exercises. It is highly recommended that you finish easy
        and medium-difficult exercises to have a good score. Given below is the difficulty scale that will be marked
        with every exercise: </p>
      <ol>
        <li><span style="color:red">&#9733;</span>: Easy</li>
        <li><span style="color:red">&#9733;&#9733;</span>: Medium</li>
        <li><span style="color:red">&#9733;&#9733;&#9733;</span>: Difficult</li>
      </ol>
      <h3>Guidelines</h3>
      <ol>
        <li>To get complete guidance from the mentors, it is highly recommended that you work on today's practical
          session and not on the preceding ones.</li>
        <li>Make sure that you rename your submissions properly and correctly. Double-check your submissions.</li>
        <li>Please check the <a href="./references.html">references</a>.</li>
        <li>There are several ways to achieve a task. Hence there are many possible solutions. But try to make maximum
          use of the libraries that have been suggested to you for your exercises.</li>
      </ol>
      <h4>Installation</h4>
      <div class="exercise">
      </div>
      <h4>Exercise 2.1 <span style="color:red">&#9733;</span></h4>
      <div class="exercise">
        <p><a href="https://matplotlib.org/api/pyplot_api.html">matplotlib</a> can be used to plot graphs. Given below
          is a very simple code with only x values. After importing the <i>matplotlib</i> library, we initialize x
          values and plot it.</p>
        <pre class="codeexample">
           <code>
             import matplotlib.pyplot as plot
             
             x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
             plot.plot(x)
             plot.show()
           </code>
          </pre>
        <p>
          <img style="width:40%" src="../../2017/DataMining/images/plot.png"></img>
          </pre>
        <p>Now let's change the color, style and width of the line.</p>
        <pre class="codeexample">
           <code>
             import matplotlib.pyplot as plot
             
             x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
             plot.plot(x, linewidth=3, drawstyle="steps", color="#00363a")
             plot.show()
           </code>
          </pre>
        <p>We will now initialize the y-values and plot the graph.</p>
        <pre class="codeexample">
           <code>
             import matplotlib.pyplot as plot
             
             x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
             y = [0, 1, 0, 0, 1, 0, 1, 1, 1, 0]
             plot.plot(x, y, linewidth=3, drawstyle="steps", color="#00363a")
             plot.show()
           </code>
          </pre>
        <p>
          <img style="width:40%" src="../../2017/DataMining/images/stepploty.png"></img>
          </pre>
        <p>In the <a href="./practicals1.html">first practical session</a>, we saw how to parse JSON files. Continuing
          with the same <a href="../../2018/DataMining/pl.json">JSON</a> file, we will now plot the results of number of
          programming languages released per year. Verify the output.</p>
        <pre class="codeexample">
           <code>
             from pandas.io.json import json_normalize
             import pandas as pd
             import json
             import matplotlib.pyplot as plot
             
             data = json.load(open('pl.json'))
             dataframe = json_normalize(data)
             grouped = dataframe.groupby('year').count()
             plot.plot(grouped)
             plot.show()
           </code>
          </pre>
        <p>Following program will add title and labels to the x-axis and y-axis.</p>
        <pre class="codeexample">
           <code>
             from pandas.io.json import json_normalize
             import pandas as pd
             import json
             import matplotlib.pyplot as plot
             
             data = json.load(open('pl.json'))
             dataframe = json_normalize(data)
             grouped = dataframe.groupby('year').count()
             plot.plot(grouped)
             plot.title("Programming languages per year")
             plot.xlabel('year',  fontsize=16)
             plot.ylabel('count',  fontsize=16)
             plot.show()
           </code>
          </pre>
        <p>There is yet another way to plot the dataframes, by using <a
            href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html">pandas.DataFrame.plot</a>.
        </p>
        <pre class="codeexample">
           <code>
             from pandas.io.json import json_normalize
             import pandas as pd
             import json
             import matplotlib.pyplot as plot
             
             data = json.load(open('pl.json'))
             dataframe = json_normalize(data)
             
             grouped = dataframe.groupby('year').count()
             grouped = grouped.rename(columns={'languageLabel':'count'}).reset_index()
             
             grouped.plot(x=0, kind='bar', title="Programming languages per year")
           </code>
          </pre>
        <p>
          <img style="width:40%" src="../../2017/DataMining/images/dataframeplot.png"></img>
          </pre>
        <p>Now, we want to create multiple subplots. A simple way is given below. Recall in <a
            href="./practicals1.html">first practical session</a>, we did group by on multiple columns. Subplots can be
          used to visualize these data.
          </pre>
        <pre class="codeexample">
           <code>
             from pandas.io.json import json_normalize
             import pandas as pd
             import json
             import math
             import matplotlib.pyplot as plot
             
             jsondata = json.load(open('plparadigm.json'))
             array = []
             
             for data in jsondata:
             &nbsp;&nbsp;&nbsp;&nbsp;array.append([data['year'], data['languageLabel'], data['paradigmLabel']])
             
             dataframe = pd.DataFrame(array, columns=['year', 'languageLabel', 'paradigmLabel'])
             dataframe = dataframe.astype(dtype= {"year" : "int64", "languageLabel" : "&lt;U200", "paradigmLabel" : "&lt;U200"})
             
             grouped = dataframe.groupby(['paradigmLabel', 'year']).count()
             grouped = grouped.rename(columns={'languageLabel':'count'})
             grouped = grouped.groupby(['paradigmLabel'])
             
             #Initialization of subplots
             nr = math.ceil(grouped.ngroups/2)
             fig, axes = plot.subplots(nrows=nr, ncols=2, figsize=(20,25))
             
             #Creation of subplots
             for i, group in enumerate(grouped.groups.keys()):
             &nbsp;&nbsp;&nbsp;&nbsp;g = grouped.get_group(group).reset_index()
             &nbsp;&nbsp;&nbsp;&nbsp;g.plot(x='year', y='count', kind='bar', title=group, ax=axes[math.floor(i/2),i%2])
             
             plot.show()
           </code>
          </pre>
        <p>
          <img style="width:50%" src="../../2017/DataMining/images/subplots.png"></img>
          </pre>
          Make changes to the above code, so that we can get visual information on count of languages of different
          programming paradigms released in every available year, i.e, for each year, we want to see the count of
          programming languages belonging to each programming language paradigm.
      </div>
      <h4>Exercise 2.2 <span style="color:red">&#9733;</span></h4>
      <div class="exercise">
        <p>In this exercise, we will work on images. Download an image (e.g., <a
            href="../../2017/DataMining/images/picture.bmp">picture.bmp</a> and <a
            href="../../2017/DataMining/images/flower.jpg">flower.jpg</a>) in your current working folder and open it in
          the following manner. We will first try to get some metadata of the image.</p>
        <pre class="codeexample">
          <code>
             import os,sys
             from PIL import Image
             imgfile = Image.open("picture.bmp")
             print(imgfile.size, imgfile.format)
          </code>
         </pre>
         <p>We use Image module of Python PIL library (<a href="http://www.effbot.org/imagingbook/image.htm">Documentation</a>). We will now try to get data of 100 pixels from an image. </p>
         <pre class="codeexample">
          <code>
             import os,sys
             from PIL import Image
             imgfile = Image.open("flower.jpg")
             
             data = imgfile.getdata()
             
             for i in range(10):
             &nbsp;&nbsp;&nbsp;&nbsp;for j in range(10):
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(i,j, data.getpixel((i,j)))
          </code>
         </pre>
         <p>You may notice the pixel position and pixel values (a tuple of 3 values). Let's try to get additional metadata of the images, i.e., mode of image (e.g., RGB), number of bands, number of bits for each band, width and height of image (in pixels).</p>
         <pre class="codeexample">
          <code>
             import os,sys
             from PIL import Image
             imgfile = Image.open("flower.jpg")
             
             print(imgfile.mode, imgfile.getbands(), imgfile.bits, imgfile.width, imgfile.height)
          </code>
         </pre>
         <p>Let's now get an histogram of colors. When you execute the following code, you will get a single array of values, frequency of each band (R, G, B etc.) concatenated together. In the following code, we will assume that we are working with an image of 3 bands (RGB mode) and each band is represented by 8 bits. We will plot the <a href="http://www.effbot.org/imagingbook/image.htm#tag-Image.Image.histogram">histogram</a> of different colors.</p>
         <pre class="codeexample">
          <code>
             from PIL import Image
             import matplotlib.pyplot as plot
             
             imgfile = Image.open("flower.jpg")
             
             histogram = imgfile.histogram()
             # we have three bands (for this image)
             red = histogram[0:255]
             green = histogram[256:511]
             blue = histogram[512:767]
             
             fig, (axis1, axis2, axis3) = plot.subplots(nrows=3, ncols=1)
             axis1.plot(red, color='red')
             axis2.plot(green, color='green')
             axis3.plot(blue, color='blue')
             plot.show()
           </code>
          </pre>
        <p>
          <img style="width:40%" src="../../2017/DataMining/images/histogramsubplots.png"></img>
          </pre>
        <p>But if wish to see all of them in one single plot.</p>
        <pre class="codeexample">
           <code>
             from PIL import Image
             import matplotlib.pyplot as plot
             
             imgfile = Image.open("flower.jpg")
             
             histogram = imgfile.histogram()
             red = histogram[0:255]
             green = histogram[256:511]
             blue = histogram[512:767]
             
             x=range(255)
             
             y = []
             for i in x:
             &nbsp;&nbsp;&nbsp;&nbsp;y.append((red[i],green[i],blue[i]))
             
             plot.plot(x,y)
             plot.show()
           </code>
          </pre>
        <p>
          <img style="width:40%" src="../../2017/DataMining/images/histogramplot.png"></img>
          </pre>
        <p>But we do not wish to loose the band colors.</p>
        <pre class="codeexample">
           <code>
             from PIL import Image
             import matplotlib.pyplot as plot
             
             imgfile = Image.open("flower.jpg")
             
             histogram = imgfile.histogram()
             red = histogram[0:255]
             green = histogram[256:511]
             blue = histogram[512:767]
             
             x=range(255)
             
             y = []
             for i in x:
             &nbsp;&nbsp;&nbsp;&nbsp;y.append((red[i],green[i],blue[i]))
             
             figure, axes = plot.subplots()
             axes.set_prop_cycle('color', ['red', 'green', 'blue'])
             plot.plot(x,y)
             plot.show()
           </code>
          </pre>
        <p>
          <img style="width:40%" src="../../2017/DataMining/images/histogramplotcolors.png"></img>
          </pre>
        <p>Your next question is to get the top 20 intensities in each band and create a single plot of these top
          intensities. Write a python program that can achieve this. </p>
      </div>
      <h4>Exercise 2.3 <span style="color:red">&#9733;&#9733;</span></h4>
      <div class="exercise">
        <p>In this exercise, we will take a look at <a
            href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">KMeans clustering
            algorithm</a>. Continuing with images, we will now find 4 predominant colors in an image.</p>
        <pre class="codeexample">
           <code>
             from PIL import Image
             import numpy
             import math
             import matplotlib.pyplot as plot
             from sklearn.cluster import KMeans
             
             imgfile = Image.open("flower.jpg")
             
             numarray = numpy.array(imgfile.getdata(), numpy.uint8)
             
             clusters = KMeans(n_clusters = 4)
             clusters.fit(numarray)
             
             
             npbins = numpy.arange(0, 5)
             histogram = numpy.histogram(clusters.labels_, bins=npbins)
             labels = numpy.unique(clusters.labels_)
             
             
             barlist = plot.bar(labels, histogram[0])
             for i in range(4):
             &nbsp;&nbsp;&nbsp;&nbsp;barlist[i].set_color('#%02x%02x%02x' % (math.ceil(clusters.cluster_centers_[i][0]), 
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;math.ceil(clusters.cluster_centers_[i][1]), math.ceil(clusters.cluster_centers_[i][2])))
             plot.show()
           </code>
          </pre>
        <p>
          <img style="width:40%" src="../../2017/DataMining/images/barchart.png"></img>
          </pre>
        <p>For your next question, your goal is to understand the above code and achieve the following:
        <ol>
          <li>Assume that the number of clusters is given by the user, generalize the above code.</li>
          <li>In case of bar chart, ensure that the bars are arranged in the descending order of the frequency of
            colors.</li>
          <li>Also add support for pie chart in addition to the bar chart. Ensure that we use the image colors as the
            wedge colors. (e.g., given below)</li>
          <li>Do you have any interesting observations?</li>
        </ol>
        </pre>
        <p>
          <img style="width:40%" src="../../2017/DataMining/images/piechart.png"></img>
          </pre>
      </div>
      <h4>Exercise 2.4 <span style="color:red">&#9733;&#9733</span></h4>
      <div class="exercise">
        <p>We will try to get more clusters and also check the time taken by each of these algorithms.</p>
        <p>Let's start with some very simple exercises to experiment with the KMeans algorithm. Consider the following
          data and visualize it on a using a scatter plot.</p>
        <div class=" highlight hl-ipython3">
          <pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plot</span>

<span class="n">numarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">],[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">numarray</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">numarray</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre>
        </div>

        <p>Visually, it is quite evident that there are two clusters. But let's use KMeans algorithm to obtain the 2
          clusters. We will first see the labels of our clustered data.</p>
        <div class=" highlight hl-ipython3">
          <pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plot</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="k">import</span> <span class="n">KMeans</span>

<span class="n">numarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">],[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>

<span class="n">clusters</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">clusters</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">numarray</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">clusters</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
</pre>
        </div>

        <p>Now, we will visualize the clusters using a scatter plot. We will use two colors for visually distinguishing
          them.</p>
        <div class=" highlight hl-ipython3">
          <pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plot</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="k">import</span> <span class="n">KMeans</span>

<span class="n">numarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">],[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>

<span class="n">clusters</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">clusters</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">numarray</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;#ff0000&quot;</span><span class="p">,</span> <span class="s2">&quot;#00ff00&quot;</span><span class="p">])</span>
    
<span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">numarray</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">numarray</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">clusters</span><span class="o">.</span><span class="n">labels_</span><span class="p">])</span>
<span class="n">plot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre>
        </div>
        <p>What if we tried to obtain 4 clusters? Try running the following code, multiple times. Any observation? Try
          changing the value of <i>n_init</i> with higher values.</p>
        <div class=" highlight hl-ipython3">
          <pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plot</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="k">import</span> <span class="n">KMeans</span>

<span class="n">numarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">],[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>

<span class="n">clusters</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">clusters</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">numarray</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;#ff0000&quot;</span><span class="p">,</span> <span class="s2">&quot;#00ff00&quot;</span><span class="p">,</span> <span class="s2">&quot;#0000ff&quot;</span><span class="p">,</span> <span class="s2">&quot;#ffff00&quot;</span><span class="p">])</span>
    
<span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">numarray</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">numarray</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">clusters</span><span class="o">.</span><span class="n">labels_</span><span class="p">])</span>
<span class="n">plot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre>
        </div>
        <p>Now we will try obtaining clusters with some real data (reference: <a
            href="../../2018/DataMining/citypopulation.json">citypopulation.json</a>, Source: Wikidata). It contains
          information concerning different cities of the world: city name, year of its foundation and its population in
          the year 2010. In the following code, we want to cluster population data and to observe whether there is any
          correlation between age and recent population (2010) statistics. In the following code, there is a commented
          line. You can un-comment it to try with different population numbers. Any observation? Why did we use
          LabelEncoder? What is its purpose?</p>
        <div class=" highlight hl-ipython3">
          <pre><span></span><span class="kn">from</span> <span class="nn">pandas.io.json</span> <span class="k">import</span> <span class="n">json_normalize</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;citypopulation.json&#39;</span><span class="p">))</span>
<span class="n">dataframe</span> <span class="o">=</span> <span class="n">json_normalize</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">dataframe</span><span class="p">[</span><span class="s1">&#39;cityLabel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dataframe</span><span class="p">[</span><span class="s1">&#39;cityLabel&#39;</span><span class="p">])</span>
<span class="n">dataframe</span> <span class="o">=</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span> <span class="p">{</span><span class="s2">&quot;year&quot;</span><span class="p">:</span><span class="s2">&quot;&lt;i4&quot;</span><span class="p">,</span> <span class="s2">&quot;cityLabel&quot;</span><span class="p">:</span><span class="s2">&quot;&lt;U200&quot;</span><span class="p">,</span> <span class="s2">&quot;population&quot;</span><span class="p">:</span><span class="s2">&quot;i&quot;</span><span class="p">})</span>
<span class="n">dataframe</span> <span class="o">=</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">dataframe</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1500</span><span class="p">]</span>
<span class="c1">#dataframe = dataframe.loc[dataframe[&#39;population&#39;] &lt; 700000]</span>
<span class="n">yearPopulation</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">[[</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;population&#39;</span><span class="p">]]</span>


<span class="n">clusters</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">clusters</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">yearPopulation</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;#ff0000&quot;</span><span class="p">,</span> <span class="s2">&quot;#00ff00&quot;</span><span class="p">,</span> <span class="s2">&quot;#0000ff&quot;</span><span class="p">,</span> <span class="s2">&quot;#ffff00&quot;</span><span class="p">])</span>
   

<span class="n">plot</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">yearPopulation</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">],</span> <span class="n">yearPopulation</span><span class="p">[</span><span class="s1">&#39;population&#39;</span><span class="p">],
     </span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">clusters</span><span class="o">.</span><span class="n">labels_</span><span class="p">])</span>
<span class="n">plot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre>
        </div>
        <p>Now let's continue working with <a href="../../2017/DataMining/images/flower.jpg">flower.jpg</a>. Let's start
          once again with <b>KMeans</b> and try to get clusters of size between 2 and 11.</p>
        <pre class="codeexample">
            <code>
             from PIL import Image
             import numpy
             import math
             import matplotlib.pyplot as plot
             from sklearn.cluster import KMeans
             
             imgfile = Image.open("flower.jpg")
             numarray = numpy.array(imgfile.getdata(), numpy.uint8)
             
             X = []
             Y = []
             
             fig, axes = plot.subplots(nrows=5, ncols=2, figsize=(20,25))
             
             xaxis = 0
             yaxis = 0
             for x in range(2, 12):
             &nbsp;&nbsp;&nbsp;&nbsp;cluster_count = x 
             &nbsp;&nbsp;&nbsp;&nbsp;
             &nbsp;&nbsp;&nbsp;&nbsp;clusters = KMeans(n_clusters = cluster_count)
             &nbsp;&nbsp;&nbsp;&nbsp;clusters.fit(numarray)
             &nbsp;&nbsp;&nbsp;&nbsp;
             &nbsp;&nbsp;&nbsp;&nbsp;npbins = numpy.arange(0, cluster_count + 1)
             &nbsp;&nbsp;&nbsp;&nbsp;histogram = numpy.histogram(clusters.labels_, bins=npbins)
             &nbsp;&nbsp;&nbsp;&nbsp;labels = numpy.unique(clusters.labels_)
             
             &nbsp;&nbsp;&nbsp;&nbsp;barlist = axes[xaxis, yaxis].bar(labels, histogram[0])
             &nbsp;&nbsp;&nbsp;&nbsp;if(yaxis == 0):
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  yaxis = 1
             &nbsp;&nbsp;&nbsp;&nbsp;else:
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  xaxis = xaxis + 1
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  yaxis = 0
             &nbsp;&nbsp;&nbsp;&nbsp;for i in range(cluster_count):
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  barlist[i].set_color('#%02x%02x%02x' % (math.ceil(clusters.cluster_centers_[i][0]),
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;      math.ceil(clusters.cluster_centers_[i][1]), math.ceil(clusters.cluster_centers_[i][2])))
             
             
             plot.show()
            </code>
          </pre>
        <p>Your next goal is to test the above code for cluster sizes between 2 and 21 which will give you the figure
          given below.</p>
        <p><span style='color:"red"'>Note:</span> The following image was generated after 6 minutes. Optionally, you can
          add <i>print</i> statements to test whether your code is working fine.</p>
        <p>
          <img style="width:50%" src="../../2017/DataMining/images/kmeans.png"></img>
          </pre>
        <p>Now we modify the above algorithm to use <b>MiniBatchKMeans</b> clustering algorithm (refer <a
            href="http://scikit-learn.org/stable/modules/clustering.html#mini-batch-kmeans">here</a>). Observe the
          changes.</p>
        <pre class="codeexample">
            <code>
             from PIL import Image
             import numpy
             import math
             import matplotlib.pyplot as plot
             from sklearn.cluster import MiniBatchKMeans
             
             imgfile = Image.open("flower.jpg")
             numarray = numpy.array(imgfile.getdata(), numpy.uint8)
             
             X = []
             Y = []
             
             fig, axes = plot.subplots(nrows=5, ncols=2, figsize=(20,25))
             
             xaxis = 0
             yaxis = 0
             for x in range(2, 12):
             &nbsp;&nbsp;&nbsp;&nbsp;cluster_count = x 
             &nbsp;&nbsp;&nbsp;&nbsp;
             &nbsp;&nbsp;&nbsp;&nbsp;clusters = MiniBatchKMeans(n_clusters = cluster_count)
             &nbsp;&nbsp;&nbsp;&nbsp;clusters.fit(numarray)
             &nbsp;&nbsp;&nbsp;&nbsp;
             &nbsp;&nbsp;&nbsp;&nbsp;npbins = numpy.arange(0, cluster_count + 1)
             &nbsp;&nbsp;&nbsp;&nbsp;histogram = numpy.histogram(clusters.labels_, bins=npbins)
             &nbsp;&nbsp;&nbsp;&nbsp;labels = numpy.unique(clusters.labels_)
             
             &nbsp;&nbsp;&nbsp;&nbsp;barlist = axes[xaxis, yaxis].bar(labels, histogram[0])
             &nbsp;&nbsp;&nbsp;&nbsp;if(yaxis == 0):
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  yaxis = 1
             &nbsp;&nbsp;&nbsp;&nbsp;else:
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  xaxis = xaxis + 1
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  yaxis = 0
             &nbsp;&nbsp;&nbsp;&nbsp;for i in range(cluster_count):
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  barlist[i].set_color('#%02x%02x%02x' % (math.ceil(clusters.cluster_centers_[i][0]),
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;      math.ceil(clusters.cluster_centers_[i][1]), math.ceil(clusters.cluster_centers_[i][2])))
             
             
             plot.show()
            </code>
          </pre>
        <p>What did you observe? Your next goal is to test the above code for cluster sizes between 2 and 21 which will
          give you the figure given below.</p>
        <p>What are your conclusions?</p>
        <p>
          <img style="width:50%" src="../../2017/DataMining/images/minibatchkmeans.png"></img>
          </pre>
        <p>In order to compare the two algorithms, we consider the time taken by each of these algorithms. We will
          repeat the above experiment, but this time we will plot the time taken to obtain clusters of different sizes.
        </p>
        <p>We start with <b>KMeans</b>.</p>
        <pre class="codeexample">
            <code>
             from PIL import Image
             import numpy
             import math
             import time
             import matplotlib.pyplot as plot
             from sklearn.cluster import KMeans
             
             imgfile = Image.open("flower.jpg")
             numarray = numpy.array(imgfile.getdata(), numpy.uint8)
             
             X = []
             Y = []
             
             for x in range(1, 20):
             &nbsp;&nbsp;&nbsp;&nbsp;cluster_count = x 
             &nbsp;&nbsp;&nbsp;&nbsp;
             &nbsp;&nbsp;&nbsp;&nbsp;start_time = time.time()
             &nbsp;&nbsp;&nbsp;&nbsp;clusters = KMeans(n_clusters = cluster_count)
             &nbsp;&nbsp;&nbsp;&nbsp;clusters.fit(numarray)
             &nbsp;&nbsp;&nbsp;&nbsp;end_time = time.time()
             &nbsp;&nbsp;&nbsp;&nbsp;total_time = end_time - start_time
             &nbsp;&nbsp;&nbsp;&nbsp;print("Total time: ", x, ":", total_time)
             &nbsp;&nbsp;&nbsp;&nbsp;X.append(x)
             &nbsp;&nbsp;&nbsp;&nbsp;Y.append(total_time)
             
             plot.bar(X, Y)
             plot.show()
            </code>
          </pre>
        <p>You may get a graph similar to the following.</p>
        <p>
          <img style="width:50%" src="../../2017/DataMining/images/kmeanstime.png"></img>
          </pre>
        <p>We now use <b>MiniBatchKMeans</b>.</p>
        <pre class="codeexample">
            <code>
             from PIL import Image
             import numpy
             import math
             import time
             import matplotlib.pyplot as plot
             from sklearn.cluster import MiniBatchKMeans
             
             imgfile = Image.open("flower.jpg")
             numarray = numpy.array(imgfile.getdata(), numpy.uint8)
             
             X = []
             Y = []
             
             for x in range(1, 20):
             &nbsp;&nbsp;&nbsp;&nbsp;cluster_count = x 
             &nbsp;&nbsp;&nbsp;&nbsp;
             &nbsp;&nbsp;&nbsp;&nbsp;start_time = time.time()
             &nbsp;&nbsp;&nbsp;&nbsp;clusters = MiniBatchKMeans(n_clusters = cluster_count)
             &nbsp;&nbsp;&nbsp;&nbsp;clusters.fit(numarray)
             &nbsp;&nbsp;&nbsp;&nbsp;end_time = time.time()
             &nbsp;&nbsp;&nbsp;&nbsp;total_time = end_time - start_time
             &nbsp;&nbsp;&nbsp;&nbsp;print("Total time: ", x, ":", total_time)
             &nbsp;&nbsp;&nbsp;&nbsp;X.append(x)
             &nbsp;&nbsp;&nbsp;&nbsp;Y.append(total_time)
             
             plot.bar(X, Y)
             plot.show()
            </code>
          </pre>
        <p>You may get a graph similar to the following.</p>
        <p>
          <img style="width:40%" src="../../2017/DataMining/images/minibatchkmeanstime.png"></img>
          </pre>
        <p>Now test the above code using <b>MiniBatchKMeans</b> algorithm with cluster sizes between 2 and 50. What are
          your observations? </p>
        <p>Finally we want to see whether we get the same cluster centers from both the algorithms. Run the following
          program to see the cluster centers produced by the two algorithms. We use two different colors (red and black)
          to distinguish the cluster centers from the two algorithms.</p>
        <p>
        <pre class="codeexample">
            <code>
              from PIL import Image
              import numpy
              import math
              import matplotlib.pyplot as plot
              from sklearn.cluster import KMeans
              from sklearn.cluster import MiniBatchKMeans
              
              imgfile = Image.open("flower.jpg")
              numarray = numpy.array(imgfile.getdata(), numpy.uint8)
              
              cluster_count = 10
              
              clusters = KMeans(n_clusters = cluster_count)
              clusters.fit(numarray)
              
              mclusters = MiniBatchKMeans(n_clusters = cluster_count)
              mclusters.fit(numarray)
              
              fig, axes = plot.subplots(nrows=3, ncols=1, figsize=(20,25))
              #Scatter plot for RG (RGB)
              axes[0].scatter(numarray[:,0],numarray[:,1])
              axes[0].scatter(clusters.cluster_centers_[:,0], clusters.cluster_centers_[:,1], c='red')
              axes[0].scatter(mclusters.cluster_centers_[:,0], mclusters.cluster_centers_[:,1], c='black')
              
              #Scatter plot of RB (RGB)
              axes[1].scatter(numarray[:,0],numarray[:,2])
              axes[1].scatter(clusters.cluster_centers_[:,0], clusters.cluster_centers_[:,2], c='red')
              axes[1].scatter(mclusters.cluster_centers_[:,0], mclusters.cluster_centers_[:,2], c='black')
              
              #Scatter plot of GB (RGB)
              axes[2].scatter(numarray[:,1],numarray[:,2])
              axes[2].scatter(clusters.cluster_centers_[:,1], clusters.cluster_centers_[:,2], c='red')
              axes[2].scatter(mclusters.cluster_centers_[:,1], mclusters.cluster_centers_[:,2], c='black')
            </code>
          </pre>
        <p>
          <img style="width:40%" src="../../2017/DataMining/images/scatterplots.png"></img>
          </pre>
        <p>We would like to see how the individual pixel values have been clustered. Run the following program a couple
          of times.</p>
        <pre class="codeexample">
            <code>
              from PIL import Image
              import numpy
              import math
              import time
              import matplotlib.pyplot as plot
              from sklearn.cluster import KMeans
              from sklearn.cluster import MiniBatchKMeans
              
              imgfile = Image.open("flower.jpg")
              numarray = numpy.array(imgfile.getdata(), numpy.uint8)
              
              cluster_count = 10
              
              mclusters = MiniBatchKMeans(n_clusters = cluster_count)
              mclusters.fit(numarray)
              
              npbins = numpy.arange(0, cluster_count + 1)
              histogram = numpy.histogram(mclusters.labels_, bins=npbins)
              labels = numpy.unique(mclusters.labels_)
              
              fig, axes = plot.subplots(nrows=3, ncols=2, figsize=(20,25))
              
              #Scatter plot for RG (RGB)
              colors = []
              for i in range(len(numarray)):
              &nbsp;&nbsp;&nbsp;&nbsp;j = mclusters.labels_[i]
              &nbsp;&nbsp;&nbsp;&nbsp;colors.append('#%02x%02x%02x' % (math.ceil(mclusters.cluster_centers_[j][0]),
              &nbsp;&nbsp;&nbsp;&nbsp;       math.ceil(mclusters.cluster_centers_[j][1]), 0))
              &nbsp;&nbsp;&nbsp;&nbsp;              
              axes[0,0].scatter(numarray[:,0],numarray[:,1], c=colors)
              axes[0,0].scatter(mclusters.cluster_centers_[:,0], mclusters.cluster_centers_[:,1], marker="+", c='red')
              
              #Scatter plot for RB (RGB)
              colors = []
              for i in range(len(numarray)):
              &nbsp;&nbsp;&nbsp;&nbsp;j = mclusters.labels_[i]
              &nbsp;&nbsp;&nbsp;&nbsp;colors.append('#%02x%02x%02x' % (math.ceil(mclusters.cluster_centers_[j][0]),
              &nbsp;&nbsp;&nbsp;&nbsp;       0, math.ceil(mclusters.cluster_centers_[j][2])))
              &nbsp;&nbsp;&nbsp;&nbsp;              
              axes[1,0].scatter(numarray[:,0],numarray[:,2], c=colors)
              axes[1,0].scatter(mclusters.cluster_centers_[:,0], mclusters.cluster_centers_[:,2], marker="+", c='white')
              
              #Scatter plot for GB (RGB)
              colors = []
              for i in range(len(numarray)):
              &nbsp;&nbsp;&nbsp;&nbsp;j = mclusters.labels_[i]
              &nbsp;&nbsp;&nbsp;&nbsp;colors.append('#%02x%02x%02x' % (0, math.ceil(mclusters.cluster_centers_[j][1]),
              &nbsp;&nbsp;&nbsp;&nbsp;        math.ceil(mclusters.cluster_centers_[j][2])))
              &nbsp;&nbsp;&nbsp;&nbsp;              
              axes[2,0].scatter(numarray[:,1],numarray[:,2], c=colors)
              axes[2,0].scatter(mclusters.cluster_centers_[:,1], mclusters.cluster_centers_[:,2], marker="+", c='yellow')
              
              clusters = KMeans(n_clusters = cluster_count)
              clusters.fit(numarray)
              
              npbins = numpy.arange(0, cluster_count + 1)
              histogram = numpy.histogram(clusters.labels_, bins=npbins)
              labels = numpy.unique(clusters.labels_)
              
              #Scatter plot for RG (RGB)
              colors = []
              for i in range(len(numarray)):
              &nbsp;&nbsp;&nbsp;&nbsp;j = clusters.labels_[i]
              &nbsp;&nbsp;&nbsp;&nbsp;colors.append('#%02x%02x%02x' % (math.ceil(clusters.cluster_centers_[j][0]),
              &nbsp;&nbsp;&nbsp;&nbsp;       math.ceil(clusters.cluster_centers_[j][1]), 0))
              &nbsp;&nbsp;&nbsp;&nbsp;              
              axes[0,1].scatter(numarray[:,0],numarray[:,1], c=colors)
              axes[0,1].scatter(clusters.cluster_centers_[:,0], clusters.cluster_centers_[:,1], marker="+", c='red')
              
              #Scatter plot for RB (RGB)
              colors = []
              for i in range(len(numarray)):
              &nbsp;&nbsp;&nbsp;&nbsp;j = clusters.labels_[i]
              &nbsp;&nbsp;&nbsp;&nbsp;colors.append('#%02x%02x%02x' % (math.ceil(clusters.cluster_centers_[j][0]),
              &nbsp;&nbsp;&nbsp;&nbsp;       0, math.ceil(clusters.cluster_centers_[j][2])))
              &nbsp;&nbsp;&nbsp;&nbsp;              
              axes[1,1].scatter(numarray[:,0],numarray[:,2], c=colors)
              axes[1,1].scatter(clusters.cluster_centers_[:,0], clusters.cluster_centers_[:,2], marker="+", c='white')
              
              #Scatter plot for GB (RGB)
              colors = []
              for i in range(len(numarray)):
              &nbsp;&nbsp;&nbsp;&nbsp;j = clusters.labels_[i]
              &nbsp;&nbsp;&nbsp;&nbsp;colors.append('#%02x%02x%02x' % (0, math.ceil(clusters.cluster_centers_[j][1]),
              &nbsp;&nbsp;&nbsp;&nbsp;        math.ceil(clusters.cluster_centers_[j][2])))
              &nbsp;&nbsp;&nbsp;&nbsp;              
              axes[2,1].scatter(numarray[:,1],numarray[:,2], c=colors)
              axes[2,1].scatter(clusters.cluster_centers_[:,1], clusters.cluster_centers_[:,2], marker="+", c='yellow')
              plot.show()
            </code>
          </pre>
        <p>
          <img style="width:40%" src="../../2017/DataMining/images/kmeansminibatchcomparison.png"></img>
        </p>
        <p>What are your conclusions? </p>
      </div>
      <h4>References</h4>
      <p><a href="./references.html">Link</a></p>
    </div>
</body>

</html>
